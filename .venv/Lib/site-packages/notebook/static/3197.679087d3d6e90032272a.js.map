{"version":3,"file":"3197.679087d3d6e90032272a.js?v=679087d3d6e90032272a","mappings":";;;;;;;;;;;;;;AAAO;AACP;AACA;AACO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;;AClCgC;AACzB;AACP,aAAa,EAAE,OAAO,KAAK,EAAE,OAAO;AACpC;AACA;AACO,uBAAuB,EAAE;AAChC,aAAa,EAAE,OAAO,KAAK,EAAE,OAAO;AACpC;AACA;AACA,aAAa,EAAE,OAAO,KAAK,EAAE,OAAO;AACpC;AACA;AACA;AACO;AACP,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN;AACA;;ACzC4G;AAClB;AAC1F;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,oCAAoC;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,aAAa;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uBAAuB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,aAAa;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,aAAa;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,aAAa;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uBAAuB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,EAAE,QAAQ,EAAE,QAAQ,EAAE,YAAY,EAAE;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,eAAe;AACrC;AACA;AACA,sBAAsB,eAAe;AACrC;AACA;AACA;AACA,sBAAsB,eAAe;AACrC;AACA;AACA,sBAAsB,eAAe;AACrC;AACA;AACA;AACA,sBAAsB,aAAa;AACnC;AACA;AACA,sBAAsB,aAAa;AACnC;AACA;AACA;AACA;AACA,YAAY,aAAa;AACzB,qBAAqB;AACrB;AACA;AACA,eAAe,uBAAuB;AACtC;AACA;AACA;AACA;AACA;AACA,6BAA6B,EAAE;AAC/B;AACA;AACA,6BAA6B,EAAE;AAC/B;AACA;AACA,6BAA6B,EAAE;AAC/B;AACA;AACA,6BAA6B,EAAE;AAC/B;AACA;AACA,6BAA6B,EAAE;AAC/B;AACA;AACA;AACA,YAAY,aAAa;AACzB,qBAAqB;AACrB;AACA;AACA,eAAe,uBAAuB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,iBAAiB,0BAA0B,EAAE;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,0BAA0B,EAAE;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAA0B,EAAE;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,WAAW;AAC3B;AACA;AACA;AACA;AACA,oBAAoB,WAAW;AAC/B;AACA;AACA;AACA,+BAA+B,gCAAgC;AAC/D;AACA;AACA;AACA,oBAAoB,WAAW;AAC/B,6BAA6B,EAAE;AAC/B,oBAAoB,WAAW;AAC/B;AACA;AACA;AACA,gBAAgB,WAAW;AAC3B;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAA0B,EAAE;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAA0B,EAAE;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,aAAa;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;;AC1tBO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrFkD;AACW;AAC7D;;;;;;;;;;;;;;;;ACI8B;;AAE9B;AAMiB;;AAEjB;AACA,yCAAyC,sFAA2B;AACpE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM,WAAW,+EAAoB;AACzE;AACA;AACA,0CAA0C,6DAAe;AACzD,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,mBAAmB,yDAAM;AACzB,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,kFAAuB;AAC3B;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;AC7C4B;;AAE9B;AAMiB;;AAEjB;AACA,sCAAsC,sFAA2B;AACjE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM,WAAW,+EAAoB;AACzE;AACA;AACA,uCAAuC,6DAAe;AACtD,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,gBAAgB,yDAAM;AACtB,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,+EAAoB;AACxB;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnDF;AACA;AACA;AACA;AACA;AAC8F;AAC1C;AACC;AACkB;AAClC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,6BAA6B,uCAA+B;AAC5D;AACA;AACA,mBAAmB,uCAAM,CAAC,uDAA6B,CAAC,2CAAe;AACvE,oBAAoB,uCAAM,CAAC,iDAAuB,GAAG,QAAQ;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,wEAAwE,cAAG,mBAAmB,+DAA+D;AAC7J;AACA;AACA;;;;;;ACtCA;AACA,4DAA4D,2BAA2B;;AAEvF;AACgD;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,yCAAqB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,wBAAwB,GAAG,iBAAiB;AACvE;AACA;AACA;AACA;AACA;AACA,2BAA2B,aAAa;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kBAAkB;AAChC,cAAc,kBAAkB;AAChC,cAAc,iCAAiC;AAC/C,cAAc,kCAAkC;AAChD,cAAc,qCAAqC;AACnD,cAAc,oCAAoC;AAClD,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,eAAe;AAC7B,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,cAAc;AAC5B,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,YAAY;AAC1B,cAAc,gBAAgB;AAC9B,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,YAAY;AAC1B,cAAc,iBAAiB;AAC/B,cAAc,gCAAgC;AAC9C,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kBAAkB;AAChC,cAAc,kBAAkB;AAChC,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,mCAAmC;AACjD,cAAc,eAAe;AAC7B,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,gBAAgB;AAC9B,cAAc,uCAAuC;AACrD,cAAc,eAAe;AAC7B,cAAc,sCAAsC;AACpD,cAAc,gBAAgB;AAC9B,cAAc,uCAAuC;AACrD,cAAc,eAAe;AAC7B,cAAc,sCAAsC;AACpD,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,cAAc;AAC5B,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kBAAkB;AAChC,cAAc,kBAAkB;AAChC,cAAc,sCAAsC;AACpD,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,cAAc;AAC5B,cAAc,YAAY;AAC1B,cAAc,YAAY;AAC1B,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kBAAkB;AAChC,cAAc,kBAAkB;AAChC,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,YAAY;AAC1B,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,gBAAgB;AAC9B,cAAc,YAAY;AAC1B,cAAc,gCAAgC;AAC9C,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,cAAc;AAC5B,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kBAAkB;AAChC,cAAc,kBAAkB;AAChC,cAAc,kCAAkC;AAChD,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,aAAa;AAC3B,cAAc,eAAe;AAC7B,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kBAAkB;AAChC,cAAc,kBAAkB;AAChC,cAAc,oCAAoC;AAClD,cAAc,uCAAuC;AACrD,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,eAAe;AAC7B,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kBAAkB;AAChC,cAAc,kBAAkB;AAChC,cAAc,gCAAgC;AAC9C,cAAc,kCAAkC;AAChD,cAAc,mCAAmC;AACjD,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,cAAc;AAC5B,cAAc,kBAAkB;AAChC,cAAc,YAAY;AAC1B,cAAc,YAAY;AAC1B,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kBAAkB;AAChC,cAAc,kBAAkB;AAChC,cAAc,aAAa;AAC3B,cAAc,sCAAsC;AACpD,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAC8C;AAC9C;AACA,yFAAyF,mBAAmB,GAAG,yEAAyE,8DAA8D,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,iCAAiC,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,6BAA6B,qCAAqC,EAAE,2BAA2B,mBAAmB,kCAAkC,oBAAoB,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,iGAAiG,EAAE,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,8FAA8F,EAAE,oFAAoF,oCAAoC,2BAA2B,mBAAmB,kCAAkC,EAAE,oBAAoB,EAAE,8FAA8F,EAAE,sDAAsD,6CAA6C,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,IAAI,iCAAiC,EAAE,wDAAwD,qGAAqG,iCAAiC,EAAE,oDAAoD,yGAAyG,iCAAiC,EAAE,uEAAuE,2CAA2C,kBAAkB,EAAE,iEAAiE,mHAAmH,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,8BAA8B,kBAAkB,EAAE,gFAAgF,2DAA2D,kBAAkB,+DAA+D,mDAAmD,oEAAoE,+CAA+C,EAAE,oEAAoE,+CAA+C,EAAE,iEAAiE,+CAA+C,kBAAkB,+BAA+B;AACnsH;AACA,+FAA+F,mBAAmB,GAAG,2EAA2E,gEAAgE,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,wCAAwC,EAAE,oCAAoC,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,oEAAoE,2BAA2B,mBAAmB,gBAAgB,mBAAmB,EAAE,EAAE,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,oEAAoE,2BAA2B,mBAAmB,gBAAgB,mBAAmB,EAAE,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,EAAE,iGAAiG,EAAE,wDAAwD,6BAA6B,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,gEAAgE,2BAA2B,mBAAmB,iBAAiB,oBAAoB,EAAE,8BAA8B,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,+GAA+G,EAAE,4CAA4C,qCAAqC,eAAe,+CAA+C,iCAAiC,EAAE,qDAAqD,uDAAuD,iCAAiC,EAAE,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,8FAA8F,EAAE,oFAAoF,oCAAoC,2BAA2B,mBAAmB,kCAAkC,EAAE,oBAAoB,EAAE,8FAA8F,EAAE,sDAAsD,6CAA6C,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,IAAI,iCAAiC,EAAE,wDAAwD,qGAAqG,iCAAiC,EAAE,oDAAoD,yGAAyG,iCAAiC,EAAE,uEAAuE,2CAA2C,kBAAkB,EAAE,iEAAiE,mHAAmH,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,8BAA8B,kBAAkB,EAAE,gFAAgF,2DAA2D,kBAAkB,+DAA+D,mDAAmD,oEAAoE,+CAA+C,EAAE,oEAAoE,+CAA+C,EAAE,iEAAiE,+CAA+C,kBAAkB,+BAA+B;AAC7oK;AACA,sFAAsF,mBAAmB,GAAG,wEAAwE,6DAA6D,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,gCAAgC,EAAE,sEAAsE,qCAAqC,mBAAmB,EAAE,oCAAoC,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,sEAAsE,2BAA2B,mBAAmB,gBAAgB,mBAAmB,EAAE,EAAE,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,sEAAsE,2BAA2B,mBAAmB,gBAAgB,mBAAmB,EAAE,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,EAAE,iGAAiG,EAAE,uDAAuD,6BAA6B,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,8BAA8B,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,+GAA+G,EAAE,gEAAgE,+CAA+C,iCAAiC,EAAE,0DAA0D,qCAAqC,eAAe,+DAA+D,iCAAiC,EAAE,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,8FAA8F,EAAE,oFAAoF,oCAAoC,2BAA2B,mBAAmB,kCAAkC,EAAE,oBAAoB,EAAE,8FAA8F,EAAE,sDAAsD,6CAA6C,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,IAAI,iCAAiC,EAAE,wDAAwD,qGAAqG,iCAAiC,EAAE,oDAAoD,yGAAyG,iCAAiC,EAAE,uEAAuE,2CAA2C,kBAAkB,EAAE,iEAAiE,mHAAmH,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,8BAA8B,kBAAkB,EAAE,gFAAgF,2DAA2D,kBAAkB,+DAA+D,mDAAmD,oEAAoE,+CAA+C,EAAE,oEAAoE,+CAA+C,EAAE,iEAAiE,+CAA+C,kBAAkB,+BAA+B;AACxkK;AACA,iHAAiH,mBAAmB,GAAG,iFAAiF,sEAAsE,6BAA6B,2BAA2B,oBAAoB,kCAAkC,EAAE,8CAA8C,EAAE,oCAAoC,6BAA6B,2BAA2B,oBAAoB,kCAAkC,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,EAAE,6BAA6B,2BAA2B,oBAAoB,kCAAkC,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,EAAE,2BAA2B,oBAAoB,kCAAkC,EAAE,EAAE,iGAAiG,EAAE,sEAAsE,oCAAoC,oEAAoE,2BAA2B,mBAAmB,iBAAiB,EAAE,sEAAsE,2BAA2B,mBAAmB,iBAAiB,EAAE,uEAAuE,2BAA2B,mBAAmB,iBAAiB,EAAE,mEAAmE,2BAA2B,mBAAmB,iBAAiB,EAAE,8FAA8F,EAAE,qEAAqE,6BAA6B,8BAA8B,EAAE,mEAAmE,2BAA2B,mBAAmB,iBAAiB,EAAE,8FAA8F,EAAE,sEAAsE,6BAA6B,mEAAmE,2BAA2B,mBAAmB,iBAAiB,EAAE,8BAA8B,EAAE,8FAA8F,EAAE,kEAAkE,6BAA6B,2BAA2B,mBAAmB,gBAAgB,EAAE,qEAAqE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,oCAAoC,+BAA+B,EAAE,6BAA6B,8BAA8B,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,8BAA8B,EAAE,EAAE,EAAE,qEAAqE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,8FAA8F,EAAE,kDAAkD,6BAA6B,kCAAkC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,iEAAiE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,kEAAkE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,6BAA6B,+BAA+B,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,+GAA+G,EAAE,oDAAoD,6BAA6B,oCAAoC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,oCAAoC,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,iEAAiE,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,kEAAkE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,6BAA6B,+BAA+B,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,+GAA+G,EAAE,qDAAqD,6BAA6B,qCAAqC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,6BAA6B,+BAA+B,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,+GAA+G,EAAE,iDAAiD,6BAA6B,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,sEAAsE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,sEAAsE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,+GAA+G,EAAE,8DAA8D,4CAA4C,4CAA4C,4CAA4C,iCAAiC,+BAA+B,EAAE,iCAAiC,+BAA+B,EAAE,EAAE,iCAAiC,+BAA+B,EAAE,EAAE,iCAAiC,+BAA+B,EAAE,iCAAiC,EAAE,sDAAsD,0CAA0C,iCAAiC,EAAE,6DAA6D,yDAAyD,iCAAiC,EAAE,wDAAwD,sDAAsD,iCAAiC,EAAE,yDAAyD,qDAAqD,iCAAiC,EAAE,0DAA0D,oCAAoC,UAAU,GAAG,iCAAiC,EAAE,yDAAyD,qCAAqC,iCAAiC,EAAE,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,2BAA2B,oBAAoB,gBAAgB,oBAAoB,8FAA8F,EAAE,oFAAoF,oCAAoC,2BAA2B,oBAAoB,kCAAkC,EAAE,oBAAoB,EAAE,8FAA8F,EAAE,sDAAsD,6CAA6C,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,IAAI,iCAAiC,EAAE,wDAAwD,qGAAqG,iCAAiC,EAAE,oDAAoD,yGAAyG,iCAAiC,EAAE,uEAAuE,2CAA2C,kBAAkB,EAAE,iEAAiE,mHAAmH,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,8BAA8B,kBAAkB,EAAE,gFAAgF,2DAA2D,kBAAkB,+DAA+D,mDAAmD,oEAAoE,+CAA+C,EAAE,oEAAoE,+CAA+C,EAAE,iEAAiE,+CAA+C,kBAAkB,+BAA+B;AAC5hW;AACA,qGAAqG,mBAAmB,GAAG,qEAAqE,mDAAmD,oEAAoE,+CAA+C,EAAE,oEAAoE,+CAA+C,EAAE,iEAAiE,+CAA+C,kBAAkB,YAAY,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,8FAA8F,EAAE,oFAAoF,oCAAoC,2BAA2B,mBAAmB,kCAAkC,EAAE,oBAAoB,EAAE,8FAA8F,EAAE,sDAAsD,6CAA6C,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,IAAI,iCAAiC,EAAE,wDAAwD,qGAAqG,iCAAiC,EAAE,oDAAoD,yGAAyG,iCAAiC,EAAE,uEAAuE,2CAA2C,kBAAkB,EAAE,iEAAiE,mHAAmH,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,8BAA8B,kBAAkB,EAAE,gFAAgF,2DAA2D,kBAAkB,EAAE,kEAAkE,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,oCAAoC,qCAAqC,EAAE,6BAA6B,qCAAqC,EAAE,8BAA8B,EAAE,EAAE,sCAAsC,EAAE,6BAA6B,qCAAqC,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,8BAA8B,EAAE,EAAE,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,oCAAoC,2BAA2B,mBAAmB,gBAAgB,EAAE,wEAAwE,2BAA2B,oBAAoB,iBAAiB,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,EAAE,EAAE,iGAAiG,EAAE,sDAAsD,oCAAoC,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,+GAA+G,EAAE,sDAAsD,gEAAgE,oCAAoC,+BAA+B,EAAE,+BAA+B,EAAE,+BAA+B,GAAG,+GAA+G,EAAE,mDAAmD,6BAA6B,mCAAmC,EAAE,oCAAoC,6BAA6B,gCAAgC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,mDAAmD,EAAE,oEAAoE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iCAAiC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,kCAAkC,EAAE,iEAAiE,oCAAoC,mCAAmC,EAAE,oCAAoC,EAAE,sCAAsC,GAAG,EAAE,oBAAoB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,+GAA+G,EAAE,mDAAmD,6BAA6B,mCAAmC,EAAE,iEAAiE,oCAAoC,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,GAAG,EAAE,6BAA6B,mCAAmC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,+GAA+G,EAAE,kDAAkD,6BAA6B,kCAAkC,EAAE,mEAAmE,oCAAoC,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,GAAG,EAAE,oCAAoC,6BAA6B,gCAAgC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iCAAiC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,kCAAkC,EAAE,iEAAiE,oCAAoC,mCAAmC,EAAE,oCAAoC,EAAE,sCAAsC,GAAG,EAAE,oBAAoB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,+GAA+G,EAAE,qDAAqD,6BAA6B,oCAAoC,qCAAqC,EAAE,mCAAmC,EAAE,EAAE,mEAAmE,oCAAoC,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,GAAG,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,+GAA+G,EAAE,0DAA0D,6BAA6B,wCAAwC,EAAE,oCAAoC,6BAA6B,gCAAgC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iCAAiC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,oCAAoC,EAAE,mEAAmE,2BAA2B,oBAAoB,iBAAiB,EAAE,oBAAoB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,+GAA+G,EAAE,4CAA4C,qCAAqC,eAAe,iDAAiD,iCAAiC,EAAE,2CAA2C,qCAAqC,eAAe,iEAAiE,iCAAiC,EAAE,qDAAqD,uDAAuD,iCAAiC,0FAA0F;AACr0U;AACA,4FAA4F,mBAAmB,GAAG,kEAAkE,mDAAmD,oEAAoE,+CAA+C,EAAE,oEAAoE,+CAA+C,EAAE,iEAAiE,+CAA+C,kBAAkB,EAAE,kDAAkD,gEAAgE,yCAAyC,gCAAgC,uBAAuB,EAAE,+CAA+C,8CAA8C,oBAAoB,kBAAkB,YAAY,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,8FAA8F,EAAE,oFAAoF,oCAAoC,2BAA2B,mBAAmB,kCAAkC,EAAE,oBAAoB,EAAE,8FAA8F,EAAE,sDAAsD,6CAA6C,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,IAAI,iCAAiC,EAAE,wDAAwD,qGAAqG,iCAAiC,EAAE,oDAAoD,yGAAyG,iCAAiC,EAAE,uEAAuE,2CAA2C,kBAAkB,EAAE,iEAAiE,mHAAmH,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,8BAA8B,kBAAkB,EAAE,gFAAgF,2DAA2D,kBAAkB,EAAE,+DAA+D,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,oCAAoC,uCAAuC,EAAE,wCAAwC,EAAE,6BAA6B,uCAAuC,EAAE,8BAA8B,EAAE,EAAE,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,oCAAoC,2BAA2B,mBAAmB,gBAAgB,EAAE,6BAA6B,iCAAiC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,EAAE,6BAA6B,kCAAkC,EAAE,oEAAoE,2BAA2B,oBAAoB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,oEAAoE,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,EAAE,6BAA6B,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,qEAAqE,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,EAAE,iGAAiG,EAAE,kEAAkE,6BAA6B,8BAA8B,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,8BAA8B,EAAE,8FAA8F,EAAE,iDAAiD,6BAA6B,iEAAiE,2BAA2B,oBAAoB,iBAAiB,EAAE,2BAA2B,oBAAoB,kCAAkC,EAAE,+GAA+G,EAAE,kDAAkD,6BAA6B,iEAAiE,2BAA2B,oBAAoB,iBAAiB,EAAE,2BAA2B,oBAAoB,kCAAkC,EAAE,4BAA4B,EAAE,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,4BAA4B,EAAE,EAAE,+GAA+G,EAAE,oEAAoE,oCAAoC,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,qEAAqE,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,EAAE,6BAA6B,2BAA2B,mBAAmB,kCAAkC,EAAE,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,qEAAqE,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,EAAE,8FAA8F,EAAE,0DAA0D,wBAAwB,eAAe,6BAA6B,iEAAiE,iCAAiC,oBAAoB,aAAa,2BAA2B,oBAAoB,gBAAgB,2BAA2B,EAAE,gDAAgD,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,+GAA+G,EAAE,wDAAwD,wBAAwB,eAAe,kEAAkE,2BAA2B,oBAAoB,iBAAiB,+GAA+G,EAAE,mDAAmD,oCAAoC,6BAA6B,iEAAiE,wCAAwC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iEAAiE,mCAAmC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iEAAiE,iCAAiC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iEAAiE,iCAAiC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iEAAiE,uCAAuC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,+GAA+G,EAAE,+CAA+C,qCAAqC,eAAe,+DAA+D,iCAAiC,EAAE,gDAAgD,sCAAsC,eAAe,4CAA4C,iCAAiC,kCAAkC,EAAE,iCAAiC,mCAAmC,EAAE,iCAAiC,EAAE,kDAAkD,qCAAqC,eAAe,4CAA4C,iCAAiC,oCAAoC,EAAE,iCAAiC,qCAAqC,EAAE,iCAAiC,EAAE,2CAA2C,qCAAqC,eAAe,6DAA6D,iCAAiC,EAAE,qDAAqD,uDAAuD,iCAAiC,0FAA0F;;AAEzpX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACgD;;AAEhD;AACA,gEAAgE,IAAI,IAAI;AACxE;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,4CAAqB;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,GAAG;AAC/C;AACA;AACA,iFAAiF,GAAG,0BAA0B,GAAG;AACjH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAC8C;AAC9C,gDAAgD,wCAAmB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAsCE;;;;;;;;;;;;;;;;;ACpjB4B;;AAE9B;AAMiB;;AAEjB;AACA,6CAA6C,sFAA2B;AACxE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA,+CAA+C,wFAA6B;AAC5E;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA,MAAM;AACN;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM;AAC1C;AACA;AACA,8CAA8C,6DAAe;AAC7D,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,uBAAuB,yDAAM;AAC7B,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,sFAA2B;AAC/B;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;AC9D4B;;AAE9B;AAMiB;;AAEjB;AACA,qCAAqC,sFAA2B;AAChE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM,WAAW,+EAAoB;AACzE;AACA;AACA,sCAAsC,6DAAe;AACrD,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,eAAe,yDAAM;AACrB,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,8EAAmB;AACvB;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;AC7C4B;;AAE9B;AAMiB;;AAEjB;AACA,oCAAoC,sFAA2B;AAC/D;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA,sCAAsC,wFAA6B;AACnE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM;AAC1C;AACA;AACA,qCAAqC,6DAAe;AACpD,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,cAAc,yDAAM;AACpB,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,6EAAkB;AACtB;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;AC1D4B;;AAE9B;AAMiB;;AAEjB;AACA,uCAAuC,sFAA2B;AAClE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM,WAAW,+EAAoB;AACzE;AACA;AACA,wCAAwC,6DAAe;AACvD,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,iBAAiB,yDAAM;AACvB,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,gFAAqB;AACzB;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;;;;AChDuD;AAIA;AAIA;AAIA;AAIA;AAIA;AAqCA;;AAEzD;AACA;AACA;AACA,wBAAwB,gGAAM;AAC9B,YAAY,0CAA0C,QAAQ,qGAAwD;AACtH;AACA;AACA,GAAG;AACH,0BAA0B,gGAAM;AAChC,YAAY,8CAA8C,QAAQ,oGAA0D;AAC5H;AACA;AACA,GAAG;AACH,uBAAuB,gGAAM;AAC7B,YAAY,wCAAwC,QAAQ,qGAAuD;AACnH;AACA;AACA,GAAG;AACH,gCAAgC,gGAAM;AACtC,YAAY,0DAA0D,QAAQ,qGAAgE;AAC9I;AACA;AACA,GAAG;AACH,4BAA4B,gGAAM;AAClC,YAAY,kDAAkD,QAAQ,qGAA4D;AAClI;AACA;AACA,GAAG;AACH,yBAAyB,gGAAM;AAC/B,YAAY,4CAA4C,QAAQ,qGAAyD;AACzH;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,6CAA6C,YAAY;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gGAAM;AACN;AACA;AACA;AACA;AACA,6BAA6B,aAAa,EAAE,aAAa;AACzD;AACA;AACA;AACA,IAAI,gGAAM;AACV;AACA;AAkDE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5KF;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,IAAC;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvBA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,aAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,iDAAe,SAAS,EAAC;;;;;AC9Be;AACD;;AAEvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,QAAQ;AACnB,YAAY,QAAQ;AACpB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,4BAAS;AAChD,SAAS,UAAS;AAClB;;AAEA,qDAAe,IAAI,EAAC;;;;;;;;;;;;;;;;;ACrCwB;AACF;AACQ;AACP;AACC;AACf;;AAE7B;AACA;;AAEA;AACA,IAAI,qBAAc;;AAElB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,WAAW;AACtB,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,QAAQ;AACtB,WAAW;AACX;AACA,IAAI,aAAM,GAAG,kCAAc;AAC3B,MAAM,+BAAW,YAAY,8BAAW;AACxC,IAAI,8BAAU,SAAS,uBAAI;AAC3B;AACA;AACA;AACA,QAAQ,qBAAc;AACtB,MAAM,+BAAW;AACjB;AACA;AACA,CAAC;;AAED,uDAAe,aAAM,EAAC;;;;;;;;;;;ACzDgB;AACQ;AACJ;AACI;;AAE9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,UAAU;AACrB,aAAa,QAAQ;AACrB;AACA;AACA,kBAAkB;AAClB;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA,cAAc,4BAAQ,CAAC,gCAAY;AACnC;AACA,GAAG;AACH,cAAc,gCAAY;AAC1B,SAAS,8BAAU;AACnB;AACA,GAAG;AACH;;AAEA,uDAAe,MAAM,EAAC;;;;;;;ACpCoB;AACG;;AAE7C;AACA;;AAEA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,SAAS;AACtB;AACA;AACA,SAAS,+BAAY,WAAW,8BAAU;AAC1C;;AAEA,oDAAe,YAAY,EAAC;;;;;;;ACjBkB;AACN;AACF;;AAEtC;AACA,mBAAmB,wBAAQ,IAAI,wBAAQ;;AAEvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,6BAAS,iBAAiB,aAAY;;AAEpE,yDAAe,QAAQ,EAAC;;;AC1BqD;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,2BAAQ;AACnB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0BAAO;AACf;AACA,SAAS;AACT;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,sBAAG;AACd;AACO;AACP;AACA,eAAe,sBAAG;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,2BAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,8BAA8B;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,8BAA8B;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,2BAAQ;AACpB;AACA;AACA;AACA;AACA,yCAAyC,kBAAQ;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChO0C;AAC8I;AACxL;AACA;AACA;AACO;AACP;AACA,QAAQ,0BAAO;AACf,6BAA6B,cAAI;AACjC;AACA,mCAAmC,WAAW;AAC9C;AACA;AACA,wCAAwC,QAAQ;AAChD;AACA;AACA,wCAAwC,WAAW;AACnD;AACA;AACA,wCAAwC,MAAM;AAC9C;AACA;AACA,wCAAwC,mBAAmB;AAC3D;AACA;AACA,wCAAwC,gCAAgC;AACxE;AACA;AACA,wCAAwC,uBAAuB;AAC/D;AACA;AACA,wCAAwC,UAAU;AAClD;AACA;AACA,wCAAwC,WAAW;AACnD;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM,GAAG,uCAAuC;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM,GAAG,iCAAiC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0BAAO;AACf;AACA;AACA;AACA,oCAAoC,WAAW,GAAG,mBAAmB;AACrE;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,YAAY,MAAM;AAClB;AACA,oBAAoB,QAAQ,GAAG,oCAAoC;AACnE;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;;;ACtGsC;;AAEtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,4BAAQ;AAC3C;;AAEA,qDAAe,IAAI,EAAC;;;;;;;;;ACxBkB;;AAEtC;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,SAAS;AACtB;AACA;AACA;AACA;;AAEA,EAAE,4BAAQ;AACV;AACA;AACA,GAAG;AACH;AACA;;AAEA,gDAAe,QAAQ,EAAC;;;;;;;ACrBgB;AACM;AACR;AACH;AACe;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,YAAY,QAAQ;AACpB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,kCAAkC;AACzC,OAAO;AACP;AACA;AACA;AACA,mBAAmB,mCAAmC;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0BAAO,eAAe,yBAAS,GAAG,SAAQ;AACvD,eAAe,kCAAc;AAC7B;AACA;AACA,0BAA0B,gCAAY;AACtC;;AAEA,qDAAe,IAAI,EAAC;;;;;AClDwB;AACD;AACN;AACE;AACN;;AAEjC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,qBAAqB;AAChC,WAAW,GAAG;AACd,WAAW,QAAQ;AACnB,YAAY,QAAQ;AACpB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,gBAAgB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,8BAAW,4BAA4B,yBAAM;AAC5D,sCAAsC,4BAAS;;AAE/C;AACA;AACA;AACA;AACA,SAAS,2BAAQ;AACjB;AACA,mBAAmB,+BAAW;AAC9B;;AAEA,yDAAe,QAAQ,EAAC;;;ACpDxB;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,kDAAe,UAAU,EAAC;;;ACtBY;;AAEtC;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA,EAAE,4BAAQ;AACV;AACA;AACA,GAAG;AACH;AACA;;AAEA,iDAAe,SAAS,EAAC;;;ACpBiB;AACF;AACM;AACX;AACe;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,YAAY,QAAQ;AACpB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,8CAA8C;AACrD,OAAO;AACP;AACA;AACA;AACA,oBAAoB,mCAAmC;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0BAAO,eAAe,WAAU,GAAG,UAAS;AACzD,eAAe,kCAAc;AAC7B;AACA;AACA,0BAA0B,gCAAY;AACtC;;AAEA,sDAAe,KAAK,EAAC;;;ACvD6B;AAC0J;AACrM;AACP,4BAA4B,WAAW;AACvC,wBAAwB,MAAM;AAC9B,wBAAwB,UAAU;AAClC,wBAAwB,mBAAmB;AAC3C,wBAAwB,gCAAgC;AACxD,wBAAwB,uBAAuB;AAC/C,wBAAwB,QAAQ;AAChC,wBAAwB,IAAI;AAC5B;AACO;AACP,+CAA+C,MAAM;AACrD,wBAAwB,UAAU;AAClC,wBAAwB,uBAAuB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,WAAW;AACnC;AACA,eAAe,cAAI;AACnB;AACA,SAAS;AACT;AACA,6BAA6B,WAAW,IAAI,kBAAQ;AACpD;AACA;AACA;AACA,6BAA6B,kBAAkB;AAC/C,4BAA4B,WAAW;AACvC;AACA;AACA,eAAe,eAAK;AACpB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACO;AACP,2BAA2B,WAAW;AACtC;AACO;AACP;AACA,wBAAwB,WAAW;AACnC;AACA;AACA,6BAA6B,MAAM;AACnC;AACA;AACA,6BAA6B,WAAW;AACxC;AACA;AACA,6BAA6B,mBAAmB;AAChD;AACA;AACA,6BAA6B,gCAAgC;AAC7D;AACA;AACA,6BAA6B,uBAAuB;AACpD;AACA;AACA,6BAA6B,UAAU;AACvC;AACA;AACA,6BAA6B,QAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9E+C;AAC4D;AACpG;AACP;AACA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,QAAQ;AACrC;AACA;AACA,aAAa,cAAc;AAC3B;AACA;AACA,aAAa,eAAe;AAC5B;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,cAAc;AAChD;AACA;AACA;AACA;AACA,WAAW,cAAI;AACf;AACO;AACP,kCAAkC,sBAAG;AACrC;AACA,KAAK;AACL,WAAW,cAAI,CAAC,0BAAO;AACvB;AACO;AACP;AACA;AACA;;ACvDA;AACO,MAAM,YAAE;AACf;;ACFuC;AACJ;AACS;AACP;AACU;AAC/C;AACA;AACO,kCAAkC,UAAU;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,WAAW,GAAG,sBAAsB;AACjE,qCAAqC,KAAK;AAC1C;AACA;AACA;AACO;AACP;AACA,IAAI,0BAAO;AACX;AACA,QAAQ,gBAAM;AACd,KAAK;AACL;AACA;AACO;AACP,4CAA4C,YAAE;AAC9C;AACO;AACP;AACA;AACA;AACA;;;;;;;;;;;;AC5CA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,UAAU;AACrB,aAAa,UAAU;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,uDAAe,MAAM,EAAC;;;ACvCsB;AACF;AACI;AACX;AACF;;AAEjC;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA,OAAO,8CAA8C;AACrD,OAAO;AACP;AACA;AACA,iCAAiC,mBAAmB;AACpD;AACA;AACA;AACA,qBAAqB,2BAA2B;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0BAAO,eAAe,2BAAW,GAAG,0BAAU;AAC3D,0BAA0B,gBAAM,CAAC,gCAAY;AAC7C;;AAEA,uDAAe,MAAM,EAAC;;;;;AC7CsB;AACL;;AAEvC;AACA,IAAI,iBAAS;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,GAAG;AACd,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,4BAAS;AAC/C;AACA,YAAY,iBAAS;AACrB;AACA,SAAS,+BAAW;AACpB;;AAEA,wDAAe,OAAO,EAAC;;;;;;;;;;;;;;;ACzCe;AACU;AACQ;AAClB;AACE;AACF;;AAEtC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA,iBAAiB,6BAAa;AAC9B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,aAAa,4BAAQ,SAAS,6BAAS;AACvC;AACA;AACA,eAAe,iCAAiB;AAChC;AACA;AACA;AACA,eAAe,wBAAQ;AACvB;AACA,iBAAiB,wBAAQ;AACzB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sDAAe,cAAc,EAAC;;;;;;;;;AClEoB;AACN;AACN;AACiB;;AAEvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,4BAAQ;AACzB,SAAS,oCAAiB;AAC1B,MAAM,eAAc,QAAQ,+BAAW,YAAY,gCAAiB;AACpE;AACA,CAAC;;AAED,2DAAe,UAAU,EAAC;;;AChC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wDAAe,OAAO,EAAC;;;AC9BvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,GAAG;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qDAAe,IAAI,EAAC;;;;;ACtBb;AACP;AACA;AACA,gCAAgC,IAAI;AACpC;AACA;AACO;AACP;AACA;AACA;AACA,iCAAiC,IAAI;AACrC;AACA;AACA;;ACb0D;AAC1D;AACA,yBAAyB,uBAAY;AAC9B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;ACjB+D;AACa;AACb;AACZ;AACuB;AAC1E;AACO;AACA;AACP;AACA,oBAAoB,YAAY;AAChC,kEAAkE;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,aAAa,IAAI,4BAA4B;AAC7D,+CAA+C,mBAAmB;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,WAAW,IAAI,4BAA4B;AACvD,uCAAuC,mBAAmB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,4BAA4B,sBAAsB;AAClD;AACA;AACA;AACA;AACA;AACA,4BAA4B,kBAAkB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,0BAAO;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,uBAAuB;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,qCAAqC,kBAAkB,EAAE;AAC9H;AACA;AACA;AACA,oDAAoD,kBAAkB;AACtE,0EAA0E,kBAAkB;AAC5F;AACA,8CAA8C,kBAAkB;AAChE;AACA,0DAA0D,wBAAwB;AAClF,0DAA0D,wBAAwB;AAClF,yEAAyE,yBAAyB;AAClG;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,yBAAM;AACjB;AACA;AACA,6BAA6B,wBAAwB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,wBAAwB;AACzD;AACA;AACA;AACA;AACA;AACA,qCAAqC,wBAAwB;AAC7D;AACA;AACA;AACA;AACA;AACA,WAAW,uBAAI;AACf;AACA,mBAAmB,kBAAQ;AAC3B;AACA;AACA;AACA;AACA,oBAAoB,uBAAI;AACxB;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,0BAAO;AAClB,UAAU,eAAK;AACf;AACA;AACA,6BAA6B,4BAAiB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,kBAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,oBAAoB,YAAY;AAChC;AACA;AACA;AACA;AACA;AACA,gBAAgB,uBAAI;AACpB,mBAAmB,kBAAQ;AAC3B,SAAS;AACT;AACA;AACA;;AC/O8D;AACO;AACuJ;AAC5K;AAC6D;AAC1D;AACnD;AACO;AACA;AACA;AACA;AACP;AACA;AACO;AACP;AACA;AACO;AACP,cAAc,2BAAQ;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,4BAA4B,gBAAM;AAClC,yCAAyC,KAAK;AAC9C,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA,iCAAiC,sBAAG;AACpC;AACA;AACA,gBAAgB,kBAAQ;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,kBAAQ;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,6BAAU;AAC/B;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qFAAqF;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,sBAAG;AAC9B,4BAA4B,sBAAG;AAC/B;AACA;AACA,8BAA8B,KAAK;AACnC;AACA;AACA,qBAAqB,2BAAQ;AAC7B;AACA;AACA,qBAAqB,8BAAW;AAChC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,sCAAsC,sBAAG;AACzC;AACA;AACA,wCAAwC,0BAAO;AAC/C,sBAAsB,sBAAG,0BAA0B,iBAAO;AAC1D,uBAAuB,iBAAO;AAC9B;AACA;AACA,SAAS;AACT,+BAA+B,sBAAG;AAClC,8BAA8B,sBAAG,+BAA+B,sBAAG;AACnE,KAAK;AACL;AACA;AACA;AACA,wCAAwC,sBAAG;AAC3C;AACA,4CAA4C,sBAAG;AAC/C,oBAAoB,sBAAG;AACvB;AACA;AACA;AACA;AACA,wBAAwB,gBAAgB;AACxC;AACA,aAAa;AACb;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,+BAA+B,sBAAG;AAClC,4BAA4B,sBAAG;AAC/B,sBAAsB,yBAAM;AAC5B;AACA,gBAAgB,2BAAQ,+BAA+B,KAAK;AAC5D;AACA;AACA;AACA,SAAS,IAAI;AACb,6BAA6B,sBAAG;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA,2CAA2C,yBAAM;AACjD;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAAO;AAChC;AACA,oBAAoB,0BAAO;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,yBAAyB,kBAAQ;AACjC;AACA;AACA;AACA,4BAA4B,WAAW,IAAI,2BAA2B,CAAC;AACvE,yDAAyD,gCAAgC;AACzF;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,6BAA6B;AAC5E;AACA;AACA;AACA,4BAA4B,0BAAO;AACnC;AACA;AACA;AACA;AACA;AACA,wBAAwB,0BAAO;AAC/B;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA,wBAAwB,WAAW,IAAI,2BAA2B,CAAC;AACnE,6CAA6C,iBAAiB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,yBAAM,8BAA8B,kBAAQ;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,yCAAyC,yBAAM;AAC/C,gBAAgB,sBAAG;AACnB,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL,kBAAkB,oBAAU;AAC5B,aAAa;AACb;AACO;AACP,yCAAyC,yBAAM;AAC/C;AACA,iBAAiB,kBAAQ;AACzB,aAAa,6BAAU;AACvB,aAAa,sBAAG;AAChB,aAAa,2BAAQ;AACrB,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA,yCAAyC,0BAA0B,gCAAgC,gBAAgB;AACnH,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL,kBAAkB,oBAAU;AAC5B,aAAa;AACb;AACA;AACO;AACP,kCAAkC,4BAAiB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,yBAAM;AAC/B;AACA;AACA,8BAA8B,YAAY;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,+BAA+B,yBAAM;AACrC;AACA;AACA,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACA;AACO;AACP,oCAAoC,4BAAiB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,yBAAM;AAC/B;AACA;AACA,8BAA8B,YAAY;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,yBAAyB,yBAAM;AAC/B;AACA;AACA,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACA;AACO;AACP;AACA,4BAA4B,sBAAG;AAC/B,eAAe,yBAAM;AACrB;AACA,iBAAiB,kBAAQ;AACzB,sCAAsC,KAAK;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL,wBAAwB,iBAAO;AAC/B,8BAA8B,yBAAM;AACpC;AACA,KAAK;AACL,mBAAmB,sBAAG;AACtB,+BAA+B,sBAAG;AAClC;AACA,SAAS;AACT,8BAA8B,cAAK;AACnC;AACA,kDAAkD,cAAc;AAChE,sEAAsE,2BAA2B;AACjG,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,yBAAyB,yBAAM;AAC/B,aAAa,sBAAG;AAChB;AACA;AACA;AACA,yBAAyB,KAAK,sBAAsB,KAAK,QAAQ,2BAAQ;AACzE,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,yBAAyB,yBAAM;AAC/B,kDAAkD,kBAAQ;AAC1D,KAAK;AACL,mBAAmB,sBAAG;AACtB,qCAAqC,aAAa,6DAA6D,kBAAkB;AACjI;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA,wBAAwB,yBAAM;AAC9B;AACA,wBAAwB,KAAK;AAC7B;AACA;AACA;AACA;AACA,YAAY,2BAAQ;AACpB,0BAA0B,uCAAuC;AACjE;AACA,iBAAiB,kBAAQ;AACzB,0BAA0B,8CAA8C;AACxE;AACA;AACA,KAAK;AACL,IAAI,0BAAO;AACX,QAAQ,0BAAO,iBAAiB,qBAAqB;AACrD;AACA,wCAAwC,eAAe;AACvD,iEAAiE,aAAa;AAC9E;AACA;AACA;AACA;AACA,0BAA0B,wBAAwB;AAClD;AACA,iBAAiB;AACjB;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA,QAAQ,kBAAQ;AAChB;AACA;AACA;AACA,aAAa,6BAAU;AACvB;AACA,qCAAqC;AACrC;AACA,aAAa,sBAAG;AAChB;AACA,0CAA0C;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA,YAAY,uBAAI;AAChB;AACO;AACP;AACA;AACA;AACA,6BAA6B,eAAe;AAC5C;AACO;AACP;AACA;AACA;AACA,yBAAyB,eAAe;AACxC;AACO;AACP;AACA;AACA,SAAS,sBAAG;AACZ;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C,SAAS;AACT;AACA,SAAS,sBAAG;AACZ;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C,SAAS;AACT;AACA,QAAQ,sBAAG;AACX,QAAQ,sBAAG;AACX,SAAS,sBAAG;AACZ;AACA,uEAAuE,aAAa,KAAK,4BAA4B;AACrH;AACA,kBAAkB,wBAAwB;AAC1C,SAAS;AACT;AACA,QAAQ,sBAAG;AACX,QAAQ,0BAAO;AACf,YAAY,0BAAO;AACnB,oBAAoB,8BAAW;AAC/B;AACA;AACA,gCAAgC,aAAa,eAAe,QAAQ;AACpE,8BAA8B,wBAAwB;AACtD,qBAAqB;AACrB;AACA,yBAAyB,sBAAG;AAC5B,sCAAsC,0BAAO;AAC7C;AACA;AACA,oBAAoB,0BAAO;AAC3B,6BAA6B,8BAAW;AACxC,6BAA6B,kBAAQ;AACrC;AACA,uGAAuG,mBAAmB,cAAc,iBAAiB,qBAAqB,aAAa;AAC3L,sCAAsC,wBAAwB;AAC9D,6BAA6B;AAC7B;AACA,qBAAqB;AACrB;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACO;AACP;AACA;AACA,0BAA0B,iBAAO,CAAC,0BAAO,CAAC,yBAAM;AAChD,+BAA+B,gBAAM,oDAAoD,KAAK;AAC9F;AACA;AACA,QAAQ,0BAAO;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sBAAG;AACvB;AACA;AACA;AACA;AACA;AACA,wBAAwB,gBAAgB;AACxC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C,SAAS;AACT;AACA;AACA;AACO;AACP;AACA,sBAAsB,uBAAI;AAC1B,IAAI,0BAAO;AACX;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACO;AACP;AACA;AACA,QAAQ,kBAAQ;AAChB;AACA;AACA,aAAa,6BAAU;AACvB;AACA;AACA;AACA,aAAa,sBAAG;AAChB;AACA;AACA;AACA,aAAa,2BAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,2BAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,qCAAqC,SAAS;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,kBAAQ;AACpB;AACA;AACA,gBAAgB,gBAAgB;AAChC;AACA;AACA;AACA;AACA,2BAA2B,wBAAwB;AACnD;AACA;AACA;AACA;AACA;AACA,iBAAiB,2BAAQ;AACzB;AACA;AACA;AACA;AACA;AACA,qBAAqB,OAAO,wBAAwB;AACpD;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,0BAA0B,wBAAwB;AAClD;AACA,wCAAwC,aAAa;AACrD,8BAA8B,eAAe;AAC7C;AACA;AACA,+BAA+B,wBAAwB;AACvD;AACA,wCAAwC,aAAa;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,sBAAG;AACzB,YAAY,2BAAQ;AACpB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0BAAO;AACf;AACA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA;;;;;;;;AC12BO;AACP;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;;ACPgH;AACzG;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,0BAAO;AACX;AACA,KAAK;AACL;AACO;AACP,iBAAiB,kCAAK;AACtB;AACA;AACA;AACA,qBAAqB,iBAAO,CAAC,0BAAO,CAAC,sBAAG;AACxC,8BAA8B,oBAAU;AACxC;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,IAAI,0BAAO;AACX;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0BAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACO;AACP,IAAI,0BAAO;AACX;AACA;AACA,QAAQ,0BAAO;AACf;AACA,SAAS;AACT,KAAK;AACL;AACO;AACP,IAAI,0BAAO;AACX;AACA,KAAK;AACL;AACO;AACP,IAAI,0BAAO;AACX;AACA,KAAK;AACL,IAAI,0BAAO;AACX;AACA;AACA,aAAa,kBAAQ;AACrB;AACA;AACA,KAAK;AACL;AACO;AACP,WAAW,sBAAG;AACd;AACO;AACP,WAAW,sBAAG;AACd;AACO;AACP,WAAW,sBAAG;AACd;AACO;AACP,WAAW,sBAAG;AACd;AACO;AACP,WAAW,sBAAG;AACd;AACA;;ACjHO;AACP;AACA,sEAAsE,YAAY;AAClF,KAAK;AACL;AACA,2CAA2C,6BAA6B,gBAAgB,YAAY,iBAAiB,QAAQ;AAC7H,KAAK;AACL;AACA;;ACR8N;AAC1F;AACzD;AAC3B;AACqB;AACR;AACtD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4DAA4D;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,yBAAyB;AACnD;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,OAAO,OAAO,UAAU;AAC3D;AACA,wBAAwB,cAAc,EAAE,KAAK;AAC7C;AACA;AACA;AACA,mCAAmC,OAAO,OAAO,UAAU,UAAU,KAAK;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,gBAAM,GAAG;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,6BAA6B;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,0BAAO;AAC3B;AACA,iCAAiC,aAAa,kCAAK,mBAAmB;AACtE,qCAAqC,YAAY;AACjD;AACA;AACA;AACA;AACA;AACA,uCAAuC,kCAAK;AAC5C;AACA,aAAa;AACb;AACA;AACA,mFAAmF,oBAAoB;AACvG,iBAAiB;AACjB;AACA,qFAAqF,2BAA2B;AAChH,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB,uDAAuD,gBAAM,iCAAiC,8BAAW;AACzG,aAAa;AACb,iCAAiC,uBAAI;AACrC,YAAY,0BAAO;AACnB,0CAA0C,YAAY;AACtD;AACA;AACA;AACA,2FAA2F,gBAAgB;AAC3G,yBAAyB;AACzB;AACA;AACA;AACA;AACA,wBAAwB,0BAAO;AAC/B,wBAAwB,iBAAiB;AACzC;AACA;AACA,gDAAgD,iBAAiB;AACjE;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,yBAAyB;AACzB;AACA;AACA;AACA;AACA,2CAA2C,gBAAM,GAAG;AACpD;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA,iBAAiB,0BAAO;AACxB;AACA,uCAAuC,sBAAG;AAC1C;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB,gBAAgB,aAAa;AAC7B,aAAa;AACb;AACA;AACA;AACA;AACA,oBAAoB,cAAc;AAClC,qCAAqC,uBAAQ;AAC7C;AACA;AACA;AACA,2CAA2C,mBAAI;AAC/C;AACA;AACA;AACA,uCAAuC,mBAAI;AAC3C;AACA;AACA,4CAA4C,uBAAQ;AACpD;AACA;AACA,4DAA4D,mBAAI;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,6BAA6B;AAC3G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,yCAAyC,yBAAM;AAC/C;AACA;AACA;AACA;AACA,iBAAiB;AACjB,mDAAmD,0BAAO;AAC1D,kDAAkD,6BAA6B;AAC/E;AACA;AACA;AACA,aAAa;AACb;AACA,gBAAgB,sBAAsB;AACtC,aAAa;AACb;AACA,gBAAgB,gBAAgB;AAChC,aAAa;AACb,SAAS;AACT;AACA;AACA,aAAa,0BAAO;AACpB,mCAAmC,sBAAG;AACtC;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,gBAAgB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,wBAAwB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,gCAAgC,uBAAI;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,0BAA0B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,qBAAqB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,4BAA4B;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACroBuD;AACb;AAC8B;AACjE,SAAS,wBAAU;AAC1B,QAAQ,2BAAa;AACrB;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO,SAAS,2BAAa;AAC7B,WAAW,2BAAQ;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,8BAAW;AACpB;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA;AACA,IAAI,iBAAiB;AACrB,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA;AACA;AACO,0BAA0B,sBAAsB,KAAK,KAAK;AACjE,iBAAiB;AACV;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,sBAAsB;AACjC;AACA;;ACtFqE;AACtB;AACuC;AAC/E;AACP,gCAAgC,sCAAsC;AACtE,yBAAyB,2BAAa;AACtC;AACA,qBAAqB,wBAAU,YAAY;AAC3C,mCAAmC,eAAe;AAClD,iCAAiC,aAAa,iBAAiB,aAAa;AAC5E;AACA,KAAK;AACL,oCAAoC,0BAA0B;AAC9D;AACA,KAAK;AACL,8BAA8B,yEAAyE;AACvG;AACA;AACA,2BAA2B,cAAK;AAChC;AACA;AACA;AACA;AACA;AACA,sCAAsC,yBAAM;AAC5C,4CAA4C,sBAAG,sCAAsC,sBAAG,8BAA8B,wBAAU,4BAA4B;AAC5J,2CAA2C,sBAAG,iDAAiD,QAAQ,IAAI,QAAQ;AACnH,qFAAqF,kCAAkC;AACvH;AACA;AACA,KAAK;AACL,4BAA4B,kEAAkE;AAC9F;AACA;AACA,2BAA2B,cAAK;AAChC;AACA;AACA;AACA;AACA;AACA,4CAA4C,sBAAG,2CAA2C,sBAAG,8BAA8B,wBAAU,2BAA2B;AAChK;AACA,oBAAoB,mCAAmC;AACvD;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACO;AACP;AACA;AACA,gCAAgC,QAAQ;AACxC;AACA;AACA,qCAAqC,WAAW;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,cAAK;AACnC;AACA,wBAAwB,oBAAoB;AAC5C;AACA;AACA,uBAAuB,QAAQ,EAAE,8BAA8B,KAAK,oCAAoC,cAAc;AACtH,4CAA4C,uBAAuB,kCAAkC,aAAa;AAClH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,uFAAuF,UAAU;AACjG;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,wBAAwB,sBAAG,kCAAkC,wBAAU;AACvE;AACA,mDAAmD,oCAAoC;AACvF,qBAAqB,WAAW,YAAY,0BAA0B;AACtE,gBAAgB,QAAQ;AACxB;AACA;AACA;AACA,KAAK;AACL;AACA,wBAAwB,sBAAG,kCAAkC,wBAAU;AACvE;AACA,+DAA+D,oCAAoC,UAAU,WAAW;AACxH,wBAAwB,0BAA0B;AAClD,gBAAgB,QAAQ;AACxB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,sBAAsB,oBAAoB;AAC1C;AACA;AACA;AACA,0CAA0C,QAAQ,iBAAiB,0BAA0B;AAC7F;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,wDAAwD,2BAA2B;AACnF,sBAAsB,wBAAwB,YAAY,0BAA0B;AACpF;AACA;AACA,KAAK;AACL;AACA;AACA,kBAAkB,wBAAwB,YAAY,0BAA0B,gBAAgB,2CAA2C;AAC3I;AACA,KAAK;AACL;AACA;AACA,0BAA0B,sBAAG;AAC7B,qCAAqC,UAAU,MAAM;AACrD;AACA,2BAA2B;AAC3B;AACA,sBAAsB,SAAS;AAC/B,sFAAsF,kBAAkB;AACxG;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,4CAA4C,IAAI;AAChD;AACA;AACA;AACA;AACA;AACA,wDAAwD,SAAS,0CAA0C,oBAAoB;AAC/H;AACA,KAAK;AACL;AACA;;AC9KwL;AACjL;AACP;AACA;AACA;AACA,iBAAiB,WAAW;AAC5B;AACA,iBAAiB,WAAW;AAC5B;AACA,iBAAiB,MAAM;AACvB;AACA,iBAAiB,mBAAmB;AACpC;AACA,iBAAiB,gCAAgC;AACjD;AACA,iBAAiB,uBAAuB;AACxC;AACA,iBAAiB,UAAU;AAC3B;AACA,iBAAiB,WAAW;AAC5B;AACA,iBAAiB,QAAQ;AACzB;AACA,iBAAiB,IAAI;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnDiE;AACrB;AACG;AACxC;AACP;AACA;AACA;AACA;AACO,qCAAqC,WAAW;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0BAAO,CAAC,yBAAM;AACtB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,yBAAyB;AAC/C;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;ACrCA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,WAAW,QAAQ;AACnB,aAAa,UAAU;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,uDAAe,eAAe,EAAC;;;ACrBO;;AAEtC;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,WAAW,QAAQ;AACnB,aAAa,UAAU;AACvB;AACA;AACA,EAAE,4BAAQ;AACV;AACA,GAAG;AACH;AACA;;AAEA,sDAAe,cAAc,EAAC;;;ACpBsB;AACF;AACJ;AACX;;AAEnC;AACA;AACA;AACA;AACA,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,aAAa,UAAU;AACvB;AACA;AACA;AACA,eAAe,0BAAO,eAAe,gBAAe,GAAG,eAAc;AACrE;;AAEA,oCAAoC,gCAAY;AAChD;AACA;;AAEA,wDAAe,gBAAgB,EAAC;;;ACtBoB;AACE;;AAEtD;AACA,IAAI,mBAAW;;AAEf;AACA,IAAI,sBAAc,GAAG,mBAAW;;AAEhC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,QAAQ;AACrB;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA,cAAc,iBAAgB;AAC9B,MAAM,sBAAc;AACpB;AACA,IAAI;AACJ,IAAI,mCAAe;AACnB;AACA,CAAC;;AAED,wDAAe,OAAO,EAAC;;;ACxCiB;AACD;;AAEvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,QAAQ;AACnB,YAAY,QAAQ;AACpB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,4BAAS;AAChD;AACA,SAAS,UAAS;AAClB;;AAEA,0DAAe,SAAS,EAAC;;;ACtCoE;AAC1D;AACI;AACuJ;AACvL,+CAA+C,UAAU;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,kCAAK,iCAAiC;AAC/D,+BAA+B,kCAAK,uCAAuC;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,WAAW,GAAG,sBAAsB;AACrE,oCAAoC,KAAK;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,wDAAwD,UAAU;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,mCAAmC,cAAM;AACzC;AACA,0CAA0C,QAAQ;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,sCAAsC,cAAM;AAC5C;AACA,6CAA6C,QAAQ;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,yCAAyC,cAAM;AAC/C;AACA,gDAAgD,QAAQ;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,sDAAsD,cAAM;AAC5D;AACA,6DAA6D,QAAQ;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,kCAAK;AACpB;AACA;AACA;AACA;AACA,8BAA8B,cAAI;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,WAAW;AACvC;AACA;AACA,iCAAiC,WAAW;AAC5C;AACA;AACA,iCAAiC,MAAM;AACvC;AACA;AACA,iCAAiC,mBAAmB;AACpD;AACA,oBAAoB,UAAU;AAC9B;AACA,iBAAiB;AACjB;AACA;AACA;AACA,iCAAiC,gCAAgC;AACjE;AACA,oBAAoB,WAAW,GAAG,6BAA6B;AAC/D,oBAAoB,UAAU;AAC9B,qCAAqC,QAAQ,GAAG,8BAA8B;AAC9E,iBAAiB;AACjB;AACA;AACA;AACA,iCAAiC,uBAAuB;AACxD;AACA,oBAAoB,UAAU;AAC9B,qCAAqC,QAAQ,GAAG,8BAA8B;AAC9E,iBAAiB;AACjB;AACA;AACA;AACA,iCAAiC,UAAU;AAC3C;AACA,oBAAoB,UAAU;AAC9B;AACA,iBAAiB;AACjB;AACA;AACA;AACA,iCAAiC,WAAW;AAC5C,YAAY,0BAAO;AACnB;AACA;AACA;AACA,oBAAoB,0BAAO;AAC3B;AACA;AACA,aAAa;AACb;AACA;AACA,iCAAiC,QAAQ;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,cAAI;AACvB,KAAK;AACL;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA,gBAAgB,uBAAI;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,cAAI;AACzB,2BAA2B,mBAAS;AACpC,iCAAiC,mBAAS;AAC1C;AACA;AACA;AACA,iCAAiC,QAAQ;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,cAAI;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,WAAW;AAC5C,iCAAiC,kCAAK;AACtC;AACA,uCAAuC,kCAAK;AAC5C;AACA;AACA;AACA,mEAAmE,cAAI;AACvE;AACA;AACA;AACA;AACA;AACA,iCAAiC,MAAM;AACvC;AACA;AACA;AACA,qBAAqB,cAAI;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,cAAI;AAChD;AACA;AACA;AACA;AACA;AACA,iCAAiC,mBAAmB;AACpD;AACA,wCAAwC,UAAU;AAClD;AACA;AACA,aAAa;AACb,sEAAsE,cAAI;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,gCAAgC;AACjE;AACA,sCAAsC,QAAQ;AAC9C;AACA,aAAa;AACb,wCAAwC,UAAU;AAClD;AACA;AACA,aAAa;AACb,sEAAsE,cAAI;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,uBAAuB;AACxD;AACA;AACA;AACA,qBAAqB,cAAI;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,QAAQ;AAC9C;AACA,aAAa;AACb,sCAAsC,UAAU;AAChD;AACA;AACA,aAAa;AACb,oEAAoE,cAAI;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,UAAU;AAC3C;AACA;AACA;AACA,qBAAqB,cAAI;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,UAAU;AAChD;AACA;AACA,aAAa;AACb,oEAAoE,cAAI;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,WAAW;AAC5C;AACA,qDAAqD,QAAQ;AAC7D;AACA;AACA;AACA,mDAAmD,cAAI;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,WAAW;AAC5C;AACA;AACA,4CAA4C,cAAI;AAChD;AACA;AACA,aAAa;AACb;AACA,iCAAiC,IAAI;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,kCAAK;AAC9B;AACA,mCAAmC,kCAAK;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3e+E;AAC1B;AACd;AAC4D;AAC8F;AAC1L;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AACxB;AACP;AACA,wBAAwB,MAAM;AAC9B;AACA;AACA,6BAA6B,UAAU;AACvC;AACA;AACA,6BAA6B,mBAAmB;AAChD;AACA;AACA;AACA,6BAA6B,gCAAgC;AAC7D;AACA;AACA;AACA,6BAA6B,uBAAuB;AACpD;AACA;AACA;AACA,6BAA6B,WAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACO;AACP,YAAY,2CAA2C;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,UAAU,kCAAkC;AAC5C,UAAU,sBAAsB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,UAAU,kCAAkC;AAC5C,UAAU,sBAAsB;AAChC;AACA;AACO;AACP;AACA,oCAAoC,eAAK;AACzC,eAAe,eAAK;AACpB;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA,qBAAqB,QAAQ;AAC7B;AACA;AACA;AACA;AACA;AACA,+BAA+B,sBAAG;AAClC,4BAA4B,eAAe;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,oBAAoB;AAC9D;AACA;AACA,oCAAoC,oBAAoB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,sBAAG;AACnC,mBAAmB,0BAAO;AAC1B,SAAS;AACT,4BAA4B,yBAAM;AAClC,YAAY,0BAAO;AACnB,qBAAqB,sBAAG;AACxB;AACA;AACA,gBAAgB,0BAAO;AACvB,yBAAyB,sBAAG;AAC5B;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA,SAAS,IAAI;AACb;AACA,qBAAqB,QAAQ;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,QAAQ;AAC7B;AACA;AACA,4BAA4B,eAAe;AAC3C;AACA;AACA,0CAA0C,oBAAoB;AAC9D;AACA;AACA,oCAAoC,oBAAoB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,oCAAoC,eAAK;AACzC;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,kCAAkC,0BAAO;AACzC;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,yBAAM;AACtC;AACA,gBAAgB,0BAAO;AACvB;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,gBAAgB;AACtD;AACA;AACA,gCAAgC,oBAAoB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,UAAU;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,WAAW;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,UAAU;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA,wBAAwB,iBAAiB;AACzC;AACA;AACA,4BAA4B,oCAAoC;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,uCAAuC;AACpE;AACA;AACA;AACA;AACA;AACA,gCAAgC,mCAAmC;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,wBAAwB,sBAAG,wBAAwB,iBAAiB;AACpE;AACA,uBAAuB,sBAAG;AAC1B;AACA,QAAQ,0BAAO;AACf;AACA,YAAY,0BAAO;AACnB;AACA,aAAa;AACb,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA,6BAA6B,iBAAiB;AAC9C;AACA;AACA;AACA,6BAA6B,6BAA6B;AAC1D;AACA;AACA,sCAAsC,8CAA8C;AACpF;AACA;AACA;AACA;AACA;AACA,gCAAgC,0BAAO;AACvC;AACA;AACA;AACA;AACA;AACA,wCAAwC,uBAAuB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,iBAAiB;AACxE;AACA;AACA,oBAAoB,0BAAO;AAC3B;AACA,wBAAwB,0BAAO;AAC/B;AACA,yBAAyB;AACzB,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,2BAA2B,WAAe,GAAG,uBAAuB;AACpE,0BAA0B,WAAe,GAAG,sBAAsB;AAClE;AACA;AACO;AACP,sCAAsC,wBAAwB;AAC9D;AACA;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,eAAK;AACb;AACA;AACA;AACA,SAAS;AACT;AACO;AACP,WAAW,eAAK,qCAAqC,eAAK,iCAAiC,eAAK,wBAAwB,0BAAO;AAC/H;AACA;;ACtdoL;AACnH;AAC6L;AAClH;AACjF;AACG;AACvD;AACP;AACA;AACA;AACA;AACA,KAAK;AACL,WAAW,sBAAG,sEAAsE,MAAM,yBAAyB,8BAA8B;AACjJ;AACO;AACP,4BAA4B,0BAAO;AACnC;AACA,8BAA8B,0BAAO;AACrC,gCAAgC,0BAAO;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,iBAAO;AACpC,uBAAuB,gBAAM;AAC7B;AACA,KAAK;AACL,mBAAmB,sBAAG,CAAC,yBAAM;AAC7B,0BAA0B,cAAK;AAC/B;AACA,wBAAwB,oBAAoB;AAC5C;AACA;AACA,kBAAkB,yBAAyB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,cAAc,oBAAoB,OAAO,KAAK,SAAS,KAAK,iCAAiC;AAC7F;AACA;AACA,wBAAwB,QAAQ;AAChC;AACA;AACA,6BAA6B,WAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACO,4CAA4C,WAAW;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,wBAAwB,yBAAM;AAC9B;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,kBAAkB,yBAAyB;AAC3C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,SAAS,kBAAQ;AACjB;AACA,8CAA8C,SAAS,4CAA4C,UAAU;AAC7G;AACA;AACA;AACA,kBAAkB,yBAAyB;AAC3C;AACA,SAAS;AACT;AACA;AACA;AACO;AACP;AACA;AACA,QAAQ,0BAAO;AACf;AACA;AACA;AACA;AACA,mCAAmC,kBAAQ;AAC3C;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,sBAAsB,yBAAyB;AAC/C;AACA,aAAa;AACb;AACA;AACA;AACA,+BAA+B,oBAAU;AACzC,oCAAoC,0BAAO;AAC3C,4BAA4B,kCAAK;AACjC;AACA;AACA,SAAS;AACT;AACA;AACA;AACO;AACP;AACA,QAAQ,0BAAO;AACf;AACA;AACA,sBAAsB,cAAK;AAC3B;AACA,6BAA6B,WAAW;AACxC;AACA;AACA,kCAAkC,WAAe;AACjD,6BAA6B,MAAM;AACnC,6BAA6B,mBAAmB;AAChD,6BAA6B,gCAAgC;AAC7D,6BAA6B,uBAAuB;AACpD,6BAA6B,UAAU;AACvC;AACA;AACA,kCAAkC,WAAW;AAC7C;AACA,iBAAiB,0BAAO,CAAC,sBAAG;AAC5B;AACA,kCAAkC,QAAQ;AAC1C;AACA;AACA;AACA;AACA;AACA,4BAA4B,cAAc;AAC1C;AACA;AACA,qBAAqB,cAAI;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,WAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mBAAmB,0BAAO;AAC1B,2BAA2B,mBAAS;AACpC,eAAe,0BAAO;AACtB,uCAAuC,uBAAuB,wBAAwB,sBAAsB;AAC5G,gBAAgB,0BAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,8BAA8B,yBAAyB;AACvD;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,UAAU,gBAAM;AAChB,mBAAmB,0BAAO;AAC1B;AACA;AACA,6BAA6B,sBAAsB;AACnD;AACA;AACA;AACA,KAAK;AACL;AACA;AACO,kCAAkC,WAAW;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mBAAmB,0BAAO;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,0BAA0B,yBAAyB;AACnD;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA,IAAI,0BAAO;AACX;AACA;AACA;AACA,QAAQ,0BAAO;AACf,6BAA6B,WAAW;AACxC;AACA;AACA,0BAA0B,gCAAgC;AAC1D;AACA,gBAAgB,0BAAO,CAAC,0BAAO;AAC/B;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,0BAA0B,yBAAyB;AACnD;AACA,iBAAiB;AACjB;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA,iCAAiC,yBAAM;AACvC;AACA;AACA;AACA;AACA,QAAQ,0BAAO;AACf;AACA,YAAY,0BAAO;AACnB;AACA,oBAAoB,YAAY;AAChC;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,iBAAiB,YAAY;AAC7B;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,SAAS;AACT;AACA,KAAK;AACL,uBAAuB,sBAAG;AAC1B,4BAA4B,sBAAG;AAC/B;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,kBAAkB,yBAAyB;AAC3C;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA,4BAA4B,yBAAM;AAClC,gCAAgC,sBAAG;AACnC,qBAAqB;AACrB,SAAS;AACT;AACA,KAAK;AACL,mBAAmB,iBAAO,CAAC,0BAAO;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,yBAAM;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC,SAAS;AACT,qCAAqC,sBAAG;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,sBAAsB,yBAAyB;AAC/C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,uBAAuB,sBAAG;AAC1B,IAAI,0BAAO;AACX;AACA,YAAY,kBAAQ;AACpB;AACA;AACA;AACA,sBAAsB,yBAAyB;AAC/C;AACA,aAAa;AACb;AACA,KAAK;AACL;AACA;AACA;;AClb8C;AACuB;AACA;AAC+C;AAC7G,SAAS,mCAAc;AAC9B,0BAA0B,2BAAQ;AAClC,wBAAwB,mCAAmC;AAC3D,KAAK;AACL;AACA,IAAI,0BAAO;AACX;AACA,KAAK;AACL,WAAW,cAAiB;AAC5B;AACO,SAAS,oCAAe;AAC/B,cAAc,2BAAQ;AACtB,wBAAwB,oCAAoC;AAC5D,KAAK;AACL,WAAW,eAAkB;AAC7B;AACA;;ACpBqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,WAAW,kBAAQ;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;ACzDyF;AACC;AACpB;AAC9B;AACa;AAC9C;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,+BAA+B,sBAAG;AAClC;AACA,cAAc,qBAAqB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,mBAAmB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,8BAA8B,wBAAwB;AACtD;AACA,mCAAmC,mBAAS;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA,yCAAyC,uBAAI;AAC7C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,kBAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,uBAAI;AACnC,iCAAiC,YAAY;AAC7C;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sBAAG;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,4BAA4B,sBAAG;AAC/B;AACA,SAAS;AACT,eAAe,0BAAO;AACtB;AACA;AACA;AACA,oBAAoB,GAAG;AACvB;AACA,6EAA6E,YAAE;AAC/E;AACA;AACA;AACA;AACA;AACA,sCAAsC,GAAG;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,mBAAS;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,kCAAK;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sBAAG;AAClB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,GAAG;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjSA;AACA;AACA;AACA;AACA;AACA;AACO;AACA;AACA;AACP;AACO;AACP;AACA;AACA;AACO;AACA;AACA;AACA;AACA;AACA;AACP;AACO;AACP;AACA;AACA;AACA;;ACzB6C;AAC8B;AACf;AACoG;AACmB;AAC5K;AACP;AACA;AACA;AACA,2HAA2H,qBAAqB;AAChJ;AACA;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,0BAAO,yBAAyB,uBAAuB,2BAA2B,oCAAoC;AACrI;AACA;AACA,eAAe,0BAAO,yBAAyB,0BAA0B,cAAc,oCAAoC;AAC3H;AACA;AACA,eAAe,0BAAO,yBAAyB,wCAAwC,4BAA4B,oCAAoC;AACvJ;AACA;AACA,eAAe,iCAAiC,sBAAsB,oCAAoC;AAC1G;AACA;AACA,eAAe,uBAAuB,kHAAkH,8BAA8B;AACtL;AACA;AACA,eAAe,iCAAiC,2FAA2F,WAAW,oBAAoB,uCAAuC;AACjN;AACA;AACA;;AC9CyC;AACY;AACoG;AACnF;AACA;AACtE;AACA;AACA;AACO;AACP;AACA,oCAAoC,sBAAG;AACvC;AACA,cAAc,qBAAqB;AACnC,4BAA4B,sBAAG;AAC/B;AACA,cAAc,qBAAqB;AACnC,iCAAiC,sBAAG;AACpC;AACA,kBAAkB,oBAAoB,GAAG,iCAAiC;AAC1E;AACA;AACA;AACA,QAAQ,0BAAO;AACf,+BAA+B,eAAe;AAC9C,wBAAwB,mHAAmH;AAC3I,gBAAgB,0BAAO;AACvB;AACA,uCAAuC,oBAAoB,WAAW,EAAE,QAAQ;AAChF;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,oCAAoC,2BAA2B,0CAA0C,MAAM;AAC/G;AACA,qBAAqB;AACrB,iBAAiB;AACjB,gBAAgB,0BAAO;AACvB,sEAAsE,QAAQ,uCAAuC,oBAAoB;AACzI,iBAAiB;AACjB,gBAAgB,0BAAO;AACvB,sEAAsE,UAAU,mCAAmC,oBAAoB;AACvI,iBAAiB;AACjB,gBAAgB,0BAAO;AACvB,sEAAsE,gBAAgB,gDAAgD,oBAAoB;AAC1J,iBAAiB;AACjB,gBAAgB,0BAAO;AACvB,sEAAsE,oBAAoB,6DAA6D,oBAAoB;AAC3K,iBAAiB;AACjB,gBAAgB,0BAAO;AACvB,sEAAsE,YAAY,oDAAoD,oBAAoB;AAC1J,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT;AACA;AACA,2BAA2B,cAAc,EAAE,2CAA2C;AACtF;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,wBAAwB,2BAA2B;AACnD;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,eAAe,2BAA2B;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,WAAW;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrIA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtEA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;ACT4G;AAC7C;AACxD;AACP,0BAA0B,uBAAI;AAC9B;AACA,oBAAoB,yBAAyB;AAC7C;AACA;AACA;AACA,wBAAwB,0BAA0B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,IAAI,cAAc;AAClB;AACA;AACA;AACA,gBAAgB,0BAAO;AACvB;AACA;AACA;AACA;AACA;AACA,gBAAgB,8BAAW;AAC3B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,iBAAiB,0BAAO;AACxB,sCAAsC,sBAAG;AACzC,+DAA+D,sBAAsB;AACrF,uBAAuB,kDAAkD;AACzE;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,IAAI,cAAc;AAClB;AACA,IAAI,0BAAO;AACX;AACA,KAAK;AACL;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,CAAC,8DAA8D;AACxD;AACP;AACA;AACA;AACO;AACP,6BAA6B,yBAAM;AACnC,eAAe,6BAAU;AACzB,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA,6CAA6C,aAAa,OAAO,oCAAoC;AACrG;AACA;AACA;AACA,KAAK;AACL,WAAW,iBAAO;AAClB;AACA;;ACzF2H;AAClE;AACkE;AACtE;AACrD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,oCAAoC,sBAAG;AACvC;AACA,cAAc,qBAAqB;AACnC;AACA,4CAA4C,mBAAI;AAChD,yCAAyC,mBAAI;AAC7C,mCAAmC,mBAAI;AACvC,sCAAsC,mBAAI;AAC1C,+BAA+B,mBAAI;AACnC;AACA;AACA;AACA;AACA,oDAAoD,mBAAmB;AACvE,mDAAmD,mBAAmB;AACtE,uCAAuC,mBAAI;AAC3C;AACA;AACA;AACA,oDAAoD,mBAAI;AACxD,mDAAmD,mBAAI;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,yBAAyB;AAC7E,mDAAmD,yBAAyB;AAC5E,uCAAuC,mBAAI;AAC3C;AACA;AACA;AACA;AACA,oDAAoD,mBAAI;AACxD,mDAAmD,mBAAI;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,mBAAI;AACpD,+CAA+C,mBAAI;AACnD,mCAAmC,mBAAI;AACvC,8CAA8C,mBAAI;AAClD;AACA;AACA,8EAA8E,4BAA4B;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,gBAAgB;AACxB;AACA;AACA;AACA;AACA;AACA,QAAQ,oBAAoB;AAC5B;AACA;AACA;AACA;AACA,YAAY,8BAAW;AACvB,iDAAiD,oCAAoC,iBAAiB,uBAAI;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8BAAW;AACvB,mCAAmC,wCAAwC,iBAAiB,uBAAI;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9L2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,WAAW;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,WAAW;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrE6C;AACuB;AACU;AACA;AACX;AACf;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,mBAAmB;AAC3D,YAAY,kBAAQ;AACpB,2BAA2B,oCAAoC;AAC/D;AACA;AACA,aAAa;AACb;AACA;AACA,sBAAsB,yBAAyB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,mBAAmB;AAC1D,2BAA2B,wBAAwB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sBAAsB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,gBAAgB,CAAC,yBAAM;AACtC;AACA;AACA;;;;AC7U0G;AACiE;AAChD;AACpE;AAC8H;AAClI;AACW;AACT;AACiF;AACtI;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,kCAAkC;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sBAAG;AACf;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA,gBAAgB,0BAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB,6BAA6B,yBAAM;AACnC;AACA;AACA,aAAa,IAAI;AACjB;AACA,iBAAiB,sBAAG;AACpB,YAAY,eAAK,CAAC,0BAAO,CAAC,yBAAM,0BAA0B,WAAW;AACrE,kCAAkC,0BAAO,CAAC,yBAAM;AAChD,iCAAiC,cAAI;AACrC,6BAA6B,yBAAM;AACnC;AACA;AACA,aAAa,IAAI;AACjB;AACA,iBAAiB,2BAAQ;AACzB,6BAA6B,kCAAK;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,GAAG;AACnC,8BAA8B,sBAAG;AACjC,cAAc,0BAAO,CAAC,yBAAM;AAC5B,cAAc,yBAAM;AACpB,sCAAsC,eAAK,sCAAsC,0BAAO;AACxF;AACA,cAAc,kCAAkC;AAChD,cAAc,sBAAsB;AACpC;AACA;AACA;AACA,QAAQ,iBAAiB,CAAC,yBAAM;AAChC;AACA;AACA;AACA,yCAAyC,SAAS;AAClD;AACA;AACA,8BAA8B,sBAAG;AACjC;AACA,cAAc,mBAAmB;AACjC,kCAAkC,sBAAG;AACrC;AACA,cAAc,mBAAmB;AACjC;AACA;AACA,oDAAoD,oBAAoB,GAAG,uBAAuB;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,uCAAuC;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sBAAsB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,UAAU;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,gBAAgB;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,SAAS;AACxE;AACA;AACA;AACA;AACA;AACA,sHAAsH,gBAAgB,kBAAkB,iCAAiC;AACzL;AACA;AACA,uDAAuD,oBAAoB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oCAAoC;AACpD,uCAAuC,oBAAoB,kBAAkB,oCAAoC;AACjH;AACA;AACA,+DAA+D,SAAS;AACxE;AACA;AACA;AACA,uDAAuD,QAAQ;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oHAAoH,QAAQ,kBAAkB,2BAA2B;AACzK;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,YAAY;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,8BAA8B;AAC9C,uCAAuC,YAAY,kBAAkB,8BAA8B;AACnG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,oBAAoB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,MAAM;AAC7D,qBAAqB,0BAAO;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,gCAAgC,0BAA0B;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sBAAsB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,kCAAkC,wBAAwB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,0BAA0B;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,kCAAK;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,GAAG;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7hB+G;AACxE;AACgE;AAClD;AACrD;AACA;AACA;AACO;AACP;AACA;AACA,oCAAoC,sBAAG;AACvC;AACA,cAAc,qBAAqB;AACnC;AACA;AACA,YAAY,sBAAsB;AAClC;AACA;AACA,qCAAqC,kCAAK;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,kCAAK;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,gCAAgC;AAC7E;AACA;AACA,wBAAwB,wBAAwB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,kCAAkC,kBAAkB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,sBAAsB;AACnE;AACA,wBAAwB,wBAAwB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,kCAAkC,oBAAoB;AACtD;AACA;AACA;;ACzE8F;AAC/C;AACxC;AACP;AACA;AACA;AACA,YAAY,8BAAW;AACvB,kCAAkC,cAAc;AAChD;AACA,eAAe,uBAAuB;AACtC;AACA;AACA;AACA;AACA,4BAA4B,cAAK;AACjC;AACA;AACA,2CAA2C,oBAAoB;AAC/D;AACA;AACA;AACA;;ACrBmF;AAC2G;AACxI;AAC4B;AACC;AACxC;AACqB;AAChE;AACA;AACA;AACA;AACA;AACA,mCAAmC,uBAAuB;AAC1D,YAAY,WAAW,GAAG,wCAAwC,KAAK,KAAK;AAC5E,iBAAiB;AACjB,8BAA8B,mBAAmB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,QAAQ;AACpC;AACA,+BAA+B,IAAI;AACnC;AACA;AACA,+BAA+B,IAAI;AACnC;AACA;AACA,8BAA8B,IAAI;AAClC;AACA;AACA,0BAA0B,IAAI;AAC9B;AACA;AACA,4BAA4B,IAAI;AAChC;AACA;AACA,gCAAgC,IAAI;AACpC;AACA;AACA,oCAAoC,IAAI;AACxC;AACA;AACA,wCAAwC,IAAI;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,QAAQ;AACpC;AACA,sCAAsC,IAAI;AAC1C,sCAAsC,IAAI;AAC1C,qCAAqC,IAAI;AACzC,iCAAiC,IAAI;AACrC,mCAAmC,IAAI;AACvC,uCAAuC,IAAI;AAC3C,2CAA2C,IAAI;AAC/C,+CAA+C,IAAI;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,WAAW;AAC1B;AACA;AACA;AACA,wCAAwC,IAAI,GAAG,4BAA4B;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,MAAM;AAC3C;AACA;AACA,8BAA8B,mBAAmB;AACjD;AACA;AACA,8BAA8B,gCAAgC;AAC9D;AACA;AACA,8BAA8B,UAAU;AACxC;AACA;AACA,8BAA8B,uBAAuB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,sBAAG;AAC9B,+CAA+C,yBAAyB;AACxE,kEAAkE,2BAA2B;AAC7F,8CAA8C,gCAAgC;AAC9E;AACA;AACA;AACA,yBAAyB,uBAAI;AAC7B;AACA,oCAAoC,WAAW;AAC/C;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,mBAAmB;AAChC,+CAA+C,yBAAyB;AACxE,8DAA8D,wBAAwB;AACtF,8CAA8C,gCAAgC;AAC9E;AACA;AACA;AACA,yBAAyB,uBAAI;AAC7B,oCAAoC,QAAQ;AAC5C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,uBAAI;AACzB,0BAA0B,6BAAU;AACpC,0CAA0C,iCAAiC;AAC3E;AACA;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,uBAAI;AACzB;AACA,uBAAuB,0BAAO;AAC9B;AACA,0BAA0B,WAAW;AACrC;AACA;AACA;AACA,KAAK;AACL,QAAQ,sBAAG;AACX;AACA;AACA,0BAA0B,cAAI,oBAAoB,6BAAU;AAC5D;AACA;AACA,IAAI,0BAAO;AACX,gCAAgC,WAAW,GAAG,gBAAgB;AAC9D;AACA,YAAY,sBAAG;AACf,wEAAwE;AACxE;AACA;AACA,iBAAiB,sBAAG;AACpB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,+BAA+B,IAAI;AACnC;AACA;AACA;AACA;AACA;AACA,0CAA0C,IAAI;AAC9C,oEAAoE,mBAAmB;AACvF;AACA;AACA;AACA;AACA;;ACtSgC;AACU;AACW;AACrD;AACA;AACA;AACO;AACP;AACA,YAAY,sBAAG;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA,iCAAiC,qBAAqB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,OAAO,OAAO,UAAU;AACvD;AACA,oBAAoB,cAAc,EAAE,KAAK;AACzC;AACA;AACA;AACA,+BAA+B,OAAO,OAAO,UAAU,UAAU,KAAK;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/CO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;;ACnBsE;AACjB;AACS;AACS;AACiC;AACb;AACrC;AACF;AACG;AACE;AACE;AACM;AACR;AACE;AACF;AACG;AACN;AACG;AAClD,oBAAoB,mBAAmB,CAAC,GAAG;AAClD;AACO;AACP;AACA;AACA;AACA;AACA,0BAA0B,0BAA0B;AACpD;AACA;AACA;AACA,CAAC;AACM;AACP;AACA;AACA,CAAC;AACM;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8DAA8D;AACxD;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,gBAAgB;AAChC,aAAa;AACb;AACA;AACA;AACA;AACA,oBAAoB,0BAAO;AAC3B;AACA;AACA;AACA,2CAA2C,cAAc;AACzD;AACA,yBAAyB;AACzB;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,iCAAiC,mCAAc;AAC/C,2BAA2B,yBAAM;AACjC,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA,oBAAoB,0BAAO;AAC3B,6CAA6C,oCAAe;AAC5D,+BAA+B,yBAAM;AACrC,oCAAoC,yBAAM;AAC1C,wCAAwC,oCAAoC;AAC5E;AACA,qBAAqB;AACrB,sDAAsD,iBAAiB;AACvE;AACA,+BAA+B,yBAAM;AACrC,oCAAoC,yBAAM;AAC1C;AACA,qBAAqB;AACrB;AACA;AACA,aAAa;AACb;AACA,gBAAgB,0BAAO;AACvB;AACA;AACA;AACA,2CAA2C,sBAAsB,CAAC,yBAAM;AACxE;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,+BAA+B,yBAAM;AACrC,qBAAqB;AACrB,sDAAsD,yBAAM;AAC5D,iBAAiB;AACjB;AACA;AACA,iBAAiB,0BAAO;AACxB,gCAAgC,sBAAG;AACnC,wEAAwE,0DAA0D;AAClI;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sBAAG;AACf;AACA;AACA;AACA;AACA;AACA,+BAA+B,sBAAG;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,IAAI,WAAW;AACf,IAAI,UAAU;AACd,IAAI,WAAW;AACf,IAAI,YAAY;AAChB,IAAI,gBAAgB;AACpB,IAAI,aAAa;AACjB,IAAI,YAAY;AAChB,IAAI,aAAa;AACjB,IAAI,YAAY;AAChB,IAAI,iBAAiB;AACrB;AACO,wBAAwB,sDAAM;AACrC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,4BAA4B,kCAAK;AACjC;AACA;AACA;AACA;AACA;;ACxMwC;AACD;AACvC;AACA;AACA;AACA;AACO;AACP,2DAA2D;AAC3D;AACA;AACA;AACA;;ACXA;AACA;AACuC;AAC4E;AAC1C;AACzE;AACsH;AACtH;AACiE;AACO;AACxE;AACsE;AACiG;AAC7F;AAC1E;AAC8L;AAC9L;AACuF;AAC9B;AACzD;AACO;AACP;AACA;AACA;AACA;AACuE;AAChE,MAAM,UAAM;AACnB;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AAC0D;AACmB;AACf;AACV;AACpD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,YAAY,8BAAc,UAAU,2CAAiB,UAAU,2CAAkB,CAAC,uCAAa;AAC/F;AACA;AACA;AACA;AACA;AACA,oBAAoB,mCAAiB;AACrC;AACA;AACA;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACmC;AACM;AAC2H;AAC7J;AACP,cAAc,UAAU,GAAG,KAAK,GAAG,WAAW;AAC9C;AACO;AACA;AACA;AACA;AACA;AACP;AACO;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oBAAQ;AACtC;AACA;AACA,mCAAmC,uBAAW;AAC9C;AACA;AACA,mCAAmC,uBAAW;AAC9C;AACA;AACA,mCAAmC,kBAAM;AACzC,eAAe,UAAM;AACrB;AACA,mCAAmC,sBAAU;AAC7C;AACA;AACA,mCAAmC,mCAAuB;AAC1D;AACA;AACA,mCAAmC,+BAAmB;AACtD;AACA;AACA,mCAAmC,4CAAgC;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,iBAAiB,sBAAG;AACpB;AACA;AACA;AACA,SAAS,UAAM;AACf;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,oBAAoB,yBAAM,CAAC,sBAAG;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA,iCAAiC;AACjC,4BAA4B;AAC5B;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,2BAA2B;AAC3B,6BAA6B;AAC7B,wBAAwB;AACxB;AACA,gCAAgC;AAChC;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,uBAAW;AACzC;AACA;AACA,mCAAmC,kBAAM;AACzC;AACA;AACA,mCAAmC,sBAAU;AAC7C;AACA;AACA,mCAAmC,mCAAuB;AAC1D;AACA;AACA,mCAAmC,+BAAmB;AACtD;AACA;AACA,mCAAmC,4CAAgC;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B,mIAAmI;AACnI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnZA;AACA;AACA;AACA;AACA;AACmC;AAC5B;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sBAAG;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,cAAc,UAAU,WAAW,OAAO,GAAG,yBAAyB,GAAG,4DAA4D;AACrI;AACA;;;;;;;;;;AC7C8C;AACR;;AAEtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ,IAAI,QAAQ,IAAI,QAAQ;AAC/C,YAAY,QAAQ,IAAI,QAAQ;AAChC;AACA;AACA,mCAAmC,4BAAQ,QAAQ,gCAAY;AAC/D;;AAEA,uDAAe,MAAM,EAAC;;;;;;;;;;;AC9BtB;AACA;AACA;AACA;AACA;AACuO;AACnH;AAChD;AACjC;AACQ;AACF;AACN;AACQ;AACA;AACA;AACF;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,UAAU;AAClC;AACA;AACA;AACA;AACA;AACA;AACO,sCAAsC,gCAAoB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,SAAS;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4DAA4D;AAC5E;AACA;AACA,oBAAoB,WAAW;AAC/B;AACA;AACA,4BAA4B,sBAAG,CAAC,iCAAiB;AACjD;AACA;AACA;AACA;AACA,SAAS,gBAAgB,sBAAG;AAC5B;AACA,gCAAgC,yBAAM;AACtC,gBAAgB,0BAAO;AACvB;AACA;AACA,wBAAwB,0BAAO;AAC/B;AACA,yBAAyB;AACzB;AACA,iBAAiB;AACjB;AACA,aAAa,IAAI;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,YAAY;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,uDAAuD;AACvE;AACA;AACA,oBAAoB,WAAW;AAC/B;AACA;AACA,qBAAqB,sBAAG,CAAC,iCAAiB;AAC1C;AACA;AACA;AACA;AACA,SAAS;AACT,mBAAmB,sBAAG;AACtB,SAAS;AACT;AACA;AACA,sCAAsC,0BAAO;AAC7C;AACA,gBAAgB,0BAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,yBAAM;AAC1C;AACA;AACA,wBAAwB,0BAAO;AAC/B;AACA,yBAAyB;AACzB;AACA;AACA,iBAAiB,IAAI;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,SAAS;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,SAAS;AACnD,eAAe,SAAS;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,sBAAG;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,oBAAoB,sBAAG,kCAAkC,0BAAU;AACnE;AACA,2DAA2D,oCAAoC,QAAQ,yCAAyC,EAAE,WAAW;AAC7J,oBAAoB,0BAA0B;AAC9C,YAAY,QAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,uBAAW;AACnC;AACA;AACA,6BAA6B,kBAAM;AACnC;AACA;AACA,6BAA6B,uBAAW;AACxC;AACA;AACA,6BAA6B,+BAAmB;AAChD;AACA;AACA,6BAA6B,4CAAgC;AAC7D;AACA;AACA,6BAA6B,mCAAuB;AACpD;AACA;AACA,6BAA6B,sBAAU;AACvC;AACA;AACA,6BAA6B,oBAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,0BAAO;AACnC,2BAA2B,gBAAM;AACjC,oCAAoC,cAAc;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,YAAY;AACzC;AACA;AACA;AACA;AACA;AACA,6BAA6B,aAAa;AAC1C;AACA;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,YAAY;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,cAAc;AAC5C,QAAQ,4BAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,SAAS;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY;AACpC;AACA,oBAAoB,yBAAyB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,aAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sBAAsB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,iBAAiB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,cAAc;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,aAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,aAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,eAAe;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3iBA;AACA;AACA;AACA;AACA;AACkE;AAClE;;;;ACNA;AACA;AACA;AACA;AACa;AACN;AACP;AACA;AACA;AACA;AACA;AACA,CAAC,kCAAkC;AAC5B;AACP;AACA;AACA;AACA;AACA;AACA,CAAC,kBAAkB;AACZ;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0BAA0B;AACpB;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA,IAAI,gBAAgB;AACpB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,gBAAgB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA,IAAI,aAAa;AACjB;AACO;AACP;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,0EAA0E,IAAI,IAAI,IAAI,IAAI,MAAM,IAAI,KAAK;AACzG;AACA;AACA;AACA;AACA,yDAAyD,aAAa;AACtE;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sBAAsB;AACvB;AACA;AACA,IAAI,gBAAgB;AACpB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,gBAAgB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA,IAAI,oBAAoB;AACxB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,oBAAoB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AACrC;AACA;AACA,IAAI,aAAa;AACjB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,aAAa;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sBAAsB;AACvB;AACA;AACA,IAAI,wBAAwB;AAC5B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,wBAAwB;AACjF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AAC7C;AACA;AACA,IAAI,yBAAyB;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,wBAAwB;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AAC7C;AACA;AACA,IAAI,oBAAoB;AACxB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,oBAAoB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AACrC;AACA;AACA,IAAI,oCAAoC;AACxC;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,oCAAoC;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oEAAoE;AACrE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gDAAgD;AACjD;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AACvC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C;AAC3C;AACA;AACA,IAAI,kBAAkB;AACtB;AACO;AACP;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,kBAAkB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AACjC;AACA;AACA,IAAI,eAAe;AACnB;AACO;AACP;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,eAAe;AACxE;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0BAA0B;AAC3B;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS,gCAAgC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AACtB;AACP;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AACtC;AACP;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gEAAgE;AAC1D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS,gCAAgC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AACtC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AAC1B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AAC1B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AAC1B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,CAAC,sCAAsC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,IAAI;AACtC;AACA;AACA,6DAA6D,GAAG;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,qBAAqB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,8BAA8B;AAClC;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,8BAA8B;AACvF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wDAAwD;AACzD;AACA;AACA,IAAI,uCAAuC;AAC3C;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,uCAAuC;AAChG;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0EAA0E;AAC3E;AACA;AACA,IAAI,+CAA+C;AACnD;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,+CAA+C;AACxG;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0FAA0F;AAC3F;AACA;AACA,IAAI,wBAAwB;AAC5B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,wBAAwB;AACjF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,kBAAkB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AAC1B;AACP;AACA;AACA,uDAAuD,qBAAqB;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AACvC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gDAAgD;AACjD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,yBAAyB;AAClF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AAClC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gEAAgE;AACjE;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,wCAAwC;AAClC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,yBAAyB;AACnE;AACA;AACA;AACA,uDAAuD,oBAAoB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AAC9B;AACP;AACA;AACA,uDAAuD,aAAa;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sBAAsB;AACvB;AACA;AACA,IAAI,4BAA4B;AAChC;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,uBAAuB,IAAI;AAC5D;AACA;AACA,CAAC,oDAAoD;AACrD;AACA;AACA,IAAI,4BAA4B;AAChC;AACO;AACP;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oDAAoD;AACrD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sDAAsD;AACvD;AACA;AACA,IAAI,yBAAyB;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AACjC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AACxB;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AACxC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,wBAAwB;AACxC,gBAAgB,wBAAwB;AACxC;AACA;AACA,CAAC,0CAA0C;AACpC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,sBAAsB;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sDAAsD;AACvD;AACA;AACA,IAAI,yBAAyB;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,yBAAyB;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AACxC;AACP;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AACjC;AACA;AACA,IAAI,gBAAgB;AACpB;AACO;AACP;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,gBAAgB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA,IAAI,yBAAyB;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,yBAAyB;AAClF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA,IAAI,oBAAoB;AACxB;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,oBAAoB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AACrC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gDAAgD;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wDAAwD;AACzD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C;AAC3C;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8DAA8D;AAC/D;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4EAA4E;AAC7E;AACA;AACA,IAAI,0BAA0B;AAC9B;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,0BAA0B;AACnF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gDAAgD;AACjD;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AAChC;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gDAAgD;AAC1C;AACP;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AACxB;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,kCAAkC;AAC5B;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,oDAAoD;AAC9C;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,oDAAoD;AACrD;AACA,qBAAqB,+DAA+D;AACpF;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,kEAAkE;AAC5D;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,wDAAwD;AAClD;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,0DAA0D;AACpD;AACP;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C;AACpC,YAAY,oEAAoB;AACvC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,qBAAqB;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,6CAA6C,QAAQ;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,iBAAiB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gBAAgB;;;AC7qEjB;AACA;AACA;AACA;AACA;AACuD;AACF;AAC9C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oFAAoF,kCAAY;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wFAAwF,kCAAY;AACpG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oBAAoB;AAC5C,wBAAwB,mBAAmB;AAC3C,qCAAqC;AACrC;AACA;AACA;AACA;AACA,qBAAqB,OAAO,QAAQ,oBAAoB,QAAQ;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,QAAQ;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClPA;AACA;AACA;AACA;AACA;AACqG;AACxC;AAC6B;AACV;AAC8B;AACvD;AAChD;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,mFAAmF,mCAAmC,+FAA+F;AACrN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,+BAA+B,cAAc;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,wCAAc;AAC/B;AACA;AACA;AACA,6BAA6B,6CAAmB;AAChD;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA,uEAAuE,aAAa;AACpF;AACA,uDAAuD;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,yBAAyB;AAC7C;AACA;AACA,uCAAuC,yBAAS;AAChD;AACA;AACA;AACA;AACA,qBAAqB,yBAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,yBAAyB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,4CAAsB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,+CAAyB;AACrC;AACA;AACA;AACA;AACA;AACA,+BAA+B,wCAAkB,UAAU,wBAAY;AACvE;AACA;AACA,yCAAyC,gCAAgB;AACzD,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,sCAA0B;AACzC;AACA;AACA,eAAe,sCAA0B;AACzC;AACA;AACA,eAAe,sCAA0B;AACzC;AACA;AACA,eAAe,sCAA0B;AACzC;AACA;AACO;AACP,gCAAgC,kBAAkB;AAClD;AACA;AACA;AACA,8BAA8B,qDAAqD;AACnF,oCAAoC,cAAc;AAClD,4BAA4B,aAAa,cAAc,aAAa;AACpE;AACA,oCAAoC,gBAAgB;AACpD,oDAAoD,qBAAqB;AACzE;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,iBAAiB;AACrE;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,iCAAqB;AACrD;AACA;AACA,kEAAkE,oBAAoB;AACtF,sBAAsB,gCAAoB,GAAG,mCAAmC;AAChF,sBAAsB,uBAAuB;AAC7C;AACA,gEAAgE;AAChE,iBAAiB,GAAG;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;ACheA;AACA;AACA;AACA;AACA;AAC4C;AAC4O;AAC9M;AAC9B;AACsD;AAC3F;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,8CAAoB;AAC1C,wBAAwB,yBAAM,uBAAuB,wBAAY;AACjE;AACA,kDAAkD,oBAAoB,qDAAqD;AAC3H;AACA;AACA;AACA;AACA;AACA,QAAQ,yBAAS;AACjB;AACA;AACA,aAAa,wBAAQ;AACrB;AACA;AACA,aAAa,4BAAY;AACzB;AACA;AACA,aAAa,gCAAgB;AAC7B;AACA;AACA,aAAa,0BAAU;AACvB;AACA;AACA,aAAa,8BAAc;AAC3B;AACA;AACA,aAAa,gCAAgB;AAC7B;AACA;AACA,aAAa,uBAAO;AACpB;AACA;AACA,aAAa,2BAAW;AACxB;AACA,+CAA+C,eAAG;AAClD;AACA;AACA,kBAAkB,+BAAiB,+CAA+C,cAAc;AAChG;AACA;AACA;AACA;AACA,uBAAuB,qCAAW;AAClC;AACA;AACA;AACA;AACA,QAAQ,4BAAY;AACpB;AACA;AACA,sHAAsH;AACtH;AACA;AACA,aAAa,8BAAc;AAC3B;AACA;AACA;AACA;AACA;AACA,kBAAkB,+BAAiB,uCAAuC,uBAAuB;AACjG;AACA;AACA,QAAQ,mCAAiB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,uBAAuB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,6BAAa;AACrB;AACA;AACA;AACA;AACA,aAAa,6BAAa;AAC1B;AACA;AACA;AACA;AACA,aAAa,0BAAU;AACvB;AACA;AACA;AACA,aAAa,oCAAoB;AACjC;AACA;AACA;AACA,aAAa,+BAAgB;AAC7B;AACA;AACA;AACA,IAAI,mCAAiB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,SAAS,GAAG,QAAQ;AAC7C;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,uBAAO;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,4CAAkB;AAC7C;AACA;AACA,0EAA0E,qCAAW;AACrF;AACA;AACA;AACA,aAAa,0BAAU,cAAc,4BAAY;AACjD;AACA;AACA;AACA;AACA;AACA,aAAa,0BAAU,cAAc,8BAAc;AACnD;AACA;AACA;AACA;AACA,aAAa,yBAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,yBAAyB,yBAAS;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,iBAAiB;AACjB;AACA,yBAAyB,yBAAS;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,QAAQ,mCAAiB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,KAAK;AACtC;AACA;AACA;AACA,QAAQ,4BAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4BAAY;AAC5B,gBAAgB,uBAAO,YAAY,8BAAc,YAAY,gCAAgB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,KAAK;AACvC;AACA;AACA;;AChXA;AACA;AACA;AACA;AACA;AAC8D;AACN;AACjD;AACP;AACA;AACA,uBAAuB,uBAAuB;AAC9C,IAAI,YAAY;AAChB;AACA;AACA;AACA;;ACfA;AACA;AACA;AACA;AACA;AACoD;AACI;AACxD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,uBAAuB,aAAa;AACpC,WAAW,YAAY;AACvB;AACA;;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACsF;AACtF;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,oCAAuB;AACtC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO,MAAM,gCAAkB;AAC/B;AACA;AACA;AACA;AACO;AACP,mBAAmB,gCAAkB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,kBAAkB,8BAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,gCAAkB;AAChC;AACA;AACA;AACA;AACA;AACA;AACO,MAAM,sBAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AClGA;AACA;AACA;AACA;AACa;AACb,MAAM,qBAAgB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,qBAAgB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,SAAS;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA,oGAAoG,SAAS;AAC7G;AACA;AACA;AACA;AACA,qBAAqB,qBAAgB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,IAAI,iBAAY;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,qBAAgB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,qBAAgB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,EAAE,iBAAY,KAAK,iBAAY,KAAK;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;;;;;ACvQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACkE;AACpB;AACe;AACjB;AACA;AAC5C;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AAChC;AACP;AACA;AACA;AACA;AACA;AACA,2CAA2C,8BAAiB;AAC5D;AACA;AACA;AACA;AACA,qDAAqD,cAAG;AACxD,YAAY,8BAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8BAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,eAAe;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,cAAc;AAC/C;AACA,6CAA6C,aAAa;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iFAAiF,iBAAY;AAC7F;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,yBAAM;AACrB;AACA;AACA;AACA;AACA,wDAAwD,UAAU;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxQA;AACA;AACA;AACA;AACA;AAC6D;AACuB;AACF;AACpB;AACJ;AAC1D;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,8BAAiB;AACxD,2BAA2B,+BAAS;AACpC,kBAAkB,iBAAiB;AACnC,YAAY,sCAAgB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sCAAc;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iFAAiF,aAAa;AAC9F;AACA,yDAAyD,cAAc,4DAA4D,aAAa,KAAK,aAAa,GAAG;AACrK;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iCAAS;AAC7B;AACA;AACA;AACA,yBAAyB,4CAAoB;AAC7C;AACA;AACA,wHAAwH,sCAAsC;AAC9J;AACA;AACA;AACA;AACA,qCAAqC,kCAAY;AACjD,2DAA2D,sCAAsC;AACjG,sEAAsE,aAAa;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,2CAA2C,GAAG,UAAU,WAAW,QAAQ;AACxJ;AACA,uBAAuB,iCAAS;AAChC,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA,uBAAuB,sCAAc;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sCAAc;AAC9B,yBAAyB;AACzB;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,2BAA2B;AACxG;AACA;AACA,qDAAqD,cAAc,4DAA4D,2BAA2B,KAAK,aAAa,GAAG;AAC/K;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,kCAAY;AACrC,yCAAyC,aAAa;AACtD,yGAAyG,aAAa;AACtH;AACA;AACA,6CAA6C,cAAc,2CAA2C,eAAe,SAAS,2BAA2B,wBAAwB;AACjL;AACA;AACA;;ACpKA;AACA;AACA;AACA;AACA;AACgE;AACzD;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6CAAmB;AAClC;AACA;AACA;;ACpBA;AACA;AACA;AACA;AACA;AACwC;AACzB;AACR;AACP;AACA,wBAAwB,gBAAK;AAC7B,uBAAuB,gBAAK;AAC5B,uBAAuB,gBAAK;AAC5B,wBAAwB,gBAAK;AAC7B,2BAA2B,gBAAK;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sBAAsB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,cAAG;AAClB;AACA;AACA,CAAC,4BAA4B;AAC7B;;ACvCA;AACA;AACA;AACA;AACA;AAC2D;AACX;AACI;AACmB;AAC3B;AACK;AAC1C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,wCAAc;AAC7C;AACA;AACA;AACA,oBAAoB,mCAAW;AAC/B;AACA;AACA;AACA;AACA,4BAA4B,mCAAW;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,iCAAW;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,QAAQ;AACpE;AACA;AACA,eAAe,yBAAM;AACrB;AACA;AACA;AACA;AACA,wBAAwB,iCAAW;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,uCAAiB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;;ACtFA;AACA;AACA;AACA;AACA;AACgD;AAChD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,wBAAS,KAAK,yBAAM;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,yBAAM;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,yBAAM;AACrB;AACA;AACA;AACA;AACA;AACA,eAAe,yBAAM;AACrB;AACA;AACA;AACA;AACA;AACA,eAAe,yBAAM;AACrB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3LA;AACA;AACA;AACA;AACA;AAC6D;AACa;AACvB;AACW;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,iDAAiD,8BAAiB;AAClE;AACA;AACA;AACA,gBAAgB,8CAA8C,eAAe,0BAA0B;AACvG,sFAAsF,eAAe;AACrG,+CAA+C,kBAAkB;AACjE;AACA,qEAAqE,0BAA0B;AAC/F;AACA,+CAA+C,kBAAkB,qCAAqC,gBAAgB,2FAA2F,iBAAiB;AAClO;AACA;AACA,2BAA2B,8CAA8C;AACzE;AACA,iEAAiE,gCAAc,gBAAgB,8BAAiB;AAChH;AACA;AACA;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,8BAAiB;AACtE;AACA,2BAA2B,QAAQ;AACnC;AACA,2BAA2B,uCAAiB;AAC5C,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpFA;AACA;AACA;AACA;AACA;AAC0D;AAC1D;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,yBAAM;AAClC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,KAAK;AACL;AACA,eAAe,2BAAY;AAC3B;AACA;AACA;;AC/EA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B,4DAAY;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,6CAA6C;AAC7C;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,yDAAyD;AACzD;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,0CAA0C;AAC1C;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;;ACzLA;AACA;AACA;AACA;AACA;AACmD;AACC;AACR;AACS;AAC9C;AACP;AACA;AACA;AACA;AACA;AACA,oCAAoC,cAAc;AAClD;AACA;AACA;AACA;AACA,4BAA4B,iCAAW;AACvC;AACA;AACA;AACA;AACA;AACA,gCAAgC,yBAAM;AACtC;AACA;AACA,cAAc;AACd;AACA;AACA,wCAAwC,QAAQ;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,WAAW,CAAC,yBAAM;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,yBAAM;AACxB;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,mBAAmB,WAAW;AAC9B;AACA;AACA;AACA;AACA;AACA,kEAAkE,QAAQ;AAC1E;AACA;AACA;;AChEA;AACA;AACA;AACA;AACA;AACiC;AAC0B;AACP;AACa;AAC1D;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,iCAAW;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,0DAA0D;AACrF;AACA;AACA;AACA;AACA,iBAAiB,mCAAW;AAC5B;AACA;AACA;AACA,uCAAuC,iCAAW;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,UAAU,GAAG,WAAW;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,iCAAS;AAC1B;AACA;AACA,iFAAiF;AACjF;AACA;AACA;AACA;AACA;AACA;AACA,8FAA8F;AAC9F;AACA;AACA;AACA,8FAA8F;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,4CAA4C,8CAAoB;AAChE;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,qBAAqB;AACzD;AACA;AACA;AACA;AACA,6BAA6B,iCAAS;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,iCAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,iCAAS;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,cAAG;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA,+FAA+F,cAAG;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzNA;AACA;AACA;AACA;AACA;AACgD;AAChD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,KAAK,wDAAwD,gBAAgB;AAChI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,QAAQ;AAC5B;AACA;AACA;AACA,gGAAgG,IAAI,kBAAkB,WAAW;AACjI;AACA;AACA,gGAAgG,IAAI;AACpG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7EA;AACA;AACA;AACA;AACA;AACgD;AACG;AACc;AACrB;AAC5C;AACA;AACA;AACO;AACP,aAAa;AACb;AACO;AACP;AACA;AACA,CAAC,gDAAgD;AACjD;AACA;AACA;AACO;AACP;AACA,2BAA2B,QAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mCAAiB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC;AACA;AACA,6BAA6B,eAAe;AAC5C;AACA;AACA;AACA;AACA,+BAA+B,eAAe,IAAI,eAAe,KAAK,MAAM;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,yBAAM;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxJA;AACA;AACA;AACA;AACA;AAC6D;AACuB;AAClC;AACG;AAC+B;AAC1B;AACnD;AACP;AACA;AACA;AACA;AACA,iDAAiD,gBAAgB,8BAAiB;AAClF;AACA;AACA,cAAc,iBAAiB;AAC/B;AACA;AACA,yEAAyE,QAAQ,wGAAwG;AACzL;AACA;AACA;AACA,0EAA0E,QAAQ,yGAAyG;AAC3L;AACA;AACA;AACA,0EAA0E,QAAQ,yGAAyG;AAC3L;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA,cAAc,iBAAiB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C,kCAAkC;AAClC;AACA;AACA;AACA;AACA,2CAA2C;AAC3C,kCAAkC;AAClC;AACA;AACA;AACA;AACA,wBAAwB,kCAAY;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,cAAc;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,8BAAiB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,8BAAiB;AACxF;AACA;AACA;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA,sEAAsE,8BAAiB;AACvF,0BAA0B,+BAAS;AACnC,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,sEAAsE,8BAAiB;AACvF;AACA;AACA;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,kBAAkB,6CAAmB;AACrC;AACA;AACA,kBAAkB,4CAAkB;AACpC;AACA;AACA;AACA;AACA,qBAAqB,uBAAuB;AAC5C,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA,gDAAgD,gCAAgC;AAChF;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,mBAAmB,cAAc;AACjC;AACA,mBAAmB,cAAc;AACjC;AACA,mBAAmB,cAAc;AACjC;AACA,mBAAmB,cAAc;AACjC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;;ACnPA;AACA;AACA;AACA;AACA;AAC6D;AACV;AAC8B;AACvB;AACI;AACb;AAC1C;AACP;AACA;AACA;AACA;AACA;AACA,0EAA0E,iCAAW;AACrF;AACA;AACA;AACA,4CAA4C,MAAM;AAClD;AACA;AACA,0CAA0C,QAAQ,qGAAqG,uCAAiB;AACxK;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,8BAA8B,uCAAiB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,qDAAqD,8BAAiB;AACtE;AACA;AACA,8BAA8B,+BAAS;AACvC,kBAAkB,iBAAiB;AACnC,YAAY,sCAAgB,6BAA6B,sCAAc;AACvE;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iCAAW;AAClC;AACA;AACA;AACA;AACA;AACA,qBAAqB,uCAAiB;AACtC,mBAAmB,QAAQ;AAC3B;AACA;AACA;AACA;;AC1EA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,qCAAqC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;;;AC7CA;AACA;AACA;AACA;AACA;AAC4C;AACS;AACrD;AACA;AACA;AACO;AACP;AACA,0BAA0B,sBAAQ;AAClC;AACA;AACA,uDAAuD,cAAO;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,wBAAwB;AACpF,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,WAAW;AAC7B;AACA;AACA;AACA;AACA;AACA;;AC3FA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AACjC;;ACdA;AACA;AACA;AACA;AACA;AAC6D;AACT;AACD;AACqD;AAC5D;AAC8B;AAC3B;AACxC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,QAAQ;AAC/C,0CAA0C,QAAQ;AAClD;AACA;AACA,4BAA4B,aAAa;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,gBAAgB,8BAAiB;AACxE;AACA;AACA;AACA,mCAAmC,aAAa;AAChD;AACA;AACA,qCAAqC,aAAa;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oHAAoH,kBAAkB;AACtI;AACA;AACA;AACA;AACA;AACA,8EAA8E,yBAAyB,YAAY;AACnH,iCAAiC;AACjC;AACA,6BAA6B;AAC7B,6CAA6C,aAAa;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,aAAa;AACzC;AACA;AACA;AACA,iDAAiD,8BAAiB;AAClE,4BAA4B,aAAa;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,kBAAkB;AAC9F,oCAAoC,aAAa;AACjD;AACA;AACA;AACA;AACA;AACA,+BAA+B,yBAAM;AACrC;AACA;AACA;AACA;AACA;AACA,4CAA4C,aAAa;AACzD;AACA,SAAS;AACT;AACA;AACA;AACA,cAAc,iBAAiB;AAC/B;AACA;AACA;AACA;AACA;AACA,+BAA+B,aAAa;AAC5C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,UAAU;AACzB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,oBAAoB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,aAAa;AACzD;AACA,4CAA4C,aAAa;AACzD;AACA,4CAA4C,aAAa;AACzD;AACA;AACA,SAAS;AACT;AACA,4CAA4C,aAAa;AACzD;AACA;AACA,SAAS;AACT;AACA,4CAA4C,aAAa;AACzD;AACA;AACA,gDAAgD,aAAa;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,0BAA0B;AAC1F;AACA;AACA,2BAA2B,oBAAoB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,uFAAuF,oBAAoB;AAC3G;AACA;AACA,sCAAsC,qBAAqB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,UAAU;AACzB;AACA,SAAS;AACT;AACA;AACA;AACA,eAAe,UAAU;AACzB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sFAAsF,8BAAiB;AACvG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,gCAAkB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,uBAAuB,gCAAkB;AACzC,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,oBAAoB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mFAAmF;AACnF,+IAA+I,kBAAkB;AACjK;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzXA;AACA;AACA;AACA;AACA;AACoD;AACD;AACU;AACjB;AACK;AAC1C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,YAAY;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,iCAAW;AACxC;AACA;AACA;AACA,oBAAoB,QAAQ;AAC5B;AACA;AACA,aAAa;AACb,SAAS;AACT,eAAe,yBAAM;AACrB;AACA;AACA,2BAA2B,yBAAM;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,8BAAiB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,8BAAiB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3FA;AACA;AACA;AACA;AACA;AAC6D;AACW;AAClB;AAC/C;AACP;AACA;AACA,0BAA0B,sBAAQ;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,QAAQ,kGAAkG;AACrJ;AACA,qDAAqD,8BAAiB;AACtE;AACA;AACA;AACA,cAAc,iBAAiB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,cAAG;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,qBAAqB,QAAQ;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,QAAQ;AACpC;AACA;AACA;AACA;AACA;AACA;;AClHA;AACA;AACA;AACA;AACA;AACiF;AAC1E;AACP;AACA,eAAe,qCAAyB;AACxC;AACA;AACA,eAAe,qCAAyB;AACxC;AACA;AACO,mCAAmC;AACnC;AACP;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,mCAAmC,iBAAe;AAClD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;ACvEA;AACA;AACA;AACA;AACA;AAC8D;AACU;AAC5B;AACrC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,QAAQ;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,mCAAc;AAC9C;AACA;AACA,4BAA4B,EAAE,KAAK,EAAE,GAAG,EAAE;AAC1C,0BAA0B,MAAM,EAAE,KAAK,EAAE,GAAG,EAAE,gBAAgB,MAAM;AACpE;AACA;AACA;AACA;AACA;AACA,oBAAoB,0BAA0B;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,QAAQ;AACzC;AACA;AACA;AACA,2BAA2B,KAAK;AAChC,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,QAAQ;AACtC,4BAA4B,QAAQ;AACpC;AACA;AACA;AACA,2BAA2B,KAAK;AAChC,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,QAAQ;AAC9B,oBAAoB,QAAQ;AAC5B;AACA;AACA;AACA,mBAAmB,KAAK;AACxB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,KAAK,QAAQ,QAAQ,gDAAgD,QAAQ;AACxG,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,KAAK,QAAQ,QAAQ,yDAAyD,QAAQ;AAC7G,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,KAAK,QAAQ,QAAQ,yDAAyD,QAAQ;AACjH,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,2BAA2B,KAAK,QAAQ,QAAQ,yDAAyD,QAAQ;AACjH,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,KAAK,QAAQ,QAAQ,gDAAgD,QAAQ;AACpG,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,QAAQ;AAClC;AACA,wCAAwC,KAAK;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,KAAK;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,KAAK;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+FAA+F,KAAK;AACpG;AACA;AACA;AACA,2DAA2D,KAAK;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,YAAY,mBAAmB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,qCAAY;AACjE;AACA,sCAAsC,QAAQ;AAC9C;AACA;AACA,qCAAqC,QAAQ;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,UAAU;AACjC;AACA;AACA,sBAAsB,MAAM,EAAE,QAAQ;AACtC;AACA;AACA,sBAAsB,KAAK,IAAI,QAAQ;AACvC;AACA;AACA;AACA,qBAAqB,EAAE,MAAM;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sHAAsH;AACtH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,OAAO,GAAG,UAAU,EAAE,OAAO;AACnD;AACA,sBAAsB,MAAM,IAAI,QAAQ;AACxC;AACA;AACA,sBAAsB,KAAK,IAAI,QAAQ;AACvC;AACA;AACA;AACA,qBAAqB,EAAE,MAAM;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,QAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,cAAG;AACX,mBAAmB,QAAQ,IAAI,QAAQ;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3fA;AACA;AACA;AACA;AACA;AACoD;AACH;AAC1C;AACP;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,OAAO;AAC9B,gCAAgC,UAAU;AAC1C;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,cAAc,KAAK,GAAG,UAAU,GAAG;AAC1F,uBAAuB,QAAQ,IAAI,eAAe;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,iCAAW;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClEA;AACA;AACA;AACA;AACA;AACwE;AAChB;AACjD;AACP;AACA;AACA;AACA;AACA;AACA,YAAY,oBAAoB;AAChC;AACA;AACA,qBAAqB,qCAAe;AACpC;AACA;AACA;;ACnBA;AACA;AACA;AACA;AACA;AACyE;AAC7B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpJA;AACA;AACA;AACA;AACA;AACsF;AACe;AAC9F;AACP;AACA,uCAAuC,oCAAuB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,wBAAwB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,8BAAiB;AAChE,6BAA6B,sBAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,qCAAqC;AACpF;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1EA;AACA;AACA;AACA;AACA;AACuG;AACrC;AAC2C;AAC3D;AACF;AACE;AAC3C;AACP;AACA,uCAAuC,KAAK;AAC5C,kCAAkC,KAAK;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sFAAsF,QAAQ,oBAAoB;AAClH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,+BAAS;AACvC,oCAAoC;AACpC;AACA;AACA,kCAAkC,+BAAS;AAC3C,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,iCAAS;AACjC;AACA;AACA,6BAA6B,mCAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,iCAAS;AAC9B;AACA;AACA,qBAAqB,mCAAW;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,qCAAa;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0CAAkB;AAC9B;AACA;AACA,iBAAiB,qCAAa;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,+BAAS;AACvC,oCAAoC;AACpC;AACA;AACA;AACA,kCAAkC,+BAAS;AAC3C;AACA;AACA,8BAA8B,eAAe;AAC7C;AACA;AACA;AACA,8BAA8B,oBAAoB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,iCAAS;AACjC;AACA;AACA,6BAA6B,mCAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,iCAAS;AAC9B;AACA;AACA,qBAAqB,mCAAW;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0CAAkB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,eAAe;AACxC;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,+BAAS;AACvC,gBAAgB,iCAAiB;AACjC;AACA;AACA;AACA;AACA;AACA;;AClRA;AACA;AACA;AACA;AACA;AACoE;AACW;AACN;AACT;AACI;AACb;AACa;AACL;AACa;AACN;AACE;AACT;AACe;AACL;AACgD;AACjD;AACI;AACH;AACyB;AAC/B;AACQ;AACQ;AACI;AACV;AACE;AACjB;AACO;AACV;AAC3D;AACA;AACA;AACA;AACO;AACP;AACA;AACA,+CAA+C,sBAAsB;AACrE,qDAAqD,0BAA0B;AAC/E,SAAS;AACT;AACA,2CAA2C,kBAAkB;AAC7D,yCAAyC,mBAAmB;AAC5D,yCAAyC,mBAAmB;AAC5D,4CAA4C,sBAAsB;AAClE,sCAAsC,4CAAqB;AAC3D,oCAAoC,wCAAmB;AACvD,qCAAqC,YAAY;AACjD,kDAAkD,iCAAiC;AACnF,iDAAiD,gCAAgC;AACjF,SAAS;AACT;AACA,sCAAsC,qBAAqB;AAC3D,0DAA0D,iCAAiC;AAC3F,4DAA4D,mCAAmC;AAC/F,SAAS;AACT;AACA,sCAAsC,aAAa;AACnD,oCAAoC,mBAAmB;AACvD,6CAA6C,oBAAoB;AACjE,gDAAgD,uBAAuB;AACvE,0CAA0C,iBAAiB;AAC3D,SAAS;AACT;AACA,wCAAwC,eAAe;AACvD,8CAA8C,qBAAqB;AACnE,SAAS;AACT;AACA,iDAAiD,wBAAwB;AACzE,kDAAkD,kBAAkB;AACpE,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,2CAA2C,sBAAsB;AACjE;AACA,gDAAgD,uBAAuB;AACvE,sDAAsD,6BAA6B;AACnF,+CAA+C,sBAAsB;AACrE,4CAA4C,mBAAmB;AAC/D,gDAAgD,uBAAuB;AACvE;AACA,qCAAqC,oBAAoB;AACzD,qDAAqD,4BAA4B;AACjF;AACA;AACA;AACA;;;;;;;;;;;;AChGA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,+CAA+C;AAC/C,CAAC,wBAAwB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,sHAAsH;AACtH;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kHAAkH,kBAAkB;AACpI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1IA;AACA;AACA;AACA;AAC6D;AACtD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO;AACA;AACP;AACA;AACO,0CAA0C,4EAAqB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,wBAAwB,GAAG,iBAAiB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,aAAa;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,cAAc;AACxC,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,cAAc;AACxC,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,kDAAkD;AAC5E,0BAA0B,wCAAwC;AAClE,0BAA0B,mCAAmC;AAC7D,0BAA0B,sCAAsC;AAChE,0BAA0B,yCAAyC;AACnE,0BAA0B,cAAc;AACxC,0BAA0B,iCAAiC;AAC3D,0BAA0B,iCAAiC;AAC3D,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,sCAAsC;AAChE,0BAA0B,cAAc;AACxC,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,2CAA2C;AACrE,0BAA0B,mBAAmB;AAC7C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,kBAAkB;AAC5C,0BAA0B,kDAAkD;AAC5E,0BAA0B,oBAAoB;AAC9C,0BAA0B,oCAAoC;AAC9D,0BAA0B,uCAAuC;AACjE,0BAA0B,wCAAwC;AAClE,0BAA0B,sBAAsB;AAChD,0BAA0B,cAAc;AACxC,0BAA0B,sCAAsC;AAChE,0BAA0B,oBAAoB;AAC9C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,uBAAuB;AACjD,0BAA0B,oBAAoB;AAC9C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,oBAAoB;AAC9C,0BAA0B,uCAAuC;AACjE,0BAA0B,qCAAqC;AAC/D,0BAA0B,cAAc;AACxC,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,cAAc;AACxC,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,sBAAsB;AAChD,0BAA0B,yCAAyC;AACnE,0BAA0B,cAAc;AACxC,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,iBAAiB;AAC3C,0BAA0B,sBAAsB;AAChD,0BAA0B,mBAAmB;AAC7C,0BAA0B,kBAAkB;AAC5C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,oCAAoC;AAC9D,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,iBAAiB;AAC3C,0BAA0B,mBAAmB;AAC7C,0BAA0B,kBAAkB;AAC5C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,cAAc;AACxC,0BAA0B,mBAAmB;AAC7C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,+CAA+C;AACzE,0BAA0B,mBAAmB;AAC7C,0BAA0B,kBAAkB;AAC5C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,oCAAoC;AAC9D,0BAA0B,wBAAwB;AAClD,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,mBAAmB;AAC7C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,mBAAmB;AAC7C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,mBAAmB;AAC7C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qCAAqC;AAC/D,0BAA0B,qBAAqB;AAC/C,0BAA0B,mBAAmB;AAC7C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,oCAAoC;AAC9D,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,oCAAoC;AAC9D,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,mBAAmB;AAC7C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,oCAAoC;AAC9D,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B,mBAAmB;AAC7C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qBAAqB;AAC/C,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;;;;;;;;;;;;;;;;;ACxsBA;AACA;AACA;AACA;AACA;AACmC;AACqD;AAC9B;AACsB;AACmB;AACvD;AACrC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,kEAAM,CAAC,uFAAoB;AAC1D;AACA;AACA;AACA;AACA,+EAA+E,8EAAY;AAC3F;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,iFAAc;AAC1C;AACA;AACA;AACA,sBAAsB,gFAAa;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,8EAAY,UAAU,uDAAK;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,+EAAY;AAChC,6BAA6B,gFAAiB,cAAc,4EAAS;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,2FAAyB;AAChD;AACA;AACA;AACA;AACA;AACA,sFAAsF,gFAAc;AACpG;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;;;;;;;;;;;;;AC1HA;AACA;AACA;AACA;AACA;AAC6E;AACM;AAC5E;AACP;AACA;AACA,YAAY,uFAAgB;AAC5B,sBAAsB,4FAAyB;AAC/C;AACA,YAAY,iFAAU;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,8EAAW;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;;;;;;;;;;;;;;;;;;AClGA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,qBAAqB;AAC3D;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;AChFA;AACA;AACA;AACA;AACA;AAC2D;AACmB;AACrC;AACzC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,wBAAwB,oEAAS;AACjC;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,qBAAqB,oEAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,eAAe,2DAAU;AACzB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,oBAAoB,oEAAS;AAC7B;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,oEAAS;AACrC,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6DAAW;AAC1B,KAAK;AACL;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,eAAe,gEAAc;AAC7B;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,mBAAmB,gEAAc;AACjC;AACA,eAAe,gEAAc,gDAAgD,mBAAmB;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,gEAAO;AAClB;AACA;AACA;AACA;AACA;AACO;AACP,eAAe,2DAAU;AACzB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,oBAAoB,sEAAW;AAC/B;AACA,6BAA6B,sBAAsB;AACnD;AACA;AACA;AACA;AACA;AACA,4BAA4B,sEAAW;AACvC,qCAAqC,sBAAsB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6DAAW;AAC1B,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AChRA;AACA;AACA;AACA;AACA;AACqF;AACxC;AAC7C;AACA;AACA;AACA;AACO;AACP,eAAe,gEAAc;AAC7B,YAAY,6EAAkB;AAC9B;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI,mBAAmB;AAC5B;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,YAAY,qBAAqB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C;AACpC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,UAAU,GAAG;AACb;AACO,kCAAkC,EAAE;AAC3C;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,YAAY,wEAAa;AACzB;AACA;AACA;AACA,uCAAuC,QAAQ;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,wEAAa;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,4CAA4C;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACpTA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,wBAAwB,SAAS,KAAK,sBAAsB,GAAG,2BAA2B;AAC1F;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACuD;AACF;AACE;AACgB;AAC5B;AACoB;AAC/D;AACA;AACA;AACA;AACO;AACP,mCAAmC,+EAAgB;AACnD;AACA;AACA;AACA;AACO;AACP,uCAAuC,iFAAkB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,iFAAkB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,0EAAiB;AACrB,YAAY,6EAAc,2BAA2B,qFAAsB;AAC3E;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,mCAAmC,wEAAY;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,2EAAkB,qBAAqB,+EAAgB;AACnF;AACA;AACA;AACA;AACA,QAAQ,6EAAkB;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,4EAAa;AACrB;AACA;AACA,yBAAyB,kEAAS;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,4EAAa;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,2BAA2B,2EAAkB,wBAAwB,+EAAgB;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,iFAAkB;AAC1B;AACA,YAAY,2EAAY;AACxB;AACA;AACA;AACA,iBAAiB,+EAAgB;AACjC;AACA;AACA;AACA;AACA,YAAY,4EAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB,OAAO,+EAAgB;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,0EAAiB;AACxC,YAAY,+EAAgB;AAC5B;AACA;AACA;AACA,iBAAiB,6EAAc,UAAU,+EAAgB;AACzD;AACA;AACA,iBAAiB,+EAAgB;AACjC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,gCAAgC,QAAQ;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,0EAAiB;AACxC,YAAY,6EAAc;AAC1B;AACA;AACA;AACA;AACA,gBAAgB,+EAAgB;AAChC;AACA;AACA;AACA,iBAAiB,+EAAgB;AACjC;AACA;AACA,iBAAiB,2EAAY;AAC7B;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,+EAAgB;AAChC;AACA;AACA,qBAAqB,8EAAe,aAAa,yEAAU;AAC3D;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,+EAAgB;AACxB;AACA;AACA,aAAa,8EAAe,UAAU,yEAAU,UAAU,+EAAgB;AAC1E;AACA;AACA,aAAa,2EAAY;AACzB;AACA;AACA;AACA;AACA;AACA,aAAa,iFAAkB;AAC/B;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;AACA;AACA;AACO;AACP;AACA,QAAQ,iFAAkB;AAC1B;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,yFAA0B;AAClC;AACA;AACA,aAAa,kFAAmB;AAChC;AACA;AACA,aAAa,mFAAoB;AACjC;AACA;AACA,aAAa,qFAAsB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,aAAa,iFAAkB;AAC/B;AACA;AACA,aAAa,+EAAgB;AAC7B;AACA;AACA,aAAa,+EAAgB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,aAAa,6EAAc;AAC3B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,qDAAqD,gEAAgE;AACrH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,8BAA8B,SAAS,IAAI,uCAAuC;AAClF;AACA;AACA,KAAK;AACL;AACA;AACA,iCAAiC,wCAAwC,GAAG,SAAS;AACrF;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,mCAAmC,2BAA2B,GAAG,4BAA4B;AAC7F;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,WAAW,wEAAY;AACvB;AACA;AACA;AACA;AACA,oBAAoB,6DAA6D,EAAE,MAAM;AACzF;AACA;AACA,kBAAkB,MAAM,EAAE,oBAAoB;AAC9C;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACnkBA;AACA;AACA;AACA;AACA;AAC4E;AACrE;AACP,yBAAyB,4EAAY;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,iFAAiB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,qBAAqB,OAAO;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACO;AACP;AACA;AACA;AACO;AACP,mCAAmC;AACnC;AACO;AACP,+EAA+E,qBAAqB,EAAE,qBAAqB;AAC3H;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD;AACxD,oEAAoE;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB,6BAA6B,UAAU;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACxSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,6EAA6E;AACpH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,cAAc;AAClC;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,sBAAsB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,cAAc;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,wBAAwB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,cAAc;AACtC;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,eAAe;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,uCAAuC,gCAAgC;AACvE;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,uCAAuC,+CAA+C;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO,oCAAoC,8BAA8B;AACzE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,UAAU;AACrD;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,uCAAuC,2BAA2B;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AAC/B;;;;;;;;;;;;AC7fA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;AChBqC;;AAErC;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,aAAa,GAAG;AAChB;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,qCAAqC,iEAAQ;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iEAAe,YAAY,EAAC;;;;;;;;;;;;AC/B5B;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,WAAW,GAAG;AACd,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;;AAEA,iEAAe,MAAM,EAAC;;;;;;;;;;;;;;ACbgB;AACK;;AAE3C;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA,eAAe,oEAAW;;AAE1B,EAAE,iEAAQ;AACV;AACA,GAAG;AACH;AACA;;AAEA,iEAAe,OAAO,EAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrBqB;AACN;AACF;AACC;AACL;;AAEhC;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,cAAc;AACzB,WAAW,GAAG;AACd,WAAW,UAAU;AACrB,aAAa,QAAQ;AACrB;AACA;AACA,OAAO,2BAAQ;AACf;AACA;AACA,SAAS,4BAAQ;;AAEjB;AACA;AACA;AACA;;AAEA;AACA,cAAc,yBAAK;AACnB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,2BAAQ;AAC3B;AACA,aAAa,2BAAO,2BAA2B;AAC/C;AACA;AACA,IAAI,+BAAW;AACf;AACA;AACA;AACA;;AAEA,+CAAe,OAAO,EAAC;;;AClDa;AACA;AACE;;AAEtC;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAgB,2BAAO;;AAEvB;AACA,MAAM,QAAO,SAAS,4BAAQ;AAC9B;AACA;AACA;AACA;;AAEA,kDAAe,UAAU,EAAC;;;;;;;;;;;;;AC7Bc;;AAExC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,GAAG;AAChB;AACA;AACA;AACA,oBAAoB,QAAQ,IAAI,QAAQ;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,kEAAS;AAClB;;AAEA,iEAAe,KAAK,EAAC;;;;;;;;;;;;;;;;ACnCiB;AACb;AACyB;AACjB;;AAEjC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,WAAW;AACtB,aAAa,QAAQ;AACrB;AACA;AACA;AACA,gBAAgB,QAAQ,IAAI,QAAQ,IAAI,QAAQ;AAChD,WAAW;AACX;AACA,eAAe,iEAAQ;AACvB;;AAEA;AACA;AACA;;AAEA,eAAe,uEAAc;AAC7B;AACA;;AAEA;AACA;AACA,gBAAgB,+DAAM;AACtB;AACA;;AAEA;AACA;AACA;;AAEA;AACA,WAAW,2DAAE;AACb;AACA;AACA;AACA;;AAEA;AACA,CAAC;;AAED,iEAAe,QAAQ,EAAC;;;;;;;;;;;;;;;;;;;;;;AC/DsB;AACH;AACd;;AAE7B;AACA;AACA;AACA;AACA,WAAW,UAAU;AACrB,aAAa,UAAU;AACvB;AACA;AACA;AACA;AACA,SAAS,8BAAW;AACpB,qBAAqB,gCAAY;AACjC,mBAAmB,uBAAI;AACvB,kCAAkC;AAClC;AACA;AACA;AACA;AACA;;AAEA,kDAAe,UAAU,EAAC;;;;;;;ACxBsB;AACF;AACP;;AAEvC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACA;AACA;AACA,OAAO,oCAAoC;AAC3C,OAAO,oCAAoC;AAC3C,OAAO;AACP;AACA;AACA,oCAAoC,4BAA4B;AAChE;AACA;AACA;AACA,wBAAwB,iCAAiC;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,4BAAS;AAC/C;AACA;AACA;AACA,SAAS,iCAAa,QAAQ,gCAAY;AAC1C;;AAEA,0DAAe,SAAS,EAAC;;;ACtDiB;AACH;;AAEvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,WAAW,QAAQ;AACnB,aAAa,GAAG;AAChB;AACA;AACA;AACA,OAAO,8CAA8C;AACrD,OAAO,+CAA+C;AACtD,OAAO;AACP;AACA;AACA,+BAA+B,oBAAoB;AACnD;AACA;AACA;AACA,mBAAmB,0BAA0B;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,WAAU,CAAC,mBAAS;;AAE/B,qDAAe,IAAI,EAAC;;;;;;;;;;;;;;ACzCwB;AACjB;;AAE3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,oEAAW,CAAC,4DAAG;AACxB;;AAEA,iEAAe,OAAO,EAAC;;;;;;;;;;;;;AC5BqB;;AAE5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,oEAAW;AAC7B;;AAEA,iEAAe,OAAO,EAAC;;;;;;;;;;;;;;;;ACrBvB;AACA;;AAEA;AACA,IAAI,uBAAc;;AAElB;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,cAAc;AACzB,aAAa,SAAS;AACtB;AACA;AACA,2BAA2B,uBAAc;AACzC;;AAEA,+CAAe,OAAO,EAAC;;;;;AClBa;AACA;;AAEpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,cAAc;AACzB,aAAa,SAAS;AACtB;AACA;AACA,kBAAkB,OAAO;AACzB,0BAA0B,gBAAgB,QAAQ,GAAG;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,2BAAO,eAAe,QAAO;AACxD;;AAEA,oDAAe,GAAG,EAAC;;;;;;;;;;;;;;;AClCuB;AACP;AACU;;AAE7C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,gEAAO,WAAW,qEAAY,WAAW,mEAAU;AACzD;;AAEA,iEAAe,QAAQ,EAAC;;;;;;;;;;;;AC7BxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,GAAG;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iEAAe,IAAI,EAAC;;;;;;;;;;;;;;;;ACnBkB;AACQ;AACV;AACD;;AAEnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,gBAAgB;AAC3B;AACA;AACA;AACA,OAAO,kBAAkB;AACzB,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,gEAAO,eAAe,6DAAQ,GAAG,4DAAO;AACrD,0BAA0B,qEAAY;AACtC;;AAEA,iEAAe,GAAG,EAAC;;;;;;;;;;;;;;;ACpD2B;AACZ;AACG;;AAErC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,GAAG;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,qEAAY,QAAQ,6DAAQ,EAAE,2DAAM;AAC1C;AACA;;AAEA,iEAAe,GAAG,EAAC;;;;;;;;;;;;;;;;AC5BnB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uDAAe,eAAe,EAAC;;;AClBqB;;AAEpD;AACA;;AAEA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACA;AACA;AACA,sBAAsB,gBAAe;AACrC;AACA;;AAEA,gDAAe,QAAQ,EAAC;;;;;;;AClBc;AACD;AACA;;AAErC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,2BAAQ;AACd;AACA;AACA,MAAM,2BAAQ;AACd;AACA,YAAY,2BAAQ;AACpB;AACA;AACA;AACA;AACA,UAAU,SAAQ;AAClB;AACA;AACA;AACA;AACA;;AAEA,yDAAe,QAAQ,EAAC;;;AC/Da;;AAErC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,kBAAQ;AAClB;AACA;AACA;AACA;AACA;AACA;;AAEA,yDAAe,QAAQ,EAAC;;;;;;;;;;;;;ACzCa;;AAErC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,iEAAQ;AACvB;;AAEA;AACA;;AAEA,iEAAe,SAAS,EAAC;;;;;;;;ACnCzB;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA,MAAM;AACN;AACA;AACA,EAAE;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;;;;AAIA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sCAAsC;;AAEtC;AACA;AACA;;AAEA,4BAA4B;AAC5B;AACA;AACA;AACA,6BAA6B;;;;;;;;;ACvLhB;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,+BAA+B,GAAG,yBAAyB;AAC3D,cAAc,mBAAO,CAAC,KAAO;AAC7B,WAAW,mBAAO,CAAC,KAAM;AACzB,iBAAiB,mBAAO,CAAC,GAAU;AACnC;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wBAAwB,yBAAyB,yBAAyB;AAC3E;AACA;AACA,aAAa,YAAY;AACzB,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;;;;;;;;;AC/FlB;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,eAAe,GAAG,aAAa;AAC/B,cAAc,mBAAO,CAAC,KAAO;AAC7B;AACA;AACA,0BAA0B;AAC1B,+BAA+B;AAC/B,CAAC,YAAY,aAAa,aAAa;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,+CAA+C;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,SAAS;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,SAAS;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;;;;;;;;;AC/Ha;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,mBAAmB,GAAG,aAAa,GAAG,YAAY,GAAG,aAAa,GAAG,cAAc,GAAG,cAAc,GAAG,eAAe;AACtH;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,mBAAmB;;;;;;;;;AClCN;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,kBAAkB;AACnB,kBAAe;;;;;;;;;;;;;;ACtBf,QAAQ,MAAM,aAAa,OAAO,QAAQ,cAAc,gGAAgG,gBAAgB,gCAAgC,YAAY,KAAK,gCAAgC,KAAK,gBAAgB,KAAK,WAAW,mBAAmB,wBAAwB,kGAAkG,yBAAyB,mBAAmB,yEAAyE,UAAU,oCAAoC,iBAAiB,SAAS,oCAAoC,+DAA+D,QAAQ,6BAA6B,SAAS,OAAO,mBAAmB,yCAAyC,UAAU,KAAK,MAAM,oCAAoC,OAAO,mEAAmE,yDAAyD,uBAAuB,+BAA+B,2DAA2D,4EAA4E,wBAAwB,6CAA6C,iBAAiB,kCAAkC,cAAc,mBAAmB,KAAK,mBAAmB,2CAA2C,qCAAqC,wBAAwB,4BAA4B,gDAAgD,YAAY,iCAAiC,KAAK,6BAA6B,iCAAiC,KAAK,wCAAwC,KAAK,KAAK,UAAU,QAAQ,gDAAgD,6BAA6B,oDAAoD,MAAM,wBAAwB,+BAA+B,cAAc,SAAS,YAAY,KAAK,iEAAiE,6EAA6E,uBAAuB,SAAS,qBAAqB,+BAA+B,0DAA0D,KAAK,iCAAiC,OAAO,IAAI,OAAO,UAAU,kDAAkD,wBAAwB,yFAAyF,KAAK,oBAAoB,+CAA+C,uCAAuC,sBAAsB,iBAAiB,KAAK,KAAK,sBAAsB,WAAW,OAAO,MAAM,OAAO,+EAA+E,mDAAmD,iBAAiB,KAAK,6BAA6B,OAAO,MAAM,OAAO,yBAAyB,6BAA6B,qBAAqB,KAAK,4CAA4C,KAAK,KAAK,sBAAsB,6EAA6E,YAAY,MAAM,OAAO,qEAAqE,oBAAoB,iIAAiI,qBAAqB,uDAAuD,kCAAkC,MAAM,mBAAmB,KAAK,OAAO,uCAAuC,yBAAyB,iCAAiC,uBAAuB,4CAA4C,KAAK,mGAAmG,YAAY,MAAM,MAAM,4QAA4Q,8CAA8C,uBAAuB,MAAM,cAAc,WAAW,+BAA+B,YAAY,YAAY,qCAAqC,YAAY,+DAA+D,uBAAuB,EAAE,8DAA8D,4FAA4F,eAAe,wCAAwC,SAAS,GAAG,SAAS,MAAM,MAAM,iBAAiB,sBAAsB,mBAAmB,OAAO,aAAa,OAAO,UAAU,oCAAoC,0BAA0B,0BAA0B,2CAA2C,gBAAgB,iEAAiE,0BAA0B,YAAY,YAAY,OAAO,aAAa,QAAQ,gBAAgB,WAAW,EAAE,GAAG,kGAAkG,0BAA0B,+KAA+K,oKAAoK,kFAAkF,QAAQ,gBAAgB,yPAAyP,OAAO,UAAU,KAAK,MAAM,SAAS,4BAA4B,4KAA4K,qBAAqB,kDAAkD,UAAU,0DAA0D,SAAS,iEAAiE,aAAa,kBAAkB,QAAQ,kBAAkB,IAAI,+CAA+C,GAAG,kUAAkU,qBAAqB,kBAAkB,uFAAuF,eAAe,QAAQ,iDAAiD,uBAAuB,uEAAuE,6BAA6B,eAAe,8DAA8D,iBAAiB,eAAe,iBAAiB,SAAS,YAAY,iBAAiB,MAAM,4BAA4B,iBAAiB,qEAAqE,UAAU,mBAAmB,kBAAkB,gBAAgB,aAAa,aAAa,4DAA4D,eAAe,oFAAoF,SAAS,SAAS,QAAQ,iSAAiS,SAAS,4KAA4K,kBAAkB,WAAW,YAAY,WAAW,KAAK,wBAAwB,8MAA8M,KAAK,8BAA8B,aAAa,wFAAwF,qEAAqE,cAAc,MAAM,YAAY,WAAW,KAAK,wBAAwB,6EAA6E,sBAAsB,gBAAgB,MAAM,8DAA8D,YAAY,EAAE,OAAO,oQAAoQ,gBAAgB,cAAc,UAAU,+CAA+C,GAAG,oDAAoD,qBAAqB,WAAW,sBAAsB,8HAA8H,uGAAuG,MAAM,4DAA4D,wBAAwB,qBAAqB,0BAA0B,GAAG,YAAY,GAAG,2CAA2C,wBAAwB,oBAAoB,0BAA0B,GAAG,YAAY,GAAG,cAAc,iEAAiE,cAAc,IAAI,6BAA6B,MAAM,kDAAkD,sCAAsC,cAAc,2CAA2C,aAAa,yBAAyB,MAAM,aAAa,4BAA4B,eAAe,yBAAyB,EAAE,gCAAgC,kBAAkB,uBAAuB,wBAAwB,6DAA6D,OAAO,EAAE,uBAAuB,0CAA0C,wBAAwB,0DAA0D,OAAO,EAAE,wBAAwB,0BAA0B,uBAAuB,0BAA0B,SAAS,GAAG,UAAU,IAAW,MAAM,UAAU;AAC98U","sources":["webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/regexp-to-ast/lib/src/utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/regexp-to-ast/lib/src/character-classes.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/regexp-to-ast/lib/src/regexp-parser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/regexp-to-ast/lib/src/base-regexp-visitor.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/regexp-to-ast/lib/src/api.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-2NYFTIL2.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-2O5ZK7RR.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/grammar-loader.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-7PKI6E2E.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-C4OEIS7N.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-EXZZNE6F.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-ROXG7S4E.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-V4Q32G6S.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/mermaid-parser.core.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/utils/lib/src/to-fast-properties.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseSlice.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/drop.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/assign.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/pickBy.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseIsRegExp.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/isRegExp.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/gast/lib/src/model.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/rest.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/uniq.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseSome.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/some.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/includes.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_arrayEvery.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseEvery.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/every.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/gast/lib/src/helpers.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/first.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/constants.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/follow.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/negate.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/reject.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/indexOf.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseDifference.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/difference.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/compact.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/head.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/utils/lib/src/print.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/reg_exp_parser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/reg_exp.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/lexer.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/utils/lib/src/timer.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/tokens.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/lexer_errors_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/lexer_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/tokens_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/errors_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/gast/lib/src/visitor.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/resolver.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_arrayAggregator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseAggregator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_createAggregator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/groupBy.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/dropRight.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/interpreter.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/lookahead.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/checks.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/gast/gast_resolver_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/exceptions_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/recoverable.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/keys.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/llk_lookahead.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/looksahead.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/cst/cst.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/lang/lang_extensions.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/cst/cst_visitor.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/tree_builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/lexer_adapter.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/recognizer_api.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/recognizer_engine.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/error_handler.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/context_assist.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/gast_recorder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/perf_tracer.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/utils/apply_mixins.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/parser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/cst-dts-gen/lib/src/api.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/api.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/languages/grammar-config.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain-allstar/lib/atn.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain-allstar/lib/dfa.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/uniqBy.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain-allstar/lib/all-star-lookahead.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain-allstar/lib/index.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-types/lib/esm/main.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/cst-node-builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/langium-parser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/parser-builder-base.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/completion-parser-builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/langium-parser-builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/promise-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-textdocument/lib/esm/main.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/documents.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/linker.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/name-provider.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/uri-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/references.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/collections.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/scope-computation.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/scope.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/caching.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/scope-provider.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/serializer/json-serializer.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/service-registry.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/validation/validation-registry.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/validation/document-validator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/ast-descriptions.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/ast-node-locator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/configuration.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/disposable.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/document-builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/index-manager.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/workspace-manager.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/lexer.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/documentation/jsdoc.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/documentation/documentation-provider.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/documentation/comment-provider.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/async-parser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/workspace-lock.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/serializer/hydrator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/default-module.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/dependency-injection.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/languages/generated/ast.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/token-builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/value-converter.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/syntax-tree.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/ast-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/cst-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/errors.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/grammar-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/regexp-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/stream.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/file-system-provider.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseExtremum.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseLt.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseMap.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseSet.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_basePickBy.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/clone.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/defaults.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_createFind.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/findIndex.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/find.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/flatMap.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/flatten.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseHas.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/has.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/isString.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/last.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/map.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/min.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_trimmedEndIndex.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseTrim.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/toNumber.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/toFinite.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/toInteger.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/process/browser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-jsonrpc/lib/common/cancellation.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-jsonrpc/lib/common/events.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-jsonrpc/lib/common/is.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-jsonrpc/lib/common/ral.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-uri/lib/esm/index.mjs"],"sourcesContent":["export function cc(char) {\n    return char.charCodeAt(0);\n}\nexport function insertToSet(item, set) {\n    if (Array.isArray(item)) {\n        item.forEach(function (subItem) {\n            set.push(subItem);\n        });\n    }\n    else {\n        set.push(item);\n    }\n}\nexport function addFlag(flagObj, flagKey) {\n    if (flagObj[flagKey] === true) {\n        throw \"duplicate flag \" + flagKey;\n    }\n    const x = flagObj[flagKey];\n    flagObj[flagKey] = true;\n}\nexport function ASSERT_EXISTS(obj) {\n    // istanbul ignore next\n    if (obj === undefined) {\n        throw Error(\"Internal Error - Should never get here!\");\n    }\n    return true;\n}\n// istanbul ignore next\nexport function ASSERT_NEVER_REACH_HERE() {\n    throw Error(\"Internal Error - Should never get here!\");\n}\nexport function isCharacter(obj) {\n    return obj[\"type\"] === \"Character\";\n}\n//# sourceMappingURL=utils.js.map","import { cc } from \"./utils.js\";\nexport const digitsCharCodes = [];\nfor (let i = cc(\"0\"); i <= cc(\"9\"); i++) {\n    digitsCharCodes.push(i);\n}\nexport const wordCharCodes = [cc(\"_\")].concat(digitsCharCodes);\nfor (let i = cc(\"a\"); i <= cc(\"z\"); i++) {\n    wordCharCodes.push(i);\n}\nfor (let i = cc(\"A\"); i <= cc(\"Z\"); i++) {\n    wordCharCodes.push(i);\n}\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp#character-classes\nexport const whitespaceCodes = [\n    cc(\" \"),\n    cc(\"\\f\"),\n    cc(\"\\n\"),\n    cc(\"\\r\"),\n    cc(\"\\t\"),\n    cc(\"\\v\"),\n    cc(\"\\t\"),\n    cc(\"\\u00a0\"),\n    cc(\"\\u1680\"),\n    cc(\"\\u2000\"),\n    cc(\"\\u2001\"),\n    cc(\"\\u2002\"),\n    cc(\"\\u2003\"),\n    cc(\"\\u2004\"),\n    cc(\"\\u2005\"),\n    cc(\"\\u2006\"),\n    cc(\"\\u2007\"),\n    cc(\"\\u2008\"),\n    cc(\"\\u2009\"),\n    cc(\"\\u200a\"),\n    cc(\"\\u2028\"),\n    cc(\"\\u2029\"),\n    cc(\"\\u202f\"),\n    cc(\"\\u205f\"),\n    cc(\"\\u3000\"),\n    cc(\"\\ufeff\"),\n];\n//# sourceMappingURL=character-classes.js.map","import { addFlag, ASSERT_EXISTS, ASSERT_NEVER_REACH_HERE, cc, insertToSet, isCharacter, } from \"./utils.js\";\nimport { digitsCharCodes, whitespaceCodes, wordCharCodes, } from \"./character-classes.js\";\n// consts and utilities\nconst hexDigitPattern = /[0-9a-fA-F]/;\nconst decimalPattern = /[0-9]/;\nconst decimalPatternNoZero = /[1-9]/;\n// https://hackernoon.com/the-madness-of-parsing-real-world-javascript-regexps-d9ee336df983\n// https://www.ecma-international.org/ecma-262/8.0/index.html#prod-Pattern\nexport class RegExpParser {\n    constructor() {\n        this.idx = 0;\n        this.input = \"\";\n        this.groupIdx = 0;\n    }\n    saveState() {\n        return {\n            idx: this.idx,\n            input: this.input,\n            groupIdx: this.groupIdx,\n        };\n    }\n    restoreState(newState) {\n        this.idx = newState.idx;\n        this.input = newState.input;\n        this.groupIdx = newState.groupIdx;\n    }\n    pattern(input) {\n        // parser state\n        this.idx = 0;\n        this.input = input;\n        this.groupIdx = 0;\n        this.consumeChar(\"/\");\n        const value = this.disjunction();\n        this.consumeChar(\"/\");\n        const flags = {\n            type: \"Flags\",\n            loc: { begin: this.idx, end: input.length },\n            global: false,\n            ignoreCase: false,\n            multiLine: false,\n            unicode: false,\n            sticky: false,\n        };\n        while (this.isRegExpFlag()) {\n            switch (this.popChar()) {\n                case \"g\":\n                    addFlag(flags, \"global\");\n                    break;\n                case \"i\":\n                    addFlag(flags, \"ignoreCase\");\n                    break;\n                case \"m\":\n                    addFlag(flags, \"multiLine\");\n                    break;\n                case \"u\":\n                    addFlag(flags, \"unicode\");\n                    break;\n                case \"y\":\n                    addFlag(flags, \"sticky\");\n                    break;\n            }\n        }\n        if (this.idx !== this.input.length) {\n            throw Error(\"Redundant input: \" + this.input.substring(this.idx));\n        }\n        return {\n            type: \"Pattern\",\n            flags: flags,\n            value: value,\n            loc: this.loc(0),\n        };\n    }\n    disjunction() {\n        const alts = [];\n        const begin = this.idx;\n        alts.push(this.alternative());\n        while (this.peekChar() === \"|\") {\n            this.consumeChar(\"|\");\n            alts.push(this.alternative());\n        }\n        return { type: \"Disjunction\", value: alts, loc: this.loc(begin) };\n    }\n    alternative() {\n        const terms = [];\n        const begin = this.idx;\n        while (this.isTerm()) {\n            terms.push(this.term());\n        }\n        return { type: \"Alternative\", value: terms, loc: this.loc(begin) };\n    }\n    term() {\n        if (this.isAssertion()) {\n            return this.assertion();\n        }\n        else {\n            return this.atom();\n        }\n    }\n    assertion() {\n        const begin = this.idx;\n        switch (this.popChar()) {\n            case \"^\":\n                return {\n                    type: \"StartAnchor\",\n                    loc: this.loc(begin),\n                };\n            case \"$\":\n                return { type: \"EndAnchor\", loc: this.loc(begin) };\n            // '\\b' or '\\B'\n            case \"\\\\\":\n                switch (this.popChar()) {\n                    case \"b\":\n                        return {\n                            type: \"WordBoundary\",\n                            loc: this.loc(begin),\n                        };\n                    case \"B\":\n                        return {\n                            type: \"NonWordBoundary\",\n                            loc: this.loc(begin),\n                        };\n                }\n                // istanbul ignore next\n                throw Error(\"Invalid Assertion Escape\");\n            // '(?=' or '(?!'\n            case \"(\":\n                this.consumeChar(\"?\");\n                let type;\n                switch (this.popChar()) {\n                    case \"=\":\n                        type = \"Lookahead\";\n                        break;\n                    case \"!\":\n                        type = \"NegativeLookahead\";\n                        break;\n                }\n                ASSERT_EXISTS(type);\n                const disjunction = this.disjunction();\n                this.consumeChar(\")\");\n                return {\n                    type: type,\n                    value: disjunction,\n                    loc: this.loc(begin),\n                };\n        }\n        // istanbul ignore next\n        return ASSERT_NEVER_REACH_HERE();\n    }\n    quantifier(isBacktracking = false) {\n        let range = undefined;\n        const begin = this.idx;\n        switch (this.popChar()) {\n            case \"*\":\n                range = {\n                    atLeast: 0,\n                    atMost: Infinity,\n                };\n                break;\n            case \"+\":\n                range = {\n                    atLeast: 1,\n                    atMost: Infinity,\n                };\n                break;\n            case \"?\":\n                range = {\n                    atLeast: 0,\n                    atMost: 1,\n                };\n                break;\n            case \"{\":\n                const atLeast = this.integerIncludingZero();\n                switch (this.popChar()) {\n                    case \"}\":\n                        range = {\n                            atLeast: atLeast,\n                            atMost: atLeast,\n                        };\n                        break;\n                    case \",\":\n                        let atMost;\n                        if (this.isDigit()) {\n                            atMost = this.integerIncludingZero();\n                            range = {\n                                atLeast: atLeast,\n                                atMost: atMost,\n                            };\n                        }\n                        else {\n                            range = {\n                                atLeast: atLeast,\n                                atMost: Infinity,\n                            };\n                        }\n                        this.consumeChar(\"}\");\n                        break;\n                }\n                // throwing exceptions from \"ASSERT_EXISTS\" during backtracking\n                // causes severe performance degradations\n                if (isBacktracking === true && range === undefined) {\n                    return undefined;\n                }\n                ASSERT_EXISTS(range);\n                break;\n        }\n        // throwing exceptions from \"ASSERT_EXISTS\" during backtracking\n        // causes severe performance degradations\n        if (isBacktracking === true && range === undefined) {\n            return undefined;\n        }\n        // istanbul ignore else\n        if (ASSERT_EXISTS(range)) {\n            if (this.peekChar(0) === \"?\") {\n                this.consumeChar(\"?\");\n                range.greedy = false;\n            }\n            else {\n                range.greedy = true;\n            }\n            range.type = \"Quantifier\";\n            range.loc = this.loc(begin);\n            return range;\n        }\n    }\n    atom() {\n        let atom;\n        const begin = this.idx;\n        switch (this.peekChar()) {\n            case \".\":\n                atom = this.dotAll();\n                break;\n            case \"\\\\\":\n                atom = this.atomEscape();\n                break;\n            case \"[\":\n                atom = this.characterClass();\n                break;\n            case \"(\":\n                atom = this.group();\n                break;\n        }\n        if (atom === undefined && this.isPatternCharacter()) {\n            atom = this.patternCharacter();\n        }\n        // istanbul ignore else\n        if (ASSERT_EXISTS(atom)) {\n            atom.loc = this.loc(begin);\n            if (this.isQuantifier()) {\n                atom.quantifier = this.quantifier();\n            }\n            return atom;\n        }\n        // istanbul ignore next\n        return ASSERT_NEVER_REACH_HERE();\n    }\n    dotAll() {\n        this.consumeChar(\".\");\n        return {\n            type: \"Set\",\n            complement: true,\n            value: [cc(\"\\n\"), cc(\"\\r\"), cc(\"\\u2028\"), cc(\"\\u2029\")],\n        };\n    }\n    atomEscape() {\n        this.consumeChar(\"\\\\\");\n        switch (this.peekChar()) {\n            case \"1\":\n            case \"2\":\n            case \"3\":\n            case \"4\":\n            case \"5\":\n            case \"6\":\n            case \"7\":\n            case \"8\":\n            case \"9\":\n                return this.decimalEscapeAtom();\n            case \"d\":\n            case \"D\":\n            case \"s\":\n            case \"S\":\n            case \"w\":\n            case \"W\":\n                return this.characterClassEscape();\n            case \"f\":\n            case \"n\":\n            case \"r\":\n            case \"t\":\n            case \"v\":\n                return this.controlEscapeAtom();\n            case \"c\":\n                return this.controlLetterEscapeAtom();\n            case \"0\":\n                return this.nulCharacterAtom();\n            case \"x\":\n                return this.hexEscapeSequenceAtom();\n            case \"u\":\n                return this.regExpUnicodeEscapeSequenceAtom();\n            default:\n                return this.identityEscapeAtom();\n        }\n    }\n    decimalEscapeAtom() {\n        const value = this.positiveInteger();\n        return { type: \"GroupBackReference\", value: value };\n    }\n    characterClassEscape() {\n        let set;\n        let complement = false;\n        switch (this.popChar()) {\n            case \"d\":\n                set = digitsCharCodes;\n                break;\n            case \"D\":\n                set = digitsCharCodes;\n                complement = true;\n                break;\n            case \"s\":\n                set = whitespaceCodes;\n                break;\n            case \"S\":\n                set = whitespaceCodes;\n                complement = true;\n                break;\n            case \"w\":\n                set = wordCharCodes;\n                break;\n            case \"W\":\n                set = wordCharCodes;\n                complement = true;\n                break;\n        }\n        // istanbul ignore else\n        if (ASSERT_EXISTS(set)) {\n            return { type: \"Set\", value: set, complement: complement };\n        }\n        // istanbul ignore next\n        return ASSERT_NEVER_REACH_HERE();\n    }\n    controlEscapeAtom() {\n        let escapeCode;\n        switch (this.popChar()) {\n            case \"f\":\n                escapeCode = cc(\"\\f\");\n                break;\n            case \"n\":\n                escapeCode = cc(\"\\n\");\n                break;\n            case \"r\":\n                escapeCode = cc(\"\\r\");\n                break;\n            case \"t\":\n                escapeCode = cc(\"\\t\");\n                break;\n            case \"v\":\n                escapeCode = cc(\"\\v\");\n                break;\n        }\n        // istanbul ignore else\n        if (ASSERT_EXISTS(escapeCode)) {\n            return { type: \"Character\", value: escapeCode };\n        }\n        // istanbul ignore next\n        return ASSERT_NEVER_REACH_HERE();\n    }\n    controlLetterEscapeAtom() {\n        this.consumeChar(\"c\");\n        const letter = this.popChar();\n        if (/[a-zA-Z]/.test(letter) === false) {\n            throw Error(\"Invalid \");\n        }\n        const letterCode = letter.toUpperCase().charCodeAt(0) - 64;\n        return { type: \"Character\", value: letterCode };\n    }\n    nulCharacterAtom() {\n        // TODO implement '[lookahead  DecimalDigit]'\n        // TODO: for the deprecated octal escape sequence\n        this.consumeChar(\"0\");\n        return { type: \"Character\", value: cc(\"\\0\") };\n    }\n    hexEscapeSequenceAtom() {\n        this.consumeChar(\"x\");\n        return this.parseHexDigits(2);\n    }\n    regExpUnicodeEscapeSequenceAtom() {\n        this.consumeChar(\"u\");\n        return this.parseHexDigits(4);\n    }\n    identityEscapeAtom() {\n        // TODO: implement \"SourceCharacter but not UnicodeIDContinue\"\n        // // http://unicode.org/reports/tr31/#Specific_Character_Adjustments\n        const escapedChar = this.popChar();\n        return { type: \"Character\", value: cc(escapedChar) };\n    }\n    classPatternCharacterAtom() {\n        switch (this.peekChar()) {\n            // istanbul ignore next\n            case \"\\n\":\n            // istanbul ignore next\n            case \"\\r\":\n            // istanbul ignore next\n            case \"\\u2028\":\n            // istanbul ignore next\n            case \"\\u2029\":\n            // istanbul ignore next\n            case \"\\\\\":\n            // istanbul ignore next\n            case \"]\":\n                throw Error(\"TBD\");\n            default:\n                const nextChar = this.popChar();\n                return { type: \"Character\", value: cc(nextChar) };\n        }\n    }\n    characterClass() {\n        const set = [];\n        let complement = false;\n        this.consumeChar(\"[\");\n        if (this.peekChar(0) === \"^\") {\n            this.consumeChar(\"^\");\n            complement = true;\n        }\n        while (this.isClassAtom()) {\n            const from = this.classAtom();\n            const isFromSingleChar = from.type === \"Character\";\n            if (isCharacter(from) && this.isRangeDash()) {\n                this.consumeChar(\"-\");\n                const to = this.classAtom();\n                const isToSingleChar = to.type === \"Character\";\n                // a range can only be used when both sides are single characters\n                if (isCharacter(to)) {\n                    if (to.value < from.value) {\n                        throw Error(\"Range out of order in character class\");\n                    }\n                    set.push({ from: from.value, to: to.value });\n                }\n                else {\n                    // literal dash\n                    insertToSet(from.value, set);\n                    set.push(cc(\"-\"));\n                    insertToSet(to.value, set);\n                }\n            }\n            else {\n                insertToSet(from.value, set);\n            }\n        }\n        this.consumeChar(\"]\");\n        return { type: \"Set\", complement: complement, value: set };\n    }\n    classAtom() {\n        switch (this.peekChar()) {\n            // istanbul ignore next\n            case \"]\":\n            // istanbul ignore next\n            case \"\\n\":\n            // istanbul ignore next\n            case \"\\r\":\n            // istanbul ignore next\n            case \"\\u2028\":\n            // istanbul ignore next\n            case \"\\u2029\":\n                throw Error(\"TBD\");\n            case \"\\\\\":\n                return this.classEscape();\n            default:\n                return this.classPatternCharacterAtom();\n        }\n    }\n    classEscape() {\n        this.consumeChar(\"\\\\\");\n        switch (this.peekChar()) {\n            // Matches a backspace.\n            // (Not to be confused with \\b word boundary outside characterClass)\n            case \"b\":\n                this.consumeChar(\"b\");\n                return { type: \"Character\", value: cc(\"\\u0008\") };\n            case \"d\":\n            case \"D\":\n            case \"s\":\n            case \"S\":\n            case \"w\":\n            case \"W\":\n                return this.characterClassEscape();\n            case \"f\":\n            case \"n\":\n            case \"r\":\n            case \"t\":\n            case \"v\":\n                return this.controlEscapeAtom();\n            case \"c\":\n                return this.controlLetterEscapeAtom();\n            case \"0\":\n                return this.nulCharacterAtom();\n            case \"x\":\n                return this.hexEscapeSequenceAtom();\n            case \"u\":\n                return this.regExpUnicodeEscapeSequenceAtom();\n            default:\n                return this.identityEscapeAtom();\n        }\n    }\n    group() {\n        let capturing = true;\n        this.consumeChar(\"(\");\n        switch (this.peekChar(0)) {\n            case \"?\":\n                this.consumeChar(\"?\");\n                this.consumeChar(\":\");\n                capturing = false;\n                break;\n            default:\n                this.groupIdx++;\n                break;\n        }\n        const value = this.disjunction();\n        this.consumeChar(\")\");\n        const groupAst = {\n            type: \"Group\",\n            capturing: capturing,\n            value: value,\n        };\n        if (capturing) {\n            groupAst[\"idx\"] = this.groupIdx;\n        }\n        return groupAst;\n    }\n    positiveInteger() {\n        let number = this.popChar();\n        // istanbul ignore next - can't ever get here due to previous lookahead checks\n        // still implementing this error checking in case this ever changes.\n        if (decimalPatternNoZero.test(number) === false) {\n            throw Error(\"Expecting a positive integer\");\n        }\n        while (decimalPattern.test(this.peekChar(0))) {\n            number += this.popChar();\n        }\n        return parseInt(number, 10);\n    }\n    integerIncludingZero() {\n        let number = this.popChar();\n        if (decimalPattern.test(number) === false) {\n            throw Error(\"Expecting an integer\");\n        }\n        while (decimalPattern.test(this.peekChar(0))) {\n            number += this.popChar();\n        }\n        return parseInt(number, 10);\n    }\n    patternCharacter() {\n        const nextChar = this.popChar();\n        switch (nextChar) {\n            // istanbul ignore next\n            case \"\\n\":\n            // istanbul ignore next\n            case \"\\r\":\n            // istanbul ignore next\n            case \"\\u2028\":\n            // istanbul ignore next\n            case \"\\u2029\":\n            // istanbul ignore next\n            case \"^\":\n            // istanbul ignore next\n            case \"$\":\n            // istanbul ignore next\n            case \"\\\\\":\n            // istanbul ignore next\n            case \".\":\n            // istanbul ignore next\n            case \"*\":\n            // istanbul ignore next\n            case \"+\":\n            // istanbul ignore next\n            case \"?\":\n            // istanbul ignore next\n            case \"(\":\n            // istanbul ignore next\n            case \")\":\n            // istanbul ignore next\n            case \"[\":\n            // istanbul ignore next\n            case \"|\":\n                // istanbul ignore next\n                throw Error(\"TBD\");\n            default:\n                return { type: \"Character\", value: cc(nextChar) };\n        }\n    }\n    isRegExpFlag() {\n        switch (this.peekChar(0)) {\n            case \"g\":\n            case \"i\":\n            case \"m\":\n            case \"u\":\n            case \"y\":\n                return true;\n            default:\n                return false;\n        }\n    }\n    isRangeDash() {\n        return this.peekChar() === \"-\" && this.isClassAtom(1);\n    }\n    isDigit() {\n        return decimalPattern.test(this.peekChar(0));\n    }\n    isClassAtom(howMuch = 0) {\n        switch (this.peekChar(howMuch)) {\n            case \"]\":\n            case \"\\n\":\n            case \"\\r\":\n            case \"\\u2028\":\n            case \"\\u2029\":\n                return false;\n            default:\n                return true;\n        }\n    }\n    isTerm() {\n        return this.isAtom() || this.isAssertion();\n    }\n    isAtom() {\n        if (this.isPatternCharacter()) {\n            return true;\n        }\n        switch (this.peekChar(0)) {\n            case \".\":\n            case \"\\\\\": // atomEscape\n            case \"[\": // characterClass\n            // TODO: isAtom must be called before isAssertion - disambiguate\n            case \"(\": // group\n                return true;\n            default:\n                return false;\n        }\n    }\n    isAssertion() {\n        switch (this.peekChar(0)) {\n            case \"^\":\n            case \"$\":\n                return true;\n            // '\\b' or '\\B'\n            case \"\\\\\":\n                switch (this.peekChar(1)) {\n                    case \"b\":\n                    case \"B\":\n                        return true;\n                    default:\n                        return false;\n                }\n            // '(?=' or '(?!'\n            case \"(\":\n                return (this.peekChar(1) === \"?\" &&\n                    (this.peekChar(2) === \"=\" || this.peekChar(2) === \"!\"));\n            default:\n                return false;\n        }\n    }\n    isQuantifier() {\n        const prevState = this.saveState();\n        try {\n            return this.quantifier(true) !== undefined;\n        }\n        catch (e) {\n            return false;\n        }\n        finally {\n            this.restoreState(prevState);\n        }\n    }\n    isPatternCharacter() {\n        switch (this.peekChar()) {\n            case \"^\":\n            case \"$\":\n            case \"\\\\\":\n            case \".\":\n            case \"*\":\n            case \"+\":\n            case \"?\":\n            case \"(\":\n            case \")\":\n            case \"[\":\n            case \"|\":\n            case \"/\":\n            case \"\\n\":\n            case \"\\r\":\n            case \"\\u2028\":\n            case \"\\u2029\":\n                return false;\n            default:\n                return true;\n        }\n    }\n    parseHexDigits(howMany) {\n        let hexString = \"\";\n        for (let i = 0; i < howMany; i++) {\n            const hexChar = this.popChar();\n            if (hexDigitPattern.test(hexChar) === false) {\n                throw Error(\"Expecting a HexDecimal digits\");\n            }\n            hexString += hexChar;\n        }\n        const charCode = parseInt(hexString, 16);\n        return { type: \"Character\", value: charCode };\n    }\n    peekChar(howMuch = 0) {\n        return this.input[this.idx + howMuch];\n    }\n    popChar() {\n        const nextChar = this.peekChar(0);\n        this.consumeChar(undefined);\n        return nextChar;\n    }\n    consumeChar(char) {\n        if (char !== undefined && this.input[this.idx] !== char) {\n            throw Error(\"Expected: '\" +\n                char +\n                \"' but found: '\" +\n                this.input[this.idx] +\n                \"' at offset: \" +\n                this.idx);\n        }\n        if (this.idx >= this.input.length) {\n            throw Error(\"Unexpected end of input\");\n        }\n        this.idx++;\n    }\n    loc(begin) {\n        return { begin: begin, end: this.idx };\n    }\n}\n//# sourceMappingURL=regexp-parser.js.map","export class BaseRegExpVisitor {\n    visitChildren(node) {\n        for (const key in node) {\n            const child = node[key];\n            /* istanbul ignore else */\n            if (node.hasOwnProperty(key)) {\n                if (child.type !== undefined) {\n                    this.visit(child);\n                }\n                else if (Array.isArray(child)) {\n                    child.forEach((subChild) => {\n                        this.visit(subChild);\n                    }, this);\n                }\n            }\n        }\n    }\n    visit(node) {\n        switch (node.type) {\n            case \"Pattern\":\n                this.visitPattern(node);\n                break;\n            case \"Flags\":\n                this.visitFlags(node);\n                break;\n            case \"Disjunction\":\n                this.visitDisjunction(node);\n                break;\n            case \"Alternative\":\n                this.visitAlternative(node);\n                break;\n            case \"StartAnchor\":\n                this.visitStartAnchor(node);\n                break;\n            case \"EndAnchor\":\n                this.visitEndAnchor(node);\n                break;\n            case \"WordBoundary\":\n                this.visitWordBoundary(node);\n                break;\n            case \"NonWordBoundary\":\n                this.visitNonWordBoundary(node);\n                break;\n            case \"Lookahead\":\n                this.visitLookahead(node);\n                break;\n            case \"NegativeLookahead\":\n                this.visitNegativeLookahead(node);\n                break;\n            case \"Character\":\n                this.visitCharacter(node);\n                break;\n            case \"Set\":\n                this.visitSet(node);\n                break;\n            case \"Group\":\n                this.visitGroup(node);\n                break;\n            case \"GroupBackReference\":\n                this.visitGroupBackReference(node);\n                break;\n            case \"Quantifier\":\n                this.visitQuantifier(node);\n                break;\n        }\n        this.visitChildren(node);\n    }\n    visitPattern(node) { }\n    visitFlags(node) { }\n    visitDisjunction(node) { }\n    visitAlternative(node) { }\n    // Assertion\n    visitStartAnchor(node) { }\n    visitEndAnchor(node) { }\n    visitWordBoundary(node) { }\n    visitNonWordBoundary(node) { }\n    visitLookahead(node) { }\n    visitNegativeLookahead(node) { }\n    // atoms\n    visitCharacter(node) { }\n    visitSet(node) { }\n    visitGroup(node) { }\n    visitGroupBackReference(node) { }\n    visitQuantifier(node) { }\n}\n//# sourceMappingURL=base-regexp-visitor.js.map","export { RegExpParser } from \"./regexp-parser.js\";\nexport { BaseRegExpVisitor } from \"./base-regexp-visitor.js\";\n//# sourceMappingURL=api.js.map","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  GitGraphGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-7PKI6E2E.mjs\";\n\n// src/language/gitGraph/module.ts\nimport {\n  inject,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  EmptyFileSystem\n} from \"langium\";\n\n// src/language/gitGraph/tokenBuilder.ts\nvar GitGraphTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"GitGraphTokenBuilder\");\n  }\n  constructor() {\n    super([\"gitGraph\"]);\n  }\n};\n\n// src/language/gitGraph/module.ts\nvar GitGraphModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new GitGraphTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createGitGraphServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const GitGraph = inject(\n    createDefaultCoreModule({ shared }),\n    GitGraphGeneratedModule,\n    GitGraphModule\n  );\n  shared.ServiceRegistry.register(GitGraph);\n  return { shared, GitGraph };\n}\n__name(createGitGraphServices, \"createGitGraphServices\");\n\nexport {\n  GitGraphModule,\n  createGitGraphServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  MermaidGeneratedSharedModule,\n  RadarGeneratedModule,\n  __name\n} from \"./chunk-7PKI6E2E.mjs\";\n\n// src/language/radar/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/radar/tokenBuilder.ts\nvar RadarTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"RadarTokenBuilder\");\n  }\n  constructor() {\n    super([\"radar-beta\"]);\n  }\n};\n\n// src/language/radar/module.ts\nvar RadarModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new RadarTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createRadarServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Radar = inject(\n    createDefaultCoreModule({ shared }),\n    RadarGeneratedModule,\n    RadarModule\n  );\n  shared.ServiceRegistry.register(Radar);\n  return { shared, Radar };\n}\n__name(createRadarServices, \"createRadarServices\");\n\nexport {\n  RadarModule,\n  createRadarServices\n};\n","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { createDefaultCoreModule, createDefaultSharedCoreModule } from '../default-module.js';\nimport { inject } from '../dependency-injection.js';\nimport * as ast from '../languages/generated/ast.js';\nimport { EmptyFileSystem } from '../workspace/file-system-provider.js';\nimport { URI } from './uri-utils.js';\nconst minimalGrammarModule = {\n    Grammar: () => undefined,\n    LanguageMetaData: () => ({\n        caseInsensitive: false,\n        fileExtensions: ['.langium'],\n        languageId: 'langium'\n    })\n};\nconst minimalSharedGrammarModule = {\n    AstReflection: () => new ast.LangiumGrammarAstReflection()\n};\nfunction createMinimalGrammarServices() {\n    const shared = inject(createDefaultSharedCoreModule(EmptyFileSystem), minimalSharedGrammarModule);\n    const grammar = inject(createDefaultCoreModule({ shared }), minimalGrammarModule);\n    shared.ServiceRegistry.register(grammar);\n    return grammar;\n}\n/**\n * Load a Langium grammar for your language from a JSON string. This is used by several services,\n * most notably the parser builder which interprets the grammar to create a parser.\n */\nexport function loadGrammarFromJson(json) {\n    var _a;\n    const services = createMinimalGrammarServices();\n    const astNode = services.serializer.JsonSerializer.deserialize(json);\n    services.shared.workspace.LangiumDocumentFactory.fromModel(astNode, URI.parse(`memory://${(_a = astNode.name) !== null && _a !== void 0 ? _a : 'grammar'}.langium`));\n    return astNode;\n}\n//# sourceMappingURL=grammar-loader.js.map","var __defProp = Object.defineProperty;\nvar __name = (target, value) => __defProp(target, \"name\", { value, configurable: true });\n\n// src/language/generated/ast.ts\nimport { AbstractAstReflection } from \"langium\";\nvar Statement = \"Statement\";\nvar Architecture = \"Architecture\";\nfunction isArchitecture(item) {\n  return reflection.isInstance(item, Architecture);\n}\n__name(isArchitecture, \"isArchitecture\");\nvar Axis = \"Axis\";\nvar Branch = \"Branch\";\nfunction isBranch(item) {\n  return reflection.isInstance(item, Branch);\n}\n__name(isBranch, \"isBranch\");\nvar Checkout = \"Checkout\";\nvar CherryPicking = \"CherryPicking\";\nvar Commit = \"Commit\";\nfunction isCommit(item) {\n  return reflection.isInstance(item, Commit);\n}\n__name(isCommit, \"isCommit\");\nvar Common = \"Common\";\nfunction isCommon(item) {\n  return reflection.isInstance(item, Common);\n}\n__name(isCommon, \"isCommon\");\nvar Curve = \"Curve\";\nvar Edge = \"Edge\";\nvar Entry = \"Entry\";\nvar GitGraph = \"GitGraph\";\nfunction isGitGraph(item) {\n  return reflection.isInstance(item, GitGraph);\n}\n__name(isGitGraph, \"isGitGraph\");\nvar Group = \"Group\";\nvar Info = \"Info\";\nfunction isInfo(item) {\n  return reflection.isInstance(item, Info);\n}\n__name(isInfo, \"isInfo\");\nvar Junction = \"Junction\";\nvar Merge = \"Merge\";\nfunction isMerge(item) {\n  return reflection.isInstance(item, Merge);\n}\n__name(isMerge, \"isMerge\");\nvar Option = \"Option\";\nvar Packet = \"Packet\";\nfunction isPacket(item) {\n  return reflection.isInstance(item, Packet);\n}\n__name(isPacket, \"isPacket\");\nvar PacketBlock = \"PacketBlock\";\nfunction isPacketBlock(item) {\n  return reflection.isInstance(item, PacketBlock);\n}\n__name(isPacketBlock, \"isPacketBlock\");\nvar Pie = \"Pie\";\nfunction isPie(item) {\n  return reflection.isInstance(item, Pie);\n}\n__name(isPie, \"isPie\");\nvar PieSection = \"PieSection\";\nfunction isPieSection(item) {\n  return reflection.isInstance(item, PieSection);\n}\n__name(isPieSection, \"isPieSection\");\nvar Radar = \"Radar\";\nvar Service = \"Service\";\nvar Direction = \"Direction\";\nvar MermaidAstReflection = class extends AbstractAstReflection {\n  static {\n    __name(this, \"MermaidAstReflection\");\n  }\n  getAllTypes() {\n    return [Architecture, Axis, Branch, Checkout, CherryPicking, Commit, Common, Curve, Direction, Edge, Entry, GitGraph, Group, Info, Junction, Merge, Option, Packet, PacketBlock, Pie, PieSection, Radar, Service, Statement];\n  }\n  computeIsSubtype(subtype, supertype) {\n    switch (subtype) {\n      case Branch:\n      case Checkout:\n      case CherryPicking:\n      case Commit:\n      case Merge: {\n        return this.isSubtype(Statement, supertype);\n      }\n      case Direction: {\n        return this.isSubtype(GitGraph, supertype);\n      }\n      default: {\n        return false;\n      }\n    }\n  }\n  getReferenceType(refInfo) {\n    const referenceId = `${refInfo.container.$type}:${refInfo.property}`;\n    switch (referenceId) {\n      case \"Entry:axis\": {\n        return Axis;\n      }\n      default: {\n        throw new Error(`${referenceId} is not a valid reference id.`);\n      }\n    }\n  }\n  getTypeMetaData(type) {\n    switch (type) {\n      case Architecture: {\n        return {\n          name: Architecture,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"edges\", defaultValue: [] },\n            { name: \"groups\", defaultValue: [] },\n            { name: \"junctions\", defaultValue: [] },\n            { name: \"services\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Axis: {\n        return {\n          name: Axis,\n          properties: [\n            { name: \"label\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      case Branch: {\n        return {\n          name: Branch,\n          properties: [\n            { name: \"name\" },\n            { name: \"order\" }\n          ]\n        };\n      }\n      case Checkout: {\n        return {\n          name: Checkout,\n          properties: [\n            { name: \"branch\" }\n          ]\n        };\n      }\n      case CherryPicking: {\n        return {\n          name: CherryPicking,\n          properties: [\n            { name: \"id\" },\n            { name: \"parent\" },\n            { name: \"tags\", defaultValue: [] }\n          ]\n        };\n      }\n      case Commit: {\n        return {\n          name: Commit,\n          properties: [\n            { name: \"id\" },\n            { name: \"message\" },\n            { name: \"tags\", defaultValue: [] },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case Common: {\n        return {\n          name: Common,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Curve: {\n        return {\n          name: Curve,\n          properties: [\n            { name: \"entries\", defaultValue: [] },\n            { name: \"label\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      case Edge: {\n        return {\n          name: Edge,\n          properties: [\n            { name: \"lhsDir\" },\n            { name: \"lhsGroup\", defaultValue: false },\n            { name: \"lhsId\" },\n            { name: \"lhsInto\", defaultValue: false },\n            { name: \"rhsDir\" },\n            { name: \"rhsGroup\", defaultValue: false },\n            { name: \"rhsId\" },\n            { name: \"rhsInto\", defaultValue: false },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Entry: {\n        return {\n          name: Entry,\n          properties: [\n            { name: \"axis\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case GitGraph: {\n        return {\n          name: GitGraph,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"statements\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Group: {\n        return {\n          name: Group,\n          properties: [\n            { name: \"icon\" },\n            { name: \"id\" },\n            { name: \"in\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Info: {\n        return {\n          name: Info,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Junction: {\n        return {\n          name: Junction,\n          properties: [\n            { name: \"id\" },\n            { name: \"in\" }\n          ]\n        };\n      }\n      case Merge: {\n        return {\n          name: Merge,\n          properties: [\n            { name: \"branch\" },\n            { name: \"id\" },\n            { name: \"tags\", defaultValue: [] },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case Option: {\n        return {\n          name: Option,\n          properties: [\n            { name: \"name\" },\n            { name: \"value\", defaultValue: false }\n          ]\n        };\n      }\n      case Packet: {\n        return {\n          name: Packet,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"blocks\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case PacketBlock: {\n        return {\n          name: PacketBlock,\n          properties: [\n            { name: \"end\" },\n            { name: \"label\" },\n            { name: \"start\" }\n          ]\n        };\n      }\n      case Pie: {\n        return {\n          name: Pie,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"sections\", defaultValue: [] },\n            { name: \"showData\", defaultValue: false },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case PieSection: {\n        return {\n          name: PieSection,\n          properties: [\n            { name: \"label\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case Radar: {\n        return {\n          name: Radar,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"axes\", defaultValue: [] },\n            { name: \"curves\", defaultValue: [] },\n            { name: \"options\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Service: {\n        return {\n          name: Service,\n          properties: [\n            { name: \"icon\" },\n            { name: \"iconText\" },\n            { name: \"id\" },\n            { name: \"in\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Direction: {\n        return {\n          name: Direction,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"dir\" },\n            { name: \"statements\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      default: {\n        return {\n          name: type,\n          properties: []\n        };\n      }\n    }\n  }\n};\nvar reflection = new MermaidAstReflection();\n\n// src/language/generated/grammar.ts\nimport { loadGrammarFromJson } from \"langium\";\nvar loadedInfoGrammar;\nvar InfoGrammar = /* @__PURE__ */ __name(() => loadedInfoGrammar ?? (loadedInfoGrammar = loadGrammarFromJson('{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Info\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Info\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"info\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"showInfo\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"*\"}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}')), \"InfoGrammar\");\nvar loadedPacketGrammar;\nvar PacketGrammar = /* @__PURE__ */ __name(() => loadedPacketGrammar ?? (loadedPacketGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Packet\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Packet\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"packet-beta\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"blocks\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"Assignment\",\"feature\":\"blocks\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"+\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"PacketBlock\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"start\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"end\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]*\\\\\"|'[^']*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}`)), \"PacketGrammar\");\nvar loadedPieGrammar;\nvar PieGrammar = /* @__PURE__ */ __name(() => loadedPieGrammar ?? (loadedPieGrammar = loadGrammarFromJson('{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Pie\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Pie\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"pie\"},{\"$type\":\"Assignment\",\"feature\":\"showData\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"showData\"},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"sections\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"Assignment\",\"feature\":\"sections\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]},\"cardinality\":\"+\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"PieSection\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"PIE_SECTION_LABEL\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]+\\\\\"/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"PIE_SECTION_VALUE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/(0|[1-9][0-9]*)(\\\\\\\\.[0-9]+)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}')), \"PieGrammar\");\nvar loadedArchitectureGrammar;\nvar ArchitectureGrammar = /* @__PURE__ */ __name(() => loadedArchitectureGrammar ?? (loadedArchitectureGrammar = loadGrammarFromJson('{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Architecture\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Architecture\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"architecture-beta\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"*\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Statement\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"groups\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"services\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"junctions\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"edges\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"LeftPort\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"lhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"RightPort\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"rhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Arrow\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"lhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"--\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\"-\"}]}]},{\"$type\":\"Assignment\",\"feature\":\"rhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Group\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"group\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Service\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"service\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"iconText\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Junction\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"junction\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Edge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"lhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"lhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"rhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"rhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_DIRECTION\",\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"L\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"R\"}}]},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"T\"}}]},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"B\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_ID\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]+/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_TEXT_ICON\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\(\\\\\"[^\\\\\"]+\\\\\"\\\\\\\\)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_ICON\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\([\\\\\\\\w-:]+\\\\\\\\)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\[[\\\\\\\\w ]+\\\\\\\\]/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_GROUP\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\{group\\\\\\\\}/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_INTO\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/<|>/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"types\":[],\"usedGrammars\":[]}')), \"ArchitectureGrammar\");\nvar loadedGitGraphGrammar;\nvar GitGraphGrammar = /* @__PURE__ */ __name(() => loadedGitGraphGrammar ?? (loadedGitGraphGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"GitGraph\",\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"rules\":[{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false},{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"GitGraph\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Keyword\",\"value\":\":\"}]},{\"$type\":\"Keyword\",\"value\":\"gitGraph:\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]},{\"$type\":\"Keyword\",\"value\":\":\"}]}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@0\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"statements\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Statement\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Direction\",\"definition\":{\"$type\":\"Assignment\",\"feature\":\"dir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"LR\"},{\"$type\":\"Keyword\",\"value\":\"TB\"},{\"$type\":\"Keyword\",\"value\":\"BT\"}]}},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Commit\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"commit\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"msg:\",\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"message\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Branch\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"branch\"},{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"order:\"},{\"$type\":\"Assignment\",\"feature\":\"order\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Merge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"merge\"},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Checkout\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"checkout\"},{\"$type\":\"Keyword\",\"value\":\"switch\"}]},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"CherryPicking\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"cherry-pick\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"parent:\"},{\"$type\":\"Assignment\",\"feature\":\"parent\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+(?=\\\\\\\\s)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\w([-\\\\\\\\./\\\\\\\\w]*[-\\\\\\\\w])?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]*\\\\\"|'[^']*'/\"},\"fragment\":false,\"hidden\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"imports\":[],\"types\":[],\"usedGrammars\":[]}`)), \"GitGraphGrammar\");\nvar loadedRadarGrammar;\nvar RadarGrammar = /* @__PURE__ */ __name(() => loadedRadarGrammar ?? (loadedRadarGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Radar\",\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Common\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]},{\"$type\":\"Interface\",\"name\":\"Entry\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"axis\",\"isOptional\":true,\"type\":{\"$type\":\"ReferenceType\",\"referenceType\":{\"$type\":\"SimpleType\",\"typeRef\":{\"$ref\":\"#/rules@12\"}}}},{\"$type\":\"TypeAttribute\",\"name\":\"value\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"number\"},\"isOptional\":false}],\"superTypes\":[]}],\"rules\":[{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false},{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Radar\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"radar-beta\"},{\"$type\":\"Keyword\",\"value\":\"radar-beta:\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"radar-beta\"},{\"$type\":\"Keyword\",\"value\":\":\"}]}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@0\"},\"arguments\":[]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"axis\"},{\"$type\":\"Assignment\",\"feature\":\"axes\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"axes\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"curve\"},{\"$type\":\"Assignment\",\"feature\":\"curves\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"curves\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"options\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"options\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Label\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"[\"},{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\"]\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Axis\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Curve\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[],\"cardinality\":\"?\"},{\"$type\":\"Keyword\",\"value\":\"{\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]},{\"$type\":\"Keyword\",\"value\":\"}\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Entries\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"DetailedEntry\",\"returnType\":{\"$ref\":\"#/interfaces@1\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"axis\",\"operator\":\"=\",\"terminal\":{\"$type\":\"CrossReference\",\"type\":{\"$ref\":\"#/rules@12\"},\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]},\"deprecatedSyntax\":false}},{\"$type\":\"Keyword\",\"value\":\":\",\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"NumberEntry\",\"returnType\":{\"$ref\":\"#/interfaces@1\"},\"definition\":{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Option\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"showLegend\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"ticks\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"max\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"min\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"graticule\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/(0|[1-9][0-9]*)(\\\\\\\\.[0-9]+)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"GRATICULE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"circle\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"polygon\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[a-zA-Z_][a-zA-Z0-9\\\\\\\\-_]*/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]*\\\\\"|'[^']*'/\"},\"fragment\":false,\"hidden\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"imports\":[],\"types\":[],\"usedGrammars\":[]}`)), \"RadarGrammar\");\n\n// src/language/generated/module.ts\nvar InfoLanguageMetaData = {\n  languageId: \"info\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar PacketLanguageMetaData = {\n  languageId: \"packet\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar PieLanguageMetaData = {\n  languageId: \"pie\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar ArchitectureLanguageMetaData = {\n  languageId: \"architecture\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar GitGraphLanguageMetaData = {\n  languageId: \"gitGraph\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar RadarLanguageMetaData = {\n  languageId: \"radar\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar MermaidGeneratedSharedModule = {\n  AstReflection: /* @__PURE__ */ __name(() => new MermaidAstReflection(), \"AstReflection\")\n};\nvar InfoGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => InfoGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => InfoLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PacketGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => PacketGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => PacketLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PieGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => PieGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => PieLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar ArchitectureGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => ArchitectureGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => ArchitectureLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar GitGraphGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => GitGraphGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => GitGraphLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar RadarGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => RadarGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => RadarLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\n\n// src/language/common/valueConverter.ts\nimport { DefaultValueConverter } from \"langium\";\n\n// src/language/common/matcher.ts\nvar accessibilityDescrRegex = /accDescr(?:[\\t ]*:([^\\n\\r]*)|\\s*{([^}]*)})/;\nvar accessibilityTitleRegex = /accTitle[\\t ]*:([^\\n\\r]*)/;\nvar titleRegex = /title([\\t ][^\\n\\r]*|)/;\n\n// src/language/common/valueConverter.ts\nvar rulesRegexes = {\n  ACC_DESCR: accessibilityDescrRegex,\n  ACC_TITLE: accessibilityTitleRegex,\n  TITLE: titleRegex\n};\nvar AbstractMermaidValueConverter = class extends DefaultValueConverter {\n  static {\n    __name(this, \"AbstractMermaidValueConverter\");\n  }\n  runConverter(rule, input, cstNode) {\n    let value = this.runCommonConverter(rule, input, cstNode);\n    if (value === void 0) {\n      value = this.runCustomConverter(rule, input, cstNode);\n    }\n    if (value === void 0) {\n      return super.runConverter(rule, input, cstNode);\n    }\n    return value;\n  }\n  runCommonConverter(rule, input, _cstNode) {\n    const regex = rulesRegexes[rule.name];\n    if (regex === void 0) {\n      return void 0;\n    }\n    const match = regex.exec(input);\n    if (match === null) {\n      return void 0;\n    }\n    if (match[1] !== void 0) {\n      return match[1].trim().replace(/[\\t ]{2,}/gm, \" \");\n    }\n    if (match[2] !== void 0) {\n      return match[2].replace(/^\\s*/gm, \"\").replace(/\\s+$/gm, \"\").replace(/[\\t ]{2,}/gm, \" \").replace(/[\\n\\r]{2,}/gm, \"\\n\");\n    }\n    return void 0;\n  }\n};\nvar CommonValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"CommonValueConverter\");\n  }\n  runCustomConverter(_rule, _input, _cstNode) {\n    return void 0;\n  }\n};\n\n// src/language/common/tokenBuilder.ts\nimport { DefaultTokenBuilder } from \"langium\";\nvar AbstractMermaidTokenBuilder = class extends DefaultTokenBuilder {\n  static {\n    __name(this, \"AbstractMermaidTokenBuilder\");\n  }\n  constructor(keywords) {\n    super();\n    this.keywords = new Set(keywords);\n  }\n  buildKeywordTokens(rules, terminalTokens, options) {\n    const tokenTypes = super.buildKeywordTokens(rules, terminalTokens, options);\n    tokenTypes.forEach((tokenType) => {\n      if (this.keywords.has(tokenType.name) && tokenType.PATTERN !== void 0) {\n        tokenType.PATTERN = new RegExp(tokenType.PATTERN.toString() + \"(?:(?=%%)|(?!\\\\S))\");\n      }\n    });\n    return tokenTypes;\n  }\n};\nvar CommonTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"CommonTokenBuilder\");\n  }\n};\n\nexport {\n  __name,\n  Statement,\n  Architecture,\n  isArchitecture,\n  Branch,\n  isBranch,\n  Commit,\n  isCommit,\n  isCommon,\n  GitGraph,\n  isGitGraph,\n  Info,\n  isInfo,\n  Merge,\n  isMerge,\n  Packet,\n  isPacket,\n  PacketBlock,\n  isPacketBlock,\n  Pie,\n  isPie,\n  PieSection,\n  isPieSection,\n  Radar,\n  MermaidGeneratedSharedModule,\n  InfoGeneratedModule,\n  PacketGeneratedModule,\n  PieGeneratedModule,\n  ArchitectureGeneratedModule,\n  GitGraphGeneratedModule,\n  RadarGeneratedModule,\n  AbstractMermaidValueConverter,\n  CommonValueConverter,\n  AbstractMermaidTokenBuilder,\n  CommonTokenBuilder\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  ArchitectureGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-7PKI6E2E.mjs\";\n\n// src/language/architecture/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/architecture/tokenBuilder.ts\nvar ArchitectureTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"ArchitectureTokenBuilder\");\n  }\n  constructor() {\n    super([\"architecture\"]);\n  }\n};\n\n// src/language/architecture/valueConverter.ts\nvar ArchitectureValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"ArchitectureValueConverter\");\n  }\n  runCustomConverter(rule, input, _cstNode) {\n    if (rule.name === \"ARCH_ICON\") {\n      return input.replace(/[()]/g, \"\").trim();\n    } else if (rule.name === \"ARCH_TEXT_ICON\") {\n      return input.replace(/[\"()]/g, \"\");\n    } else if (rule.name === \"ARCH_TITLE\") {\n      return input.replace(/[[\\]]/g, \"\").trim();\n    }\n    return void 0;\n  }\n};\n\n// src/language/architecture/module.ts\nvar ArchitectureModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new ArchitectureTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new ArchitectureValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createArchitectureServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Architecture = inject(\n    createDefaultCoreModule({ shared }),\n    ArchitectureGeneratedModule,\n    ArchitectureModule\n  );\n  shared.ServiceRegistry.register(Architecture);\n  return { shared, Architecture };\n}\n__name(createArchitectureServices, \"createArchitectureServices\");\n\nexport {\n  ArchitectureModule,\n  createArchitectureServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  InfoGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-7PKI6E2E.mjs\";\n\n// src/language/info/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/info/tokenBuilder.ts\nvar InfoTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"InfoTokenBuilder\");\n  }\n  constructor() {\n    super([\"info\", \"showInfo\"]);\n  }\n};\n\n// src/language/info/module.ts\nvar InfoModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new InfoTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createInfoServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Info = inject(\n    createDefaultCoreModule({ shared }),\n    InfoGeneratedModule,\n    InfoModule\n  );\n  shared.ServiceRegistry.register(Info);\n  return { shared, Info };\n}\n__name(createInfoServices, \"createInfoServices\");\n\nexport {\n  InfoModule,\n  createInfoServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  MermaidGeneratedSharedModule,\n  PieGeneratedModule,\n  __name\n} from \"./chunk-7PKI6E2E.mjs\";\n\n// src/language/pie/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/pie/tokenBuilder.ts\nvar PieTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"PieTokenBuilder\");\n  }\n  constructor() {\n    super([\"pie\", \"showData\"]);\n  }\n};\n\n// src/language/pie/valueConverter.ts\nvar PieValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"PieValueConverter\");\n  }\n  runCustomConverter(rule, input, _cstNode) {\n    if (rule.name !== \"PIE_SECTION_LABEL\") {\n      return void 0;\n    }\n    return input.replace(/\"/g, \"\").trim();\n  }\n};\n\n// src/language/pie/module.ts\nvar PieModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new PieTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new PieValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createPieServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Pie = inject(\n    createDefaultCoreModule({ shared }),\n    PieGeneratedModule,\n    PieModule\n  );\n  shared.ServiceRegistry.register(Pie);\n  return { shared, Pie };\n}\n__name(createPieServices, \"createPieServices\");\n\nexport {\n  PieModule,\n  createPieServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  MermaidGeneratedSharedModule,\n  PacketGeneratedModule,\n  __name\n} from \"./chunk-7PKI6E2E.mjs\";\n\n// src/language/packet/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/packet/tokenBuilder.ts\nvar PacketTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"PacketTokenBuilder\");\n  }\n  constructor() {\n    super([\"packet-beta\"]);\n  }\n};\n\n// src/language/packet/module.ts\nvar PacketModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new PacketTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createPacketServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Packet = inject(\n    createDefaultCoreModule({ shared }),\n    PacketGeneratedModule,\n    PacketModule\n  );\n  shared.ServiceRegistry.register(Packet);\n  return { shared, Packet };\n}\n__name(createPacketServices, \"createPacketServices\");\n\nexport {\n  PacketModule,\n  createPacketServices\n};\n","import {\n  GitGraphModule,\n  createGitGraphServices\n} from \"./chunks/mermaid-parser.core/chunk-2NYFTIL2.mjs\";\nimport {\n  InfoModule,\n  createInfoServices\n} from \"./chunks/mermaid-parser.core/chunk-EXZZNE6F.mjs\";\nimport {\n  PacketModule,\n  createPacketServices\n} from \"./chunks/mermaid-parser.core/chunk-V4Q32G6S.mjs\";\nimport {\n  PieModule,\n  createPieServices\n} from \"./chunks/mermaid-parser.core/chunk-ROXG7S4E.mjs\";\nimport {\n  ArchitectureModule,\n  createArchitectureServices\n} from \"./chunks/mermaid-parser.core/chunk-C4OEIS7N.mjs\";\nimport {\n  RadarModule,\n  createRadarServices\n} from \"./chunks/mermaid-parser.core/chunk-2O5ZK7RR.mjs\";\nimport {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  Architecture,\n  ArchitectureGeneratedModule,\n  Branch,\n  Commit,\n  CommonTokenBuilder,\n  CommonValueConverter,\n  GitGraph,\n  GitGraphGeneratedModule,\n  Info,\n  InfoGeneratedModule,\n  Merge,\n  MermaidGeneratedSharedModule,\n  Packet,\n  PacketBlock,\n  PacketGeneratedModule,\n  Pie,\n  PieGeneratedModule,\n  PieSection,\n  Radar,\n  RadarGeneratedModule,\n  Statement,\n  __name,\n  isArchitecture,\n  isBranch,\n  isCommit,\n  isCommon,\n  isGitGraph,\n  isInfo,\n  isMerge,\n  isPacket,\n  isPacketBlock,\n  isPie,\n  isPieSection\n} from \"./chunks/mermaid-parser.core/chunk-7PKI6E2E.mjs\";\n\n// src/parse.ts\nvar parsers = {};\nvar initializers = {\n  info: /* @__PURE__ */ __name(async () => {\n    const { createInfoServices: createInfoServices2 } = await import(\"./chunks/mermaid-parser.core/info-4N47QTOZ.mjs\");\n    const parser = createInfoServices2().Info.parser.LangiumParser;\n    parsers.info = parser;\n  }, \"info\"),\n  packet: /* @__PURE__ */ __name(async () => {\n    const { createPacketServices: createPacketServices2 } = await import(\"./chunks/mermaid-parser.core/packet-KVYON367.mjs\");\n    const parser = createPacketServices2().Packet.parser.LangiumParser;\n    parsers.packet = parser;\n  }, \"packet\"),\n  pie: /* @__PURE__ */ __name(async () => {\n    const { createPieServices: createPieServices2 } = await import(\"./chunks/mermaid-parser.core/pie-R6RNRRYF.mjs\");\n    const parser = createPieServices2().Pie.parser.LangiumParser;\n    parsers.pie = parser;\n  }, \"pie\"),\n  architecture: /* @__PURE__ */ __name(async () => {\n    const { createArchitectureServices: createArchitectureServices2 } = await import(\"./chunks/mermaid-parser.core/architecture-4AB2E3PP.mjs\");\n    const parser = createArchitectureServices2().Architecture.parser.LangiumParser;\n    parsers.architecture = parser;\n  }, \"architecture\"),\n  gitGraph: /* @__PURE__ */ __name(async () => {\n    const { createGitGraphServices: createGitGraphServices2 } = await import(\"./chunks/mermaid-parser.core/gitGraph-O2Q2CXLX.mjs\");\n    const parser = createGitGraphServices2().GitGraph.parser.LangiumParser;\n    parsers.gitGraph = parser;\n  }, \"gitGraph\"),\n  radar: /* @__PURE__ */ __name(async () => {\n    const { createRadarServices: createRadarServices2 } = await import(\"./chunks/mermaid-parser.core/radar-MK3ICKWK.mjs\");\n    const parser = createRadarServices2().Radar.parser.LangiumParser;\n    parsers.radar = parser;\n  }, \"radar\")\n};\nasync function parse(diagramType, text) {\n  const initializer = initializers[diagramType];\n  if (!initializer) {\n    throw new Error(`Unknown diagram type: ${diagramType}`);\n  }\n  if (!parsers[diagramType]) {\n    await initializer();\n  }\n  const parser = parsers[diagramType];\n  const result = parser.parse(text);\n  if (result.lexerErrors.length > 0 || result.parserErrors.length > 0) {\n    throw new MermaidParseError(result);\n  }\n  return result.value;\n}\n__name(parse, \"parse\");\nvar MermaidParseError = class extends Error {\n  constructor(result) {\n    const lexerErrors = result.lexerErrors.map((err) => err.message).join(\"\\n\");\n    const parserErrors = result.parserErrors.map((err) => err.message).join(\"\\n\");\n    super(`Parsing failed: ${lexerErrors} ${parserErrors}`);\n    this.result = result;\n  }\n  static {\n    __name(this, \"MermaidParseError\");\n  }\n};\nexport {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  Architecture,\n  ArchitectureGeneratedModule,\n  ArchitectureModule,\n  Branch,\n  Commit,\n  CommonTokenBuilder,\n  CommonValueConverter,\n  GitGraph,\n  GitGraphGeneratedModule,\n  GitGraphModule,\n  Info,\n  InfoGeneratedModule,\n  InfoModule,\n  Merge,\n  MermaidGeneratedSharedModule,\n  MermaidParseError,\n  Packet,\n  PacketBlock,\n  PacketGeneratedModule,\n  PacketModule,\n  Pie,\n  PieGeneratedModule,\n  PieModule,\n  PieSection,\n  Radar,\n  RadarGeneratedModule,\n  RadarModule,\n  Statement,\n  createArchitectureServices,\n  createGitGraphServices,\n  createInfoServices,\n  createPacketServices,\n  createPieServices,\n  createRadarServices,\n  isArchitecture,\n  isBranch,\n  isCommit,\n  isCommon,\n  isGitGraph,\n  isInfo,\n  isMerge,\n  isPacket,\n  isPacketBlock,\n  isPie,\n  isPieSection,\n  parse\n};\n","// based on: https://github.com/petkaantonov/bluebird/blob/b97c0d2d487e8c5076e8bd897e0dcd4622d31846/src/util.js#L201-L216\nexport function toFastProperties(toBecomeFast) {\n    function FakeConstructor() { }\n    // If our object is used as a constructor, it would receive\n    FakeConstructor.prototype = toBecomeFast;\n    const fakeInstance = new FakeConstructor();\n    function fakeAccess() {\n        return typeof fakeInstance.bar;\n    }\n    // help V8 understand this is a \"real\" prototype by actually using\n    // the fake instance.\n    fakeAccess();\n    fakeAccess();\n    // Always true condition to suppress the Firefox warning of unreachable\n    // code after a return statement.\n    if (1)\n        return toBecomeFast;\n    // Eval prevents optimization of this method (even though this is dead code)\n    // - https://esbuild.github.io/content-types/#direct-eval\n    /* istanbul ignore next */\n    // tslint:disable-next-line\n    (0, eval)(toBecomeFast);\n}\n//# sourceMappingURL=to-fast-properties.js.map","/**\n * The base implementation of `_.slice` without an iteratee call guard.\n *\n * @private\n * @param {Array} array The array to slice.\n * @param {number} [start=0] The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns the slice of `array`.\n */\nfunction baseSlice(array, start, end) {\n  var index = -1,\n      length = array.length;\n\n  if (start < 0) {\n    start = -start > length ? 0 : (length + start);\n  }\n  end = end > length ? length : end;\n  if (end < 0) {\n    end += length;\n  }\n  length = start > end ? 0 : ((end - start) >>> 0);\n  start >>>= 0;\n\n  var result = Array(length);\n  while (++index < length) {\n    result[index] = array[index + start];\n  }\n  return result;\n}\n\nexport default baseSlice;\n","import baseSlice from './_baseSlice.js';\nimport toInteger from './toInteger.js';\n\n/**\n * Creates a slice of `array` with `n` elements dropped from the beginning.\n *\n * @static\n * @memberOf _\n * @since 0.5.0\n * @category Array\n * @param {Array} array The array to query.\n * @param {number} [n=1] The number of elements to drop.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the slice of `array`.\n * @example\n *\n * _.drop([1, 2, 3]);\n * // => [2, 3]\n *\n * _.drop([1, 2, 3], 2);\n * // => [3]\n *\n * _.drop([1, 2, 3], 5);\n * // => []\n *\n * _.drop([1, 2, 3], 0);\n * // => [1, 2, 3]\n */\nfunction drop(array, n, guard) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return [];\n  }\n  n = (guard || n === undefined) ? 1 : toInteger(n);\n  return baseSlice(array, n < 0 ? 0 : n, length);\n}\n\nexport default drop;\n","import assignValue from './_assignValue.js';\nimport copyObject from './_copyObject.js';\nimport createAssigner from './_createAssigner.js';\nimport isArrayLike from './isArrayLike.js';\nimport isPrototype from './_isPrototype.js';\nimport keys from './keys.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own enumerable string keyed properties of source objects to the\n * destination object. Source objects are applied from left to right.\n * Subsequent sources overwrite property assignments of previous sources.\n *\n * **Note:** This method mutates `object` and is loosely based on\n * [`Object.assign`](https://mdn.io/Object/assign).\n *\n * @static\n * @memberOf _\n * @since 0.10.0\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.assignIn\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n * }\n *\n * function Bar() {\n *   this.c = 3;\n * }\n *\n * Foo.prototype.b = 2;\n * Bar.prototype.d = 4;\n *\n * _.assign({ 'a': 0 }, new Foo, new Bar);\n * // => { 'a': 1, 'c': 3 }\n */\nvar assign = createAssigner(function(object, source) {\n  if (isPrototype(source) || isArrayLike(source)) {\n    copyObject(source, keys(source), object);\n    return;\n  }\n  for (var key in source) {\n    if (hasOwnProperty.call(source, key)) {\n      assignValue(object, key, source[key]);\n    }\n  }\n});\n\nexport default assign;\n","import arrayMap from './_arrayMap.js';\nimport baseIteratee from './_baseIteratee.js';\nimport basePickBy from './_basePickBy.js';\nimport getAllKeysIn from './_getAllKeysIn.js';\n\n/**\n * Creates an object composed of the `object` properties `predicate` returns\n * truthy for. The predicate is invoked with two arguments: (value, key).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Object\n * @param {Object} object The source object.\n * @param {Function} [predicate=_.identity] The function invoked per property.\n * @returns {Object} Returns the new object.\n * @example\n *\n * var object = { 'a': 1, 'b': '2', 'c': 3 };\n *\n * _.pickBy(object, _.isNumber);\n * // => { 'a': 1, 'c': 3 }\n */\nfunction pickBy(object, predicate) {\n  if (object == null) {\n    return {};\n  }\n  var props = arrayMap(getAllKeysIn(object), function(prop) {\n    return [prop];\n  });\n  predicate = baseIteratee(predicate);\n  return basePickBy(object, props, function(value, path) {\n    return predicate(value, path[0]);\n  });\n}\n\nexport default pickBy;\n","import baseGetTag from './_baseGetTag.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar regexpTag = '[object RegExp]';\n\n/**\n * The base implementation of `_.isRegExp` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a regexp, else `false`.\n */\nfunction baseIsRegExp(value) {\n  return isObjectLike(value) && baseGetTag(value) == regexpTag;\n}\n\nexport default baseIsRegExp;\n","import baseIsRegExp from './_baseIsRegExp.js';\nimport baseUnary from './_baseUnary.js';\nimport nodeUtil from './_nodeUtil.js';\n\n/* Node.js helper references. */\nvar nodeIsRegExp = nodeUtil && nodeUtil.isRegExp;\n\n/**\n * Checks if `value` is classified as a `RegExp` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a regexp, else `false`.\n * @example\n *\n * _.isRegExp(/abc/);\n * // => true\n *\n * _.isRegExp('/abc/');\n * // => false\n */\nvar isRegExp = nodeIsRegExp ? baseUnary(nodeIsRegExp) : baseIsRegExp;\n\nexport default isRegExp;\n","import { assign, forEach, isRegExp, isString, map, pickBy } from \"lodash-es\";\n// TODO: duplicated code to avoid extracting another sub-package -- how to avoid?\nfunction tokenLabel(tokType) {\n    if (hasTokenLabel(tokType)) {\n        return tokType.LABEL;\n    }\n    else {\n        return tokType.name;\n    }\n}\n// TODO: duplicated code to avoid extracting another sub-package -- how to avoid?\nfunction hasTokenLabel(obj) {\n    return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\nexport class AbstractProduction {\n    get definition() {\n        return this._definition;\n    }\n    set definition(value) {\n        this._definition = value;\n    }\n    constructor(_definition) {\n        this._definition = _definition;\n    }\n    accept(visitor) {\n        visitor.visit(this);\n        forEach(this.definition, (prod) => {\n            prod.accept(visitor);\n        });\n    }\n}\nexport class NonTerminal extends AbstractProduction {\n    constructor(options) {\n        super([]);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n    set definition(definition) {\n        // immutable\n    }\n    get definition() {\n        if (this.referencedRule !== undefined) {\n            return this.referencedRule.definition;\n        }\n        return [];\n    }\n    accept(visitor) {\n        visitor.visit(this);\n        // don't visit children of a reference, we will get cyclic infinite loops if we do so\n    }\n}\nexport class Rule extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.orgText = \"\";\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class Alternative extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.ignoreAmbiguities = false;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class Option extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class RepetitionMandatory extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class RepetitionMandatoryWithSeparator extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class Repetition extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class RepetitionWithSeparator extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class Alternation extends AbstractProduction {\n    get definition() {\n        return this._definition;\n    }\n    set definition(value) {\n        this._definition = value;\n    }\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        this.ignoreAmbiguities = false;\n        this.hasPredicates = false;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class Terminal {\n    constructor(options) {\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n    accept(visitor) {\n        visitor.visit(this);\n    }\n}\nexport function serializeGrammar(topRules) {\n    return map(topRules, serializeProduction);\n}\nexport function serializeProduction(node) {\n    function convertDefinition(definition) {\n        return map(definition, serializeProduction);\n    }\n    /* istanbul ignore else */\n    if (node instanceof NonTerminal) {\n        const serializedNonTerminal = {\n            type: \"NonTerminal\",\n            name: node.nonTerminalName,\n            idx: node.idx,\n        };\n        if (isString(node.label)) {\n            serializedNonTerminal.label = node.label;\n        }\n        return serializedNonTerminal;\n    }\n    else if (node instanceof Alternative) {\n        return {\n            type: \"Alternative\",\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof Option) {\n        return {\n            type: \"Option\",\n            idx: node.idx,\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof RepetitionMandatory) {\n        return {\n            type: \"RepetitionMandatory\",\n            idx: node.idx,\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof RepetitionMandatoryWithSeparator) {\n        return {\n            type: \"RepetitionMandatoryWithSeparator\",\n            idx: node.idx,\n            separator: (serializeProduction(new Terminal({ terminalType: node.separator }))),\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof RepetitionWithSeparator) {\n        return {\n            type: \"RepetitionWithSeparator\",\n            idx: node.idx,\n            separator: (serializeProduction(new Terminal({ terminalType: node.separator }))),\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof Repetition) {\n        return {\n            type: \"Repetition\",\n            idx: node.idx,\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof Alternation) {\n        return {\n            type: \"Alternation\",\n            idx: node.idx,\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof Terminal) {\n        const serializedTerminal = {\n            type: \"Terminal\",\n            name: node.terminalType.name,\n            label: tokenLabel(node.terminalType),\n            idx: node.idx,\n        };\n        if (isString(node.label)) {\n            serializedTerminal.terminalLabel = node.label;\n        }\n        const pattern = node.terminalType.PATTERN;\n        if (node.terminalType.PATTERN) {\n            serializedTerminal.pattern = isRegExp(pattern)\n                ? pattern.source\n                : pattern;\n        }\n        return serializedTerminal;\n    }\n    else if (node instanceof Rule) {\n        return {\n            type: \"Rule\",\n            name: node.name,\n            orgText: node.orgText,\n            definition: convertDefinition(node.definition),\n        };\n        /* c8 ignore next 3 */\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\n//# sourceMappingURL=model.js.map","import { drop, forEach } from \"lodash-es\";\nimport { Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Terminal, } from \"@chevrotain/gast\";\n/**\n *  A Grammar Walker that computes the \"remaining\" grammar \"after\" a productions in the grammar.\n */\nexport class RestWalker {\n    walk(prod, prevRest = []) {\n        forEach(prod.definition, (subProd, index) => {\n            const currRest = drop(prod.definition, index + 1);\n            /* istanbul ignore else */\n            if (subProd instanceof NonTerminal) {\n                this.walkProdRef(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof Terminal) {\n                this.walkTerminal(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof Alternative) {\n                this.walkFlat(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof Option) {\n                this.walkOption(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof RepetitionMandatory) {\n                this.walkAtLeastOne(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof RepetitionMandatoryWithSeparator) {\n                this.walkAtLeastOneSep(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof RepetitionWithSeparator) {\n                this.walkManySep(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof Repetition) {\n                this.walkMany(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof Alternation) {\n                this.walkOr(subProd, currRest, prevRest);\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n    }\n    walkTerminal(terminal, currRest, prevRest) { }\n    walkProdRef(refProd, currRest, prevRest) { }\n    walkFlat(flatProd, currRest, prevRest) {\n        // ABCDEF => after the D the rest is EF\n        const fullOrRest = currRest.concat(prevRest);\n        this.walk(flatProd, fullOrRest);\n    }\n    walkOption(optionProd, currRest, prevRest) {\n        // ABC(DE)?F => after the (DE)? the rest is F\n        const fullOrRest = currRest.concat(prevRest);\n        this.walk(optionProd, fullOrRest);\n    }\n    walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n        // ABC(DE)+F => after the (DE)+ the rest is (DE)?F\n        const fullAtLeastOneRest = [\n            new Option({ definition: atLeastOneProd.definition }),\n        ].concat(currRest, prevRest);\n        this.walk(atLeastOneProd, fullAtLeastOneRest);\n    }\n    walkAtLeastOneSep(atLeastOneSepProd, currRest, prevRest) {\n        // ABC DE(,DE)* F => after the (,DE)+ the rest is (,DE)?F\n        const fullAtLeastOneSepRest = restForRepetitionWithSeparator(atLeastOneSepProd, currRest, prevRest);\n        this.walk(atLeastOneSepProd, fullAtLeastOneSepRest);\n    }\n    walkMany(manyProd, currRest, prevRest) {\n        // ABC(DE)*F => after the (DE)* the rest is (DE)?F\n        const fullManyRest = [\n            new Option({ definition: manyProd.definition }),\n        ].concat(currRest, prevRest);\n        this.walk(manyProd, fullManyRest);\n    }\n    walkManySep(manySepProd, currRest, prevRest) {\n        // ABC (DE(,DE)*)? F => after the (,DE)* the rest is (,DE)?F\n        const fullManySepRest = restForRepetitionWithSeparator(manySepProd, currRest, prevRest);\n        this.walk(manySepProd, fullManySepRest);\n    }\n    walkOr(orProd, currRest, prevRest) {\n        // ABC(D|E|F)G => when finding the (D|E|F) the rest is G\n        const fullOrRest = currRest.concat(prevRest);\n        // walk all different alternatives\n        forEach(orProd.definition, (alt) => {\n            // wrapping each alternative in a single definition wrapper\n            // to avoid errors in computing the rest of that alternative in the invocation to computeInProdFollows\n            // (otherwise for OR([alt1,alt2]) alt2 will be considered in 'rest' of alt1\n            const prodWrapper = new Alternative({ definition: [alt] });\n            this.walk(prodWrapper, fullOrRest);\n        });\n    }\n}\nfunction restForRepetitionWithSeparator(repSepProd, currRest, prevRest) {\n    const repSepRest = [\n        new Option({\n            definition: [\n                new Terminal({ terminalType: repSepProd.separator }),\n            ].concat(repSepProd.definition),\n        }),\n    ];\n    const fullRepSepRest = repSepRest.concat(currRest, prevRest);\n    return fullRepSepRest;\n}\n//# sourceMappingURL=rest.js.map","import baseUniq from './_baseUniq.js';\n\n/**\n * Creates a duplicate-free version of an array, using\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons, in which only the first occurrence of each element\n * is kept. The order of result values is determined by the order they occur\n * in the array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @returns {Array} Returns the new duplicate free array.\n * @example\n *\n * _.uniq([2, 1, 2]);\n * // => [2, 1]\n */\nfunction uniq(array) {\n  return (array && array.length) ? baseUniq(array) : [];\n}\n\nexport default uniq;\n","import baseEach from './_baseEach.js';\n\n/**\n * The base implementation of `_.some` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n */\nfunction baseSome(collection, predicate) {\n  var result;\n\n  baseEach(collection, function(value, index, collection) {\n    result = predicate(value, index, collection);\n    return !result;\n  });\n  return !!result;\n}\n\nexport default baseSome;\n","import arraySome from './_arraySome.js';\nimport baseIteratee from './_baseIteratee.js';\nimport baseSome from './_baseSome.js';\nimport isArray from './isArray.js';\nimport isIterateeCall from './_isIterateeCall.js';\n\n/**\n * Checks if `predicate` returns truthy for **any** element of `collection`.\n * Iteration is stopped once `predicate` returns truthy. The predicate is\n * invoked with three arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n * @example\n *\n * _.some([null, 0, 'yes', false], Boolean);\n * // => true\n *\n * var users = [\n *   { 'user': 'barney', 'active': true },\n *   { 'user': 'fred',   'active': false }\n * ];\n *\n * // The `_.matches` iteratee shorthand.\n * _.some(users, { 'user': 'barney', 'active': false });\n * // => false\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.some(users, ['active', false]);\n * // => true\n *\n * // The `_.property` iteratee shorthand.\n * _.some(users, 'active');\n * // => true\n */\nfunction some(collection, predicate, guard) {\n  var func = isArray(collection) ? arraySome : baseSome;\n  if (guard && isIterateeCall(collection, predicate, guard)) {\n    predicate = undefined;\n  }\n  return func(collection, baseIteratee(predicate, 3));\n}\n\nexport default some;\n","import baseIndexOf from './_baseIndexOf.js';\nimport isArrayLike from './isArrayLike.js';\nimport isString from './isString.js';\nimport toInteger from './toInteger.js';\nimport values from './values.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Checks if `value` is in `collection`. If `collection` is a string, it's\n * checked for a substring of `value`, otherwise\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * is used for equality comparisons. If `fromIndex` is negative, it's used as\n * the offset from the end of `collection`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object|string} collection The collection to inspect.\n * @param {*} value The value to search for.\n * @param {number} [fromIndex=0] The index to search from.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.reduce`.\n * @returns {boolean} Returns `true` if `value` is found, else `false`.\n * @example\n *\n * _.includes([1, 2, 3], 1);\n * // => true\n *\n * _.includes([1, 2, 3], 1, 2);\n * // => false\n *\n * _.includes({ 'a': 1, 'b': 2 }, 1);\n * // => true\n *\n * _.includes('abcd', 'bc');\n * // => true\n */\nfunction includes(collection, value, fromIndex, guard) {\n  collection = isArrayLike(collection) ? collection : values(collection);\n  fromIndex = (fromIndex && !guard) ? toInteger(fromIndex) : 0;\n\n  var length = collection.length;\n  if (fromIndex < 0) {\n    fromIndex = nativeMax(length + fromIndex, 0);\n  }\n  return isString(collection)\n    ? (fromIndex <= length && collection.indexOf(value, fromIndex) > -1)\n    : (!!length && baseIndexOf(collection, value, fromIndex) > -1);\n}\n\nexport default includes;\n","/**\n * A specialized version of `_.every` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`.\n */\nfunction arrayEvery(array, predicate) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (!predicate(array[index], index, array)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport default arrayEvery;\n","import baseEach from './_baseEach.js';\n\n/**\n * The base implementation of `_.every` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`\n */\nfunction baseEvery(collection, predicate) {\n  var result = true;\n  baseEach(collection, function(value, index, collection) {\n    result = !!predicate(value, index, collection);\n    return result;\n  });\n  return result;\n}\n\nexport default baseEvery;\n","import arrayEvery from './_arrayEvery.js';\nimport baseEvery from './_baseEvery.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\nimport isIterateeCall from './_isIterateeCall.js';\n\n/**\n * Checks if `predicate` returns truthy for **all** elements of `collection`.\n * Iteration is stopped once `predicate` returns falsey. The predicate is\n * invoked with three arguments: (value, index|key, collection).\n *\n * **Note:** This method returns `true` for\n * [empty collections](https://en.wikipedia.org/wiki/Empty_set) because\n * [everything is true](https://en.wikipedia.org/wiki/Vacuous_truth) of\n * elements of empty collections.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`.\n * @example\n *\n * _.every([true, 1, null, 'yes'], Boolean);\n * // => false\n *\n * var users = [\n *   { 'user': 'barney', 'age': 36, 'active': false },\n *   { 'user': 'fred',   'age': 40, 'active': false }\n * ];\n *\n * // The `_.matches` iteratee shorthand.\n * _.every(users, { 'user': 'barney', 'active': false });\n * // => false\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.every(users, ['active', false]);\n * // => true\n *\n * // The `_.property` iteratee shorthand.\n * _.every(users, 'active');\n * // => false\n */\nfunction every(collection, predicate, guard) {\n  var func = isArray(collection) ? arrayEvery : baseEvery;\n  if (guard && isIterateeCall(collection, predicate, guard)) {\n    predicate = undefined;\n  }\n  return func(collection, baseIteratee(predicate, 3));\n}\n\nexport default every;\n","import { every, includes, some } from \"lodash-es\";\nimport { AbstractProduction, Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Rule, Terminal, } from \"./model.js\";\nexport function isSequenceProd(prod) {\n    return (prod instanceof Alternative ||\n        prod instanceof Option ||\n        prod instanceof Repetition ||\n        prod instanceof RepetitionMandatory ||\n        prod instanceof RepetitionMandatoryWithSeparator ||\n        prod instanceof RepetitionWithSeparator ||\n        prod instanceof Terminal ||\n        prod instanceof Rule);\n}\nexport function isOptionalProd(prod, alreadyVisited = []) {\n    const isDirectlyOptional = prod instanceof Option ||\n        prod instanceof Repetition ||\n        prod instanceof RepetitionWithSeparator;\n    if (isDirectlyOptional) {\n        return true;\n    }\n    // note that this can cause infinite loop if one optional empty TOP production has a cyclic dependency with another\n    // empty optional top rule\n    // may be indirectly optional ((A?B?C?) | (D?E?F?))\n    if (prod instanceof Alternation) {\n        // for OR its enough for just one of the alternatives to be optional\n        return some(prod.definition, (subProd) => {\n            return isOptionalProd(subProd, alreadyVisited);\n        });\n    }\n    else if (prod instanceof NonTerminal && includes(alreadyVisited, prod)) {\n        // avoiding stack overflow due to infinite recursion\n        return false;\n    }\n    else if (prod instanceof AbstractProduction) {\n        if (prod instanceof NonTerminal) {\n            alreadyVisited.push(prod);\n        }\n        return every(prod.definition, (subProd) => {\n            return isOptionalProd(subProd, alreadyVisited);\n        });\n    }\n    else {\n        return false;\n    }\n}\nexport function isBranchingProd(prod) {\n    return prod instanceof Alternation;\n}\nexport function getProductionDslName(prod) {\n    /* istanbul ignore else */\n    if (prod instanceof NonTerminal) {\n        return \"SUBRULE\";\n    }\n    else if (prod instanceof Option) {\n        return \"OPTION\";\n    }\n    else if (prod instanceof Alternation) {\n        return \"OR\";\n    }\n    else if (prod instanceof RepetitionMandatory) {\n        return \"AT_LEAST_ONE\";\n    }\n    else if (prod instanceof RepetitionMandatoryWithSeparator) {\n        return \"AT_LEAST_ONE_SEP\";\n    }\n    else if (prod instanceof RepetitionWithSeparator) {\n        return \"MANY_SEP\";\n    }\n    else if (prod instanceof Repetition) {\n        return \"MANY\";\n    }\n    else if (prod instanceof Terminal) {\n        return \"CONSUME\";\n        /* c8 ignore next 3 */\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\n//# sourceMappingURL=helpers.js.map","import { flatten, map, uniq } from \"lodash-es\";\nimport { isBranchingProd, isOptionalProd, isSequenceProd, NonTerminal, Terminal, } from \"@chevrotain/gast\";\nexport function first(prod) {\n    /* istanbul ignore else */\n    if (prod instanceof NonTerminal) {\n        // this could in theory cause infinite loops if\n        // (1) prod A refs prod B.\n        // (2) prod B refs prod A\n        // (3) AB can match the empty set\n        // in other words a cycle where everything is optional so the first will keep\n        // looking ahead for the next optional part and will never exit\n        // currently there is no safeguard for this unique edge case because\n        // (1) not sure a grammar in which this can happen is useful for anything (productive)\n        return first(prod.referencedRule);\n    }\n    else if (prod instanceof Terminal) {\n        return firstForTerminal(prod);\n    }\n    else if (isSequenceProd(prod)) {\n        return firstForSequence(prod);\n    }\n    else if (isBranchingProd(prod)) {\n        return firstForBranching(prod);\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexport function firstForSequence(prod) {\n    let firstSet = [];\n    const seq = prod.definition;\n    let nextSubProdIdx = 0;\n    let hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n    let currSubProd;\n    // so we enter the loop at least once (if the definition is not empty\n    let isLastInnerProdOptional = true;\n    // scan a sequence until it's end or until we have found a NONE optional production in it\n    while (hasInnerProdsRemaining && isLastInnerProdOptional) {\n        currSubProd = seq[nextSubProdIdx];\n        isLastInnerProdOptional = isOptionalProd(currSubProd);\n        firstSet = firstSet.concat(first(currSubProd));\n        nextSubProdIdx = nextSubProdIdx + 1;\n        hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n    }\n    return uniq(firstSet);\n}\nexport function firstForBranching(prod) {\n    const allAlternativesFirsts = map(prod.definition, (innerProd) => {\n        return first(innerProd);\n    });\n    return uniq(flatten(allAlternativesFirsts));\n}\nexport function firstForTerminal(terminal) {\n    return [terminal.terminalType];\n}\n//# sourceMappingURL=first.js.map","// TODO: can this be removed? where is it used?\nexport const IN = \"_~IN~_\";\n//# sourceMappingURL=constants.js.map","import { RestWalker } from \"./rest.js\";\nimport { first } from \"./first.js\";\nimport { assign, forEach } from \"lodash-es\";\nimport { IN } from \"../constants.js\";\nimport { Alternative } from \"@chevrotain/gast\";\n// This ResyncFollowsWalker computes all of the follows required for RESYNC\n// (skipping reference production).\nexport class ResyncFollowsWalker extends RestWalker {\n    constructor(topProd) {\n        super();\n        this.topProd = topProd;\n        this.follows = {};\n    }\n    startWalking() {\n        this.walk(this.topProd);\n        return this.follows;\n    }\n    walkTerminal(terminal, currRest, prevRest) {\n        // do nothing! just like in the public sector after 13:00\n    }\n    walkProdRef(refProd, currRest, prevRest) {\n        const followName = buildBetweenProdsFollowPrefix(refProd.referencedRule, refProd.idx) +\n            this.topProd.name;\n        const fullRest = currRest.concat(prevRest);\n        const restProd = new Alternative({ definition: fullRest });\n        const t_in_topProd_follows = first(restProd);\n        this.follows[followName] = t_in_topProd_follows;\n    }\n}\nexport function computeAllProdsFollows(topProductions) {\n    const reSyncFollows = {};\n    forEach(topProductions, (topProd) => {\n        const currRefsFollow = new ResyncFollowsWalker(topProd).startWalking();\n        assign(reSyncFollows, currRefsFollow);\n    });\n    return reSyncFollows;\n}\nexport function buildBetweenProdsFollowPrefix(inner, occurenceInParent) {\n    return inner.name + occurenceInParent + IN;\n}\nexport function buildInProdFollowPrefix(terminal) {\n    const terminalName = terminal.terminalType.name;\n    return terminalName + terminal.idx + IN;\n}\n//# sourceMappingURL=follow.js.map","/** Error message constants. */\nvar FUNC_ERROR_TEXT = 'Expected a function';\n\n/**\n * Creates a function that negates the result of the predicate `func`. The\n * `func` predicate is invoked with the `this` binding and arguments of the\n * created function.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Function\n * @param {Function} predicate The predicate to negate.\n * @returns {Function} Returns the new negated function.\n * @example\n *\n * function isEven(n) {\n *   return n % 2 == 0;\n * }\n *\n * _.filter([1, 2, 3, 4, 5, 6], _.negate(isEven));\n * // => [1, 3, 5]\n */\nfunction negate(predicate) {\n  if (typeof predicate != 'function') {\n    throw new TypeError(FUNC_ERROR_TEXT);\n  }\n  return function() {\n    var args = arguments;\n    switch (args.length) {\n      case 0: return !predicate.call(this);\n      case 1: return !predicate.call(this, args[0]);\n      case 2: return !predicate.call(this, args[0], args[1]);\n      case 3: return !predicate.call(this, args[0], args[1], args[2]);\n    }\n    return !predicate.apply(this, args);\n  };\n}\n\nexport default negate;\n","import arrayFilter from './_arrayFilter.js';\nimport baseFilter from './_baseFilter.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\nimport negate from './negate.js';\n\n/**\n * The opposite of `_.filter`; this method returns the elements of `collection`\n * that `predicate` does **not** return truthy for.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new filtered array.\n * @see _.filter\n * @example\n *\n * var users = [\n *   { 'user': 'barney', 'age': 36, 'active': false },\n *   { 'user': 'fred',   'age': 40, 'active': true }\n * ];\n *\n * _.reject(users, function(o) { return !o.active; });\n * // => objects for ['fred']\n *\n * // The `_.matches` iteratee shorthand.\n * _.reject(users, { 'age': 40, 'active': true });\n * // => objects for ['barney']\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.reject(users, ['active', false]);\n * // => objects for ['fred']\n *\n * // The `_.property` iteratee shorthand.\n * _.reject(users, 'active');\n * // => objects for ['barney']\n */\nfunction reject(collection, predicate) {\n  var func = isArray(collection) ? arrayFilter : baseFilter;\n  return func(collection, negate(baseIteratee(predicate, 3)));\n}\n\nexport default reject;\n","import baseIndexOf from './_baseIndexOf.js';\nimport toInteger from './toInteger.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Gets the index at which the first occurrence of `value` is found in `array`\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. If `fromIndex` is negative, it's used as the\n * offset from the end of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n * @example\n *\n * _.indexOf([1, 2, 1, 2], 2);\n * // => 1\n *\n * // Search from the `fromIndex`.\n * _.indexOf([1, 2, 1, 2], 2, 2);\n * // => 3\n */\nfunction indexOf(array, value, fromIndex) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return -1;\n  }\n  var index = fromIndex == null ? 0 : toInteger(fromIndex);\n  if (index < 0) {\n    index = nativeMax(length + index, 0);\n  }\n  return baseIndexOf(array, value, index);\n}\n\nexport default indexOf;\n","import SetCache from './_SetCache.js';\nimport arrayIncludes from './_arrayIncludes.js';\nimport arrayIncludesWith from './_arrayIncludesWith.js';\nimport arrayMap from './_arrayMap.js';\nimport baseUnary from './_baseUnary.js';\nimport cacheHas from './_cacheHas.js';\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/**\n * The base implementation of methods like `_.difference` without support\n * for excluding multiple arrays or iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Array} values The values to exclude.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new array of filtered values.\n */\nfunction baseDifference(array, values, iteratee, comparator) {\n  var index = -1,\n      includes = arrayIncludes,\n      isCommon = true,\n      length = array.length,\n      result = [],\n      valuesLength = values.length;\n\n  if (!length) {\n    return result;\n  }\n  if (iteratee) {\n    values = arrayMap(values, baseUnary(iteratee));\n  }\n  if (comparator) {\n    includes = arrayIncludesWith;\n    isCommon = false;\n  }\n  else if (values.length >= LARGE_ARRAY_SIZE) {\n    includes = cacheHas;\n    isCommon = false;\n    values = new SetCache(values);\n  }\n  outer:\n  while (++index < length) {\n    var value = array[index],\n        computed = iteratee == null ? value : iteratee(value);\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (isCommon && computed === computed) {\n      var valuesIndex = valuesLength;\n      while (valuesIndex--) {\n        if (values[valuesIndex] === computed) {\n          continue outer;\n        }\n      }\n      result.push(value);\n    }\n    else if (!includes(values, computed, comparator)) {\n      result.push(value);\n    }\n  }\n  return result;\n}\n\nexport default baseDifference;\n","import baseDifference from './_baseDifference.js';\nimport baseFlatten from './_baseFlatten.js';\nimport baseRest from './_baseRest.js';\nimport isArrayLikeObject from './isArrayLikeObject.js';\n\n/**\n * Creates an array of `array` values not included in the other given arrays\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. The order and references of result values are\n * determined by the first array.\n *\n * **Note:** Unlike `_.pullAll`, this method returns a new array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {...Array} [values] The values to exclude.\n * @returns {Array} Returns the new array of filtered values.\n * @see _.without, _.xor\n * @example\n *\n * _.difference([2, 1], [2, 3]);\n * // => [1]\n */\nvar difference = baseRest(function(array, values) {\n  return isArrayLikeObject(array)\n    ? baseDifference(array, baseFlatten(values, 1, isArrayLikeObject, true))\n    : [];\n});\n\nexport default difference;\n","/**\n * Creates an array with all falsey values removed. The values `false`, `null`,\n * `0`, `\"\"`, `undefined`, and `NaN` are falsey.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to compact.\n * @returns {Array} Returns the new array of filtered values.\n * @example\n *\n * _.compact([0, 1, false, 2, '', 3]);\n * // => [1, 2, 3]\n */\nfunction compact(array) {\n  var index = -1,\n      length = array == null ? 0 : array.length,\n      resIndex = 0,\n      result = [];\n\n  while (++index < length) {\n    var value = array[index];\n    if (value) {\n      result[resIndex++] = value;\n    }\n  }\n  return result;\n}\n\nexport default compact;\n","/**\n * Gets the first element of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @alias first\n * @category Array\n * @param {Array} array The array to query.\n * @returns {*} Returns the first element of `array`.\n * @example\n *\n * _.head([1, 2, 3]);\n * // => 1\n *\n * _.head([]);\n * // => undefined\n */\nfunction head(array) {\n  return (array && array.length) ? array[0] : undefined;\n}\n\nexport default head;\n","export function PRINT_ERROR(msg) {\n    /* istanbul ignore else - can't override global.console in node.js */\n    if (console && console.error) {\n        console.error(`Error: ${msg}`);\n    }\n}\nexport function PRINT_WARNING(msg) {\n    /* istanbul ignore else - can't override global.console in node.js*/\n    if (console && console.warn) {\n        // TODO: modify docs accordingly\n        console.warn(`Warning: ${msg}`);\n    }\n}\n//# sourceMappingURL=print.js.map","import { RegExpParser, } from \"@chevrotain/regexp-to-ast\";\nlet regExpAstCache = {};\nconst regExpParser = new RegExpParser();\nexport function getRegExpAst(regExp) {\n    const regExpStr = regExp.toString();\n    if (regExpAstCache.hasOwnProperty(regExpStr)) {\n        return regExpAstCache[regExpStr];\n    }\n    else {\n        const regExpAst = regExpParser.pattern(regExpStr);\n        regExpAstCache[regExpStr] = regExpAst;\n        return regExpAst;\n    }\n}\nexport function clearRegExpParserCache() {\n    regExpAstCache = {};\n}\n//# sourceMappingURL=reg_exp_parser.js.map","import { BaseRegExpVisitor, } from \"@chevrotain/regexp-to-ast\";\nimport { every, find, forEach, includes, isArray, values } from \"lodash-es\";\nimport { PRINT_ERROR, PRINT_WARNING } from \"@chevrotain/utils\";\nimport { getRegExpAst } from \"./reg_exp_parser.js\";\nimport { charCodeToOptimizedIndex, minOptimizationVal } from \"./lexer.js\";\nconst complementErrorMessage = \"Complement Sets are not supported for first char optimization\";\nexport const failedOptimizationPrefixMsg = 'Unable to use \"first char\" lexer optimizations:\\n';\nexport function getOptimizedStartCodesIndices(regExp, ensureOptimizations = false) {\n    try {\n        const ast = getRegExpAst(regExp);\n        const firstChars = firstCharOptimizedIndices(ast.value, {}, ast.flags.ignoreCase);\n        return firstChars;\n    }\n    catch (e) {\n        /* istanbul ignore next */\n        // Testing this relies on the regexp-to-ast library having a bug... */\n        // TODO: only the else branch needs to be ignored, try to fix with newer prettier / tsc\n        if (e.message === complementErrorMessage) {\n            if (ensureOptimizations) {\n                PRINT_WARNING(`${failedOptimizationPrefixMsg}` +\n                    `\\tUnable to optimize: < ${regExp.toString()} >\\n` +\n                    \"\\tComplement Sets cannot be automatically optimized.\\n\" +\n                    \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                    \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#COMPLEMENT for details.\");\n            }\n        }\n        else {\n            let msgSuffix = \"\";\n            if (ensureOptimizations) {\n                msgSuffix =\n                    \"\\n\\tThis will disable the lexer's first char optimizations.\\n\" +\n                        \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#REGEXP_PARSING for details.\";\n            }\n            PRINT_ERROR(`${failedOptimizationPrefixMsg}\\n` +\n                `\\tFailed parsing: < ${regExp.toString()} >\\n` +\n                `\\tUsing the @chevrotain/regexp-to-ast library\\n` +\n                \"\\tPlease open an issue at: https://github.com/chevrotain/chevrotain/issues\" +\n                msgSuffix);\n        }\n    }\n    return [];\n}\nexport function firstCharOptimizedIndices(ast, result, ignoreCase) {\n    switch (ast.type) {\n        case \"Disjunction\":\n            for (let i = 0; i < ast.value.length; i++) {\n                firstCharOptimizedIndices(ast.value[i], result, ignoreCase);\n            }\n            break;\n        case \"Alternative\":\n            const terms = ast.value;\n            for (let i = 0; i < terms.length; i++) {\n                const term = terms[i];\n                // skip terms that cannot effect the first char results\n                switch (term.type) {\n                    case \"EndAnchor\":\n                    // A group back reference cannot affect potential starting char.\n                    // because if a back reference is the first production than automatically\n                    // the group being referenced has had to come BEFORE so its codes have already been added\n                    case \"GroupBackReference\":\n                    // assertions do not affect potential starting codes\n                    case \"Lookahead\":\n                    case \"NegativeLookahead\":\n                    case \"StartAnchor\":\n                    case \"WordBoundary\":\n                    case \"NonWordBoundary\":\n                        continue;\n                }\n                const atom = term;\n                switch (atom.type) {\n                    case \"Character\":\n                        addOptimizedIdxToResult(atom.value, result, ignoreCase);\n                        break;\n                    case \"Set\":\n                        if (atom.complement === true) {\n                            throw Error(complementErrorMessage);\n                        }\n                        forEach(atom.value, (code) => {\n                            if (typeof code === \"number\") {\n                                addOptimizedIdxToResult(code, result, ignoreCase);\n                            }\n                            else {\n                                // range\n                                const range = code;\n                                // cannot optimize when ignoreCase is\n                                if (ignoreCase === true) {\n                                    for (let rangeCode = range.from; rangeCode <= range.to; rangeCode++) {\n                                        addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                                    }\n                                }\n                                // Optimization (2 orders of magnitude less work for very large ranges)\n                                else {\n                                    // handle unoptimized values\n                                    for (let rangeCode = range.from; rangeCode <= range.to && rangeCode < minOptimizationVal; rangeCode++) {\n                                        addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                                    }\n                                    // Less common charCode where we optimize for faster init time, by using larger \"buckets\"\n                                    if (range.to >= minOptimizationVal) {\n                                        const minUnOptVal = range.from >= minOptimizationVal\n                                            ? range.from\n                                            : minOptimizationVal;\n                                        const maxUnOptVal = range.to;\n                                        const minOptIdx = charCodeToOptimizedIndex(minUnOptVal);\n                                        const maxOptIdx = charCodeToOptimizedIndex(maxUnOptVal);\n                                        for (let currOptIdx = minOptIdx; currOptIdx <= maxOptIdx; currOptIdx++) {\n                                            result[currOptIdx] = currOptIdx;\n                                        }\n                                    }\n                                }\n                            }\n                        });\n                        break;\n                    case \"Group\":\n                        firstCharOptimizedIndices(atom.value, result, ignoreCase);\n                        break;\n                    /* istanbul ignore next */\n                    default:\n                        throw Error(\"Non Exhaustive Match\");\n                }\n                // reached a mandatory production, no more **start** codes can be found on this alternative\n                const isOptionalQuantifier = atom.quantifier !== undefined && atom.quantifier.atLeast === 0;\n                if (\n                // A group may be optional due to empty contents /(?:)/\n                // or if everything inside it is optional /((a)?)/\n                (atom.type === \"Group\" && isWholeOptional(atom) === false) ||\n                    // If this term is not a group it may only be optional if it has an optional quantifier\n                    (atom.type !== \"Group\" && isOptionalQuantifier === false)) {\n                    break;\n                }\n            }\n            break;\n        /* istanbul ignore next */\n        default:\n            throw Error(\"non exhaustive match!\");\n    }\n    // console.log(Object.keys(result).length)\n    return values(result);\n}\nfunction addOptimizedIdxToResult(code, result, ignoreCase) {\n    const optimizedCharIdx = charCodeToOptimizedIndex(code);\n    result[optimizedCharIdx] = optimizedCharIdx;\n    if (ignoreCase === true) {\n        handleIgnoreCase(code, result);\n    }\n}\nfunction handleIgnoreCase(code, result) {\n    const char = String.fromCharCode(code);\n    const upperChar = char.toUpperCase();\n    /* istanbul ignore else */\n    if (upperChar !== char) {\n        const optimizedCharIdx = charCodeToOptimizedIndex(upperChar.charCodeAt(0));\n        result[optimizedCharIdx] = optimizedCharIdx;\n    }\n    else {\n        const lowerChar = char.toLowerCase();\n        if (lowerChar !== char) {\n            const optimizedCharIdx = charCodeToOptimizedIndex(lowerChar.charCodeAt(0));\n            result[optimizedCharIdx] = optimizedCharIdx;\n        }\n    }\n}\nfunction findCode(setNode, targetCharCodes) {\n    return find(setNode.value, (codeOrRange) => {\n        if (typeof codeOrRange === \"number\") {\n            return includes(targetCharCodes, codeOrRange);\n        }\n        else {\n            // range\n            const range = codeOrRange;\n            return (find(targetCharCodes, (targetCode) => range.from <= targetCode && targetCode <= range.to) !== undefined);\n        }\n    });\n}\nfunction isWholeOptional(ast) {\n    const quantifier = ast.quantifier;\n    if (quantifier && quantifier.atLeast === 0) {\n        return true;\n    }\n    if (!ast.value) {\n        return false;\n    }\n    return isArray(ast.value)\n        ? every(ast.value, isWholeOptional)\n        : isWholeOptional(ast.value);\n}\nclass CharCodeFinder extends BaseRegExpVisitor {\n    constructor(targetCharCodes) {\n        super();\n        this.targetCharCodes = targetCharCodes;\n        this.found = false;\n    }\n    visitChildren(node) {\n        // No need to keep looking...\n        if (this.found === true) {\n            return;\n        }\n        // switch lookaheads as they do not actually consume any characters thus\n        // finding a charCode at lookahead context does not mean that regexp can actually contain it in a match.\n        switch (node.type) {\n            case \"Lookahead\":\n                this.visitLookahead(node);\n                return;\n            case \"NegativeLookahead\":\n                this.visitNegativeLookahead(node);\n                return;\n        }\n        super.visitChildren(node);\n    }\n    visitCharacter(node) {\n        if (includes(this.targetCharCodes, node.value)) {\n            this.found = true;\n        }\n    }\n    visitSet(node) {\n        if (node.complement) {\n            if (findCode(node, this.targetCharCodes) === undefined) {\n                this.found = true;\n            }\n        }\n        else {\n            if (findCode(node, this.targetCharCodes) !== undefined) {\n                this.found = true;\n            }\n        }\n    }\n}\nexport function canMatchCharCode(charCodes, pattern) {\n    if (pattern instanceof RegExp) {\n        const ast = getRegExpAst(pattern);\n        const charCodeFinder = new CharCodeFinder(charCodes);\n        charCodeFinder.visit(ast);\n        return charCodeFinder.found;\n    }\n    else {\n        return (find(pattern, (char) => {\n            return includes(charCodes, char.charCodeAt(0));\n        }) !== undefined);\n    }\n}\n//# sourceMappingURL=reg_exp.js.map","import { BaseRegExpVisitor } from \"@chevrotain/regexp-to-ast\";\nimport { Lexer, LexerDefinitionErrorType, } from \"./lexer_public.js\";\nimport { compact, defaults, difference, filter, find, first, flatten, forEach, has, includes, indexOf, isArray, isEmpty, isFunction, isRegExp, isString, isUndefined, keys, map, reduce, reject, values, } from \"lodash-es\";\nimport { PRINT_ERROR } from \"@chevrotain/utils\";\nimport { canMatchCharCode, failedOptimizationPrefixMsg, getOptimizedStartCodesIndices, } from \"./reg_exp.js\";\nimport { getRegExpAst } from \"./reg_exp_parser.js\";\nconst PATTERN = \"PATTERN\";\nexport const DEFAULT_MODE = \"defaultMode\";\nexport const MODES = \"modes\";\nexport let SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\nexport function disableSticky() {\n    SUPPORT_STICKY = false;\n}\nexport function enableSticky() {\n    SUPPORT_STICKY = true;\n}\nexport function analyzeTokenTypes(tokenTypes, options) {\n    options = defaults(options, {\n        useSticky: SUPPORT_STICKY,\n        debug: false,\n        safeMode: false,\n        positionTracking: \"full\",\n        lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n        tracer: (msg, action) => action(),\n    });\n    const tracer = options.tracer;\n    tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n        initCharCodeToOptimizedIndexMap();\n    });\n    let onlyRelevantTypes;\n    tracer(\"Reject Lexer.NA\", () => {\n        onlyRelevantTypes = reject(tokenTypes, (currType) => {\n            return currType[PATTERN] === Lexer.NA;\n        });\n    });\n    let hasCustom = false;\n    let allTransformedPatterns;\n    tracer(\"Transform Patterns\", () => {\n        hasCustom = false;\n        allTransformedPatterns = map(onlyRelevantTypes, (currType) => {\n            const currPattern = currType[PATTERN];\n            /* istanbul ignore else */\n            if (isRegExp(currPattern)) {\n                const regExpSource = currPattern.source;\n                if (regExpSource.length === 1 &&\n                    // only these regExp meta characters which can appear in a length one regExp\n                    regExpSource !== \"^\" &&\n                    regExpSource !== \"$\" &&\n                    regExpSource !== \".\" &&\n                    !currPattern.ignoreCase) {\n                    return regExpSource;\n                }\n                else if (regExpSource.length === 2 &&\n                    regExpSource[0] === \"\\\\\" &&\n                    // not a meta character\n                    !includes([\n                        \"d\",\n                        \"D\",\n                        \"s\",\n                        \"S\",\n                        \"t\",\n                        \"r\",\n                        \"n\",\n                        \"t\",\n                        \"0\",\n                        \"c\",\n                        \"b\",\n                        \"B\",\n                        \"f\",\n                        \"v\",\n                        \"w\",\n                        \"W\",\n                    ], regExpSource[1])) {\n                    // escaped meta Characters: /\\+/ /\\[/\n                    // or redundant escaping: /\\a/\n                    // without the escaping \"\\\"\n                    return regExpSource[1];\n                }\n                else {\n                    return options.useSticky\n                        ? addStickyFlag(currPattern)\n                        : addStartOfInput(currPattern);\n                }\n            }\n            else if (isFunction(currPattern)) {\n                hasCustom = true;\n                // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n                return { exec: currPattern };\n            }\n            else if (typeof currPattern === \"object\") {\n                hasCustom = true;\n                // ICustomPattern\n                return currPattern;\n            }\n            else if (typeof currPattern === \"string\") {\n                if (currPattern.length === 1) {\n                    return currPattern;\n                }\n                else {\n                    const escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n                    const wrappedRegExp = new RegExp(escapedRegExpString);\n                    return options.useSticky\n                        ? addStickyFlag(wrappedRegExp)\n                        : addStartOfInput(wrappedRegExp);\n                }\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n    });\n    let patternIdxToType;\n    let patternIdxToGroup;\n    let patternIdxToLongerAltIdxArr;\n    let patternIdxToPushMode;\n    let patternIdxToPopMode;\n    tracer(\"misc mapping\", () => {\n        patternIdxToType = map(onlyRelevantTypes, (currType) => currType.tokenTypeIdx);\n        patternIdxToGroup = map(onlyRelevantTypes, (clazz) => {\n            const groupName = clazz.GROUP;\n            /* istanbul ignore next */\n            if (groupName === Lexer.SKIPPED) {\n                return undefined;\n            }\n            else if (isString(groupName)) {\n                return groupName;\n            }\n            else if (isUndefined(groupName)) {\n                return false;\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n        patternIdxToLongerAltIdxArr = map(onlyRelevantTypes, (clazz) => {\n            const longerAltType = clazz.LONGER_ALT;\n            if (longerAltType) {\n                const longerAltIdxArr = isArray(longerAltType)\n                    ? map(longerAltType, (type) => indexOf(onlyRelevantTypes, type))\n                    : [indexOf(onlyRelevantTypes, longerAltType)];\n                return longerAltIdxArr;\n            }\n        });\n        patternIdxToPushMode = map(onlyRelevantTypes, (clazz) => clazz.PUSH_MODE);\n        patternIdxToPopMode = map(onlyRelevantTypes, (clazz) => has(clazz, \"POP_MODE\"));\n    });\n    let patternIdxToCanLineTerminator;\n    tracer(\"Line Terminator Handling\", () => {\n        const lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n        patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => false);\n        if (options.positionTracking !== \"onlyOffset\") {\n            patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => {\n                if (has(tokType, \"LINE_BREAKS\")) {\n                    return !!tokType.LINE_BREAKS;\n                }\n                else {\n                    return (checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false &&\n                        canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN));\n                }\n            });\n        }\n    });\n    let patternIdxToIsCustom;\n    let patternIdxToShort;\n    let emptyGroups;\n    let patternIdxToConfig;\n    tracer(\"Misc Mapping #2\", () => {\n        patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern);\n        patternIdxToShort = map(allTransformedPatterns, isShortPattern);\n        emptyGroups = reduce(onlyRelevantTypes, (acc, clazz) => {\n            const groupName = clazz.GROUP;\n            if (isString(groupName) && !(groupName === Lexer.SKIPPED)) {\n                acc[groupName] = [];\n            }\n            return acc;\n        }, {});\n        patternIdxToConfig = map(allTransformedPatterns, (x, idx) => {\n            return {\n                pattern: allTransformedPatterns[idx],\n                longerAlt: patternIdxToLongerAltIdxArr[idx],\n                canLineTerminator: patternIdxToCanLineTerminator[idx],\n                isCustom: patternIdxToIsCustom[idx],\n                short: patternIdxToShort[idx],\n                group: patternIdxToGroup[idx],\n                push: patternIdxToPushMode[idx],\n                pop: patternIdxToPopMode[idx],\n                tokenTypeIdx: patternIdxToType[idx],\n                tokenType: onlyRelevantTypes[idx],\n            };\n        });\n    });\n    let canBeOptimized = true;\n    let charCodeToPatternIdxToConfig = [];\n    if (!options.safeMode) {\n        tracer(\"First Char Optimization\", () => {\n            charCodeToPatternIdxToConfig = reduce(onlyRelevantTypes, (result, currTokType, idx) => {\n                if (typeof currTokType.PATTERN === \"string\") {\n                    const charCode = currTokType.PATTERN.charCodeAt(0);\n                    const optimizedIdx = charCodeToOptimizedIndex(charCode);\n                    addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n                }\n                else if (isArray(currTokType.START_CHARS_HINT)) {\n                    let lastOptimizedIdx;\n                    forEach(currTokType.START_CHARS_HINT, (charOrInt) => {\n                        const charCode = typeof charOrInt === \"string\"\n                            ? charOrInt.charCodeAt(0)\n                            : charOrInt;\n                        const currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n                        // Avoid adding the config multiple times\n                        /* istanbul ignore else */\n                        // - Difficult to check this scenario effects as it is only a performance\n                        //   optimization that does not change correctness\n                        if (lastOptimizedIdx !== currOptimizedIdx) {\n                            lastOptimizedIdx = currOptimizedIdx;\n                            addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n                        }\n                    });\n                }\n                else if (isRegExp(currTokType.PATTERN)) {\n                    if (currTokType.PATTERN.unicode) {\n                        canBeOptimized = false;\n                        if (options.ensureOptimizations) {\n                            PRINT_ERROR(`${failedOptimizationPrefixMsg}` +\n                                `\\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\\n` +\n                                \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                                \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                                \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n                        }\n                    }\n                    else {\n                        const optimizedCodes = getOptimizedStartCodesIndices(currTokType.PATTERN, options.ensureOptimizations);\n                        /* istanbul ignore if */\n                        // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n                        // the first should be a different validation and the second cannot be tested.\n                        if (isEmpty(optimizedCodes)) {\n                            // we cannot understand what codes may start possible matches\n                            // The optimization correctness requires knowing start codes for ALL patterns.\n                            // Not actually sure this is an error, no debug message\n                            canBeOptimized = false;\n                        }\n                        forEach(optimizedCodes, (code) => {\n                            addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n                        });\n                    }\n                }\n                else {\n                    if (options.ensureOptimizations) {\n                        PRINT_ERROR(`${failedOptimizationPrefixMsg}` +\n                            `\\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\\n` +\n                            \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n                    }\n                    canBeOptimized = false;\n                }\n                return result;\n            }, []);\n        });\n    }\n    return {\n        emptyGroups: emptyGroups,\n        patternIdxToConfig: patternIdxToConfig,\n        charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n        hasCustom: hasCustom,\n        canBeOptimized: canBeOptimized,\n    };\n}\nexport function validatePatterns(tokenTypes, validModesNames) {\n    let errors = [];\n    const missingResult = findMissingPatterns(tokenTypes);\n    errors = errors.concat(missingResult.errors);\n    const invalidResult = findInvalidPatterns(missingResult.valid);\n    const validTokenTypes = invalidResult.valid;\n    errors = errors.concat(invalidResult.errors);\n    errors = errors.concat(validateRegExpPattern(validTokenTypes));\n    errors = errors.concat(findInvalidGroupType(validTokenTypes));\n    errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n    errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n    return errors;\n}\nfunction validateRegExpPattern(tokenTypes) {\n    let errors = [];\n    const withRegExpPatterns = filter(tokenTypes, (currTokType) => isRegExp(currTokType[PATTERN]));\n    errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n    errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n    errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n    return errors;\n}\nexport function findMissingPatterns(tokenTypes) {\n    const tokenTypesWithMissingPattern = filter(tokenTypes, (currType) => {\n        return !has(currType, PATTERN);\n    });\n    const errors = map(tokenTypesWithMissingPattern, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- missing static 'PATTERN' property\",\n            type: LexerDefinitionErrorType.MISSING_PATTERN,\n            tokenTypes: [currType],\n        };\n    });\n    const valid = difference(tokenTypes, tokenTypesWithMissingPattern);\n    return { errors, valid };\n}\nexport function findInvalidPatterns(tokenTypes) {\n    const tokenTypesWithInvalidPattern = filter(tokenTypes, (currType) => {\n        const pattern = currType[PATTERN];\n        return (!isRegExp(pattern) &&\n            !isFunction(pattern) &&\n            !has(pattern, \"exec\") &&\n            !isString(pattern));\n    });\n    const errors = map(tokenTypesWithInvalidPattern, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' can only be a RegExp, a\" +\n                \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n            type: LexerDefinitionErrorType.INVALID_PATTERN,\n            tokenTypes: [currType],\n        };\n    });\n    const valid = difference(tokenTypes, tokenTypesWithInvalidPattern);\n    return { errors, valid };\n}\nconst end_of_input = /[^\\\\][$]/;\nexport function findEndOfInputAnchor(tokenTypes) {\n    class EndAnchorFinder extends BaseRegExpVisitor {\n        constructor() {\n            super(...arguments);\n            this.found = false;\n        }\n        visitEndAnchor(node) {\n            this.found = true;\n        }\n    }\n    const invalidRegex = filter(tokenTypes, (currType) => {\n        const pattern = currType.PATTERN;\n        try {\n            const regexpAst = getRegExpAst(pattern);\n            const endAnchorVisitor = new EndAnchorFinder();\n            endAnchorVisitor.visit(regexpAst);\n            return endAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return end_of_input.test(pattern.source);\n        }\n    });\n    const errors = map(invalidRegex, (currType) => {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n                \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n            tokenTypes: [currType],\n        };\n    });\n    return errors;\n}\nexport function findEmptyMatchRegExps(tokenTypes) {\n    const matchesEmptyString = filter(tokenTypes, (currType) => {\n        const pattern = currType.PATTERN;\n        return pattern.test(\"\");\n    });\n    const errors = map(matchesEmptyString, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' must not match an empty string\",\n            type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n            tokenTypes: [currType],\n        };\n    });\n    return errors;\n}\nconst start_of_input = /[^\\\\[][\\^]|^\\^/;\nexport function findStartOfInputAnchor(tokenTypes) {\n    class StartAnchorFinder extends BaseRegExpVisitor {\n        constructor() {\n            super(...arguments);\n            this.found = false;\n        }\n        visitStartAnchor(node) {\n            this.found = true;\n        }\n    }\n    const invalidRegex = filter(tokenTypes, (currType) => {\n        const pattern = currType.PATTERN;\n        try {\n            const regexpAst = getRegExpAst(pattern);\n            const startAnchorVisitor = new StartAnchorFinder();\n            startAnchorVisitor.visit(regexpAst);\n            return startAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return start_of_input.test(pattern.source);\n        }\n    });\n    const errors = map(invalidRegex, (currType) => {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n                \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n            tokenTypes: [currType],\n        };\n    });\n    return errors;\n}\nexport function findUnsupportedFlags(tokenTypes) {\n    const invalidFlags = filter(tokenTypes, (currType) => {\n        const pattern = currType[PATTERN];\n        return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n    });\n    const errors = map(invalidFlags, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n            type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n            tokenTypes: [currType],\n        };\n    });\n    return errors;\n}\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nexport function findDuplicatePatterns(tokenTypes) {\n    const found = [];\n    let identicalPatterns = map(tokenTypes, (outerType) => {\n        return reduce(tokenTypes, (result, innerType) => {\n            if (outerType.PATTERN.source === innerType.PATTERN.source &&\n                !includes(found, innerType) &&\n                innerType.PATTERN !== Lexer.NA) {\n                // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n                // in essence we are creating Equivalence classes on equality relation.\n                found.push(innerType);\n                result.push(innerType);\n                return result;\n            }\n            return result;\n        }, []);\n    });\n    identicalPatterns = compact(identicalPatterns);\n    const duplicatePatterns = filter(identicalPatterns, (currIdenticalSet) => {\n        return currIdenticalSet.length > 1;\n    });\n    const errors = map(duplicatePatterns, (setOfIdentical) => {\n        const tokenTypeNames = map(setOfIdentical, (currType) => {\n            return currType.name;\n        });\n        const dupPatternSrc = first(setOfIdentical).PATTERN;\n        return {\n            message: `The same RegExp pattern ->${dupPatternSrc}<-` +\n                `has been used in all of the following Token Types: ${tokenTypeNames.join(\", \")} <-`,\n            type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n            tokenTypes: setOfIdentical,\n        };\n    });\n    return errors;\n}\nexport function findInvalidGroupType(tokenTypes) {\n    const invalidTypes = filter(tokenTypes, (clazz) => {\n        if (!has(clazz, \"GROUP\")) {\n            return false;\n        }\n        const group = clazz.GROUP;\n        return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString(group);\n    });\n    const errors = map(invalidTypes, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n            type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n            tokenTypes: [currType],\n        };\n    });\n    return errors;\n}\nexport function findModesThatDoNotExist(tokenTypes, validModes) {\n    const invalidModes = filter(tokenTypes, (clazz) => {\n        return (clazz.PUSH_MODE !== undefined && !includes(validModes, clazz.PUSH_MODE));\n    });\n    const errors = map(invalidModes, (tokType) => {\n        const msg = `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-` +\n            `which does not exist`;\n        return {\n            message: msg,\n            type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n            tokenTypes: [tokType],\n        };\n    });\n    return errors;\n}\nexport function findUnreachablePatterns(tokenTypes) {\n    const errors = [];\n    const canBeTested = reduce(tokenTypes, (result, tokType, idx) => {\n        const pattern = tokType.PATTERN;\n        if (pattern === Lexer.NA) {\n            return result;\n        }\n        // a more comprehensive validation for all forms of regExps would require\n        // deeper regExp analysis capabilities\n        if (isString(pattern)) {\n            result.push({ str: pattern, idx, tokenType: tokType });\n        }\n        else if (isRegExp(pattern) && noMetaChar(pattern)) {\n            result.push({ str: pattern.source, idx, tokenType: tokType });\n        }\n        return result;\n    }, []);\n    forEach(tokenTypes, (tokType, testIdx) => {\n        forEach(canBeTested, ({ str, idx, tokenType }) => {\n            if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n                const msg = `Token: ->${tokenType.name}<- can never be matched.\\n` +\n                    `Because it appears AFTER the Token Type ->${tokType.name}<-` +\n                    `in the lexer's definition.\\n` +\n                    `See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`;\n                errors.push({\n                    message: msg,\n                    type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n                    tokenTypes: [tokType, tokenType],\n                });\n            }\n        });\n    });\n    return errors;\n}\nfunction testTokenType(str, pattern) {\n    /* istanbul ignore else */\n    if (isRegExp(pattern)) {\n        const regExpArray = pattern.exec(str);\n        return regExpArray !== null && regExpArray.index === 0;\n    }\n    else if (isFunction(pattern)) {\n        // maintain the API of custom patterns\n        return pattern(str, 0, [], {});\n    }\n    else if (has(pattern, \"exec\")) {\n        // maintain the API of custom patterns\n        return pattern.exec(str, 0, [], {});\n    }\n    else if (typeof pattern === \"string\") {\n        return pattern === str;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nfunction noMetaChar(regExp) {\n    //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n    const metaChars = [\n        \".\",\n        \"\\\\\",\n        \"[\",\n        \"]\",\n        \"|\",\n        \"^\",\n        \"$\",\n        \"(\",\n        \")\",\n        \"?\",\n        \"*\",\n        \"+\",\n        \"{\",\n    ];\n    return (find(metaChars, (char) => regExp.source.indexOf(char) !== -1) === undefined);\n}\nexport function addStartOfInput(pattern) {\n    const flags = pattern.ignoreCase ? \"i\" : \"\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(`^(?:${pattern.source})`, flags);\n}\nexport function addStickyFlag(pattern) {\n    const flags = pattern.ignoreCase ? \"iy\" : \"y\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(`${pattern.source}`, flags);\n}\nexport function performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    const errors = [];\n    // some run time checks to help the end users.\n    if (!has(lexerDefinition, DEFAULT_MODE)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                DEFAULT_MODE +\n                \"> property in its definition\\n\",\n            type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n        });\n    }\n    if (!has(lexerDefinition, MODES)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                MODES +\n                \"> property in its definition\\n\",\n            type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n        });\n    }\n    if (has(lexerDefinition, MODES) &&\n        has(lexerDefinition, DEFAULT_MODE) &&\n        !has(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n        errors.push({\n            message: `A MultiMode Lexer cannot be initialized with a ${DEFAULT_MODE}: <${lexerDefinition.defaultMode}>` +\n                `which does not exist\\n`,\n            type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n        });\n    }\n    if (has(lexerDefinition, MODES)) {\n        forEach(lexerDefinition.modes, (currModeValue, currModeName) => {\n            forEach(currModeValue, (currTokType, currIdx) => {\n                if (isUndefined(currTokType)) {\n                    errors.push({\n                        message: `A Lexer cannot be initialized using an undefined Token Type. Mode:` +\n                            `<${currModeName}> at index: <${currIdx}>\\n`,\n                        type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n                    });\n                }\n                else if (has(currTokType, \"LONGER_ALT\")) {\n                    const longerAlt = isArray(currTokType.LONGER_ALT)\n                        ? currTokType.LONGER_ALT\n                        : [currTokType.LONGER_ALT];\n                    forEach(longerAlt, (currLongerAlt) => {\n                        if (!isUndefined(currLongerAlt) &&\n                            !includes(currModeValue, currLongerAlt)) {\n                            errors.push({\n                                message: `A MultiMode Lexer cannot be initialized with a longer_alt <${currLongerAlt.name}> on token <${currTokType.name}> outside of mode <${currModeName}>\\n`,\n                                type: LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE,\n                            });\n                        }\n                    });\n                }\n            });\n        });\n    }\n    return errors;\n}\nexport function performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    const warnings = [];\n    let hasAnyLineBreak = false;\n    const allTokenTypes = compact(flatten(values(lexerDefinition.modes)));\n    const concreteTokenTypes = reject(allTokenTypes, (currType) => currType[PATTERN] === Lexer.NA);\n    const terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n    if (trackLines) {\n        forEach(concreteTokenTypes, (tokType) => {\n            const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n            if (currIssue !== false) {\n                const message = buildLineBreakIssueMessage(tokType, currIssue);\n                const warningDescriptor = {\n                    message,\n                    type: currIssue.issue,\n                    tokenType: tokType,\n                };\n                warnings.push(warningDescriptor);\n            }\n            else {\n                // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n                if (has(tokType, \"LINE_BREAKS\")) {\n                    if (tokType.LINE_BREAKS === true) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n                else {\n                    if (canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n            }\n        });\n    }\n    if (trackLines && !hasAnyLineBreak) {\n        warnings.push({\n            message: \"Warning: No LINE_BREAKS Found.\\n\" +\n                \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n                \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n                \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n                \"\\tfor details.\",\n            type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS,\n        });\n    }\n    return warnings;\n}\nexport function cloneEmptyGroups(emptyGroups) {\n    const clonedResult = {};\n    const groupKeys = keys(emptyGroups);\n    forEach(groupKeys, (currKey) => {\n        const currGroupValue = emptyGroups[currKey];\n        /* istanbul ignore else */\n        if (isArray(currGroupValue)) {\n            clonedResult[currKey] = [];\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    });\n    return clonedResult;\n}\n// TODO: refactor to avoid duplication\nexport function isCustomPattern(tokenType) {\n    const pattern = tokenType.PATTERN;\n    /* istanbul ignore else */\n    if (isRegExp(pattern)) {\n        return false;\n    }\n    else if (isFunction(pattern)) {\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n        return true;\n    }\n    else if (has(pattern, \"exec\")) {\n        // ICustomPattern\n        return true;\n    }\n    else if (isString(pattern)) {\n        return false;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexport function isShortPattern(pattern) {\n    if (isString(pattern) && pattern.length === 1) {\n        return pattern.charCodeAt(0);\n    }\n    else {\n        return false;\n    }\n}\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexport const LineTerminatorOptimizedTester = {\n    // implements /\\n|\\r\\n?/g.test\n    test: function (text) {\n        const len = text.length;\n        for (let i = this.lastIndex; i < len; i++) {\n            const c = text.charCodeAt(i);\n            if (c === 10) {\n                this.lastIndex = i + 1;\n                return true;\n            }\n            else if (c === 13) {\n                if (text.charCodeAt(i + 1) === 10) {\n                    this.lastIndex = i + 2;\n                }\n                else {\n                    this.lastIndex = i + 1;\n                }\n                return true;\n            }\n        }\n        return false;\n    },\n    lastIndex: 0,\n};\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n    if (has(tokType, \"LINE_BREAKS\")) {\n        // if the user explicitly declared the line_breaks option we will respect their choice\n        // and assume it is correct.\n        return false;\n    }\n    else {\n        /* istanbul ignore else */\n        if (isRegExp(tokType.PATTERN)) {\n            try {\n                // TODO: why is the casting suddenly needed?\n                canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n            }\n            catch (e) {\n                /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n                return {\n                    issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n                    errMsg: e.message,\n                };\n            }\n            return false;\n        }\n        else if (isString(tokType.PATTERN)) {\n            // string literal patterns can always be analyzed to detect line terminator usage\n            return false;\n        }\n        else if (isCustomPattern(tokType)) {\n            // custom token types\n            return { issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    }\n}\nexport function buildLineBreakIssueMessage(tokType, details) {\n    /* istanbul ignore else */\n    if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n        return (\"Warning: unable to identify line terminator usage in pattern.\\n\" +\n            `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n            `\\t Root cause: ${details.errMsg}.\\n` +\n            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\");\n    }\n    else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n        return (\"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n            `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\");\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nfunction getCharCodes(charsOrCodes) {\n    const charCodes = map(charsOrCodes, (numOrString) => {\n        if (isString(numOrString)) {\n            return numOrString.charCodeAt(0);\n        }\n        else {\n            return numOrString;\n        }\n    });\n    return charCodes;\n}\nfunction addToMapOfArrays(map, key, value) {\n    if (map[key] === undefined) {\n        map[key] = [value];\n    }\n    else {\n        map[key].push(value);\n    }\n}\nexport const minOptimizationVal = 256;\n/**\n * We are mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nlet charCodeToOptimizedIdxMap = [];\nexport function charCodeToOptimizedIndex(charCode) {\n    return charCode < minOptimizationVal\n        ? charCode\n        : charCodeToOptimizedIdxMap[charCode];\n}\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n    if (isEmpty(charCodeToOptimizedIdxMap)) {\n        charCodeToOptimizedIdxMap = new Array(65536);\n        for (let i = 0; i < 65536; i++) {\n            charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n        }\n    }\n}\n//# sourceMappingURL=lexer.js.map","export function timer(func) {\n    const start = new Date().getTime();\n    const val = func();\n    const end = new Date().getTime();\n    const total = end - start;\n    return { time: total, value: val };\n}\n//# sourceMappingURL=timer.js.map","import { clone, compact, difference, flatten, forEach, has, includes, isArray, isEmpty, map, } from \"lodash-es\";\nexport function tokenStructuredMatcher(tokInstance, tokConstructor) {\n    const instanceType = tokInstance.tokenTypeIdx;\n    if (instanceType === tokConstructor.tokenTypeIdx) {\n        return true;\n    }\n    else {\n        return (tokConstructor.isParent === true &&\n            tokConstructor.categoryMatchesMap[instanceType] === true);\n    }\n}\n// Optimized tokenMatcher in case our grammar does not use token categories\n// Being so tiny it is much more likely to be in-lined and this avoid the function call overhead\nexport function tokenStructuredMatcherNoCategories(token, tokType) {\n    return token.tokenTypeIdx === tokType.tokenTypeIdx;\n}\nexport let tokenShortNameIdx = 1;\nexport const tokenIdxToClass = {};\nexport function augmentTokenTypes(tokenTypes) {\n    // collect the parent Token Types as well.\n    const tokenTypesAndParents = expandCategories(tokenTypes);\n    // add required tokenType and categoryMatches properties\n    assignTokenDefaultProps(tokenTypesAndParents);\n    // fill up the categoryMatches\n    assignCategoriesMapProp(tokenTypesAndParents);\n    assignCategoriesTokensProp(tokenTypesAndParents);\n    forEach(tokenTypesAndParents, (tokType) => {\n        tokType.isParent = tokType.categoryMatches.length > 0;\n    });\n}\nexport function expandCategories(tokenTypes) {\n    let result = clone(tokenTypes);\n    let categories = tokenTypes;\n    let searching = true;\n    while (searching) {\n        categories = compact(flatten(map(categories, (currTokType) => currTokType.CATEGORIES)));\n        const newCategories = difference(categories, result);\n        result = result.concat(newCategories);\n        if (isEmpty(newCategories)) {\n            searching = false;\n        }\n        else {\n            categories = newCategories;\n        }\n    }\n    return result;\n}\nexport function assignTokenDefaultProps(tokenTypes) {\n    forEach(tokenTypes, (currTokType) => {\n        if (!hasShortKeyProperty(currTokType)) {\n            tokenIdxToClass[tokenShortNameIdx] = currTokType;\n            currTokType.tokenTypeIdx = tokenShortNameIdx++;\n        }\n        // CATEGORIES? : TokenType | TokenType[]\n        if (hasCategoriesProperty(currTokType) &&\n            !isArray(currTokType.CATEGORIES)\n        // &&\n        // !isUndefined(currTokType.CATEGORIES.PATTERN)\n        ) {\n            currTokType.CATEGORIES = [currTokType.CATEGORIES];\n        }\n        if (!hasCategoriesProperty(currTokType)) {\n            currTokType.CATEGORIES = [];\n        }\n        if (!hasExtendingTokensTypesProperty(currTokType)) {\n            currTokType.categoryMatches = [];\n        }\n        if (!hasExtendingTokensTypesMapProperty(currTokType)) {\n            currTokType.categoryMatchesMap = {};\n        }\n    });\n}\nexport function assignCategoriesTokensProp(tokenTypes) {\n    forEach(tokenTypes, (currTokType) => {\n        // avoid duplications\n        currTokType.categoryMatches = [];\n        forEach(currTokType.categoryMatchesMap, (val, key) => {\n            currTokType.categoryMatches.push(tokenIdxToClass[key].tokenTypeIdx);\n        });\n    });\n}\nexport function assignCategoriesMapProp(tokenTypes) {\n    forEach(tokenTypes, (currTokType) => {\n        singleAssignCategoriesToksMap([], currTokType);\n    });\n}\nexport function singleAssignCategoriesToksMap(path, nextNode) {\n    forEach(path, (pathNode) => {\n        nextNode.categoryMatchesMap[pathNode.tokenTypeIdx] = true;\n    });\n    forEach(nextNode.CATEGORIES, (nextCategory) => {\n        const newPath = path.concat(nextNode);\n        // avoids infinite loops due to cyclic categories.\n        if (!includes(newPath, nextCategory)) {\n            singleAssignCategoriesToksMap(newPath, nextCategory);\n        }\n    });\n}\nexport function hasShortKeyProperty(tokType) {\n    return has(tokType, \"tokenTypeIdx\");\n}\nexport function hasCategoriesProperty(tokType) {\n    return has(tokType, \"CATEGORIES\");\n}\nexport function hasExtendingTokensTypesProperty(tokType) {\n    return has(tokType, \"categoryMatches\");\n}\nexport function hasExtendingTokensTypesMapProperty(tokType) {\n    return has(tokType, \"categoryMatchesMap\");\n}\nexport function isTokenType(tokType) {\n    return has(tokType, \"tokenTypeIdx\");\n}\n//# sourceMappingURL=tokens.js.map","export const defaultLexerErrorProvider = {\n    buildUnableToPopLexerModeMessage(token) {\n        return `Unable to pop Lexer Mode after encountering Token ->${token.image}<- The Mode Stack is empty`;\n    },\n    buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column) {\n        return (`unexpected character: ->${fullText.charAt(startOffset)}<- at offset: ${startOffset},` + ` skipped ${length} characters.`);\n    },\n};\n//# sourceMappingURL=lexer_errors_public.js.map","import { analyzeTokenTypes, charCodeToOptimizedIndex, cloneEmptyGroups, DEFAULT_MODE, LineTerminatorOptimizedTester, performRuntimeChecks, performWarningRuntimeChecks, SUPPORT_STICKY, validatePatterns, } from \"./lexer.js\";\nimport { assign, clone, forEach, identity, isArray, isEmpty, isUndefined, keys, last, map, noop, reduce, reject, } from \"lodash-es\";\nimport { PRINT_WARNING, timer, toFastProperties } from \"@chevrotain/utils\";\nimport { augmentTokenTypes } from \"./tokens.js\";\nimport { defaultLexerErrorProvider } from \"./lexer_errors_public.js\";\nimport { clearRegExpParserCache } from \"./reg_exp_parser.js\";\nexport var LexerDefinitionErrorType;\n(function (LexerDefinitionErrorType) {\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MISSING_PATTERN\"] = 0] = \"MISSING_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_PATTERN\"] = 1] = \"INVALID_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"EOI_ANCHOR_FOUND\"] = 2] = \"EOI_ANCHOR_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNSUPPORTED_FLAGS_FOUND\"] = 3] = \"UNSUPPORTED_FLAGS_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"DUPLICATE_PATTERNS_FOUND\"] = 4] = \"DUPLICATE_PATTERNS_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_GROUP_TYPE_FOUND\"] = 5] = \"INVALID_GROUP_TYPE_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"PUSH_MODE_DOES_NOT_EXIST\"] = 6] = \"PUSH_MODE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\"] = 7] = \"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\"] = 8] = \"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\"] = 9] = \"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\"] = 10] = \"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"SOI_ANCHOR_FOUND\"] = 11] = \"SOI_ANCHOR_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"EMPTY_MATCH_PATTERN\"] = 12] = \"EMPTY_MATCH_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"NO_LINE_BREAKS_FLAGS\"] = 13] = \"NO_LINE_BREAKS_FLAGS\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNREACHABLE_PATTERN\"] = 14] = \"UNREACHABLE_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"IDENTIFY_TERMINATOR\"] = 15] = \"IDENTIFY_TERMINATOR\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"CUSTOM_LINE_BREAK\"] = 16] = \"CUSTOM_LINE_BREAK\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\"] = 17] = \"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\";\n})(LexerDefinitionErrorType || (LexerDefinitionErrorType = {}));\nconst DEFAULT_LEXER_CONFIG = {\n    deferDefinitionErrorsHandling: false,\n    positionTracking: \"full\",\n    lineTerminatorsPattern: /\\n|\\r\\n?/g,\n    lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n    ensureOptimizations: false,\n    safeMode: false,\n    errorMessageProvider: defaultLexerErrorProvider,\n    traceInitPerf: false,\n    skipValidations: false,\n    recoveryEnabled: true,\n};\nObject.freeze(DEFAULT_LEXER_CONFIG);\nexport class Lexer {\n    constructor(lexerDefinition, config = DEFAULT_LEXER_CONFIG) {\n        this.lexerDefinition = lexerDefinition;\n        this.lexerDefinitionErrors = [];\n        this.lexerDefinitionWarning = [];\n        this.patternIdxToConfig = {};\n        this.charCodeToPatternIdxToConfig = {};\n        this.modes = [];\n        this.emptyGroups = {};\n        this.trackStartLines = true;\n        this.trackEndLines = true;\n        this.hasCustom = false;\n        this.canModeBeOptimized = {};\n        // Duplicated from the parser's perf trace trait to allow future extraction\n        // of the lexer to a separate package.\n        this.TRACE_INIT = (phaseDesc, phaseImpl) => {\n            // No need to optimize this using NOOP pattern because\n            // It is not called in a hot spot...\n            if (this.traceInitPerf === true) {\n                this.traceInitIndent++;\n                const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n                if (this.traceInitIndent < this.traceInitMaxIdent) {\n                    console.log(`${indent}--> <${phaseDesc}>`);\n                }\n                const { time, value } = timer(phaseImpl);\n                /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n                const traceMethod = time > 10 ? console.warn : console.log;\n                if (this.traceInitIndent < this.traceInitMaxIdent) {\n                    traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n                }\n                this.traceInitIndent--;\n                return value;\n            }\n            else {\n                return phaseImpl();\n            }\n        };\n        if (typeof config === \"boolean\") {\n            throw Error(\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" +\n                \"a boolean 2nd argument is no longer supported\");\n        }\n        // todo: defaults func?\n        this.config = assign({}, DEFAULT_LEXER_CONFIG, config);\n        const traceInitVal = this.config.traceInitPerf;\n        if (traceInitVal === true) {\n            this.traceInitMaxIdent = Infinity;\n            this.traceInitPerf = true;\n        }\n        else if (typeof traceInitVal === \"number\") {\n            this.traceInitMaxIdent = traceInitVal;\n            this.traceInitPerf = true;\n        }\n        this.traceInitIndent = -1;\n        this.TRACE_INIT(\"Lexer Constructor\", () => {\n            let actualDefinition;\n            let hasOnlySingleMode = true;\n            this.TRACE_INIT(\"Lexer Config handling\", () => {\n                if (this.config.lineTerminatorsPattern ===\n                    DEFAULT_LEXER_CONFIG.lineTerminatorsPattern) {\n                    // optimized built-in implementation for the defaults definition of lineTerminators\n                    this.config.lineTerminatorsPattern = LineTerminatorOptimizedTester;\n                }\n                else {\n                    if (this.config.lineTerminatorCharacters ===\n                        DEFAULT_LEXER_CONFIG.lineTerminatorCharacters) {\n                        throw Error(\"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" +\n                            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\");\n                    }\n                }\n                if (config.safeMode && config.ensureOptimizations) {\n                    throw Error('\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.');\n                }\n                this.trackStartLines = /full|onlyStart/i.test(this.config.positionTracking);\n                this.trackEndLines = /full/i.test(this.config.positionTracking);\n                // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n                if (isArray(lexerDefinition)) {\n                    actualDefinition = {\n                        modes: { defaultMode: clone(lexerDefinition) },\n                        defaultMode: DEFAULT_MODE,\n                    };\n                }\n                else {\n                    // no conversion needed, input should already be a IMultiModeLexerDefinition\n                    hasOnlySingleMode = false;\n                    actualDefinition = clone(lexerDefinition);\n                }\n            });\n            if (this.config.skipValidations === false) {\n                this.TRACE_INIT(\"performRuntimeChecks\", () => {\n                    this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(performRuntimeChecks(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n                });\n                this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n                    this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat(performWarningRuntimeChecks(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n                });\n            }\n            // for extra robustness to avoid throwing an none informative error message\n            actualDefinition.modes = actualDefinition.modes\n                ? actualDefinition.modes\n                : {};\n            // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n            // this transformation is to increase robustness in the case of partially invalid lexer definition.\n            forEach(actualDefinition.modes, (currModeValue, currModeName) => {\n                actualDefinition.modes[currModeName] = reject(currModeValue, (currTokType) => isUndefined(currTokType));\n            });\n            const allModeNames = keys(actualDefinition.modes);\n            forEach(actualDefinition.modes, (currModDef, currModName) => {\n                this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n                    this.modes.push(currModName);\n                    if (this.config.skipValidations === false) {\n                        this.TRACE_INIT(`validatePatterns`, () => {\n                            this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(validatePatterns(currModDef, allModeNames));\n                        });\n                    }\n                    // If definition errors were encountered, the analysis phase may fail unexpectedly/\n                    // Considering a lexer with definition errors may never be used, there is no point\n                    // to performing the analysis anyhow...\n                    if (isEmpty(this.lexerDefinitionErrors)) {\n                        augmentTokenTypes(currModDef);\n                        let currAnalyzeResult;\n                        this.TRACE_INIT(`analyzeTokenTypes`, () => {\n                            currAnalyzeResult = analyzeTokenTypes(currModDef, {\n                                lineTerminatorCharacters: this.config.lineTerminatorCharacters,\n                                positionTracking: config.positionTracking,\n                                ensureOptimizations: config.ensureOptimizations,\n                                safeMode: config.safeMode,\n                                tracer: this.TRACE_INIT,\n                            });\n                        });\n                        this.patternIdxToConfig[currModName] =\n                            currAnalyzeResult.patternIdxToConfig;\n                        this.charCodeToPatternIdxToConfig[currModName] =\n                            currAnalyzeResult.charCodeToPatternIdxToConfig;\n                        this.emptyGroups = assign({}, this.emptyGroups, currAnalyzeResult.emptyGroups);\n                        this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom;\n                        this.canModeBeOptimized[currModName] =\n                            currAnalyzeResult.canBeOptimized;\n                    }\n                });\n            });\n            this.defaultMode = actualDefinition.defaultMode;\n            if (!isEmpty(this.lexerDefinitionErrors) &&\n                !this.config.deferDefinitionErrorsHandling) {\n                const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n                    return error.message;\n                });\n                const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n                throw new Error(\"Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n            }\n            // Only print warning if there are no errors, This will avoid pl\n            forEach(this.lexerDefinitionWarning, (warningDescriptor) => {\n                PRINT_WARNING(warningDescriptor.message);\n            });\n            this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n                // Choose the relevant internal implementations for this specific parser.\n                // These implementations should be in-lined by the JavaScript engine\n                // to provide optimal performance in each scenario.\n                if (SUPPORT_STICKY) {\n                    this.chopInput = identity;\n                    this.match = this.matchWithTest;\n                }\n                else {\n                    this.updateLastIndex = noop;\n                    this.match = this.matchWithExec;\n                }\n                if (hasOnlySingleMode) {\n                    this.handleModes = noop;\n                }\n                if (this.trackStartLines === false) {\n                    this.computeNewColumn = identity;\n                }\n                if (this.trackEndLines === false) {\n                    this.updateTokenEndLineColumnLocation = noop;\n                }\n                if (/full/i.test(this.config.positionTracking)) {\n                    this.createTokenInstance = this.createFullToken;\n                }\n                else if (/onlyStart/i.test(this.config.positionTracking)) {\n                    this.createTokenInstance = this.createStartOnlyToken;\n                }\n                else if (/onlyOffset/i.test(this.config.positionTracking)) {\n                    this.createTokenInstance = this.createOffsetOnlyToken;\n                }\n                else {\n                    throw Error(`Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`);\n                }\n                if (this.hasCustom) {\n                    this.addToken = this.addTokenUsingPush;\n                    this.handlePayload = this.handlePayloadWithCustom;\n                }\n                else {\n                    this.addToken = this.addTokenUsingMemberAccess;\n                    this.handlePayload = this.handlePayloadNoCustom;\n                }\n            });\n            this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n                const unOptimizedModes = reduce(this.canModeBeOptimized, (cannotBeOptimized, canBeOptimized, modeName) => {\n                    if (canBeOptimized === false) {\n                        cannotBeOptimized.push(modeName);\n                    }\n                    return cannotBeOptimized;\n                }, []);\n                if (config.ensureOptimizations && !isEmpty(unOptimizedModes)) {\n                    throw Error(`Lexer Modes: < ${unOptimizedModes.join(\", \")} > cannot be optimized.\\n` +\n                        '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' +\n                        \"\\t Or inspect the console log for details on how to resolve these issues.\");\n                }\n            });\n            this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n                clearRegExpParserCache();\n            });\n            this.TRACE_INIT(\"toFastProperties\", () => {\n                toFastProperties(this);\n            });\n        });\n    }\n    tokenize(text, initialMode = this.defaultMode) {\n        if (!isEmpty(this.lexerDefinitionErrors)) {\n            const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n                return error.message;\n            });\n            const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n            throw new Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" +\n                allErrMessagesString);\n        }\n        return this.tokenizeInternal(text, initialMode);\n    }\n    // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n    // This is intentional due to performance considerations.\n    // this method also used quite a bit of `!` none null assertions because it is too optimized\n    // for `tsc` to always understand it is \"safe\"\n    tokenizeInternal(text, initialMode) {\n        let i, j, k, matchAltImage, longerAlt, matchedImage, payload, altPayload, imageLength, group, tokType, newToken, errLength, droppedChar, msg, match;\n        const orgText = text;\n        const orgLength = orgText.length;\n        let offset = 0;\n        let matchedTokensIndex = 0;\n        // initializing the tokensArray to the \"guessed\" size.\n        // guessing too little will still reduce the number of array re-sizes on pushes.\n        // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n        // but would still have a faster runtime by avoiding (All but one) array resizing.\n        const guessedNumberOfTokens = this.hasCustom\n            ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n            : Math.floor(text.length / 10);\n        const matchedTokens = new Array(guessedNumberOfTokens);\n        const errors = [];\n        let line = this.trackStartLines ? 1 : undefined;\n        let column = this.trackStartLines ? 1 : undefined;\n        const groups = cloneEmptyGroups(this.emptyGroups);\n        const trackLines = this.trackStartLines;\n        const lineTerminatorPattern = this.config.lineTerminatorsPattern;\n        let currModePatternsLength = 0;\n        let patternIdxToConfig = [];\n        let currCharCodeToPatternIdxToConfig = [];\n        const modeStack = [];\n        const emptyArray = [];\n        Object.freeze(emptyArray);\n        let getPossiblePatterns;\n        function getPossiblePatternsSlow() {\n            return patternIdxToConfig;\n        }\n        function getPossiblePatternsOptimized(charCode) {\n            const optimizedCharIdx = charCodeToOptimizedIndex(charCode);\n            const possiblePatterns = currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n            if (possiblePatterns === undefined) {\n                return emptyArray;\n            }\n            else {\n                return possiblePatterns;\n            }\n        }\n        const pop_mode = (popToken) => {\n            // TODO: perhaps avoid this error in the edge case there is no more input?\n            if (modeStack.length === 1 &&\n                // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n                // So no error should occur.\n                popToken.tokenType.PUSH_MODE === undefined) {\n                // if we try to pop the last mode there lexer will no longer have ANY mode.\n                // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n                const msg = this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);\n                errors.push({\n                    offset: popToken.startOffset,\n                    line: popToken.startLine,\n                    column: popToken.startColumn,\n                    length: popToken.image.length,\n                    message: msg,\n                });\n            }\n            else {\n                modeStack.pop();\n                const newMode = last(modeStack);\n                patternIdxToConfig = this.patternIdxToConfig[newMode];\n                currCharCodeToPatternIdxToConfig =\n                    this.charCodeToPatternIdxToConfig[newMode];\n                currModePatternsLength = patternIdxToConfig.length;\n                const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n                if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n                    getPossiblePatterns = getPossiblePatternsOptimized;\n                }\n                else {\n                    getPossiblePatterns = getPossiblePatternsSlow;\n                }\n            }\n        };\n        function push_mode(newMode) {\n            modeStack.push(newMode);\n            currCharCodeToPatternIdxToConfig =\n                this.charCodeToPatternIdxToConfig[newMode];\n            patternIdxToConfig = this.patternIdxToConfig[newMode];\n            currModePatternsLength = patternIdxToConfig.length;\n            currModePatternsLength = patternIdxToConfig.length;\n            const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n            if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n                getPossiblePatterns = getPossiblePatternsOptimized;\n            }\n            else {\n                getPossiblePatterns = getPossiblePatternsSlow;\n            }\n        }\n        // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n        // seem to matter performance wise.\n        push_mode.call(this, initialMode);\n        let currConfig;\n        const recoveryEnabled = this.config.recoveryEnabled;\n        while (offset < orgLength) {\n            matchedImage = null;\n            const nextCharCode = orgText.charCodeAt(offset);\n            const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n            const chosenPatternsLength = chosenPatternIdxToConfig.length;\n            for (i = 0; i < chosenPatternsLength; i++) {\n                currConfig = chosenPatternIdxToConfig[i];\n                const currPattern = currConfig.pattern;\n                payload = null;\n                // manually in-lined because > 600 chars won't be in-lined in V8\n                const singleCharCode = currConfig.short;\n                if (singleCharCode !== false) {\n                    if (nextCharCode === singleCharCode) {\n                        // single character string\n                        matchedImage = currPattern;\n                    }\n                }\n                else if (currConfig.isCustom === true) {\n                    match = currPattern.exec(orgText, offset, matchedTokens, groups);\n                    if (match !== null) {\n                        matchedImage = match[0];\n                        if (match.payload !== undefined) {\n                            payload = match.payload;\n                        }\n                    }\n                    else {\n                        matchedImage = null;\n                    }\n                }\n                else {\n                    this.updateLastIndex(currPattern, offset);\n                    matchedImage = this.match(currPattern, text, offset);\n                }\n                if (matchedImage !== null) {\n                    // even though this pattern matched we must try a another longer alternative.\n                    // this can be used to prioritize keywords over identifiers\n                    longerAlt = currConfig.longerAlt;\n                    if (longerAlt !== undefined) {\n                        // TODO: micro optimize, avoid extra prop access\n                        // by saving/linking longerAlt on the original config?\n                        const longerAltLength = longerAlt.length;\n                        for (k = 0; k < longerAltLength; k++) {\n                            const longerAltConfig = patternIdxToConfig[longerAlt[k]];\n                            const longerAltPattern = longerAltConfig.pattern;\n                            altPayload = null;\n                            // single Char can never be a longer alt so no need to test it.\n                            // manually in-lined because > 600 chars won't be in-lined in V8\n                            if (longerAltConfig.isCustom === true) {\n                                match = longerAltPattern.exec(orgText, offset, matchedTokens, groups);\n                                if (match !== null) {\n                                    matchAltImage = match[0];\n                                    if (match.payload !== undefined) {\n                                        altPayload = match.payload;\n                                    }\n                                }\n                                else {\n                                    matchAltImage = null;\n                                }\n                            }\n                            else {\n                                this.updateLastIndex(longerAltPattern, offset);\n                                matchAltImage = this.match(longerAltPattern, text, offset);\n                            }\n                            if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                                matchedImage = matchAltImage;\n                                payload = altPayload;\n                                currConfig = longerAltConfig;\n                                // Exit the loop early after matching one of the longer alternatives\n                                // The first matched alternative takes precedence\n                                break;\n                            }\n                        }\n                    }\n                    break;\n                }\n            }\n            // successful match\n            if (matchedImage !== null) {\n                imageLength = matchedImage.length;\n                group = currConfig.group;\n                if (group !== undefined) {\n                    tokType = currConfig.tokenTypeIdx;\n                    // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n                    // createFullToken method\n                    newToken = this.createTokenInstance(matchedImage, offset, tokType, currConfig.tokenType, line, column, imageLength);\n                    this.handlePayload(newToken, payload);\n                    // TODO: optimize NOOP in case there are no special groups?\n                    if (group === false) {\n                        matchedTokensIndex = this.addToken(matchedTokens, matchedTokensIndex, newToken);\n                    }\n                    else {\n                        groups[group].push(newToken);\n                    }\n                }\n                text = this.chopInput(text, imageLength);\n                offset = offset + imageLength;\n                // TODO: with newlines the column may be assigned twice\n                column = this.computeNewColumn(column, imageLength);\n                if (trackLines === true && currConfig.canLineTerminator === true) {\n                    let numOfLTsInMatch = 0;\n                    let foundTerminator;\n                    let lastLTEndOffset;\n                    lineTerminatorPattern.lastIndex = 0;\n                    do {\n                        foundTerminator = lineTerminatorPattern.test(matchedImage);\n                        if (foundTerminator === true) {\n                            lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n                            numOfLTsInMatch++;\n                        }\n                    } while (foundTerminator === true);\n                    if (numOfLTsInMatch !== 0) {\n                        line = line + numOfLTsInMatch;\n                        column = imageLength - lastLTEndOffset;\n                        this.updateTokenEndLineColumnLocation(newToken, group, lastLTEndOffset, numOfLTsInMatch, line, column, imageLength);\n                    }\n                }\n                // will be NOOP if no modes present\n                this.handleModes(currConfig, pop_mode, push_mode, newToken);\n            }\n            else {\n                // error recovery, drop characters until we identify a valid token's start point\n                const errorStartOffset = offset;\n                const errorLine = line;\n                const errorColumn = column;\n                let foundResyncPoint = recoveryEnabled === false;\n                while (foundResyncPoint === false && offset < orgLength) {\n                    // Identity Func (when sticky flag is enabled)\n                    text = this.chopInput(text, 1);\n                    offset++;\n                    for (j = 0; j < currModePatternsLength; j++) {\n                        const currConfig = patternIdxToConfig[j];\n                        const currPattern = currConfig.pattern;\n                        // manually in-lined because > 600 chars won't be in-lined in V8\n                        const singleCharCode = currConfig.short;\n                        if (singleCharCode !== false) {\n                            if (orgText.charCodeAt(offset) === singleCharCode) {\n                                // single character string\n                                foundResyncPoint = true;\n                            }\n                        }\n                        else if (currConfig.isCustom === true) {\n                            foundResyncPoint =\n                                currPattern.exec(orgText, offset, matchedTokens, groups) !== null;\n                        }\n                        else {\n                            this.updateLastIndex(currPattern, offset);\n                            foundResyncPoint = currPattern.exec(text) !== null;\n                        }\n                        if (foundResyncPoint === true) {\n                            break;\n                        }\n                    }\n                }\n                errLength = offset - errorStartOffset;\n                column = this.computeNewColumn(column, errLength);\n                // at this point we either re-synced or reached the end of the input text\n                msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText, errorStartOffset, errLength, errorLine, errorColumn);\n                errors.push({\n                    offset: errorStartOffset,\n                    line: errorLine,\n                    column: errorColumn,\n                    length: errLength,\n                    message: msg,\n                });\n                if (recoveryEnabled === false) {\n                    break;\n                }\n            }\n        }\n        // if we do have custom patterns which push directly into the\n        // TODO: custom tokens should not push directly??\n        if (!this.hasCustom) {\n            // if we guessed a too large size for the tokens array this will shrink it to the right size.\n            matchedTokens.length = matchedTokensIndex;\n        }\n        return {\n            tokens: matchedTokens,\n            groups: groups,\n            errors: errors,\n        };\n    }\n    handleModes(config, pop_mode, push_mode, newToken) {\n        if (config.pop === true) {\n            // need to save the PUSH_MODE property as if the mode is popped\n            // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n            const pushMode = config.push;\n            pop_mode(newToken);\n            if (pushMode !== undefined) {\n                push_mode.call(this, pushMode);\n            }\n        }\n        else if (config.push !== undefined) {\n            push_mode.call(this, config.push);\n        }\n    }\n    chopInput(text, length) {\n        return text.substring(length);\n    }\n    updateLastIndex(regExp, newLastIndex) {\n        regExp.lastIndex = newLastIndex;\n    }\n    // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n    updateTokenEndLineColumnLocation(newToken, group, lastLTIdx, numOfLTsInMatch, line, column, imageLength) {\n        let lastCharIsLT, fixForEndingInLT;\n        if (group !== undefined) {\n            // a none skipped multi line Token, need to update endLine/endColumn\n            lastCharIsLT = lastLTIdx === imageLength - 1;\n            fixForEndingInLT = lastCharIsLT ? -1 : 0;\n            if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n                // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n                newToken.endLine = line + fixForEndingInLT;\n                // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n                // inclusive to exclusive range.\n                newToken.endColumn = column - 1 + -fixForEndingInLT;\n            }\n            // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n        }\n    }\n    computeNewColumn(oldColumn, imageLength) {\n        return oldColumn + imageLength;\n    }\n    createOffsetOnlyToken(image, startOffset, tokenTypeIdx, tokenType) {\n        return {\n            image,\n            startOffset,\n            tokenTypeIdx,\n            tokenType,\n        };\n    }\n    createStartOnlyToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn) {\n        return {\n            image,\n            startOffset,\n            startLine,\n            startColumn,\n            tokenTypeIdx,\n            tokenType,\n        };\n    }\n    createFullToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn, imageLength) {\n        return {\n            image,\n            startOffset,\n            endOffset: startOffset + imageLength - 1,\n            startLine,\n            endLine: startLine,\n            startColumn,\n            endColumn: startColumn + imageLength - 1,\n            tokenTypeIdx,\n            tokenType,\n        };\n    }\n    addTokenUsingPush(tokenVector, index, tokenToAdd) {\n        tokenVector.push(tokenToAdd);\n        return index;\n    }\n    addTokenUsingMemberAccess(tokenVector, index, tokenToAdd) {\n        tokenVector[index] = tokenToAdd;\n        index++;\n        return index;\n    }\n    handlePayloadNoCustom(token, payload) { }\n    handlePayloadWithCustom(token, payload) {\n        if (payload !== null) {\n            token.payload = payload;\n        }\n    }\n    matchWithTest(pattern, text, offset) {\n        const found = pattern.test(text);\n        if (found === true) {\n            return text.substring(offset, pattern.lastIndex);\n        }\n        return null;\n    }\n    matchWithExec(pattern, text) {\n        const regExpArray = pattern.exec(text);\n        return regExpArray !== null ? regExpArray[0] : null;\n    }\n}\nLexer.SKIPPED = \"This marks a skipped Token pattern, this means each token identified by it will\" +\n    \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\nLexer.NA = /NOT_APPLICABLE/;\n//# sourceMappingURL=lexer_public.js.map","import { has, isString, isUndefined } from \"lodash-es\";\nimport { Lexer } from \"./lexer_public.js\";\nimport { augmentTokenTypes, tokenStructuredMatcher } from \"./tokens.js\";\nexport function tokenLabel(tokType) {\n    if (hasTokenLabel(tokType)) {\n        return tokType.LABEL;\n    }\n    else {\n        return tokType.name;\n    }\n}\nexport function tokenName(tokType) {\n    return tokType.name;\n}\nexport function hasTokenLabel(obj) {\n    return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\nconst PARENT = \"parent\";\nconst CATEGORIES = \"categories\";\nconst LABEL = \"label\";\nconst GROUP = \"group\";\nconst PUSH_MODE = \"push_mode\";\nconst POP_MODE = \"pop_mode\";\nconst LONGER_ALT = \"longer_alt\";\nconst LINE_BREAKS = \"line_breaks\";\nconst START_CHARS_HINT = \"start_chars_hint\";\nexport function createToken(config) {\n    return createTokenInternal(config);\n}\nfunction createTokenInternal(config) {\n    const pattern = config.pattern;\n    const tokenType = {};\n    tokenType.name = config.name;\n    if (!isUndefined(pattern)) {\n        tokenType.PATTERN = pattern;\n    }\n    if (has(config, PARENT)) {\n        throw (\"The parent property is no longer supported.\\n\" +\n            \"See: https://github.com/chevrotain/chevrotain/issues/564#issuecomment-349062346 for details.\");\n    }\n    if (has(config, CATEGORIES)) {\n        // casting to ANY as this will be fixed inside `augmentTokenTypes``\n        tokenType.CATEGORIES = config[CATEGORIES];\n    }\n    augmentTokenTypes([tokenType]);\n    if (has(config, LABEL)) {\n        tokenType.LABEL = config[LABEL];\n    }\n    if (has(config, GROUP)) {\n        tokenType.GROUP = config[GROUP];\n    }\n    if (has(config, POP_MODE)) {\n        tokenType.POP_MODE = config[POP_MODE];\n    }\n    if (has(config, PUSH_MODE)) {\n        tokenType.PUSH_MODE = config[PUSH_MODE];\n    }\n    if (has(config, LONGER_ALT)) {\n        tokenType.LONGER_ALT = config[LONGER_ALT];\n    }\n    if (has(config, LINE_BREAKS)) {\n        tokenType.LINE_BREAKS = config[LINE_BREAKS];\n    }\n    if (has(config, START_CHARS_HINT)) {\n        tokenType.START_CHARS_HINT = config[START_CHARS_HINT];\n    }\n    return tokenType;\n}\nexport const EOF = createToken({ name: \"EOF\", pattern: Lexer.NA });\naugmentTokenTypes([EOF]);\nexport function createTokenInstance(tokType, image, startOffset, endOffset, startLine, endLine, startColumn, endColumn) {\n    return {\n        image,\n        startOffset,\n        endOffset,\n        startLine,\n        endLine,\n        startColumn,\n        endColumn,\n        tokenTypeIdx: tokType.tokenTypeIdx,\n        tokenType: tokType,\n    };\n}\nexport function tokenMatcher(token, tokType) {\n    return tokenStructuredMatcher(token, tokType);\n}\n//# sourceMappingURL=tokens_public.js.map","import { hasTokenLabel, tokenLabel } from \"../scan/tokens_public.js\";\nimport { first, map, reduce } from \"lodash-es\";\nimport { getProductionDslName, NonTerminal, Rule, Terminal, } from \"@chevrotain/gast\";\nexport const defaultParserErrorProvider = {\n    buildMismatchTokenMessage({ expected, actual, previous, ruleName }) {\n        const hasLabel = hasTokenLabel(expected);\n        const expectedMsg = hasLabel\n            ? `--> ${tokenLabel(expected)} <--`\n            : `token of type --> ${expected.name} <--`;\n        const msg = `Expecting ${expectedMsg} but found --> '${actual.image}' <--`;\n        return msg;\n    },\n    buildNotAllInputParsedMessage({ firstRedundant, ruleName }) {\n        return \"Redundant input, expecting EOF but found: \" + firstRedundant.image;\n    },\n    buildNoViableAltMessage({ expectedPathsPerAlt, actual, previous, customUserDescription, ruleName, }) {\n        const errPrefix = \"Expecting: \";\n        // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n        const actualText = first(actual).image;\n        const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n        if (customUserDescription) {\n            return errPrefix + customUserDescription + errSuffix;\n        }\n        else {\n            const allLookAheadPaths = reduce(expectedPathsPerAlt, (result, currAltPaths) => result.concat(currAltPaths), []);\n            const nextValidTokenSequences = map(allLookAheadPaths, (currPath) => `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\", \")}]`);\n            const nextValidSequenceItems = map(nextValidTokenSequences, (itemMsg, idx) => `  ${idx + 1}. ${itemMsg}`);\n            const calculatedDescription = `one of these possible Token sequences:\\n${nextValidSequenceItems.join(\"\\n\")}`;\n            return errPrefix + calculatedDescription + errSuffix;\n        }\n    },\n    buildEarlyExitMessage({ expectedIterationPaths, actual, customUserDescription, ruleName, }) {\n        const errPrefix = \"Expecting: \";\n        // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n        const actualText = first(actual).image;\n        const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n        if (customUserDescription) {\n            return errPrefix + customUserDescription + errSuffix;\n        }\n        else {\n            const nextValidTokenSequences = map(expectedIterationPaths, (currPath) => `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\",\")}]`);\n            const calculatedDescription = `expecting at least one iteration which starts with one of these possible Token sequences::\\n  ` +\n                `<${nextValidTokenSequences.join(\" ,\")}>`;\n            return errPrefix + calculatedDescription + errSuffix;\n        }\n    },\n};\nObject.freeze(defaultParserErrorProvider);\nexport const defaultGrammarResolverErrorProvider = {\n    buildRuleNotFoundError(topLevelRule, undefinedRule) {\n        const msg = \"Invalid grammar, reference to a rule which is not defined: ->\" +\n            undefinedRule.nonTerminalName +\n            \"<-\\n\" +\n            \"inside top level rule: ->\" +\n            topLevelRule.name +\n            \"<-\";\n        return msg;\n    },\n};\nexport const defaultGrammarValidatorErrorProvider = {\n    buildDuplicateFoundError(topLevelRule, duplicateProds) {\n        function getExtraProductionArgument(prod) {\n            if (prod instanceof Terminal) {\n                return prod.terminalType.name;\n            }\n            else if (prod instanceof NonTerminal) {\n                return prod.nonTerminalName;\n            }\n            else {\n                return \"\";\n            }\n        }\n        const topLevelName = topLevelRule.name;\n        const duplicateProd = first(duplicateProds);\n        const index = duplicateProd.idx;\n        const dslName = getProductionDslName(duplicateProd);\n        const extraArgument = getExtraProductionArgument(duplicateProd);\n        const hasExplicitIndex = index > 0;\n        let msg = `->${dslName}${hasExplicitIndex ? index : \"\"}<- ${extraArgument ? `with argument: ->${extraArgument}<-` : \"\"}\n                  appears more than once (${duplicateProds.length} times) in the top level rule: ->${topLevelName}<-.                  \n                  For further details see: https://chevrotain.io/docs/FAQ.html#NUMERICAL_SUFFIXES \n                  `;\n        // white space trimming time! better to trim afterwards as it allows to use WELL formatted multi line template strings...\n        msg = msg.replace(/[ \\t]+/g, \" \");\n        msg = msg.replace(/\\s\\s+/g, \"\\n\");\n        return msg;\n    },\n    buildNamespaceConflictError(rule) {\n        const errMsg = `Namespace conflict found in grammar.\\n` +\n            `The grammar has both a Terminal(Token) and a Non-Terminal(Rule) named: <${rule.name}>.\\n` +\n            `To resolve this make sure each Terminal and Non-Terminal names are unique\\n` +\n            `This is easy to accomplish by using the convention that Terminal names start with an uppercase letter\\n` +\n            `and Non-Terminal names start with a lower case letter.`;\n        return errMsg;\n    },\n    buildAlternationPrefixAmbiguityError(options) {\n        const pathMsg = map(options.prefixPath, (currTok) => tokenLabel(currTok)).join(\", \");\n        const occurrence = options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n        const errMsg = `Ambiguous alternatives: <${options.ambiguityIndices.join(\" ,\")}> due to common lookahead prefix\\n` +\n            `in <OR${occurrence}> inside <${options.topLevelRule.name}> Rule,\\n` +\n            `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n` +\n            `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#COMMON_PREFIX\\n` +\n            `For Further details.`;\n        return errMsg;\n    },\n    buildAlternationAmbiguityError(options) {\n        const pathMsg = map(options.prefixPath, (currtok) => tokenLabel(currtok)).join(\", \");\n        const occurrence = options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n        let currMessage = `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\" ,\")}> in <OR${occurrence}>` +\n            ` inside <${options.topLevelRule.name}> Rule,\\n` +\n            `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n`;\n        currMessage =\n            currMessage +\n                `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\\n` +\n                `For Further details.`;\n        return currMessage;\n    },\n    buildEmptyRepetitionError(options) {\n        let dslName = getProductionDslName(options.repetition);\n        if (options.repetition.idx !== 0) {\n            dslName += options.repetition.idx;\n        }\n        const errMsg = `The repetition <${dslName}> within Rule <${options.topLevelRule.name}> can never consume any tokens.\\n` +\n            `This could lead to an infinite loop.`;\n        return errMsg;\n    },\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildTokenNameError(options) {\n        /* istanbul ignore next */\n        return \"deprecated\";\n    },\n    buildEmptyAlternationError(options) {\n        const errMsg = `Ambiguous empty alternative: <${options.emptyChoiceIdx + 1}>` +\n            ` in <OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\\n` +\n            `Only the last alternative may be an empty alternative.`;\n        return errMsg;\n    },\n    buildTooManyAlternativesError(options) {\n        const errMsg = `An Alternation cannot have more than 256 alternatives:\\n` +\n            `<OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\\n has ${options.alternation.definition.length + 1} alternatives.`;\n        return errMsg;\n    },\n    buildLeftRecursionError(options) {\n        const ruleName = options.topLevelRule.name;\n        const pathNames = map(options.leftRecursionPath, (currRule) => currRule.name);\n        const leftRecursivePath = `${ruleName} --> ${pathNames\n            .concat([ruleName])\n            .join(\" --> \")}`;\n        const errMsg = `Left Recursion found in grammar.\\n` +\n            `rule: <${ruleName}> can be invoked from itself (directly or indirectly)\\n` +\n            `without consuming any Tokens. The grammar path that causes this is: \\n ${leftRecursivePath}\\n` +\n            ` To fix this refactor your grammar to remove the left recursion.\\n` +\n            `see: https://en.wikipedia.org/wiki/LL_parser#Left_factoring.`;\n        return errMsg;\n    },\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildInvalidRuleNameError(options) {\n        /* istanbul ignore next */\n        return \"deprecated\";\n    },\n    buildDuplicateRuleNameError(options) {\n        let ruleName;\n        if (options.topLevelRule instanceof Rule) {\n            ruleName = options.topLevelRule.name;\n        }\n        else {\n            ruleName = options.topLevelRule;\n        }\n        const errMsg = `Duplicate definition, rule: ->${ruleName}<- is already defined in the grammar: ->${options.grammarName}<-`;\n        return errMsg;\n    },\n};\n//# sourceMappingURL=errors_public.js.map","import { Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Rule, Terminal, } from \"./model.js\";\nexport class GAstVisitor {\n    visit(node) {\n        const nodeAny = node;\n        switch (nodeAny.constructor) {\n            case NonTerminal:\n                return this.visitNonTerminal(nodeAny);\n            case Alternative:\n                return this.visitAlternative(nodeAny);\n            case Option:\n                return this.visitOption(nodeAny);\n            case RepetitionMandatory:\n                return this.visitRepetitionMandatory(nodeAny);\n            case RepetitionMandatoryWithSeparator:\n                return this.visitRepetitionMandatoryWithSeparator(nodeAny);\n            case RepetitionWithSeparator:\n                return this.visitRepetitionWithSeparator(nodeAny);\n            case Repetition:\n                return this.visitRepetition(nodeAny);\n            case Alternation:\n                return this.visitAlternation(nodeAny);\n            case Terminal:\n                return this.visitTerminal(nodeAny);\n            case Rule:\n                return this.visitRule(nodeAny);\n            /* c8 ignore next 2 */\n            default:\n                throw Error(\"non exhaustive match\");\n        }\n    }\n    /* c8 ignore next */\n    visitNonTerminal(node) { }\n    /* c8 ignore next */\n    visitAlternative(node) { }\n    /* c8 ignore next */\n    visitOption(node) { }\n    /* c8 ignore next */\n    visitRepetition(node) { }\n    /* c8 ignore next */\n    visitRepetitionMandatory(node) { }\n    /* c8 ignore next 3 */\n    visitRepetitionMandatoryWithSeparator(node) { }\n    /* c8 ignore next */\n    visitRepetitionWithSeparator(node) { }\n    /* c8 ignore next */\n    visitAlternation(node) { }\n    /* c8 ignore next */\n    visitTerminal(node) { }\n    /* c8 ignore next */\n    visitRule(node) { }\n}\n//# sourceMappingURL=visitor.js.map","import { ParserDefinitionErrorType, } from \"../parser/parser.js\";\nimport { forEach, values } from \"lodash-es\";\nimport { GAstVisitor } from \"@chevrotain/gast\";\nexport function resolveGrammar(topLevels, errMsgProvider) {\n    const refResolver = new GastRefResolverVisitor(topLevels, errMsgProvider);\n    refResolver.resolveRefs();\n    return refResolver.errors;\n}\nexport class GastRefResolverVisitor extends GAstVisitor {\n    constructor(nameToTopRule, errMsgProvider) {\n        super();\n        this.nameToTopRule = nameToTopRule;\n        this.errMsgProvider = errMsgProvider;\n        this.errors = [];\n    }\n    resolveRefs() {\n        forEach(values(this.nameToTopRule), (prod) => {\n            this.currTopLevel = prod;\n            prod.accept(this);\n        });\n    }\n    visitNonTerminal(node) {\n        const ref = this.nameToTopRule[node.nonTerminalName];\n        if (!ref) {\n            const msg = this.errMsgProvider.buildRuleNotFoundError(this.currTopLevel, node);\n            this.errors.push({\n                message: msg,\n                type: ParserDefinitionErrorType.UNRESOLVED_SUBRULE_REF,\n                ruleName: this.currTopLevel.name,\n                unresolvedRefName: node.nonTerminalName,\n            });\n        }\n        else {\n            node.referencedRule = ref;\n        }\n    }\n}\n//# sourceMappingURL=resolver.js.map","/**\n * A specialized version of `baseAggregator` for arrays.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} setter The function to set `accumulator` values.\n * @param {Function} iteratee The iteratee to transform keys.\n * @param {Object} accumulator The initial aggregated object.\n * @returns {Function} Returns `accumulator`.\n */\nfunction arrayAggregator(array, setter, iteratee, accumulator) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    var value = array[index];\n    setter(accumulator, value, iteratee(value), array);\n  }\n  return accumulator;\n}\n\nexport default arrayAggregator;\n","import baseEach from './_baseEach.js';\n\n/**\n * Aggregates elements of `collection` on `accumulator` with keys transformed\n * by `iteratee` and values set by `setter`.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} setter The function to set `accumulator` values.\n * @param {Function} iteratee The iteratee to transform keys.\n * @param {Object} accumulator The initial aggregated object.\n * @returns {Function} Returns `accumulator`.\n */\nfunction baseAggregator(collection, setter, iteratee, accumulator) {\n  baseEach(collection, function(value, key, collection) {\n    setter(accumulator, value, iteratee(value), collection);\n  });\n  return accumulator;\n}\n\nexport default baseAggregator;\n","import arrayAggregator from './_arrayAggregator.js';\nimport baseAggregator from './_baseAggregator.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\n\n/**\n * Creates a function like `_.groupBy`.\n *\n * @private\n * @param {Function} setter The function to set accumulator values.\n * @param {Function} [initializer] The accumulator object initializer.\n * @returns {Function} Returns the new aggregator function.\n */\nfunction createAggregator(setter, initializer) {\n  return function(collection, iteratee) {\n    var func = isArray(collection) ? arrayAggregator : baseAggregator,\n        accumulator = initializer ? initializer() : {};\n\n    return func(collection, setter, baseIteratee(iteratee, 2), accumulator);\n  };\n}\n\nexport default createAggregator;\n","import baseAssignValue from './_baseAssignValue.js';\nimport createAggregator from './_createAggregator.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Creates an object composed of keys generated from the results of running\n * each element of `collection` thru `iteratee`. The order of grouped values\n * is determined by the order they occur in `collection`. The corresponding\n * value of each key is an array of elements responsible for generating the\n * key. The iteratee is invoked with one argument: (value).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The iteratee to transform keys.\n * @returns {Object} Returns the composed aggregate object.\n * @example\n *\n * _.groupBy([6.1, 4.2, 6.3], Math.floor);\n * // => { '4': [4.2], '6': [6.1, 6.3] }\n *\n * // The `_.property` iteratee shorthand.\n * _.groupBy(['one', 'two', 'three'], 'length');\n * // => { '3': ['one', 'two'], '5': ['three'] }\n */\nvar groupBy = createAggregator(function(result, value, key) {\n  if (hasOwnProperty.call(result, key)) {\n    result[key].push(value);\n  } else {\n    baseAssignValue(result, key, [value]);\n  }\n});\n\nexport default groupBy;\n","import baseSlice from './_baseSlice.js';\nimport toInteger from './toInteger.js';\n\n/**\n * Creates a slice of `array` with `n` elements dropped from the end.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Array\n * @param {Array} array The array to query.\n * @param {number} [n=1] The number of elements to drop.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the slice of `array`.\n * @example\n *\n * _.dropRight([1, 2, 3]);\n * // => [1, 2]\n *\n * _.dropRight([1, 2, 3], 2);\n * // => [1]\n *\n * _.dropRight([1, 2, 3], 5);\n * // => []\n *\n * _.dropRight([1, 2, 3], 0);\n * // => [1, 2, 3]\n */\nfunction dropRight(array, n, guard) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return [];\n  }\n  n = (guard || n === undefined) ? 1 : toInteger(n);\n  n = length - n;\n  return baseSlice(array, 0, n < 0 ? 0 : n);\n}\n\nexport default dropRight;\n","import { clone, drop, dropRight, first as _first, forEach, isEmpty, last, } from \"lodash-es\";\nimport { first } from \"./first.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Rule, Terminal, } from \"@chevrotain/gast\";\nexport class AbstractNextPossibleTokensWalker extends RestWalker {\n    constructor(topProd, path) {\n        super();\n        this.topProd = topProd;\n        this.path = path;\n        this.possibleTokTypes = [];\n        this.nextProductionName = \"\";\n        this.nextProductionOccurrence = 0;\n        this.found = false;\n        this.isAtEndOfPath = false;\n    }\n    startWalking() {\n        this.found = false;\n        if (this.path.ruleStack[0] !== this.topProd.name) {\n            throw Error(\"The path does not start with the walker's top Rule!\");\n        }\n        // immutable for the win\n        this.ruleStack = clone(this.path.ruleStack).reverse(); // intelij bug requires assertion\n        this.occurrenceStack = clone(this.path.occurrenceStack).reverse(); // intelij bug requires assertion\n        // already verified that the first production is valid, we now seek the 2nd production\n        this.ruleStack.pop();\n        this.occurrenceStack.pop();\n        this.updateExpectedNext();\n        this.walk(this.topProd);\n        return this.possibleTokTypes;\n    }\n    walk(prod, prevRest = []) {\n        // stop scanning once we found the path\n        if (!this.found) {\n            super.walk(prod, prevRest);\n        }\n    }\n    walkProdRef(refProd, currRest, prevRest) {\n        // found the next production, need to keep walking in it\n        if (refProd.referencedRule.name === this.nextProductionName &&\n            refProd.idx === this.nextProductionOccurrence) {\n            const fullRest = currRest.concat(prevRest);\n            this.updateExpectedNext();\n            this.walk(refProd.referencedRule, fullRest);\n        }\n    }\n    updateExpectedNext() {\n        // need to consume the Terminal\n        if (isEmpty(this.ruleStack)) {\n            // must reset nextProductionXXX to avoid walking down another Top Level production while what we are\n            // really seeking is the last Terminal...\n            this.nextProductionName = \"\";\n            this.nextProductionOccurrence = 0;\n            this.isAtEndOfPath = true;\n        }\n        else {\n            this.nextProductionName = this.ruleStack.pop();\n            this.nextProductionOccurrence = this.occurrenceStack.pop();\n        }\n    }\n}\nexport class NextAfterTokenWalker extends AbstractNextPossibleTokensWalker {\n    constructor(topProd, path) {\n        super(topProd, path);\n        this.path = path;\n        this.nextTerminalName = \"\";\n        this.nextTerminalOccurrence = 0;\n        this.nextTerminalName = this.path.lastTok.name;\n        this.nextTerminalOccurrence = this.path.lastTokOccurrence;\n    }\n    walkTerminal(terminal, currRest, prevRest) {\n        if (this.isAtEndOfPath &&\n            terminal.terminalType.name === this.nextTerminalName &&\n            terminal.idx === this.nextTerminalOccurrence &&\n            !this.found) {\n            const fullRest = currRest.concat(prevRest);\n            const restProd = new Alternative({ definition: fullRest });\n            this.possibleTokTypes = first(restProd);\n            this.found = true;\n        }\n    }\n}\n/**\n * This walker only \"walks\" a single \"TOP\" level in the Grammar Ast, this means\n * it never \"follows\" production refs\n */\nexport class AbstractNextTerminalAfterProductionWalker extends RestWalker {\n    constructor(topRule, occurrence) {\n        super();\n        this.topRule = topRule;\n        this.occurrence = occurrence;\n        this.result = {\n            token: undefined,\n            occurrence: undefined,\n            isEndOfRule: undefined,\n        };\n    }\n    startWalking() {\n        this.walk(this.topRule);\n        return this.result;\n    }\n}\nexport class NextTerminalAfterManyWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkMany(manyProd, currRest, prevRest) {\n        if (manyProd.idx === this.occurrence) {\n            const firstAfterMany = _first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterMany === undefined;\n            if (firstAfterMany instanceof Terminal) {\n                this.result.token = firstAfterMany.terminalType;\n                this.result.occurrence = firstAfterMany.idx;\n            }\n        }\n        else {\n            super.walkMany(manyProd, currRest, prevRest);\n        }\n    }\n}\nexport class NextTerminalAfterManySepWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkManySep(manySepProd, currRest, prevRest) {\n        if (manySepProd.idx === this.occurrence) {\n            const firstAfterManySep = _first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterManySep === undefined;\n            if (firstAfterManySep instanceof Terminal) {\n                this.result.token = firstAfterManySep.terminalType;\n                this.result.occurrence = firstAfterManySep.idx;\n            }\n        }\n        else {\n            super.walkManySep(manySepProd, currRest, prevRest);\n        }\n    }\n}\nexport class NextTerminalAfterAtLeastOneWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n        if (atLeastOneProd.idx === this.occurrence) {\n            const firstAfterAtLeastOne = _first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterAtLeastOne === undefined;\n            if (firstAfterAtLeastOne instanceof Terminal) {\n                this.result.token = firstAfterAtLeastOne.terminalType;\n                this.result.occurrence = firstAfterAtLeastOne.idx;\n            }\n        }\n        else {\n            super.walkAtLeastOne(atLeastOneProd, currRest, prevRest);\n        }\n    }\n}\n// TODO: reduce code duplication in the AfterWalkers\nexport class NextTerminalAfterAtLeastOneSepWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest) {\n        if (atleastOneSepProd.idx === this.occurrence) {\n            const firstAfterfirstAfterAtLeastOneSep = _first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterfirstAfterAtLeastOneSep === undefined;\n            if (firstAfterfirstAfterAtLeastOneSep instanceof Terminal) {\n                this.result.token = firstAfterfirstAfterAtLeastOneSep.terminalType;\n                this.result.occurrence = firstAfterfirstAfterAtLeastOneSep.idx;\n            }\n        }\n        else {\n            super.walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest);\n        }\n    }\n}\nexport function possiblePathsFrom(targetDef, maxLength, currPath = []) {\n    // avoid side effects\n    currPath = clone(currPath);\n    let result = [];\n    let i = 0;\n    // TODO: avoid inner funcs\n    function remainingPathWith(nextDef) {\n        return nextDef.concat(drop(targetDef, i + 1));\n    }\n    // TODO: avoid inner funcs\n    function getAlternativesForProd(definition) {\n        const alternatives = possiblePathsFrom(remainingPathWith(definition), maxLength, currPath);\n        return result.concat(alternatives);\n    }\n    /**\n     * Mandatory productions will halt the loop as the paths computed from their recursive calls will already contain the\n     * following (rest) of the targetDef.\n     *\n     * For optional productions (Option/Repetition/...) the loop will continue to represent the paths that do not include the\n     * the optional production.\n     */\n    while (currPath.length < maxLength && i < targetDef.length) {\n        const prod = targetDef[i];\n        /* istanbul ignore else */\n        if (prod instanceof Alternative) {\n            return getAlternativesForProd(prod.definition);\n        }\n        else if (prod instanceof NonTerminal) {\n            return getAlternativesForProd(prod.definition);\n        }\n        else if (prod instanceof Option) {\n            result = getAlternativesForProd(prod.definition);\n        }\n        else if (prod instanceof RepetitionMandatory) {\n            const newDef = prod.definition.concat([\n                new Repetition({\n                    definition: prod.definition,\n                }),\n            ]);\n            return getAlternativesForProd(newDef);\n        }\n        else if (prod instanceof RepetitionMandatoryWithSeparator) {\n            const newDef = [\n                new Alternative({ definition: prod.definition }),\n                new Repetition({\n                    definition: [new Terminal({ terminalType: prod.separator })].concat(prod.definition),\n                }),\n            ];\n            return getAlternativesForProd(newDef);\n        }\n        else if (prod instanceof RepetitionWithSeparator) {\n            const newDef = prod.definition.concat([\n                new Repetition({\n                    definition: [new Terminal({ terminalType: prod.separator })].concat(prod.definition),\n                }),\n            ]);\n            result = getAlternativesForProd(newDef);\n        }\n        else if (prod instanceof Repetition) {\n            const newDef = prod.definition.concat([\n                new Repetition({\n                    definition: prod.definition,\n                }),\n            ]);\n            result = getAlternativesForProd(newDef);\n        }\n        else if (prod instanceof Alternation) {\n            forEach(prod.definition, (currAlt) => {\n                // TODO: this is a limited check for empty alternatives\n                //   It would prevent a common case of infinite loops during parser initialization.\n                //   However **in-directly** empty alternatives may still cause issues.\n                if (isEmpty(currAlt.definition) === false) {\n                    result = getAlternativesForProd(currAlt.definition);\n                }\n            });\n            return result;\n        }\n        else if (prod instanceof Terminal) {\n            currPath.push(prod.terminalType);\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n        i++;\n    }\n    result.push({\n        partialPath: currPath,\n        suffixDef: drop(targetDef, i),\n    });\n    return result;\n}\nexport function nextPossibleTokensAfter(initialDef, tokenVector, tokMatcher, maxLookAhead) {\n    const EXIT_NON_TERMINAL = \"EXIT_NONE_TERMINAL\";\n    // to avoid creating a new Array each time.\n    const EXIT_NON_TERMINAL_ARR = [EXIT_NON_TERMINAL];\n    const EXIT_ALTERNATIVE = \"EXIT_ALTERNATIVE\";\n    let foundCompletePath = false;\n    const tokenVectorLength = tokenVector.length;\n    const minimalAlternativesIndex = tokenVectorLength - maxLookAhead - 1;\n    const result = [];\n    const possiblePaths = [];\n    possiblePaths.push({\n        idx: -1,\n        def: initialDef,\n        ruleStack: [],\n        occurrenceStack: [],\n    });\n    while (!isEmpty(possiblePaths)) {\n        const currPath = possiblePaths.pop();\n        // skip alternatives if no more results can be found (assuming deterministic grammar with fixed lookahead)\n        if (currPath === EXIT_ALTERNATIVE) {\n            if (foundCompletePath &&\n                last(possiblePaths).idx <= minimalAlternativesIndex) {\n                // remove irrelevant alternative\n                possiblePaths.pop();\n            }\n            continue;\n        }\n        const currDef = currPath.def;\n        const currIdx = currPath.idx;\n        const currRuleStack = currPath.ruleStack;\n        const currOccurrenceStack = currPath.occurrenceStack;\n        // For Example: an empty path could exist in a valid grammar in the case of an EMPTY_ALT\n        if (isEmpty(currDef)) {\n            continue;\n        }\n        const prod = currDef[0];\n        /* istanbul ignore else */\n        if (prod === EXIT_NON_TERMINAL) {\n            const nextPath = {\n                idx: currIdx,\n                def: drop(currDef),\n                ruleStack: dropRight(currRuleStack),\n                occurrenceStack: dropRight(currOccurrenceStack),\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof Terminal) {\n            /* istanbul ignore else */\n            if (currIdx < tokenVectorLength - 1) {\n                const nextIdx = currIdx + 1;\n                const actualToken = tokenVector[nextIdx];\n                if (tokMatcher(actualToken, prod.terminalType)) {\n                    const nextPath = {\n                        idx: nextIdx,\n                        def: drop(currDef),\n                        ruleStack: currRuleStack,\n                        occurrenceStack: currOccurrenceStack,\n                    };\n                    possiblePaths.push(nextPath);\n                }\n                // end of the line\n            }\n            else if (currIdx === tokenVectorLength - 1) {\n                // IGNORE ABOVE ELSE\n                result.push({\n                    nextTokenType: prod.terminalType,\n                    nextTokenOccurrence: prod.idx,\n                    ruleStack: currRuleStack,\n                    occurrenceStack: currOccurrenceStack,\n                });\n                foundCompletePath = true;\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        }\n        else if (prod instanceof NonTerminal) {\n            const newRuleStack = clone(currRuleStack);\n            newRuleStack.push(prod.nonTerminalName);\n            const newOccurrenceStack = clone(currOccurrenceStack);\n            newOccurrenceStack.push(prod.idx);\n            const nextPath = {\n                idx: currIdx,\n                def: prod.definition.concat(EXIT_NON_TERMINAL_ARR, drop(currDef)),\n                ruleStack: newRuleStack,\n                occurrenceStack: newOccurrenceStack,\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof Option) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            const nextPathWithout = {\n                idx: currIdx,\n                def: drop(currDef),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWithout);\n            // required marker to avoid backtracking paths whose higher priority alternatives already matched\n            possiblePaths.push(EXIT_ALTERNATIVE);\n            const nextPathWith = {\n                idx: currIdx,\n                def: prod.definition.concat(drop(currDef)),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWith);\n        }\n        else if (prod instanceof RepetitionMandatory) {\n            // TODO:(THE NEW operators here take a while...) (convert once?)\n            const secondIteration = new Repetition({\n                definition: prod.definition,\n                idx: prod.idx,\n            });\n            const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n            const nextPath = {\n                idx: currIdx,\n                def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof RepetitionMandatoryWithSeparator) {\n            // TODO:(THE NEW operators here take a while...) (convert once?)\n            const separatorGast = new Terminal({\n                terminalType: prod.separator,\n            });\n            const secondIteration = new Repetition({\n                definition: [separatorGast].concat(prod.definition),\n                idx: prod.idx,\n            });\n            const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n            const nextPath = {\n                idx: currIdx,\n                def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof RepetitionWithSeparator) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            const nextPathWithout = {\n                idx: currIdx,\n                def: drop(currDef),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWithout);\n            // required marker to avoid backtracking paths whose higher priority alternatives already matched\n            possiblePaths.push(EXIT_ALTERNATIVE);\n            const separatorGast = new Terminal({\n                terminalType: prod.separator,\n            });\n            const nthRepetition = new Repetition({\n                definition: [separatorGast].concat(prod.definition),\n                idx: prod.idx,\n            });\n            const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n            const nextPathWith = {\n                idx: currIdx,\n                def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWith);\n        }\n        else if (prod instanceof Repetition) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            const nextPathWithout = {\n                idx: currIdx,\n                def: drop(currDef),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWithout);\n            // required marker to avoid backtracking paths whose higher priority alternatives already matched\n            possiblePaths.push(EXIT_ALTERNATIVE);\n            // TODO: an empty repetition will cause infinite loops here, will the parser detect this in selfAnalysis?\n            const nthRepetition = new Repetition({\n                definition: prod.definition,\n                idx: prod.idx,\n            });\n            const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n            const nextPathWith = {\n                idx: currIdx,\n                def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWith);\n        }\n        else if (prod instanceof Alternation) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            for (let i = prod.definition.length - 1; i >= 0; i--) {\n                const currAlt = prod.definition[i];\n                const currAltPath = {\n                    idx: currIdx,\n                    def: currAlt.definition.concat(drop(currDef)),\n                    ruleStack: currRuleStack,\n                    occurrenceStack: currOccurrenceStack,\n                };\n                possiblePaths.push(currAltPath);\n                possiblePaths.push(EXIT_ALTERNATIVE);\n            }\n        }\n        else if (prod instanceof Alternative) {\n            possiblePaths.push({\n                idx: currIdx,\n                def: prod.definition.concat(drop(currDef)),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            });\n        }\n        else if (prod instanceof Rule) {\n            // last because we should only encounter at most a single one of these per invocation.\n            possiblePaths.push(expandTopLevelRule(prod, currIdx, currRuleStack, currOccurrenceStack));\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    }\n    return result;\n}\nfunction expandTopLevelRule(topRule, currIdx, currRuleStack, currOccurrenceStack) {\n    const newRuleStack = clone(currRuleStack);\n    newRuleStack.push(topRule.name);\n    const newCurrOccurrenceStack = clone(currOccurrenceStack);\n    // top rule is always assumed to have been called with occurrence index 1\n    newCurrOccurrenceStack.push(1);\n    return {\n        idx: currIdx,\n        def: topRule.definition,\n        ruleStack: newRuleStack,\n        occurrenceStack: newCurrOccurrenceStack,\n    };\n}\n//# sourceMappingURL=interpreter.js.map","import { every, flatten, forEach, has, isEmpty, map, reduce } from \"lodash-es\";\nimport { possiblePathsFrom } from \"./interpreter.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { tokenStructuredMatcher, tokenStructuredMatcherNoCategories, } from \"../../scan/tokens.js\";\nimport { Alternation, Alternative as AlternativeGAST, GAstVisitor, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, } from \"@chevrotain/gast\";\nexport var PROD_TYPE;\n(function (PROD_TYPE) {\n    PROD_TYPE[PROD_TYPE[\"OPTION\"] = 0] = \"OPTION\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION\"] = 1] = \"REPETITION\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION_MANDATORY\"] = 2] = \"REPETITION_MANDATORY\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION_MANDATORY_WITH_SEPARATOR\"] = 3] = \"REPETITION_MANDATORY_WITH_SEPARATOR\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION_WITH_SEPARATOR\"] = 4] = \"REPETITION_WITH_SEPARATOR\";\n    PROD_TYPE[PROD_TYPE[\"ALTERNATION\"] = 5] = \"ALTERNATION\";\n})(PROD_TYPE || (PROD_TYPE = {}));\nexport function getProdType(prod) {\n    /* istanbul ignore else */\n    if (prod instanceof Option || prod === \"Option\") {\n        return PROD_TYPE.OPTION;\n    }\n    else if (prod instanceof Repetition || prod === \"Repetition\") {\n        return PROD_TYPE.REPETITION;\n    }\n    else if (prod instanceof RepetitionMandatory ||\n        prod === \"RepetitionMandatory\") {\n        return PROD_TYPE.REPETITION_MANDATORY;\n    }\n    else if (prod instanceof RepetitionMandatoryWithSeparator ||\n        prod === \"RepetitionMandatoryWithSeparator\") {\n        return PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR;\n    }\n    else if (prod instanceof RepetitionWithSeparator ||\n        prod === \"RepetitionWithSeparator\") {\n        return PROD_TYPE.REPETITION_WITH_SEPARATOR;\n    }\n    else if (prod instanceof Alternation || prod === \"Alternation\") {\n        return PROD_TYPE.ALTERNATION;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexport function getLookaheadPaths(options) {\n    const { occurrence, rule, prodType, maxLookahead } = options;\n    const type = getProdType(prodType);\n    if (type === PROD_TYPE.ALTERNATION) {\n        return getLookaheadPathsForOr(occurrence, rule, maxLookahead);\n    }\n    else {\n        return getLookaheadPathsForOptionalProd(occurrence, rule, type, maxLookahead);\n    }\n}\nexport function buildLookaheadFuncForOr(occurrence, ruleGrammar, maxLookahead, hasPredicates, dynamicTokensEnabled, laFuncBuilder) {\n    const lookAheadPaths = getLookaheadPathsForOr(occurrence, ruleGrammar, maxLookahead);\n    const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n        ? tokenStructuredMatcherNoCategories\n        : tokenStructuredMatcher;\n    return laFuncBuilder(lookAheadPaths, hasPredicates, tokenMatcher, dynamicTokensEnabled);\n}\n/**\n *  When dealing with an Optional production (OPTION/MANY/2nd iteration of AT_LEAST_ONE/...) we need to compare\n *  the lookahead \"inside\" the production and the lookahead immediately \"after\" it in the same top level rule (context free).\n *\n *  Example: given a production:\n *  ABC(DE)?DF\n *\n *  The optional '(DE)?' should only be entered if we see 'DE'. a single Token 'D' is not sufficient to distinguish between the two\n *  alternatives.\n *\n *  @returns A Lookahead function which will return true IFF the parser should parse the Optional production.\n */\nexport function buildLookaheadFuncForOptionalProd(occurrence, ruleGrammar, k, dynamicTokensEnabled, prodType, lookaheadBuilder) {\n    const lookAheadPaths = getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, k);\n    const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n        ? tokenStructuredMatcherNoCategories\n        : tokenStructuredMatcher;\n    return lookaheadBuilder(lookAheadPaths[0], tokenMatcher, dynamicTokensEnabled);\n}\nexport function buildAlternativesLookAheadFunc(alts, hasPredicates, tokenMatcher, dynamicTokensEnabled) {\n    const numOfAlts = alts.length;\n    const areAllOneTokenLookahead = every(alts, (currAlt) => {\n        return every(currAlt, (currPath) => {\n            return currPath.length === 1;\n        });\n    });\n    // This version takes into account the predicates as well.\n    if (hasPredicates) {\n        /**\n         * @returns {number} - The chosen alternative index\n         */\n        return function (orAlts) {\n            // unfortunately the predicates must be extracted every single time\n            // as they cannot be cached due to references to parameters(vars) which are no longer valid.\n            // note that in the common case of no predicates, no cpu time will be wasted on this (see else block)\n            const predicates = map(orAlts, (currAlt) => currAlt.GATE);\n            for (let t = 0; t < numOfAlts; t++) {\n                const currAlt = alts[t];\n                const currNumOfPaths = currAlt.length;\n                const currPredicate = predicates[t];\n                if (currPredicate !== undefined && currPredicate.call(this) === false) {\n                    // if the predicate does not match there is no point in checking the paths\n                    continue;\n                }\n                nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n                    const currPath = currAlt[j];\n                    const currPathLength = currPath.length;\n                    for (let i = 0; i < currPathLength; i++) {\n                        const nextToken = this.LA(i + 1);\n                        if (tokenMatcher(nextToken, currPath[i]) === false) {\n                            // mismatch in current path\n                            // try the next pth\n                            continue nextPath;\n                        }\n                    }\n                    // found a full path that matches.\n                    // this will also work for an empty ALT as the loop will be skipped\n                    return t;\n                }\n                // none of the paths for the current alternative matched\n                // try the next alternative\n            }\n            // none of the alternatives could be matched\n            return undefined;\n        };\n    }\n    else if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n        // optimized (common) case of all the lookaheads paths requiring only\n        // a single token lookahead. These Optimizations cannot work if dynamically defined Tokens are used.\n        const singleTokenAlts = map(alts, (currAlt) => {\n            return flatten(currAlt);\n        });\n        const choiceToAlt = reduce(singleTokenAlts, (result, currAlt, idx) => {\n            forEach(currAlt, (currTokType) => {\n                if (!has(result, currTokType.tokenTypeIdx)) {\n                    result[currTokType.tokenTypeIdx] = idx;\n                }\n                forEach(currTokType.categoryMatches, (currExtendingType) => {\n                    if (!has(result, currExtendingType)) {\n                        result[currExtendingType] = idx;\n                    }\n                });\n            });\n            return result;\n        }, {});\n        /**\n         * @returns {number} - The chosen alternative index\n         */\n        return function () {\n            const nextToken = this.LA(1);\n            return choiceToAlt[nextToken.tokenTypeIdx];\n        };\n    }\n    else {\n        // optimized lookahead without needing to check the predicates at all.\n        // this causes code duplication which is intentional to improve performance.\n        /**\n         * @returns {number} - The chosen alternative index\n         */\n        return function () {\n            for (let t = 0; t < numOfAlts; t++) {\n                const currAlt = alts[t];\n                const currNumOfPaths = currAlt.length;\n                nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n                    const currPath = currAlt[j];\n                    const currPathLength = currPath.length;\n                    for (let i = 0; i < currPathLength; i++) {\n                        const nextToken = this.LA(i + 1);\n                        if (tokenMatcher(nextToken, currPath[i]) === false) {\n                            // mismatch in current path\n                            // try the next pth\n                            continue nextPath;\n                        }\n                    }\n                    // found a full path that matches.\n                    // this will also work for an empty ALT as the loop will be skipped\n                    return t;\n                }\n                // none of the paths for the current alternative matched\n                // try the next alternative\n            }\n            // none of the alternatives could be matched\n            return undefined;\n        };\n    }\n}\nexport function buildSingleAlternativeLookaheadFunction(alt, tokenMatcher, dynamicTokensEnabled) {\n    const areAllOneTokenLookahead = every(alt, (currPath) => {\n        return currPath.length === 1;\n    });\n    const numOfPaths = alt.length;\n    // optimized (common) case of all the lookaheads paths requiring only\n    // a single token lookahead.\n    if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n        const singleTokensTypes = flatten(alt);\n        if (singleTokensTypes.length === 1 &&\n            isEmpty(singleTokensTypes[0].categoryMatches)) {\n            const expectedTokenType = singleTokensTypes[0];\n            const expectedTokenUniqueKey = expectedTokenType.tokenTypeIdx;\n            return function () {\n                return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey;\n            };\n        }\n        else {\n            const choiceToAlt = reduce(singleTokensTypes, (result, currTokType, idx) => {\n                result[currTokType.tokenTypeIdx] = true;\n                forEach(currTokType.categoryMatches, (currExtendingType) => {\n                    result[currExtendingType] = true;\n                });\n                return result;\n            }, []);\n            return function () {\n                const nextToken = this.LA(1);\n                return choiceToAlt[nextToken.tokenTypeIdx] === true;\n            };\n        }\n    }\n    else {\n        return function () {\n            nextPath: for (let j = 0; j < numOfPaths; j++) {\n                const currPath = alt[j];\n                const currPathLength = currPath.length;\n                for (let i = 0; i < currPathLength; i++) {\n                    const nextToken = this.LA(i + 1);\n                    if (tokenMatcher(nextToken, currPath[i]) === false) {\n                        // mismatch in current path\n                        // try the next pth\n                        continue nextPath;\n                    }\n                }\n                // found a full path that matches.\n                return true;\n            }\n            // none of the paths matched\n            return false;\n        };\n    }\n}\nclass RestDefinitionFinderWalker extends RestWalker {\n    constructor(topProd, targetOccurrence, targetProdType) {\n        super();\n        this.topProd = topProd;\n        this.targetOccurrence = targetOccurrence;\n        this.targetProdType = targetProdType;\n    }\n    startWalking() {\n        this.walk(this.topProd);\n        return this.restDef;\n    }\n    checkIsTarget(node, expectedProdType, currRest, prevRest) {\n        if (node.idx === this.targetOccurrence &&\n            this.targetProdType === expectedProdType) {\n            this.restDef = currRest.concat(prevRest);\n            return true;\n        }\n        // performance optimization, do not iterate over the entire Grammar ast after we have found the target\n        return false;\n    }\n    walkOption(optionProd, currRest, prevRest) {\n        if (!this.checkIsTarget(optionProd, PROD_TYPE.OPTION, currRest, prevRest)) {\n            super.walkOption(optionProd, currRest, prevRest);\n        }\n    }\n    walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n        if (!this.checkIsTarget(atLeastOneProd, PROD_TYPE.REPETITION_MANDATORY, currRest, prevRest)) {\n            super.walkOption(atLeastOneProd, currRest, prevRest);\n        }\n    }\n    walkAtLeastOneSep(atLeastOneSepProd, currRest, prevRest) {\n        if (!this.checkIsTarget(atLeastOneSepProd, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR, currRest, prevRest)) {\n            super.walkOption(atLeastOneSepProd, currRest, prevRest);\n        }\n    }\n    walkMany(manyProd, currRest, prevRest) {\n        if (!this.checkIsTarget(manyProd, PROD_TYPE.REPETITION, currRest, prevRest)) {\n            super.walkOption(manyProd, currRest, prevRest);\n        }\n    }\n    walkManySep(manySepProd, currRest, prevRest) {\n        if (!this.checkIsTarget(manySepProd, PROD_TYPE.REPETITION_WITH_SEPARATOR, currRest, prevRest)) {\n            super.walkOption(manySepProd, currRest, prevRest);\n        }\n    }\n}\n/**\n * Returns the definition of a target production in a top level level rule.\n */\nclass InsideDefinitionFinderVisitor extends GAstVisitor {\n    constructor(targetOccurrence, targetProdType, targetRef) {\n        super();\n        this.targetOccurrence = targetOccurrence;\n        this.targetProdType = targetProdType;\n        this.targetRef = targetRef;\n        this.result = [];\n    }\n    checkIsTarget(node, expectedProdName) {\n        if (node.idx === this.targetOccurrence &&\n            this.targetProdType === expectedProdName &&\n            (this.targetRef === undefined || node === this.targetRef)) {\n            this.result = node.definition;\n        }\n    }\n    visitOption(node) {\n        this.checkIsTarget(node, PROD_TYPE.OPTION);\n    }\n    visitRepetition(node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION);\n    }\n    visitRepetitionMandatory(node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY);\n    }\n    visitRepetitionMandatoryWithSeparator(node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR);\n    }\n    visitRepetitionWithSeparator(node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION_WITH_SEPARATOR);\n    }\n    visitAlternation(node) {\n        this.checkIsTarget(node, PROD_TYPE.ALTERNATION);\n    }\n}\nfunction initializeArrayOfArrays(size) {\n    const result = new Array(size);\n    for (let i = 0; i < size; i++) {\n        result[i] = [];\n    }\n    return result;\n}\n/**\n * A sort of hash function between a Path in the grammar and a string.\n * Note that this returns multiple \"hashes\" to support the scenario of token categories.\n * -  A single path with categories may match multiple **actual** paths.\n */\nfunction pathToHashKeys(path) {\n    let keys = [\"\"];\n    for (let i = 0; i < path.length; i++) {\n        const tokType = path[i];\n        const longerKeys = [];\n        for (let j = 0; j < keys.length; j++) {\n            const currShorterKey = keys[j];\n            longerKeys.push(currShorterKey + \"_\" + tokType.tokenTypeIdx);\n            for (let t = 0; t < tokType.categoryMatches.length; t++) {\n                const categoriesKeySuffix = \"_\" + tokType.categoryMatches[t];\n                longerKeys.push(currShorterKey + categoriesKeySuffix);\n            }\n        }\n        keys = longerKeys;\n    }\n    return keys;\n}\n/**\n * Imperative style due to being called from a hot spot\n */\nfunction isUniquePrefixHash(altKnownPathsKeys, searchPathKeys, idx) {\n    for (let currAltIdx = 0; currAltIdx < altKnownPathsKeys.length; currAltIdx++) {\n        // We only want to test vs the other alternatives\n        if (currAltIdx === idx) {\n            continue;\n        }\n        const otherAltKnownPathsKeys = altKnownPathsKeys[currAltIdx];\n        for (let searchIdx = 0; searchIdx < searchPathKeys.length; searchIdx++) {\n            const searchKey = searchPathKeys[searchIdx];\n            if (otherAltKnownPathsKeys[searchKey] === true) {\n                return false;\n            }\n        }\n    }\n    // None of the SearchPathKeys were found in any of the other alternatives\n    return true;\n}\nexport function lookAheadSequenceFromAlternatives(altsDefs, k) {\n    const partialAlts = map(altsDefs, (currAlt) => possiblePathsFrom([currAlt], 1));\n    const finalResult = initializeArrayOfArrays(partialAlts.length);\n    const altsHashes = map(partialAlts, (currAltPaths) => {\n        const dict = {};\n        forEach(currAltPaths, (item) => {\n            const keys = pathToHashKeys(item.partialPath);\n            forEach(keys, (currKey) => {\n                dict[currKey] = true;\n            });\n        });\n        return dict;\n    });\n    let newData = partialAlts;\n    // maxLookahead loop\n    for (let pathLength = 1; pathLength <= k; pathLength++) {\n        const currDataset = newData;\n        newData = initializeArrayOfArrays(currDataset.length);\n        // alternatives loop\n        for (let altIdx = 0; altIdx < currDataset.length; altIdx++) {\n            const currAltPathsAndSuffixes = currDataset[altIdx];\n            // paths in current alternative loop\n            for (let currPathIdx = 0; currPathIdx < currAltPathsAndSuffixes.length; currPathIdx++) {\n                const currPathPrefix = currAltPathsAndSuffixes[currPathIdx].partialPath;\n                const suffixDef = currAltPathsAndSuffixes[currPathIdx].suffixDef;\n                const prefixKeys = pathToHashKeys(currPathPrefix);\n                const isUnique = isUniquePrefixHash(altsHashes, prefixKeys, altIdx);\n                // End of the line for this path.\n                if (isUnique || isEmpty(suffixDef) || currPathPrefix.length === k) {\n                    const currAltResult = finalResult[altIdx];\n                    // TODO: Can we implement a containsPath using Maps/Dictionaries?\n                    if (containsPath(currAltResult, currPathPrefix) === false) {\n                        currAltResult.push(currPathPrefix);\n                        // Update all new  keys for the current path.\n                        for (let j = 0; j < prefixKeys.length; j++) {\n                            const currKey = prefixKeys[j];\n                            altsHashes[altIdx][currKey] = true;\n                        }\n                    }\n                }\n                // Expand longer paths\n                else {\n                    const newPartialPathsAndSuffixes = possiblePathsFrom(suffixDef, pathLength + 1, currPathPrefix);\n                    newData[altIdx] = newData[altIdx].concat(newPartialPathsAndSuffixes);\n                    // Update keys for new known paths\n                    forEach(newPartialPathsAndSuffixes, (item) => {\n                        const prefixKeys = pathToHashKeys(item.partialPath);\n                        forEach(prefixKeys, (key) => {\n                            altsHashes[altIdx][key] = true;\n                        });\n                    });\n                }\n            }\n        }\n    }\n    return finalResult;\n}\nexport function getLookaheadPathsForOr(occurrence, ruleGrammar, k, orProd) {\n    const visitor = new InsideDefinitionFinderVisitor(occurrence, PROD_TYPE.ALTERNATION, orProd);\n    ruleGrammar.accept(visitor);\n    return lookAheadSequenceFromAlternatives(visitor.result, k);\n}\nexport function getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, k) {\n    const insideDefVisitor = new InsideDefinitionFinderVisitor(occurrence, prodType);\n    ruleGrammar.accept(insideDefVisitor);\n    const insideDef = insideDefVisitor.result;\n    const afterDefWalker = new RestDefinitionFinderWalker(ruleGrammar, occurrence, prodType);\n    const afterDef = afterDefWalker.startWalking();\n    const insideFlat = new AlternativeGAST({ definition: insideDef });\n    const afterFlat = new AlternativeGAST({ definition: afterDef });\n    return lookAheadSequenceFromAlternatives([insideFlat, afterFlat], k);\n}\nexport function containsPath(alternative, searchPath) {\n    compareOtherPath: for (let i = 0; i < alternative.length; i++) {\n        const otherPath = alternative[i];\n        if (otherPath.length !== searchPath.length) {\n            continue;\n        }\n        for (let j = 0; j < otherPath.length; j++) {\n            const searchTok = searchPath[j];\n            const otherTok = otherPath[j];\n            const matchingTokens = searchTok === otherTok ||\n                otherTok.categoryMatchesMap[searchTok.tokenTypeIdx] !== undefined;\n            if (matchingTokens === false) {\n                continue compareOtherPath;\n            }\n        }\n        return true;\n    }\n    return false;\n}\nexport function isStrictPrefixOfPath(prefix, other) {\n    return (prefix.length < other.length &&\n        every(prefix, (tokType, idx) => {\n            const otherTokType = other[idx];\n            return (tokType === otherTokType ||\n                otherTokType.categoryMatchesMap[tokType.tokenTypeIdx]);\n        }));\n}\nexport function areTokenCategoriesNotUsed(lookAheadPaths) {\n    return every(lookAheadPaths, (singleAltPaths) => every(singleAltPaths, (singlePath) => every(singlePath, (token) => isEmpty(token.categoryMatches))));\n}\n//# sourceMappingURL=lookahead.js.map","import { clone, compact, difference, drop, dropRight, filter, first, flatMap, flatten, forEach, groupBy, includes, isEmpty, map, pickBy, reduce, reject, values, } from \"lodash-es\";\nimport { ParserDefinitionErrorType, } from \"../parser/parser.js\";\nimport { Alternation, Alternative as AlternativeGAST, GAstVisitor, getProductionDslName, isOptionalProd, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Terminal, } from \"@chevrotain/gast\";\nimport { containsPath, getLookaheadPathsForOptionalProd, getLookaheadPathsForOr, getProdType, isStrictPrefixOfPath, } from \"./lookahead.js\";\nimport { nextPossibleTokensAfter } from \"./interpreter.js\";\nimport { tokenStructuredMatcher } from \"../../scan/tokens.js\";\nexport function validateLookahead(options) {\n    const lookaheadValidationErrorMessages = options.lookaheadStrategy.validate({\n        rules: options.rules,\n        tokenTypes: options.tokenTypes,\n        grammarName: options.grammarName,\n    });\n    return map(lookaheadValidationErrorMessages, (errorMessage) => (Object.assign({ type: ParserDefinitionErrorType.CUSTOM_LOOKAHEAD_VALIDATION }, errorMessage)));\n}\nexport function validateGrammar(topLevels, tokenTypes, errMsgProvider, grammarName) {\n    const duplicateErrors = flatMap(topLevels, (currTopLevel) => validateDuplicateProductions(currTopLevel, errMsgProvider));\n    const termsNamespaceConflictErrors = checkTerminalAndNoneTerminalsNameSpace(topLevels, tokenTypes, errMsgProvider);\n    const tooManyAltsErrors = flatMap(topLevels, (curRule) => validateTooManyAlts(curRule, errMsgProvider));\n    const duplicateRulesError = flatMap(topLevels, (curRule) => validateRuleDoesNotAlreadyExist(curRule, topLevels, grammarName, errMsgProvider));\n    return duplicateErrors.concat(termsNamespaceConflictErrors, tooManyAltsErrors, duplicateRulesError);\n}\nfunction validateDuplicateProductions(topLevelRule, errMsgProvider) {\n    const collectorVisitor = new OccurrenceValidationCollector();\n    topLevelRule.accept(collectorVisitor);\n    const allRuleProductions = collectorVisitor.allProductions;\n    const productionGroups = groupBy(allRuleProductions, identifyProductionForDuplicates);\n    const duplicates = pickBy(productionGroups, (currGroup) => {\n        return currGroup.length > 1;\n    });\n    const errors = map(values(duplicates), (currDuplicates) => {\n        const firstProd = first(currDuplicates);\n        const msg = errMsgProvider.buildDuplicateFoundError(topLevelRule, currDuplicates);\n        const dslName = getProductionDslName(firstProd);\n        const defError = {\n            message: msg,\n            type: ParserDefinitionErrorType.DUPLICATE_PRODUCTIONS,\n            ruleName: topLevelRule.name,\n            dslName: dslName,\n            occurrence: firstProd.idx,\n        };\n        const param = getExtraProductionArgument(firstProd);\n        if (param) {\n            defError.parameter = param;\n        }\n        return defError;\n    });\n    return errors;\n}\nexport function identifyProductionForDuplicates(prod) {\n    return `${getProductionDslName(prod)}_#_${prod.idx}_#_${getExtraProductionArgument(prod)}`;\n}\nfunction getExtraProductionArgument(prod) {\n    if (prod instanceof Terminal) {\n        return prod.terminalType.name;\n    }\n    else if (prod instanceof NonTerminal) {\n        return prod.nonTerminalName;\n    }\n    else {\n        return \"\";\n    }\n}\nexport class OccurrenceValidationCollector extends GAstVisitor {\n    constructor() {\n        super(...arguments);\n        this.allProductions = [];\n    }\n    visitNonTerminal(subrule) {\n        this.allProductions.push(subrule);\n    }\n    visitOption(option) {\n        this.allProductions.push(option);\n    }\n    visitRepetitionWithSeparator(manySep) {\n        this.allProductions.push(manySep);\n    }\n    visitRepetitionMandatory(atLeastOne) {\n        this.allProductions.push(atLeastOne);\n    }\n    visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n        this.allProductions.push(atLeastOneSep);\n    }\n    visitRepetition(many) {\n        this.allProductions.push(many);\n    }\n    visitAlternation(or) {\n        this.allProductions.push(or);\n    }\n    visitTerminal(terminal) {\n        this.allProductions.push(terminal);\n    }\n}\nexport function validateRuleDoesNotAlreadyExist(rule, allRules, className, errMsgProvider) {\n    const errors = [];\n    const occurrences = reduce(allRules, (result, curRule) => {\n        if (curRule.name === rule.name) {\n            return result + 1;\n        }\n        return result;\n    }, 0);\n    if (occurrences > 1) {\n        const errMsg = errMsgProvider.buildDuplicateRuleNameError({\n            topLevelRule: rule,\n            grammarName: className,\n        });\n        errors.push({\n            message: errMsg,\n            type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n            ruleName: rule.name,\n        });\n    }\n    return errors;\n}\n// TODO: is there anyway to get only the rule names of rules inherited from the super grammars?\n// This is not part of the IGrammarErrorProvider because the validation cannot be performed on\n// The grammar structure, only at runtime.\nexport function validateRuleIsOverridden(ruleName, definedRulesNames, className) {\n    const errors = [];\n    let errMsg;\n    if (!includes(definedRulesNames, ruleName)) {\n        errMsg =\n            `Invalid rule override, rule: ->${ruleName}<- cannot be overridden in the grammar: ->${className}<-` +\n                `as it is not defined in any of the super grammars `;\n        errors.push({\n            message: errMsg,\n            type: ParserDefinitionErrorType.INVALID_RULE_OVERRIDE,\n            ruleName: ruleName,\n        });\n    }\n    return errors;\n}\nexport function validateNoLeftRecursion(topRule, currRule, errMsgProvider, path = []) {\n    const errors = [];\n    const nextNonTerminals = getFirstNoneTerminal(currRule.definition);\n    if (isEmpty(nextNonTerminals)) {\n        return [];\n    }\n    else {\n        const ruleName = topRule.name;\n        const foundLeftRecursion = includes(nextNonTerminals, topRule);\n        if (foundLeftRecursion) {\n            errors.push({\n                message: errMsgProvider.buildLeftRecursionError({\n                    topLevelRule: topRule,\n                    leftRecursionPath: path,\n                }),\n                type: ParserDefinitionErrorType.LEFT_RECURSION,\n                ruleName: ruleName,\n            });\n        }\n        // we are only looking for cyclic paths leading back to the specific topRule\n        // other cyclic paths are ignored, we still need this difference to avoid infinite loops...\n        const validNextSteps = difference(nextNonTerminals, path.concat([topRule]));\n        const errorsFromNextSteps = flatMap(validNextSteps, (currRefRule) => {\n            const newPath = clone(path);\n            newPath.push(currRefRule);\n            return validateNoLeftRecursion(topRule, currRefRule, errMsgProvider, newPath);\n        });\n        return errors.concat(errorsFromNextSteps);\n    }\n}\nexport function getFirstNoneTerminal(definition) {\n    let result = [];\n    if (isEmpty(definition)) {\n        return result;\n    }\n    const firstProd = first(definition);\n    /* istanbul ignore else */\n    if (firstProd instanceof NonTerminal) {\n        result.push(firstProd.referencedRule);\n    }\n    else if (firstProd instanceof AlternativeGAST ||\n        firstProd instanceof Option ||\n        firstProd instanceof RepetitionMandatory ||\n        firstProd instanceof RepetitionMandatoryWithSeparator ||\n        firstProd instanceof RepetitionWithSeparator ||\n        firstProd instanceof Repetition) {\n        result = result.concat(getFirstNoneTerminal(firstProd.definition));\n    }\n    else if (firstProd instanceof Alternation) {\n        // each sub definition in alternation is a FLAT\n        result = flatten(map(firstProd.definition, (currSubDef) => getFirstNoneTerminal(currSubDef.definition)));\n    }\n    else if (firstProd instanceof Terminal) {\n        // nothing to see, move along\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n    const isFirstOptional = isOptionalProd(firstProd);\n    const hasMore = definition.length > 1;\n    if (isFirstOptional && hasMore) {\n        const rest = drop(definition);\n        return result.concat(getFirstNoneTerminal(rest));\n    }\n    else {\n        return result;\n    }\n}\nclass OrCollector extends GAstVisitor {\n    constructor() {\n        super(...arguments);\n        this.alternations = [];\n    }\n    visitAlternation(node) {\n        this.alternations.push(node);\n    }\n}\nexport function validateEmptyOrAlternative(topLevelRule, errMsgProvider) {\n    const orCollector = new OrCollector();\n    topLevelRule.accept(orCollector);\n    const ors = orCollector.alternations;\n    const errors = flatMap(ors, (currOr) => {\n        const exceptLast = dropRight(currOr.definition);\n        return flatMap(exceptLast, (currAlternative, currAltIdx) => {\n            const possibleFirstInAlt = nextPossibleTokensAfter([currAlternative], [], tokenStructuredMatcher, 1);\n            if (isEmpty(possibleFirstInAlt)) {\n                return [\n                    {\n                        message: errMsgProvider.buildEmptyAlternationError({\n                            topLevelRule: topLevelRule,\n                            alternation: currOr,\n                            emptyChoiceIdx: currAltIdx,\n                        }),\n                        type: ParserDefinitionErrorType.NONE_LAST_EMPTY_ALT,\n                        ruleName: topLevelRule.name,\n                        occurrence: currOr.idx,\n                        alternative: currAltIdx + 1,\n                    },\n                ];\n            }\n            else {\n                return [];\n            }\n        });\n    });\n    return errors;\n}\nexport function validateAmbiguousAlternationAlternatives(topLevelRule, globalMaxLookahead, errMsgProvider) {\n    const orCollector = new OrCollector();\n    topLevelRule.accept(orCollector);\n    let ors = orCollector.alternations;\n    // New Handling of ignoring ambiguities\n    // - https://github.com/chevrotain/chevrotain/issues/869\n    ors = reject(ors, (currOr) => currOr.ignoreAmbiguities === true);\n    const errors = flatMap(ors, (currOr) => {\n        const currOccurrence = currOr.idx;\n        const actualMaxLookahead = currOr.maxLookahead || globalMaxLookahead;\n        const alternatives = getLookaheadPathsForOr(currOccurrence, topLevelRule, actualMaxLookahead, currOr);\n        const altsAmbiguityErrors = checkAlternativesAmbiguities(alternatives, currOr, topLevelRule, errMsgProvider);\n        const altsPrefixAmbiguityErrors = checkPrefixAlternativesAmbiguities(alternatives, currOr, topLevelRule, errMsgProvider);\n        return altsAmbiguityErrors.concat(altsPrefixAmbiguityErrors);\n    });\n    return errors;\n}\nexport class RepetitionCollector extends GAstVisitor {\n    constructor() {\n        super(...arguments);\n        this.allProductions = [];\n    }\n    visitRepetitionWithSeparator(manySep) {\n        this.allProductions.push(manySep);\n    }\n    visitRepetitionMandatory(atLeastOne) {\n        this.allProductions.push(atLeastOne);\n    }\n    visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n        this.allProductions.push(atLeastOneSep);\n    }\n    visitRepetition(many) {\n        this.allProductions.push(many);\n    }\n}\nexport function validateTooManyAlts(topLevelRule, errMsgProvider) {\n    const orCollector = new OrCollector();\n    topLevelRule.accept(orCollector);\n    const ors = orCollector.alternations;\n    const errors = flatMap(ors, (currOr) => {\n        if (currOr.definition.length > 255) {\n            return [\n                {\n                    message: errMsgProvider.buildTooManyAlternativesError({\n                        topLevelRule: topLevelRule,\n                        alternation: currOr,\n                    }),\n                    type: ParserDefinitionErrorType.TOO_MANY_ALTS,\n                    ruleName: topLevelRule.name,\n                    occurrence: currOr.idx,\n                },\n            ];\n        }\n        else {\n            return [];\n        }\n    });\n    return errors;\n}\nexport function validateSomeNonEmptyLookaheadPath(topLevelRules, maxLookahead, errMsgProvider) {\n    const errors = [];\n    forEach(topLevelRules, (currTopRule) => {\n        const collectorVisitor = new RepetitionCollector();\n        currTopRule.accept(collectorVisitor);\n        const allRuleProductions = collectorVisitor.allProductions;\n        forEach(allRuleProductions, (currProd) => {\n            const prodType = getProdType(currProd);\n            const actualMaxLookahead = currProd.maxLookahead || maxLookahead;\n            const currOccurrence = currProd.idx;\n            const paths = getLookaheadPathsForOptionalProd(currOccurrence, currTopRule, prodType, actualMaxLookahead);\n            const pathsInsideProduction = paths[0];\n            if (isEmpty(flatten(pathsInsideProduction))) {\n                const errMsg = errMsgProvider.buildEmptyRepetitionError({\n                    topLevelRule: currTopRule,\n                    repetition: currProd,\n                });\n                errors.push({\n                    message: errMsg,\n                    type: ParserDefinitionErrorType.NO_NON_EMPTY_LOOKAHEAD,\n                    ruleName: currTopRule.name,\n                });\n            }\n        });\n    });\n    return errors;\n}\nfunction checkAlternativesAmbiguities(alternatives, alternation, rule, errMsgProvider) {\n    const foundAmbiguousPaths = [];\n    const identicalAmbiguities = reduce(alternatives, (result, currAlt, currAltIdx) => {\n        // ignore (skip) ambiguities with this alternative\n        if (alternation.definition[currAltIdx].ignoreAmbiguities === true) {\n            return result;\n        }\n        forEach(currAlt, (currPath) => {\n            const altsCurrPathAppearsIn = [currAltIdx];\n            forEach(alternatives, (currOtherAlt, currOtherAltIdx) => {\n                if (currAltIdx !== currOtherAltIdx &&\n                    containsPath(currOtherAlt, currPath) &&\n                    // ignore (skip) ambiguities with this \"other\" alternative\n                    alternation.definition[currOtherAltIdx].ignoreAmbiguities !== true) {\n                    altsCurrPathAppearsIn.push(currOtherAltIdx);\n                }\n            });\n            if (altsCurrPathAppearsIn.length > 1 &&\n                !containsPath(foundAmbiguousPaths, currPath)) {\n                foundAmbiguousPaths.push(currPath);\n                result.push({\n                    alts: altsCurrPathAppearsIn,\n                    path: currPath,\n                });\n            }\n        });\n        return result;\n    }, []);\n    const currErrors = map(identicalAmbiguities, (currAmbDescriptor) => {\n        const ambgIndices = map(currAmbDescriptor.alts, (currAltIdx) => currAltIdx + 1);\n        const currMessage = errMsgProvider.buildAlternationAmbiguityError({\n            topLevelRule: rule,\n            alternation: alternation,\n            ambiguityIndices: ambgIndices,\n            prefixPath: currAmbDescriptor.path,\n        });\n        return {\n            message: currMessage,\n            type: ParserDefinitionErrorType.AMBIGUOUS_ALTS,\n            ruleName: rule.name,\n            occurrence: alternation.idx,\n            alternatives: currAmbDescriptor.alts,\n        };\n    });\n    return currErrors;\n}\nexport function checkPrefixAlternativesAmbiguities(alternatives, alternation, rule, errMsgProvider) {\n    // flatten\n    const pathsAndIndices = reduce(alternatives, (result, currAlt, idx) => {\n        const currPathsAndIdx = map(currAlt, (currPath) => {\n            return { idx: idx, path: currPath };\n        });\n        return result.concat(currPathsAndIdx);\n    }, []);\n    const errors = compact(flatMap(pathsAndIndices, (currPathAndIdx) => {\n        const alternativeGast = alternation.definition[currPathAndIdx.idx];\n        // ignore (skip) ambiguities with this alternative\n        if (alternativeGast.ignoreAmbiguities === true) {\n            return [];\n        }\n        const targetIdx = currPathAndIdx.idx;\n        const targetPath = currPathAndIdx.path;\n        const prefixAmbiguitiesPathsAndIndices = filter(pathsAndIndices, (searchPathAndIdx) => {\n            // prefix ambiguity can only be created from lower idx (higher priority) path\n            return (\n            // ignore (skip) ambiguities with this \"other\" alternative\n            alternation.definition[searchPathAndIdx.idx].ignoreAmbiguities !==\n                true &&\n                searchPathAndIdx.idx < targetIdx &&\n                // checking for strict prefix because identical lookaheads\n                // will be be detected using a different validation.\n                isStrictPrefixOfPath(searchPathAndIdx.path, targetPath));\n        });\n        const currPathPrefixErrors = map(prefixAmbiguitiesPathsAndIndices, (currAmbPathAndIdx) => {\n            const ambgIndices = [currAmbPathAndIdx.idx + 1, targetIdx + 1];\n            const occurrence = alternation.idx === 0 ? \"\" : alternation.idx;\n            const message = errMsgProvider.buildAlternationPrefixAmbiguityError({\n                topLevelRule: rule,\n                alternation: alternation,\n                ambiguityIndices: ambgIndices,\n                prefixPath: currAmbPathAndIdx.path,\n            });\n            return {\n                message: message,\n                type: ParserDefinitionErrorType.AMBIGUOUS_PREFIX_ALTS,\n                ruleName: rule.name,\n                occurrence: occurrence,\n                alternatives: ambgIndices,\n            };\n        });\n        return currPathPrefixErrors;\n    }));\n    return errors;\n}\nfunction checkTerminalAndNoneTerminalsNameSpace(topLevels, tokenTypes, errMsgProvider) {\n    const errors = [];\n    const tokenNames = map(tokenTypes, (currToken) => currToken.name);\n    forEach(topLevels, (currRule) => {\n        const currRuleName = currRule.name;\n        if (includes(tokenNames, currRuleName)) {\n            const errMsg = errMsgProvider.buildNamespaceConflictError(currRule);\n            errors.push({\n                message: errMsg,\n                type: ParserDefinitionErrorType.CONFLICT_TOKENS_RULES_NAMESPACE,\n                ruleName: currRuleName,\n            });\n        }\n    });\n    return errors;\n}\n//# sourceMappingURL=checks.js.map","import { defaults, forEach } from \"lodash-es\";\nimport { resolveGrammar as orgResolveGrammar } from \"../resolver.js\";\nimport { validateGrammar as orgValidateGrammar } from \"../checks.js\";\nimport { defaultGrammarResolverErrorProvider, defaultGrammarValidatorErrorProvider, } from \"../../errors_public.js\";\nexport function resolveGrammar(options) {\n    const actualOptions = defaults(options, {\n        errMsgProvider: defaultGrammarResolverErrorProvider,\n    });\n    const topRulesTable = {};\n    forEach(options.rules, (rule) => {\n        topRulesTable[rule.name] = rule;\n    });\n    return orgResolveGrammar(topRulesTable, actualOptions.errMsgProvider);\n}\nexport function validateGrammar(options) {\n    options = defaults(options, {\n        errMsgProvider: defaultGrammarValidatorErrorProvider,\n    });\n    return orgValidateGrammar(options.rules, options.tokenTypes, options.errMsgProvider, options.grammarName);\n}\n//# sourceMappingURL=gast_resolver_public.js.map","import { includes } from \"lodash-es\";\nconst MISMATCHED_TOKEN_EXCEPTION = \"MismatchedTokenException\";\nconst NO_VIABLE_ALT_EXCEPTION = \"NoViableAltException\";\nconst EARLY_EXIT_EXCEPTION = \"EarlyExitException\";\nconst NOT_ALL_INPUT_PARSED_EXCEPTION = \"NotAllInputParsedException\";\nconst RECOGNITION_EXCEPTION_NAMES = [\n    MISMATCHED_TOKEN_EXCEPTION,\n    NO_VIABLE_ALT_EXCEPTION,\n    EARLY_EXIT_EXCEPTION,\n    NOT_ALL_INPUT_PARSED_EXCEPTION,\n];\nObject.freeze(RECOGNITION_EXCEPTION_NAMES);\n// hacks to bypass no support for custom Errors in javascript/typescript\nexport function isRecognitionException(error) {\n    // can't do instanceof on hacked custom js exceptions\n    return includes(RECOGNITION_EXCEPTION_NAMES, error.name);\n}\nclass RecognitionException extends Error {\n    constructor(message, token) {\n        super(message);\n        this.token = token;\n        this.resyncedTokens = [];\n        // fix prototype chain when typescript target is ES5\n        Object.setPrototypeOf(this, new.target.prototype);\n        /* istanbul ignore next - V8 workaround to remove constructor from stacktrace when typescript target is ES5 */\n        if (Error.captureStackTrace) {\n            Error.captureStackTrace(this, this.constructor);\n        }\n    }\n}\nexport class MismatchedTokenException extends RecognitionException {\n    constructor(message, token, previousToken) {\n        super(message, token);\n        this.previousToken = previousToken;\n        this.name = MISMATCHED_TOKEN_EXCEPTION;\n    }\n}\nexport class NoViableAltException extends RecognitionException {\n    constructor(message, token, previousToken) {\n        super(message, token);\n        this.previousToken = previousToken;\n        this.name = NO_VIABLE_ALT_EXCEPTION;\n    }\n}\nexport class NotAllInputParsedException extends RecognitionException {\n    constructor(message, token) {\n        super(message, token);\n        this.name = NOT_ALL_INPUT_PARSED_EXCEPTION;\n    }\n}\nexport class EarlyExitException extends RecognitionException {\n    constructor(message, token, previousToken) {\n        super(message, token);\n        this.previousToken = previousToken;\n        this.name = EARLY_EXIT_EXCEPTION;\n    }\n}\n//# sourceMappingURL=exceptions_public.js.map","import { createTokenInstance, EOF, tokenMatcher, } from \"../../../scan/tokens_public.js\";\nimport { clone, dropRight, find, flatten, has, includes, isEmpty, map, } from \"lodash-es\";\nimport { MismatchedTokenException } from \"../../exceptions_public.js\";\nimport { IN } from \"../../constants.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\nexport const EOF_FOLLOW_KEY = {};\nexport const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\nexport class InRuleRecoveryException extends Error {\n    constructor(message) {\n        super(message);\n        this.name = IN_RULE_RECOVERY_EXCEPTION;\n    }\n}\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nexport class Recoverable {\n    initRecoverable(config) {\n        this.firstAfterRepMap = {};\n        this.resyncFollows = {};\n        this.recoveryEnabled = has(config, \"recoveryEnabled\")\n            ? config.recoveryEnabled // assumes end user provides the correct config value/type\n            : DEFAULT_PARSER_CONFIG.recoveryEnabled;\n        // performance optimization, NOOP will be inlined which\n        // effectively means that this optional feature does not exist\n        // when not used.\n        if (this.recoveryEnabled) {\n            this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n        }\n    }\n    getTokenToInsert(tokType) {\n        const tokToInsert = createTokenInstance(tokType, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\n        tokToInsert.isInsertedInRecovery = true;\n        return tokToInsert;\n    }\n    canTokenTypeBeInsertedInRecovery(tokType) {\n        return true;\n    }\n    canTokenTypeBeDeletedInRecovery(tokType) {\n        return true;\n    }\n    tryInRepetitionRecovery(grammarRule, grammarRuleArgs, lookAheadFunc, expectedTokType) {\n        // TODO: can the resyncTokenType be cached?\n        const reSyncTokType = this.findReSyncTokenType();\n        const savedLexerState = this.exportLexerState();\n        const resyncedTokens = [];\n        let passedResyncPoint = false;\n        const nextTokenWithoutResync = this.LA(1);\n        let currToken = this.LA(1);\n        const generateErrorMessage = () => {\n            const previousToken = this.LA(0);\n            // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n            // the error that would have been thrown\n            const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n                expected: expectedTokType,\n                actual: nextTokenWithoutResync,\n                previous: previousToken,\n                ruleName: this.getCurrRuleFullName(),\n            });\n            const error = new MismatchedTokenException(msg, nextTokenWithoutResync, this.LA(0));\n            // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n            error.resyncedTokens = dropRight(resyncedTokens);\n            this.SAVE_ERROR(error);\n        };\n        while (!passedResyncPoint) {\n            // re-synced to a point where we can safely exit the repetition/\n            if (this.tokenMatcher(currToken, expectedTokType)) {\n                generateErrorMessage();\n                return; // must return here to avoid reverting the inputIdx\n            }\n            else if (lookAheadFunc.call(this)) {\n                // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n                generateErrorMessage();\n                // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n                grammarRule.apply(this, grammarRuleArgs);\n                return; // must return here to avoid reverting the inputIdx\n            }\n            else if (this.tokenMatcher(currToken, reSyncTokType)) {\n                passedResyncPoint = true;\n            }\n            else {\n                currToken = this.SKIP_TOKEN();\n                this.addToResyncTokens(currToken, resyncedTokens);\n            }\n        }\n        // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n        // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n        // \"between rules\" resync recovery later in the flow.\n        this.importLexerState(savedLexerState);\n    }\n    shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck) {\n        // Edge case of arriving from a MANY repetition which is stuck\n        // Attempting recovery in this case could cause an infinite loop\n        if (notStuck === false) {\n            return false;\n        }\n        // no need to recover, next token is what we expect...\n        if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n            return false;\n        }\n        // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n        // and prefer some backtracking path that includes recovered errors.\n        if (this.isBackTracking()) {\n            return false;\n        }\n        // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n        // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n        //noinspection RedundantIfStatementJS\n        if (this.canPerformInRuleRecovery(expectTokAfterLastMatch, this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx))) {\n            return false;\n        }\n        return true;\n    }\n    // Error Recovery functionality\n    getFollowsForInRuleRecovery(tokType, tokIdxInRule) {\n        const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n        const follows = this.getNextPossibleTokenTypes(grammarPath);\n        return follows;\n    }\n    tryInRuleRecovery(expectedTokType, follows) {\n        if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n            const tokToInsert = this.getTokenToInsert(expectedTokType);\n            return tokToInsert;\n        }\n        if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n            const nextTok = this.SKIP_TOKEN();\n            this.consumeToken();\n            return nextTok;\n        }\n        throw new InRuleRecoveryException(\"sad sad panda\");\n    }\n    canPerformInRuleRecovery(expectedToken, follows) {\n        return (this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\n            this.canRecoverWithSingleTokenDeletion(expectedToken));\n    }\n    canRecoverWithSingleTokenInsertion(expectedTokType, follows) {\n        if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n            return false;\n        }\n        // must know the possible following tokens to perform single token insertion\n        if (isEmpty(follows)) {\n            return false;\n        }\n        const mismatchedTok = this.LA(1);\n        const isMisMatchedTokInFollows = find(follows, (possibleFollowsTokType) => {\n            return this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n        }) !== undefined;\n        return isMisMatchedTokInFollows;\n    }\n    canRecoverWithSingleTokenDeletion(expectedTokType) {\n        if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n            return false;\n        }\n        const isNextTokenWhatIsExpected = this.tokenMatcher(this.LA(2), expectedTokType);\n        return isNextTokenWhatIsExpected;\n    }\n    isInCurrentRuleReSyncSet(tokenTypeIdx) {\n        const followKey = this.getCurrFollowKey();\n        const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n        return includes(currentRuleReSyncSet, tokenTypeIdx);\n    }\n    findReSyncTokenType() {\n        const allPossibleReSyncTokTypes = this.flattenFollowSet();\n        // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n        let nextToken = this.LA(1);\n        let k = 2;\n        while (true) {\n            const foundMatch = find(allPossibleReSyncTokTypes, (resyncTokType) => {\n                const canMatch = tokenMatcher(nextToken, resyncTokType);\n                return canMatch;\n            });\n            if (foundMatch !== undefined) {\n                return foundMatch;\n            }\n            nextToken = this.LA(k);\n            k++;\n        }\n    }\n    getCurrFollowKey() {\n        // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n        if (this.RULE_STACK.length === 1) {\n            return EOF_FOLLOW_KEY;\n        }\n        const currRuleShortName = this.getLastExplicitRuleShortName();\n        const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n        const prevRuleShortName = this.getPreviousExplicitRuleShortName();\n        return {\n            ruleName: this.shortRuleNameToFullName(currRuleShortName),\n            idxInCallingRule: currRuleIdx,\n            inRule: this.shortRuleNameToFullName(prevRuleShortName),\n        };\n    }\n    buildFullFollowKeyStack() {\n        const explicitRuleStack = this.RULE_STACK;\n        const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n        return map(explicitRuleStack, (ruleName, idx) => {\n            if (idx === 0) {\n                return EOF_FOLLOW_KEY;\n            }\n            return {\n                ruleName: this.shortRuleNameToFullName(ruleName),\n                idxInCallingRule: explicitOccurrenceStack[idx],\n                inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1]),\n            };\n        });\n    }\n    flattenFollowSet() {\n        const followStack = map(this.buildFullFollowKeyStack(), (currKey) => {\n            return this.getFollowSetFromFollowKey(currKey);\n        });\n        return flatten(followStack);\n    }\n    getFollowSetFromFollowKey(followKey) {\n        if (followKey === EOF_FOLLOW_KEY) {\n            return [EOF];\n        }\n        const followName = followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule;\n        return this.resyncFollows[followName];\n    }\n    // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n    // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n    addToResyncTokens(token, resyncTokens) {\n        if (!this.tokenMatcher(token, EOF)) {\n            resyncTokens.push(token);\n        }\n        return resyncTokens;\n    }\n    reSyncTo(tokType) {\n        const resyncedTokens = [];\n        let nextTok = this.LA(1);\n        while (this.tokenMatcher(nextTok, tokType) === false) {\n            nextTok = this.SKIP_TOKEN();\n            this.addToResyncTokens(nextTok, resyncedTokens);\n        }\n        // the last token is not part of the error.\n        return dropRight(resyncedTokens);\n    }\n    attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n        // by default this is a NO-OP\n        // The actual implementation is with the function(not method) below\n    }\n    getCurrentGrammarPath(tokType, tokIdxInRule) {\n        const pathRuleStack = this.getHumanReadableRuleStack();\n        const pathOccurrenceStack = clone(this.RULE_OCCURRENCE_STACK);\n        const grammarPath = {\n            ruleStack: pathRuleStack,\n            occurrenceStack: pathOccurrenceStack,\n            lastTok: tokType,\n            lastTokOccurrence: tokIdxInRule,\n        };\n        return grammarPath;\n    }\n    getHumanReadableRuleStack() {\n        return map(this.RULE_STACK, (currShortName) => this.shortRuleNameToFullName(currShortName));\n    }\n}\nexport function attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n    const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n    let firstAfterRepInfo = this.firstAfterRepMap[key];\n    if (firstAfterRepInfo === undefined) {\n        const currRuleName = this.getCurrRuleFullName();\n        const ruleGrammar = this.getGAstProductions()[currRuleName];\n        const walker = new nextToksWalker(ruleGrammar, prodOccurrence);\n        firstAfterRepInfo = walker.startWalking();\n        this.firstAfterRepMap[key] = firstAfterRepInfo;\n    }\n    let expectTokAfterLastMatch = firstAfterRepInfo.token;\n    let nextTokIdx = firstAfterRepInfo.occurrence;\n    const isEndOfRule = firstAfterRepInfo.isEndOfRule;\n    // special edge case of a TOP most repetition after which the input should END.\n    // this will force an attempt for inRule recovery in that scenario.\n    if (this.RULE_STACK.length === 1 &&\n        isEndOfRule &&\n        expectTokAfterLastMatch === undefined) {\n        expectTokAfterLastMatch = EOF;\n        nextTokIdx = 1;\n    }\n    // We don't have anything to re-sync to...\n    // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\n    if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n        return;\n    }\n    if (this.shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck)) {\n        // TODO: performance optimization: instead of passing the original args here, we modify\n        // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n        // to avoid searching the cache for it once more.\n        this.tryInRepetitionRecovery(prodFunc, args, lookaheadFunc, expectTokAfterLastMatch);\n    }\n}\n//# sourceMappingURL=recoverable.js.map","// Lookahead keys are 32Bit integers in the form\n// TTTTTTTT-ZZZZZZZZZZZZ-YYYY-XXXXXXXX\n// XXXX -> Occurrence Index bitmap.\n// YYYY -> DSL Method Type bitmap.\n// ZZZZZZZZZZZZZZZ -> Rule short Index bitmap.\n// TTTTTTTTT -> alternation alternative index bitmap\nexport const BITS_FOR_METHOD_TYPE = 4;\nexport const BITS_FOR_OCCURRENCE_IDX = 8;\nexport const BITS_FOR_RULE_IDX = 12;\n// TODO: validation, this means that there may at most 2^8 --> 256 alternatives for an alternation.\nexport const BITS_FOR_ALT_IDX = 8;\n// short string used as part of mapping keys.\n// being short improves the performance when composing KEYS for maps out of these\n// The 5 - 8 bits (16 possible values, are reserved for the DSL method indices)\nexport const OR_IDX = 1 << BITS_FOR_OCCURRENCE_IDX;\nexport const OPTION_IDX = 2 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_IDX = 3 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_IDX = 4 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_SEP_IDX = 5 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_SEP_IDX = 6 << BITS_FOR_OCCURRENCE_IDX;\n// this actually returns a number, but it is always used as a string (object prop key)\nexport function getKeyForAutomaticLookahead(ruleIdx, dslMethodIdx, occurrence) {\n    return occurrence | dslMethodIdx | ruleIdx;\n}\nconst BITS_START_FOR_ALT_IDX = 32 - BITS_FOR_ALT_IDX;\n//# sourceMappingURL=keys.js.map","import { flatMap, isEmpty } from \"lodash-es\";\nimport { defaultGrammarValidatorErrorProvider } from \"../errors_public.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser/parser.js\";\nimport { validateAmbiguousAlternationAlternatives, validateEmptyOrAlternative, validateNoLeftRecursion, validateSomeNonEmptyLookaheadPath, } from \"./checks.js\";\nimport { buildAlternativesLookAheadFunc, buildLookaheadFuncForOptionalProd, buildLookaheadFuncForOr, buildSingleAlternativeLookaheadFunction, getProdType, } from \"./lookahead.js\";\nexport class LLkLookaheadStrategy {\n    constructor(options) {\n        var _a;\n        this.maxLookahead =\n            (_a = options === null || options === void 0 ? void 0 : options.maxLookahead) !== null && _a !== void 0 ? _a : DEFAULT_PARSER_CONFIG.maxLookahead;\n    }\n    validate(options) {\n        const leftRecursionErrors = this.validateNoLeftRecursion(options.rules);\n        if (isEmpty(leftRecursionErrors)) {\n            const emptyAltErrors = this.validateEmptyOrAlternatives(options.rules);\n            const ambiguousAltsErrors = this.validateAmbiguousAlternationAlternatives(options.rules, this.maxLookahead);\n            const emptyRepetitionErrors = this.validateSomeNonEmptyLookaheadPath(options.rules, this.maxLookahead);\n            const allErrors = [\n                ...leftRecursionErrors,\n                ...emptyAltErrors,\n                ...ambiguousAltsErrors,\n                ...emptyRepetitionErrors,\n            ];\n            return allErrors;\n        }\n        return leftRecursionErrors;\n    }\n    validateNoLeftRecursion(rules) {\n        return flatMap(rules, (currTopRule) => validateNoLeftRecursion(currTopRule, currTopRule, defaultGrammarValidatorErrorProvider));\n    }\n    validateEmptyOrAlternatives(rules) {\n        return flatMap(rules, (currTopRule) => validateEmptyOrAlternative(currTopRule, defaultGrammarValidatorErrorProvider));\n    }\n    validateAmbiguousAlternationAlternatives(rules, maxLookahead) {\n        return flatMap(rules, (currTopRule) => validateAmbiguousAlternationAlternatives(currTopRule, maxLookahead, defaultGrammarValidatorErrorProvider));\n    }\n    validateSomeNonEmptyLookaheadPath(rules, maxLookahead) {\n        return validateSomeNonEmptyLookaheadPath(rules, maxLookahead, defaultGrammarValidatorErrorProvider);\n    }\n    buildLookaheadForAlternation(options) {\n        return buildLookaheadFuncForOr(options.prodOccurrence, options.rule, options.maxLookahead, options.hasPredicates, options.dynamicTokensEnabled, buildAlternativesLookAheadFunc);\n    }\n    buildLookaheadForOptional(options) {\n        return buildLookaheadFuncForOptionalProd(options.prodOccurrence, options.rule, options.maxLookahead, options.dynamicTokensEnabled, getProdType(options.prodType), buildSingleAlternativeLookaheadFunction);\n    }\n}\n//# sourceMappingURL=llk_lookahead.js.map","import { forEach, has } from \"lodash-es\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\nimport { AT_LEAST_ONE_IDX, AT_LEAST_ONE_SEP_IDX, getKeyForAutomaticLookahead, MANY_IDX, MANY_SEP_IDX, OPTION_IDX, OR_IDX, } from \"../../grammar/keys.js\";\nimport { GAstVisitor, getProductionDslName, } from \"@chevrotain/gast\";\nimport { LLkLookaheadStrategy } from \"../../grammar/llk_lookahead.js\";\n/**\n * Trait responsible for the lookahead related utilities and optimizations.\n */\nexport class LooksAhead {\n    initLooksAhead(config) {\n        this.dynamicTokensEnabled = has(config, \"dynamicTokensEnabled\")\n            ? config.dynamicTokensEnabled // assumes end user provides the correct config value/type\n            : DEFAULT_PARSER_CONFIG.dynamicTokensEnabled;\n        this.maxLookahead = has(config, \"maxLookahead\")\n            ? config.maxLookahead // assumes end user provides the correct config value/type\n            : DEFAULT_PARSER_CONFIG.maxLookahead;\n        this.lookaheadStrategy = has(config, \"lookaheadStrategy\")\n            ? config.lookaheadStrategy // assumes end user provides the correct config value/type\n            : new LLkLookaheadStrategy({ maxLookahead: this.maxLookahead });\n        this.lookAheadFuncsCache = new Map();\n    }\n    preComputeLookaheadFunctions(rules) {\n        forEach(rules, (currRule) => {\n            this.TRACE_INIT(`${currRule.name} Rule Lookahead`, () => {\n                const { alternation, repetition, option, repetitionMandatory, repetitionMandatoryWithSeparator, repetitionWithSeparator, } = collectMethods(currRule);\n                forEach(alternation, (currProd) => {\n                    const prodIdx = currProd.idx === 0 ? \"\" : currProd.idx;\n                    this.TRACE_INIT(`${getProductionDslName(currProd)}${prodIdx}`, () => {\n                        const laFunc = this.lookaheadStrategy.buildLookaheadForAlternation({\n                            prodOccurrence: currProd.idx,\n                            rule: currRule,\n                            maxLookahead: currProd.maxLookahead || this.maxLookahead,\n                            hasPredicates: currProd.hasPredicates,\n                            dynamicTokensEnabled: this.dynamicTokensEnabled,\n                        });\n                        const key = getKeyForAutomaticLookahead(this.fullRuleNameToShort[currRule.name], OR_IDX, currProd.idx);\n                        this.setLaFuncCache(key, laFunc);\n                    });\n                });\n                forEach(repetition, (currProd) => {\n                    this.computeLookaheadFunc(currRule, currProd.idx, MANY_IDX, \"Repetition\", currProd.maxLookahead, getProductionDslName(currProd));\n                });\n                forEach(option, (currProd) => {\n                    this.computeLookaheadFunc(currRule, currProd.idx, OPTION_IDX, \"Option\", currProd.maxLookahead, getProductionDslName(currProd));\n                });\n                forEach(repetitionMandatory, (currProd) => {\n                    this.computeLookaheadFunc(currRule, currProd.idx, AT_LEAST_ONE_IDX, \"RepetitionMandatory\", currProd.maxLookahead, getProductionDslName(currProd));\n                });\n                forEach(repetitionMandatoryWithSeparator, (currProd) => {\n                    this.computeLookaheadFunc(currRule, currProd.idx, AT_LEAST_ONE_SEP_IDX, \"RepetitionMandatoryWithSeparator\", currProd.maxLookahead, getProductionDslName(currProd));\n                });\n                forEach(repetitionWithSeparator, (currProd) => {\n                    this.computeLookaheadFunc(currRule, currProd.idx, MANY_SEP_IDX, \"RepetitionWithSeparator\", currProd.maxLookahead, getProductionDslName(currProd));\n                });\n            });\n        });\n    }\n    computeLookaheadFunc(rule, prodOccurrence, prodKey, prodType, prodMaxLookahead, dslMethodName) {\n        this.TRACE_INIT(`${dslMethodName}${prodOccurrence === 0 ? \"\" : prodOccurrence}`, () => {\n            const laFunc = this.lookaheadStrategy.buildLookaheadForOptional({\n                prodOccurrence,\n                rule,\n                maxLookahead: prodMaxLookahead || this.maxLookahead,\n                dynamicTokensEnabled: this.dynamicTokensEnabled,\n                prodType,\n            });\n            const key = getKeyForAutomaticLookahead(this.fullRuleNameToShort[rule.name], prodKey, prodOccurrence);\n            this.setLaFuncCache(key, laFunc);\n        });\n    }\n    // this actually returns a number, but it is always used as a string (object prop key)\n    getKeyForAutomaticLookahead(dslMethodIdx, occurrence) {\n        const currRuleShortName = this.getLastExplicitRuleShortName();\n        return getKeyForAutomaticLookahead(currRuleShortName, dslMethodIdx, occurrence);\n    }\n    getLaFuncFromCache(key) {\n        return this.lookAheadFuncsCache.get(key);\n    }\n    /* istanbul ignore next */\n    setLaFuncCache(key, value) {\n        this.lookAheadFuncsCache.set(key, value);\n    }\n}\nclass DslMethodsCollectorVisitor extends GAstVisitor {\n    constructor() {\n        super(...arguments);\n        this.dslMethods = {\n            option: [],\n            alternation: [],\n            repetition: [],\n            repetitionWithSeparator: [],\n            repetitionMandatory: [],\n            repetitionMandatoryWithSeparator: [],\n        };\n    }\n    reset() {\n        this.dslMethods = {\n            option: [],\n            alternation: [],\n            repetition: [],\n            repetitionWithSeparator: [],\n            repetitionMandatory: [],\n            repetitionMandatoryWithSeparator: [],\n        };\n    }\n    visitOption(option) {\n        this.dslMethods.option.push(option);\n    }\n    visitRepetitionWithSeparator(manySep) {\n        this.dslMethods.repetitionWithSeparator.push(manySep);\n    }\n    visitRepetitionMandatory(atLeastOne) {\n        this.dslMethods.repetitionMandatory.push(atLeastOne);\n    }\n    visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n        this.dslMethods.repetitionMandatoryWithSeparator.push(atLeastOneSep);\n    }\n    visitRepetition(many) {\n        this.dslMethods.repetition.push(many);\n    }\n    visitAlternation(or) {\n        this.dslMethods.alternation.push(or);\n    }\n}\nconst collectorVisitor = new DslMethodsCollectorVisitor();\nexport function collectMethods(rule) {\n    collectorVisitor.reset();\n    rule.accept(collectorVisitor);\n    const dslMethods = collectorVisitor.dslMethods;\n    // avoid uncleaned references\n    collectorVisitor.reset();\n    return dslMethods;\n}\n//# sourceMappingURL=looksahead.js.map","/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationOnlyOffset(currNodeLocation, newLocationInfo) {\n    // First (valid) update for this cst node\n    if (isNaN(currNodeLocation.startOffset) === true) {\n        // assumption1: Token location information is either NaN or a valid number\n        // assumption2: Token location information is fully valid if it exist\n        // (both start/end offsets exist and are numbers).\n        currNodeLocation.startOffset = newLocationInfo.startOffset;\n        currNodeLocation.endOffset = newLocationInfo.endOffset;\n    }\n    // Once the startOffset has been updated with a valid number it should never receive\n    // any farther updates as the Token vector is sorted.\n    // We still have to check this this condition for every new possible location info\n    // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n    else if (currNodeLocation.endOffset < newLocationInfo.endOffset === true) {\n        currNodeLocation.endOffset = newLocationInfo.endOffset;\n    }\n}\n/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationFull(currNodeLocation, newLocationInfo) {\n    // First (valid) update for this cst node\n    if (isNaN(currNodeLocation.startOffset) === true) {\n        // assumption1: Token location information is either NaN or a valid number\n        // assumption2: Token location information is fully valid if it exist\n        // (all start/end props exist and are numbers).\n        currNodeLocation.startOffset = newLocationInfo.startOffset;\n        currNodeLocation.startColumn = newLocationInfo.startColumn;\n        currNodeLocation.startLine = newLocationInfo.startLine;\n        currNodeLocation.endOffset = newLocationInfo.endOffset;\n        currNodeLocation.endColumn = newLocationInfo.endColumn;\n        currNodeLocation.endLine = newLocationInfo.endLine;\n    }\n    // Once the start props has been updated with a valid number it should never receive\n    // any farther updates as the Token vector is sorted.\n    // We still have to check this this condition for every new possible location info\n    // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n    else if (currNodeLocation.endOffset < newLocationInfo.endOffset === true) {\n        currNodeLocation.endOffset = newLocationInfo.endOffset;\n        currNodeLocation.endColumn = newLocationInfo.endColumn;\n        currNodeLocation.endLine = newLocationInfo.endLine;\n    }\n}\nexport function addTerminalToCst(node, token, tokenTypeName) {\n    if (node.children[tokenTypeName] === undefined) {\n        node.children[tokenTypeName] = [token];\n    }\n    else {\n        node.children[tokenTypeName].push(token);\n    }\n}\nexport function addNoneTerminalToCst(node, ruleName, ruleResult) {\n    if (node.children[ruleName] === undefined) {\n        node.children[ruleName] = [ruleResult];\n    }\n    else {\n        node.children[ruleName].push(ruleResult);\n    }\n}\n//# sourceMappingURL=cst.js.map","const NAME = \"name\";\nexport function defineNameProp(obj, nameValue) {\n    Object.defineProperty(obj, NAME, {\n        enumerable: false,\n        configurable: true,\n        writable: false,\n        value: nameValue,\n    });\n}\n//# sourceMappingURL=lang_extensions.js.map","import { compact, filter, forEach, isArray, isEmpty, isFunction, isUndefined, keys, map, } from \"lodash-es\";\nimport { defineNameProp } from \"../../lang/lang_extensions.js\";\nexport function defaultVisit(ctx, param) {\n    const childrenNames = keys(ctx);\n    const childrenNamesLength = childrenNames.length;\n    for (let i = 0; i < childrenNamesLength; i++) {\n        const currChildName = childrenNames[i];\n        const currChildArray = ctx[currChildName];\n        const currChildArrayLength = currChildArray.length;\n        for (let j = 0; j < currChildArrayLength; j++) {\n            const currChild = currChildArray[j];\n            // distinction between Tokens Children and CstNode children\n            if (currChild.tokenTypeIdx === undefined) {\n                this[currChild.name](currChild.children, param);\n            }\n        }\n    }\n    // defaultVisit does not support generic out param\n}\nexport function createBaseSemanticVisitorConstructor(grammarName, ruleNames) {\n    const derivedConstructor = function () { };\n    // can be overwritten according to:\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n    // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n    defineNameProp(derivedConstructor, grammarName + \"BaseSemantics\");\n    const semanticProto = {\n        visit: function (cstNode, param) {\n            // enables writing more concise visitor methods when CstNode has only a single child\n            if (isArray(cstNode)) {\n                // A CST Node's children dictionary can never have empty arrays as values\n                // If a key is defined there will be at least one element in the corresponding value array.\n                cstNode = cstNode[0];\n            }\n            // enables passing optional CstNodes concisely.\n            if (isUndefined(cstNode)) {\n                return undefined;\n            }\n            return this[cstNode.name](cstNode.children, param);\n        },\n        validateVisitor: function () {\n            const semanticDefinitionErrors = validateVisitor(this, ruleNames);\n            if (!isEmpty(semanticDefinitionErrors)) {\n                const errorMessages = map(semanticDefinitionErrors, (currDefError) => currDefError.msg);\n                throw Error(`Errors Detected in CST Visitor <${this.constructor.name}>:\\n\\t` +\n                    `${errorMessages.join(\"\\n\\n\").replace(/\\n/g, \"\\n\\t\")}`);\n            }\n        },\n    };\n    derivedConstructor.prototype = semanticProto;\n    derivedConstructor.prototype.constructor = derivedConstructor;\n    derivedConstructor._RULE_NAMES = ruleNames;\n    return derivedConstructor;\n}\nexport function createBaseVisitorConstructorWithDefaults(grammarName, ruleNames, baseConstructor) {\n    const derivedConstructor = function () { };\n    // can be overwritten according to:\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n    // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n    defineNameProp(derivedConstructor, grammarName + \"BaseSemanticsWithDefaults\");\n    const withDefaultsProto = Object.create(baseConstructor.prototype);\n    forEach(ruleNames, (ruleName) => {\n        withDefaultsProto[ruleName] = defaultVisit;\n    });\n    derivedConstructor.prototype = withDefaultsProto;\n    derivedConstructor.prototype.constructor = derivedConstructor;\n    return derivedConstructor;\n}\nexport var CstVisitorDefinitionError;\n(function (CstVisitorDefinitionError) {\n    CstVisitorDefinitionError[CstVisitorDefinitionError[\"REDUNDANT_METHOD\"] = 0] = \"REDUNDANT_METHOD\";\n    CstVisitorDefinitionError[CstVisitorDefinitionError[\"MISSING_METHOD\"] = 1] = \"MISSING_METHOD\";\n})(CstVisitorDefinitionError || (CstVisitorDefinitionError = {}));\nexport function validateVisitor(visitorInstance, ruleNames) {\n    const missingErrors = validateMissingCstMethods(visitorInstance, ruleNames);\n    return missingErrors;\n}\nexport function validateMissingCstMethods(visitorInstance, ruleNames) {\n    const missingRuleNames = filter(ruleNames, (currRuleName) => {\n        return isFunction(visitorInstance[currRuleName]) === false;\n    });\n    const errors = map(missingRuleNames, (currRuleName) => {\n        return {\n            msg: `Missing visitor method: <${currRuleName}> on ${(visitorInstance.constructor.name)} CST Visitor.`,\n            type: CstVisitorDefinitionError.MISSING_METHOD,\n            methodName: currRuleName,\n        };\n    });\n    return compact(errors);\n}\n//# sourceMappingURL=cst_visitor.js.map","import { addNoneTerminalToCst, addTerminalToCst, setNodeLocationFull, setNodeLocationOnlyOffset, } from \"../../cst/cst.js\";\nimport { has, isUndefined, keys, noop } from \"lodash-es\";\nimport { createBaseSemanticVisitorConstructor, createBaseVisitorConstructorWithDefaults, } from \"../../cst/cst_visitor.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n/**\n * This trait is responsible for the CST building logic.\n */\nexport class TreeBuilder {\n    initTreeBuilder(config) {\n        this.CST_STACK = [];\n        // outputCst is no longer exposed/defined in the pubic API\n        this.outputCst = config.outputCst;\n        this.nodeLocationTracking = has(config, \"nodeLocationTracking\")\n            ? config.nodeLocationTracking // assumes end user provides the correct config value/type\n            : DEFAULT_PARSER_CONFIG.nodeLocationTracking;\n        if (!this.outputCst) {\n            this.cstInvocationStateUpdate = noop;\n            this.cstFinallyStateUpdate = noop;\n            this.cstPostTerminal = noop;\n            this.cstPostNonTerminal = noop;\n            this.cstPostRule = noop;\n        }\n        else {\n            if (/full/i.test(this.nodeLocationTracking)) {\n                if (this.recoveryEnabled) {\n                    this.setNodeLocationFromToken = setNodeLocationFull;\n                    this.setNodeLocationFromNode = setNodeLocationFull;\n                    this.cstPostRule = noop;\n                    this.setInitialNodeLocation = this.setInitialNodeLocationFullRecovery;\n                }\n                else {\n                    this.setNodeLocationFromToken = noop;\n                    this.setNodeLocationFromNode = noop;\n                    this.cstPostRule = this.cstPostRuleFull;\n                    this.setInitialNodeLocation = this.setInitialNodeLocationFullRegular;\n                }\n            }\n            else if (/onlyOffset/i.test(this.nodeLocationTracking)) {\n                if (this.recoveryEnabled) {\n                    this.setNodeLocationFromToken = setNodeLocationOnlyOffset;\n                    this.setNodeLocationFromNode = setNodeLocationOnlyOffset;\n                    this.cstPostRule = noop;\n                    this.setInitialNodeLocation =\n                        this.setInitialNodeLocationOnlyOffsetRecovery;\n                }\n                else {\n                    this.setNodeLocationFromToken = noop;\n                    this.setNodeLocationFromNode = noop;\n                    this.cstPostRule = this.cstPostRuleOnlyOffset;\n                    this.setInitialNodeLocation =\n                        this.setInitialNodeLocationOnlyOffsetRegular;\n                }\n            }\n            else if (/none/i.test(this.nodeLocationTracking)) {\n                this.setNodeLocationFromToken = noop;\n                this.setNodeLocationFromNode = noop;\n                this.cstPostRule = noop;\n                this.setInitialNodeLocation = noop;\n            }\n            else {\n                throw Error(`Invalid <nodeLocationTracking> config option: \"${config.nodeLocationTracking}\"`);\n            }\n        }\n    }\n    setInitialNodeLocationOnlyOffsetRecovery(cstNode) {\n        cstNode.location = {\n            startOffset: NaN,\n            endOffset: NaN,\n        };\n    }\n    setInitialNodeLocationOnlyOffsetRegular(cstNode) {\n        cstNode.location = {\n            // without error recovery the starting Location of a new CstNode is guaranteed\n            // To be the next Token's startOffset (for valid inputs).\n            // For invalid inputs there won't be any CSTOutput so this potential\n            // inaccuracy does not matter\n            startOffset: this.LA(1).startOffset,\n            endOffset: NaN,\n        };\n    }\n    setInitialNodeLocationFullRecovery(cstNode) {\n        cstNode.location = {\n            startOffset: NaN,\n            startLine: NaN,\n            startColumn: NaN,\n            endOffset: NaN,\n            endLine: NaN,\n            endColumn: NaN,\n        };\n    }\n    /**\n       *  @see setInitialNodeLocationOnlyOffsetRegular for explanation why this work\n  \n       * @param cstNode\n       */\n    setInitialNodeLocationFullRegular(cstNode) {\n        const nextToken = this.LA(1);\n        cstNode.location = {\n            startOffset: nextToken.startOffset,\n            startLine: nextToken.startLine,\n            startColumn: nextToken.startColumn,\n            endOffset: NaN,\n            endLine: NaN,\n            endColumn: NaN,\n        };\n    }\n    cstInvocationStateUpdate(fullRuleName) {\n        const cstNode = {\n            name: fullRuleName,\n            children: Object.create(null),\n        };\n        this.setInitialNodeLocation(cstNode);\n        this.CST_STACK.push(cstNode);\n    }\n    cstFinallyStateUpdate() {\n        this.CST_STACK.pop();\n    }\n    cstPostRuleFull(ruleCstNode) {\n        // casts to `required<CstNodeLocation>` are safe because `cstPostRuleFull` should only be invoked when full location is enabled\n        const prevToken = this.LA(0);\n        const loc = ruleCstNode.location;\n        // If this condition is true it means we consumed at least one Token\n        // In this CstNode.\n        if (loc.startOffset <= prevToken.startOffset === true) {\n            loc.endOffset = prevToken.endOffset;\n            loc.endLine = prevToken.endLine;\n            loc.endColumn = prevToken.endColumn;\n        }\n        // \"empty\" CstNode edge case\n        else {\n            loc.startOffset = NaN;\n            loc.startLine = NaN;\n            loc.startColumn = NaN;\n        }\n    }\n    cstPostRuleOnlyOffset(ruleCstNode) {\n        const prevToken = this.LA(0);\n        // `location' is not null because `cstPostRuleOnlyOffset` will only be invoked when location tracking is enabled.\n        const loc = ruleCstNode.location;\n        // If this condition is true it means we consumed at least one Token\n        // In this CstNode.\n        if (loc.startOffset <= prevToken.startOffset === true) {\n            loc.endOffset = prevToken.endOffset;\n        }\n        // \"empty\" CstNode edge case\n        else {\n            loc.startOffset = NaN;\n        }\n    }\n    cstPostTerminal(key, consumedToken) {\n        const rootCst = this.CST_STACK[this.CST_STACK.length - 1];\n        addTerminalToCst(rootCst, consumedToken, key);\n        // This is only used when **both** error recovery and CST Output are enabled.\n        this.setNodeLocationFromToken(rootCst.location, consumedToken);\n    }\n    cstPostNonTerminal(ruleCstResult, ruleName) {\n        const preCstNode = this.CST_STACK[this.CST_STACK.length - 1];\n        addNoneTerminalToCst(preCstNode, ruleName, ruleCstResult);\n        // This is only used when **both** error recovery and CST Output are enabled.\n        this.setNodeLocationFromNode(preCstNode.location, ruleCstResult.location);\n    }\n    getBaseCstVisitorConstructor() {\n        if (isUndefined(this.baseCstVisitorConstructor)) {\n            const newBaseCstVisitorConstructor = createBaseSemanticVisitorConstructor(this.className, keys(this.gastProductionsCache));\n            this.baseCstVisitorConstructor = newBaseCstVisitorConstructor;\n            return newBaseCstVisitorConstructor;\n        }\n        return this.baseCstVisitorConstructor;\n    }\n    getBaseCstVisitorConstructorWithDefaults() {\n        if (isUndefined(this.baseCstVisitorWithDefaultsConstructor)) {\n            const newConstructor = createBaseVisitorConstructorWithDefaults(this.className, keys(this.gastProductionsCache), this.getBaseCstVisitorConstructor());\n            this.baseCstVisitorWithDefaultsConstructor = newConstructor;\n            return newConstructor;\n        }\n        return this.baseCstVisitorWithDefaultsConstructor;\n    }\n    getLastExplicitRuleShortName() {\n        const ruleStack = this.RULE_STACK;\n        return ruleStack[ruleStack.length - 1];\n    }\n    getPreviousExplicitRuleShortName() {\n        const ruleStack = this.RULE_STACK;\n        return ruleStack[ruleStack.length - 2];\n    }\n    getLastExplicitRuleOccurrenceIndex() {\n        const occurrenceStack = this.RULE_OCCURRENCE_STACK;\n        return occurrenceStack[occurrenceStack.length - 1];\n    }\n}\n//# sourceMappingURL=tree_builder.js.map","import { END_OF_FILE } from \"../parser.js\";\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\nexport class LexerAdapter {\n    initLexerAdapter() {\n        this.tokVector = [];\n        this.tokVectorLength = 0;\n        this.currIdx = -1;\n    }\n    set input(newInput) {\n        // @ts-ignore - `this parameter` not supported in setters/getters\n        //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n        if (this.selfAnalysisDone !== true) {\n            throw Error(`Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.`);\n        }\n        // @ts-ignore - `this parameter` not supported in setters/getters\n        //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n        this.reset();\n        this.tokVector = newInput;\n        this.tokVectorLength = newInput.length;\n    }\n    get input() {\n        return this.tokVector;\n    }\n    // skips a token and returns the next token\n    SKIP_TOKEN() {\n        if (this.currIdx <= this.tokVector.length - 2) {\n            this.consumeToken();\n            return this.LA(1);\n        }\n        else {\n            return END_OF_FILE;\n        }\n    }\n    // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n    // or lexers dependent on parser context.\n    LA(howMuch) {\n        const soughtIdx = this.currIdx + howMuch;\n        if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n            return END_OF_FILE;\n        }\n        else {\n            return this.tokVector[soughtIdx];\n        }\n    }\n    consumeToken() {\n        this.currIdx++;\n    }\n    exportLexerState() {\n        return this.currIdx;\n    }\n    importLexerState(newState) {\n        this.currIdx = newState;\n    }\n    resetLexerState() {\n        this.currIdx = -1;\n    }\n    moveToTerminatedState() {\n        this.currIdx = this.tokVector.length - 1;\n    }\n    getLexerPosition() {\n        return this.exportLexerState();\n    }\n}\n//# sourceMappingURL=lexer_adapter.js.map","import { includes, values } from \"lodash-es\";\nimport { isRecognitionException } from \"../../exceptions_public.js\";\nimport { DEFAULT_RULE_CONFIG, ParserDefinitionErrorType } from \"../parser.js\";\nimport { defaultGrammarValidatorErrorProvider } from \"../../errors_public.js\";\nimport { validateRuleIsOverridden } from \"../../grammar/checks.js\";\nimport { serializeGrammar } from \"@chevrotain/gast\";\n/**\n * This trait is responsible for implementing the public API\n * for defining Chevrotain parsers, i.e:\n * - CONSUME\n * - RULE\n * - OPTION\n * - ...\n */\nexport class RecognizerApi {\n    ACTION(impl) {\n        return impl.call(this);\n    }\n    consume(idx, tokType, options) {\n        return this.consumeInternal(tokType, idx, options);\n    }\n    subrule(idx, ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, idx, options);\n    }\n    option(idx, actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, idx);\n    }\n    or(idx, altsOrOpts) {\n        return this.orInternal(altsOrOpts, idx);\n    }\n    many(idx, actionORMethodDef) {\n        return this.manyInternal(idx, actionORMethodDef);\n    }\n    atLeastOne(idx, actionORMethodDef) {\n        return this.atLeastOneInternal(idx, actionORMethodDef);\n    }\n    CONSUME(tokType, options) {\n        return this.consumeInternal(tokType, 0, options);\n    }\n    CONSUME1(tokType, options) {\n        return this.consumeInternal(tokType, 1, options);\n    }\n    CONSUME2(tokType, options) {\n        return this.consumeInternal(tokType, 2, options);\n    }\n    CONSUME3(tokType, options) {\n        return this.consumeInternal(tokType, 3, options);\n    }\n    CONSUME4(tokType, options) {\n        return this.consumeInternal(tokType, 4, options);\n    }\n    CONSUME5(tokType, options) {\n        return this.consumeInternal(tokType, 5, options);\n    }\n    CONSUME6(tokType, options) {\n        return this.consumeInternal(tokType, 6, options);\n    }\n    CONSUME7(tokType, options) {\n        return this.consumeInternal(tokType, 7, options);\n    }\n    CONSUME8(tokType, options) {\n        return this.consumeInternal(tokType, 8, options);\n    }\n    CONSUME9(tokType, options) {\n        return this.consumeInternal(tokType, 9, options);\n    }\n    SUBRULE(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 0, options);\n    }\n    SUBRULE1(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 1, options);\n    }\n    SUBRULE2(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 2, options);\n    }\n    SUBRULE3(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 3, options);\n    }\n    SUBRULE4(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 4, options);\n    }\n    SUBRULE5(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 5, options);\n    }\n    SUBRULE6(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 6, options);\n    }\n    SUBRULE7(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 7, options);\n    }\n    SUBRULE8(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 8, options);\n    }\n    SUBRULE9(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 9, options);\n    }\n    OPTION(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 0);\n    }\n    OPTION1(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 1);\n    }\n    OPTION2(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 2);\n    }\n    OPTION3(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 3);\n    }\n    OPTION4(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 4);\n    }\n    OPTION5(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 5);\n    }\n    OPTION6(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 6);\n    }\n    OPTION7(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 7);\n    }\n    OPTION8(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 8);\n    }\n    OPTION9(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 9);\n    }\n    OR(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 0);\n    }\n    OR1(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 1);\n    }\n    OR2(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 2);\n    }\n    OR3(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 3);\n    }\n    OR4(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 4);\n    }\n    OR5(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 5);\n    }\n    OR6(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 6);\n    }\n    OR7(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 7);\n    }\n    OR8(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 8);\n    }\n    OR9(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 9);\n    }\n    MANY(actionORMethodDef) {\n        this.manyInternal(0, actionORMethodDef);\n    }\n    MANY1(actionORMethodDef) {\n        this.manyInternal(1, actionORMethodDef);\n    }\n    MANY2(actionORMethodDef) {\n        this.manyInternal(2, actionORMethodDef);\n    }\n    MANY3(actionORMethodDef) {\n        this.manyInternal(3, actionORMethodDef);\n    }\n    MANY4(actionORMethodDef) {\n        this.manyInternal(4, actionORMethodDef);\n    }\n    MANY5(actionORMethodDef) {\n        this.manyInternal(5, actionORMethodDef);\n    }\n    MANY6(actionORMethodDef) {\n        this.manyInternal(6, actionORMethodDef);\n    }\n    MANY7(actionORMethodDef) {\n        this.manyInternal(7, actionORMethodDef);\n    }\n    MANY8(actionORMethodDef) {\n        this.manyInternal(8, actionORMethodDef);\n    }\n    MANY9(actionORMethodDef) {\n        this.manyInternal(9, actionORMethodDef);\n    }\n    MANY_SEP(options) {\n        this.manySepFirstInternal(0, options);\n    }\n    MANY_SEP1(options) {\n        this.manySepFirstInternal(1, options);\n    }\n    MANY_SEP2(options) {\n        this.manySepFirstInternal(2, options);\n    }\n    MANY_SEP3(options) {\n        this.manySepFirstInternal(3, options);\n    }\n    MANY_SEP4(options) {\n        this.manySepFirstInternal(4, options);\n    }\n    MANY_SEP5(options) {\n        this.manySepFirstInternal(5, options);\n    }\n    MANY_SEP6(options) {\n        this.manySepFirstInternal(6, options);\n    }\n    MANY_SEP7(options) {\n        this.manySepFirstInternal(7, options);\n    }\n    MANY_SEP8(options) {\n        this.manySepFirstInternal(8, options);\n    }\n    MANY_SEP9(options) {\n        this.manySepFirstInternal(9, options);\n    }\n    AT_LEAST_ONE(actionORMethodDef) {\n        this.atLeastOneInternal(0, actionORMethodDef);\n    }\n    AT_LEAST_ONE1(actionORMethodDef) {\n        return this.atLeastOneInternal(1, actionORMethodDef);\n    }\n    AT_LEAST_ONE2(actionORMethodDef) {\n        this.atLeastOneInternal(2, actionORMethodDef);\n    }\n    AT_LEAST_ONE3(actionORMethodDef) {\n        this.atLeastOneInternal(3, actionORMethodDef);\n    }\n    AT_LEAST_ONE4(actionORMethodDef) {\n        this.atLeastOneInternal(4, actionORMethodDef);\n    }\n    AT_LEAST_ONE5(actionORMethodDef) {\n        this.atLeastOneInternal(5, actionORMethodDef);\n    }\n    AT_LEAST_ONE6(actionORMethodDef) {\n        this.atLeastOneInternal(6, actionORMethodDef);\n    }\n    AT_LEAST_ONE7(actionORMethodDef) {\n        this.atLeastOneInternal(7, actionORMethodDef);\n    }\n    AT_LEAST_ONE8(actionORMethodDef) {\n        this.atLeastOneInternal(8, actionORMethodDef);\n    }\n    AT_LEAST_ONE9(actionORMethodDef) {\n        this.atLeastOneInternal(9, actionORMethodDef);\n    }\n    AT_LEAST_ONE_SEP(options) {\n        this.atLeastOneSepFirstInternal(0, options);\n    }\n    AT_LEAST_ONE_SEP1(options) {\n        this.atLeastOneSepFirstInternal(1, options);\n    }\n    AT_LEAST_ONE_SEP2(options) {\n        this.atLeastOneSepFirstInternal(2, options);\n    }\n    AT_LEAST_ONE_SEP3(options) {\n        this.atLeastOneSepFirstInternal(3, options);\n    }\n    AT_LEAST_ONE_SEP4(options) {\n        this.atLeastOneSepFirstInternal(4, options);\n    }\n    AT_LEAST_ONE_SEP5(options) {\n        this.atLeastOneSepFirstInternal(5, options);\n    }\n    AT_LEAST_ONE_SEP6(options) {\n        this.atLeastOneSepFirstInternal(6, options);\n    }\n    AT_LEAST_ONE_SEP7(options) {\n        this.atLeastOneSepFirstInternal(7, options);\n    }\n    AT_LEAST_ONE_SEP8(options) {\n        this.atLeastOneSepFirstInternal(8, options);\n    }\n    AT_LEAST_ONE_SEP9(options) {\n        this.atLeastOneSepFirstInternal(9, options);\n    }\n    RULE(name, implementation, config = DEFAULT_RULE_CONFIG) {\n        if (includes(this.definedRulesNames, name)) {\n            const errMsg = defaultGrammarValidatorErrorProvider.buildDuplicateRuleNameError({\n                topLevelRule: name,\n                grammarName: this.className,\n            });\n            const error = {\n                message: errMsg,\n                type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n                ruleName: name,\n            };\n            this.definitionErrors.push(error);\n        }\n        this.definedRulesNames.push(name);\n        const ruleImplementation = this.defineRule(name, implementation, config);\n        this[name] = ruleImplementation;\n        return ruleImplementation;\n    }\n    OVERRIDE_RULE(name, impl, config = DEFAULT_RULE_CONFIG) {\n        const ruleErrors = validateRuleIsOverridden(name, this.definedRulesNames, this.className);\n        this.definitionErrors = this.definitionErrors.concat(ruleErrors);\n        const ruleImplementation = this.defineRule(name, impl, config);\n        this[name] = ruleImplementation;\n        return ruleImplementation;\n    }\n    BACKTRACK(grammarRule, args) {\n        return function () {\n            // save org state\n            this.isBackTrackingStack.push(1);\n            const orgState = this.saveRecogState();\n            try {\n                grammarRule.apply(this, args);\n                // if no exception was thrown we have succeed parsing the rule.\n                return true;\n            }\n            catch (e) {\n                if (isRecognitionException(e)) {\n                    return false;\n                }\n                else {\n                    throw e;\n                }\n            }\n            finally {\n                this.reloadRecogState(orgState);\n                this.isBackTrackingStack.pop();\n            }\n        };\n    }\n    // GAST export APIs\n    getGAstProductions() {\n        return this.gastProductionsCache;\n    }\n    getSerializedGastProductions() {\n        return serializeGrammar(values(this.gastProductionsCache));\n    }\n}\n//# sourceMappingURL=recognizer_api.js.map","import { clone, every, flatten, has, isArray, isEmpty, isObject, reduce, uniq, values, } from \"lodash-es\";\nimport { AT_LEAST_ONE_IDX, AT_LEAST_ONE_SEP_IDX, BITS_FOR_METHOD_TYPE, BITS_FOR_OCCURRENCE_IDX, MANY_IDX, MANY_SEP_IDX, OPTION_IDX, OR_IDX, } from \"../../grammar/keys.js\";\nimport { isRecognitionException, MismatchedTokenException, NotAllInputParsedException, } from \"../../exceptions_public.js\";\nimport { PROD_TYPE } from \"../../grammar/lookahead.js\";\nimport { NextTerminalAfterAtLeastOneSepWalker, NextTerminalAfterAtLeastOneWalker, NextTerminalAfterManySepWalker, NextTerminalAfterManyWalker, } from \"../../grammar/interpreter.js\";\nimport { DEFAULT_RULE_CONFIG } from \"../parser.js\";\nimport { IN_RULE_RECOVERY_EXCEPTION } from \"./recoverable.js\";\nimport { EOF } from \"../../../scan/tokens_public.js\";\nimport { augmentTokenTypes, isTokenType, tokenStructuredMatcher, tokenStructuredMatcherNoCategories, } from \"../../../scan/tokens.js\";\n/**\n * This trait is responsible for the runtime parsing engine\n * Used by the official API (recognizer_api.ts)\n */\nexport class RecognizerEngine {\n    initRecognizerEngine(tokenVocabulary, config) {\n        this.className = this.constructor.name;\n        // TODO: would using an ES6 Map or plain object be faster (CST building scenario)\n        this.shortRuleNameToFull = {};\n        this.fullRuleNameToShort = {};\n        this.ruleShortNameIdx = 256;\n        this.tokenMatcher = tokenStructuredMatcherNoCategories;\n        this.subruleIdx = 0;\n        this.definedRulesNames = [];\n        this.tokensMap = {};\n        this.isBackTrackingStack = [];\n        this.RULE_STACK = [];\n        this.RULE_OCCURRENCE_STACK = [];\n        this.gastProductionsCache = {};\n        if (has(config, \"serializedGrammar\")) {\n            throw Error(\"The Parser's configuration can no longer contain a <serializedGrammar> property.\\n\" +\n                \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_6-0-0\\n\" +\n                \"\\tFor Further details.\");\n        }\n        if (isArray(tokenVocabulary)) {\n            // This only checks for Token vocabularies provided as arrays.\n            // That is good enough because the main objective is to detect users of pre-V4.0 APIs\n            // rather than all edge cases of empty Token vocabularies.\n            if (isEmpty(tokenVocabulary)) {\n                throw Error(\"A Token Vocabulary cannot be empty.\\n\" +\n                    \"\\tNote that the first argument for the parser constructor\\n\" +\n                    \"\\tis no longer a Token vector (since v4.0).\");\n            }\n            if (typeof tokenVocabulary[0].startOffset === \"number\") {\n                throw Error(\"The Parser constructor no longer accepts a token vector as the first argument.\\n\" +\n                    \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_4-0-0\\n\" +\n                    \"\\tFor Further details.\");\n            }\n        }\n        if (isArray(tokenVocabulary)) {\n            this.tokensMap = reduce(tokenVocabulary, (acc, tokType) => {\n                acc[tokType.name] = tokType;\n                return acc;\n            }, {});\n        }\n        else if (has(tokenVocabulary, \"modes\") &&\n            every(flatten(values(tokenVocabulary.modes)), isTokenType)) {\n            const allTokenTypes = flatten(values(tokenVocabulary.modes));\n            const uniqueTokens = uniq(allTokenTypes);\n            this.tokensMap = reduce(uniqueTokens, (acc, tokType) => {\n                acc[tokType.name] = tokType;\n                return acc;\n            }, {});\n        }\n        else if (isObject(tokenVocabulary)) {\n            this.tokensMap = clone(tokenVocabulary);\n        }\n        else {\n            throw new Error(\"<tokensDictionary> argument must be An Array of Token constructors,\" +\n                \" A dictionary of Token constructors or an IMultiModeLexerDefinition\");\n        }\n        // always add EOF to the tokenNames -> constructors map. it is useful to assure all the input has been\n        // parsed with a clear error message (\"expecting EOF but found ...\")\n        this.tokensMap[\"EOF\"] = EOF;\n        const allTokenTypes = has(tokenVocabulary, \"modes\")\n            ? flatten(values(tokenVocabulary.modes))\n            : values(tokenVocabulary);\n        const noTokenCategoriesUsed = every(allTokenTypes, (tokenConstructor) => isEmpty(tokenConstructor.categoryMatches));\n        this.tokenMatcher = noTokenCategoriesUsed\n            ? tokenStructuredMatcherNoCategories\n            : tokenStructuredMatcher;\n        // Because ES2015+ syntax should be supported for creating Token classes\n        // We cannot assume that the Token classes were created using the \"extendToken\" utilities\n        // Therefore we must augment the Token classes both on Lexer initialization and on Parser initialization\n        augmentTokenTypes(values(this.tokensMap));\n    }\n    defineRule(ruleName, impl, config) {\n        if (this.selfAnalysisDone) {\n            throw Error(`Grammar rule <${ruleName}> may not be defined after the 'performSelfAnalysis' method has been called'\\n` +\n                `Make sure that all grammar rule definitions are done before 'performSelfAnalysis' is called.`);\n        }\n        const resyncEnabled = has(config, \"resyncEnabled\")\n            ? config.resyncEnabled // assumes end user provides the correct config value/type\n            : DEFAULT_RULE_CONFIG.resyncEnabled;\n        const recoveryValueFunc = has(config, \"recoveryValueFunc\")\n            ? config.recoveryValueFunc // assumes end user provides the correct config value/type\n            : DEFAULT_RULE_CONFIG.recoveryValueFunc;\n        // performance optimization: Use small integers as keys for the longer human readable \"full\" rule names.\n        // this greatly improves Map access time (as much as 8% for some performance benchmarks).\n        const shortName = this.ruleShortNameIdx << (BITS_FOR_METHOD_TYPE + BITS_FOR_OCCURRENCE_IDX);\n        this.ruleShortNameIdx++;\n        this.shortRuleNameToFull[shortName] = ruleName;\n        this.fullRuleNameToShort[ruleName] = shortName;\n        let invokeRuleWithTry;\n        // Micro optimization, only check the condition **once** on rule definition\n        // instead of **every single** rule invocation.\n        if (this.outputCst === true) {\n            invokeRuleWithTry = function invokeRuleWithTry(...args) {\n                try {\n                    this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n                    impl.apply(this, args);\n                    const cst = this.CST_STACK[this.CST_STACK.length - 1];\n                    this.cstPostRule(cst);\n                    return cst;\n                }\n                catch (e) {\n                    return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc);\n                }\n                finally {\n                    this.ruleFinallyStateUpdate();\n                }\n            };\n        }\n        else {\n            invokeRuleWithTry = function invokeRuleWithTryCst(...args) {\n                try {\n                    this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n                    return impl.apply(this, args);\n                }\n                catch (e) {\n                    return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc);\n                }\n                finally {\n                    this.ruleFinallyStateUpdate();\n                }\n            };\n        }\n        const wrappedGrammarRule = Object.assign(invokeRuleWithTry, { ruleName, originalGrammarAction: impl });\n        return wrappedGrammarRule;\n    }\n    invokeRuleCatch(e, resyncEnabledConfig, recoveryValueFunc) {\n        const isFirstInvokedRule = this.RULE_STACK.length === 1;\n        // note the reSync is always enabled for the first rule invocation, because we must always be able to\n        // reSync with EOF and just output some INVALID ParseTree\n        // during backtracking reSync recovery is disabled, otherwise we can't be certain the backtracking\n        // path is really the most valid one\n        const reSyncEnabled = resyncEnabledConfig && !this.isBackTracking() && this.recoveryEnabled;\n        if (isRecognitionException(e)) {\n            const recogError = e;\n            if (reSyncEnabled) {\n                const reSyncTokType = this.findReSyncTokenType();\n                if (this.isInCurrentRuleReSyncSet(reSyncTokType)) {\n                    recogError.resyncedTokens = this.reSyncTo(reSyncTokType);\n                    if (this.outputCst) {\n                        const partialCstResult = this.CST_STACK[this.CST_STACK.length - 1];\n                        partialCstResult.recoveredNode = true;\n                        return partialCstResult;\n                    }\n                    else {\n                        return recoveryValueFunc(e);\n                    }\n                }\n                else {\n                    if (this.outputCst) {\n                        const partialCstResult = this.CST_STACK[this.CST_STACK.length - 1];\n                        partialCstResult.recoveredNode = true;\n                        recogError.partialCstResult = partialCstResult;\n                    }\n                    // to be handled Further up the call stack\n                    throw recogError;\n                }\n            }\n            else if (isFirstInvokedRule) {\n                // otherwise a Redundant input error will be created as well and we cannot guarantee that this is indeed the case\n                this.moveToTerminatedState();\n                // the parser should never throw one of its own errors outside its flow.\n                // even if error recovery is disabled\n                return recoveryValueFunc(e);\n            }\n            else {\n                // to be recovered Further up the call stack\n                throw recogError;\n            }\n        }\n        else {\n            // some other Error type which we don't know how to handle (for example a built in JavaScript Error)\n            throw e;\n        }\n    }\n    // Implementation of parsing DSL\n    optionInternal(actionORMethodDef, occurrence) {\n        const key = this.getKeyForAutomaticLookahead(OPTION_IDX, occurrence);\n        return this.optionInternalLogic(actionORMethodDef, occurrence, key);\n    }\n    optionInternalLogic(actionORMethodDef, occurrence, key) {\n        let lookAheadFunc = this.getLaFuncFromCache(key);\n        let action;\n        if (typeof actionORMethodDef !== \"function\") {\n            action = actionORMethodDef.DEF;\n            const predicate = actionORMethodDef.GATE;\n            // predicate present\n            if (predicate !== undefined) {\n                const orgLookaheadFunction = lookAheadFunc;\n                lookAheadFunc = () => {\n                    return predicate.call(this) && orgLookaheadFunction.call(this);\n                };\n            }\n        }\n        else {\n            action = actionORMethodDef;\n        }\n        if (lookAheadFunc.call(this) === true) {\n            return action.call(this);\n        }\n        return undefined;\n    }\n    atLeastOneInternal(prodOccurrence, actionORMethodDef) {\n        const laKey = this.getKeyForAutomaticLookahead(AT_LEAST_ONE_IDX, prodOccurrence);\n        return this.atLeastOneInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n    }\n    atLeastOneInternalLogic(prodOccurrence, actionORMethodDef, key) {\n        let lookAheadFunc = this.getLaFuncFromCache(key);\n        let action;\n        if (typeof actionORMethodDef !== \"function\") {\n            action = actionORMethodDef.DEF;\n            const predicate = actionORMethodDef.GATE;\n            // predicate present\n            if (predicate !== undefined) {\n                const orgLookaheadFunction = lookAheadFunc;\n                lookAheadFunc = () => {\n                    return predicate.call(this) && orgLookaheadFunction.call(this);\n                };\n            }\n        }\n        else {\n            action = actionORMethodDef;\n        }\n        if (lookAheadFunc.call(this) === true) {\n            let notStuck = this.doSingleRepetition(action);\n            while (lookAheadFunc.call(this) === true &&\n                notStuck === true) {\n                notStuck = this.doSingleRepetition(action);\n            }\n        }\n        else {\n            throw this.raiseEarlyExitException(prodOccurrence, PROD_TYPE.REPETITION_MANDATORY, actionORMethodDef.ERR_MSG);\n        }\n        // note that while it may seem that this can cause an error because by using a recursive call to\n        // AT_LEAST_ONE we change the grammar to AT_LEAST_TWO, AT_LEAST_THREE ... , the possible recursive call\n        // from the tryInRepetitionRecovery(...) will only happen IFF there really are TWO/THREE/.... items.\n        // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n        this.attemptInRepetitionRecovery(this.atLeastOneInternal, [prodOccurrence, actionORMethodDef], lookAheadFunc, AT_LEAST_ONE_IDX, prodOccurrence, NextTerminalAfterAtLeastOneWalker);\n    }\n    atLeastOneSepFirstInternal(prodOccurrence, options) {\n        const laKey = this.getKeyForAutomaticLookahead(AT_LEAST_ONE_SEP_IDX, prodOccurrence);\n        this.atLeastOneSepFirstInternalLogic(prodOccurrence, options, laKey);\n    }\n    atLeastOneSepFirstInternalLogic(prodOccurrence, options, key) {\n        const action = options.DEF;\n        const separator = options.SEP;\n        const firstIterationLookaheadFunc = this.getLaFuncFromCache(key);\n        // 1st iteration\n        if (firstIterationLookaheadFunc.call(this) === true) {\n            action.call(this);\n            //  TODO: Optimization can move this function construction into \"attemptInRepetitionRecovery\"\n            //  because it is only needed in error recovery scenarios.\n            const separatorLookAheadFunc = () => {\n                return this.tokenMatcher(this.LA(1), separator);\n            };\n            // 2nd..nth iterations\n            while (this.tokenMatcher(this.LA(1), separator) === true) {\n                // note that this CONSUME will never enter recovery because\n                // the separatorLookAheadFunc checks that the separator really does exist.\n                this.CONSUME(separator);\n                // No need for checking infinite loop here due to consuming the separator.\n                action.call(this);\n            }\n            // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n            this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [\n                prodOccurrence,\n                separator,\n                separatorLookAheadFunc,\n                action,\n                NextTerminalAfterAtLeastOneSepWalker,\n            ], separatorLookAheadFunc, AT_LEAST_ONE_SEP_IDX, prodOccurrence, NextTerminalAfterAtLeastOneSepWalker);\n        }\n        else {\n            throw this.raiseEarlyExitException(prodOccurrence, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR, options.ERR_MSG);\n        }\n    }\n    manyInternal(prodOccurrence, actionORMethodDef) {\n        const laKey = this.getKeyForAutomaticLookahead(MANY_IDX, prodOccurrence);\n        return this.manyInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n    }\n    manyInternalLogic(prodOccurrence, actionORMethodDef, key) {\n        let lookaheadFunction = this.getLaFuncFromCache(key);\n        let action;\n        if (typeof actionORMethodDef !== \"function\") {\n            action = actionORMethodDef.DEF;\n            const predicate = actionORMethodDef.GATE;\n            // predicate present\n            if (predicate !== undefined) {\n                const orgLookaheadFunction = lookaheadFunction;\n                lookaheadFunction = () => {\n                    return predicate.call(this) && orgLookaheadFunction.call(this);\n                };\n            }\n        }\n        else {\n            action = actionORMethodDef;\n        }\n        let notStuck = true;\n        while (lookaheadFunction.call(this) === true && notStuck === true) {\n            notStuck = this.doSingleRepetition(action);\n        }\n        // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n        this.attemptInRepetitionRecovery(this.manyInternal, [prodOccurrence, actionORMethodDef], lookaheadFunction, MANY_IDX, prodOccurrence, NextTerminalAfterManyWalker, \n        // The notStuck parameter is only relevant when \"attemptInRepetitionRecovery\"\n        // is invoked from manyInternal, in the MANY_SEP case and AT_LEAST_ONE[_SEP]\n        // An infinite loop cannot occur as:\n        // - Either the lookahead is guaranteed to consume something (Single Token Separator)\n        // - AT_LEAST_ONE by definition is guaranteed to consume something (or error out).\n        notStuck);\n    }\n    manySepFirstInternal(prodOccurrence, options) {\n        const laKey = this.getKeyForAutomaticLookahead(MANY_SEP_IDX, prodOccurrence);\n        this.manySepFirstInternalLogic(prodOccurrence, options, laKey);\n    }\n    manySepFirstInternalLogic(prodOccurrence, options, key) {\n        const action = options.DEF;\n        const separator = options.SEP;\n        const firstIterationLaFunc = this.getLaFuncFromCache(key);\n        // 1st iteration\n        if (firstIterationLaFunc.call(this) === true) {\n            action.call(this);\n            const separatorLookAheadFunc = () => {\n                return this.tokenMatcher(this.LA(1), separator);\n            };\n            // 2nd..nth iterations\n            while (this.tokenMatcher(this.LA(1), separator) === true) {\n                // note that this CONSUME will never enter recovery because\n                // the separatorLookAheadFunc checks that the separator really does exist.\n                this.CONSUME(separator);\n                // No need for checking infinite loop here due to consuming the separator.\n                action.call(this);\n            }\n            // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n            this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [\n                prodOccurrence,\n                separator,\n                separatorLookAheadFunc,\n                action,\n                NextTerminalAfterManySepWalker,\n            ], separatorLookAheadFunc, MANY_SEP_IDX, prodOccurrence, NextTerminalAfterManySepWalker);\n        }\n    }\n    repetitionSepSecondInternal(prodOccurrence, separator, separatorLookAheadFunc, action, nextTerminalAfterWalker) {\n        while (separatorLookAheadFunc()) {\n            // note that this CONSUME will never enter recovery because\n            // the separatorLookAheadFunc checks that the separator really does exist.\n            this.CONSUME(separator);\n            action.call(this);\n        }\n        // we can only arrive to this function after an error\n        // has occurred (hence the name 'second') so the following\n        // IF will always be entered, its possible to remove it...\n        // however it is kept to avoid confusion and be consistent.\n        // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n        /* istanbul ignore else */\n        this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [\n            prodOccurrence,\n            separator,\n            separatorLookAheadFunc,\n            action,\n            nextTerminalAfterWalker,\n        ], separatorLookAheadFunc, AT_LEAST_ONE_SEP_IDX, prodOccurrence, nextTerminalAfterWalker);\n    }\n    doSingleRepetition(action) {\n        const beforeIteration = this.getLexerPosition();\n        action.call(this);\n        const afterIteration = this.getLexerPosition();\n        // This boolean will indicate if this repetition progressed\n        // or if we are \"stuck\" (potential infinite loop in the repetition).\n        return afterIteration > beforeIteration;\n    }\n    orInternal(altsOrOpts, occurrence) {\n        const laKey = this.getKeyForAutomaticLookahead(OR_IDX, occurrence);\n        const alts = isArray(altsOrOpts) ? altsOrOpts : altsOrOpts.DEF;\n        const laFunc = this.getLaFuncFromCache(laKey);\n        const altIdxToTake = laFunc.call(this, alts);\n        if (altIdxToTake !== undefined) {\n            const chosenAlternative = alts[altIdxToTake];\n            return chosenAlternative.ALT.call(this);\n        }\n        this.raiseNoAltException(occurrence, altsOrOpts.ERR_MSG);\n    }\n    ruleFinallyStateUpdate() {\n        this.RULE_STACK.pop();\n        this.RULE_OCCURRENCE_STACK.pop();\n        // NOOP when cst is disabled\n        this.cstFinallyStateUpdate();\n        if (this.RULE_STACK.length === 0 && this.isAtEndOfInput() === false) {\n            const firstRedundantTok = this.LA(1);\n            const errMsg = this.errorMessageProvider.buildNotAllInputParsedMessage({\n                firstRedundant: firstRedundantTok,\n                ruleName: this.getCurrRuleFullName(),\n            });\n            this.SAVE_ERROR(new NotAllInputParsedException(errMsg, firstRedundantTok));\n        }\n    }\n    subruleInternal(ruleToCall, idx, options) {\n        let ruleResult;\n        try {\n            const args = options !== undefined ? options.ARGS : undefined;\n            this.subruleIdx = idx;\n            ruleResult = ruleToCall.apply(this, args);\n            this.cstPostNonTerminal(ruleResult, options !== undefined && options.LABEL !== undefined\n                ? options.LABEL\n                : ruleToCall.ruleName);\n            return ruleResult;\n        }\n        catch (e) {\n            throw this.subruleInternalError(e, options, ruleToCall.ruleName);\n        }\n    }\n    subruleInternalError(e, options, ruleName) {\n        if (isRecognitionException(e) && e.partialCstResult !== undefined) {\n            this.cstPostNonTerminal(e.partialCstResult, options !== undefined && options.LABEL !== undefined\n                ? options.LABEL\n                : ruleName);\n            delete e.partialCstResult;\n        }\n        throw e;\n    }\n    consumeInternal(tokType, idx, options) {\n        let consumedToken;\n        try {\n            const nextToken = this.LA(1);\n            if (this.tokenMatcher(nextToken, tokType) === true) {\n                this.consumeToken();\n                consumedToken = nextToken;\n            }\n            else {\n                this.consumeInternalError(tokType, nextToken, options);\n            }\n        }\n        catch (eFromConsumption) {\n            consumedToken = this.consumeInternalRecovery(tokType, idx, eFromConsumption);\n        }\n        this.cstPostTerminal(options !== undefined && options.LABEL !== undefined\n            ? options.LABEL\n            : tokType.name, consumedToken);\n        return consumedToken;\n    }\n    consumeInternalError(tokType, nextToken, options) {\n        let msg;\n        const previousToken = this.LA(0);\n        if (options !== undefined && options.ERR_MSG) {\n            msg = options.ERR_MSG;\n        }\n        else {\n            msg = this.errorMessageProvider.buildMismatchTokenMessage({\n                expected: tokType,\n                actual: nextToken,\n                previous: previousToken,\n                ruleName: this.getCurrRuleFullName(),\n            });\n        }\n        throw this.SAVE_ERROR(new MismatchedTokenException(msg, nextToken, previousToken));\n    }\n    consumeInternalRecovery(tokType, idx, eFromConsumption) {\n        // no recovery allowed during backtracking, otherwise backtracking may recover invalid syntax and accept it\n        // but the original syntax could have been parsed successfully without any backtracking + recovery\n        if (this.recoveryEnabled &&\n            // TODO: more robust checking of the exception type. Perhaps Typescript extending expressions?\n            eFromConsumption.name === \"MismatchedTokenException\" &&\n            !this.isBackTracking()) {\n            const follows = this.getFollowsForInRuleRecovery(tokType, idx);\n            try {\n                return this.tryInRuleRecovery(tokType, follows);\n            }\n            catch (eFromInRuleRecovery) {\n                if (eFromInRuleRecovery.name === IN_RULE_RECOVERY_EXCEPTION) {\n                    // failed in RuleRecovery.\n                    // throw the original error in order to trigger reSync error recovery\n                    throw eFromConsumption;\n                }\n                else {\n                    throw eFromInRuleRecovery;\n                }\n            }\n        }\n        else {\n            throw eFromConsumption;\n        }\n    }\n    saveRecogState() {\n        // errors is a getter which will clone the errors array\n        const savedErrors = this.errors;\n        const savedRuleStack = clone(this.RULE_STACK);\n        return {\n            errors: savedErrors,\n            lexerState: this.exportLexerState(),\n            RULE_STACK: savedRuleStack,\n            CST_STACK: this.CST_STACK,\n        };\n    }\n    reloadRecogState(newState) {\n        this.errors = newState.errors;\n        this.importLexerState(newState.lexerState);\n        this.RULE_STACK = newState.RULE_STACK;\n    }\n    ruleInvocationStateUpdate(shortName, fullName, idxInCallingRule) {\n        this.RULE_OCCURRENCE_STACK.push(idxInCallingRule);\n        this.RULE_STACK.push(shortName);\n        // NOOP when cst is disabled\n        this.cstInvocationStateUpdate(fullName);\n    }\n    isBackTracking() {\n        return this.isBackTrackingStack.length !== 0;\n    }\n    getCurrRuleFullName() {\n        const shortName = this.getLastExplicitRuleShortName();\n        return this.shortRuleNameToFull[shortName];\n    }\n    shortRuleNameToFullName(shortName) {\n        return this.shortRuleNameToFull[shortName];\n    }\n    isAtEndOfInput() {\n        return this.tokenMatcher(this.LA(1), EOF);\n    }\n    reset() {\n        this.resetLexerState();\n        this.subruleIdx = 0;\n        this.isBackTrackingStack = [];\n        this.errors = [];\n        this.RULE_STACK = [];\n        // TODO: extract a specific reset for TreeBuilder trait\n        this.CST_STACK = [];\n        this.RULE_OCCURRENCE_STACK = [];\n    }\n}\n//# sourceMappingURL=recognizer_engine.js.map","import { EarlyExitException, isRecognitionException, NoViableAltException, } from \"../../exceptions_public.js\";\nimport { clone, has } from \"lodash-es\";\nimport { getLookaheadPathsForOptionalProd, getLookaheadPathsForOr, } from \"../../grammar/lookahead.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class ErrorHandler {\n    initErrorHandler(config) {\n        this._errors = [];\n        this.errorMessageProvider = has(config, \"errorMessageProvider\")\n            ? config.errorMessageProvider // assumes end user provides the correct config value/type\n            : DEFAULT_PARSER_CONFIG.errorMessageProvider;\n    }\n    SAVE_ERROR(error) {\n        if (isRecognitionException(error)) {\n            error.context = {\n                ruleStack: this.getHumanReadableRuleStack(),\n                ruleOccurrenceStack: clone(this.RULE_OCCURRENCE_STACK),\n            };\n            this._errors.push(error);\n            return error;\n        }\n        else {\n            throw Error(\"Trying to save an Error which is not a RecognitionException\");\n        }\n    }\n    get errors() {\n        return clone(this._errors);\n    }\n    set errors(newErrors) {\n        this._errors = newErrors;\n    }\n    // TODO: consider caching the error message computed information\n    raiseEarlyExitException(occurrence, prodType, userDefinedErrMsg) {\n        const ruleName = this.getCurrRuleFullName();\n        const ruleGrammar = this.getGAstProductions()[ruleName];\n        const lookAheadPathsPerAlternative = getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, this.maxLookahead);\n        const insideProdPaths = lookAheadPathsPerAlternative[0];\n        const actualTokens = [];\n        for (let i = 1; i <= this.maxLookahead; i++) {\n            actualTokens.push(this.LA(i));\n        }\n        const msg = this.errorMessageProvider.buildEarlyExitMessage({\n            expectedIterationPaths: insideProdPaths,\n            actual: actualTokens,\n            previous: this.LA(0),\n            customUserDescription: userDefinedErrMsg,\n            ruleName: ruleName,\n        });\n        throw this.SAVE_ERROR(new EarlyExitException(msg, this.LA(1), this.LA(0)));\n    }\n    // TODO: consider caching the error message computed information\n    raiseNoAltException(occurrence, errMsgTypes) {\n        const ruleName = this.getCurrRuleFullName();\n        const ruleGrammar = this.getGAstProductions()[ruleName];\n        // TODO: getLookaheadPathsForOr can be slow for large enough maxLookahead and certain grammars, consider caching ?\n        const lookAheadPathsPerAlternative = getLookaheadPathsForOr(occurrence, ruleGrammar, this.maxLookahead);\n        const actualTokens = [];\n        for (let i = 1; i <= this.maxLookahead; i++) {\n            actualTokens.push(this.LA(i));\n        }\n        const previousToken = this.LA(0);\n        const errMsg = this.errorMessageProvider.buildNoViableAltMessage({\n            expectedPathsPerAlt: lookAheadPathsPerAlternative,\n            actual: actualTokens,\n            previous: previousToken,\n            customUserDescription: errMsgTypes,\n            ruleName: this.getCurrRuleFullName(),\n        });\n        throw this.SAVE_ERROR(new NoViableAltException(errMsg, this.LA(1), previousToken));\n    }\n}\n//# sourceMappingURL=error_handler.js.map","import { NextAfterTokenWalker, nextPossibleTokensAfter, } from \"../../grammar/interpreter.js\";\nimport { first, isUndefined } from \"lodash-es\";\nexport class ContentAssist {\n    initContentAssist() { }\n    computeContentAssist(startRuleName, precedingInput) {\n        const startRuleGast = this.gastProductionsCache[startRuleName];\n        if (isUndefined(startRuleGast)) {\n            throw Error(`Rule ->${startRuleName}<- does not exist in this grammar.`);\n        }\n        return nextPossibleTokensAfter([startRuleGast], precedingInput, this.tokenMatcher, this.maxLookahead);\n    }\n    // TODO: should this be a member method or a utility? it does not have any state or usage of 'this'...\n    // TODO: should this be more explicitly part of the public API?\n    getNextPossibleTokenTypes(grammarPath) {\n        const topRuleName = first(grammarPath.ruleStack);\n        const gastProductions = this.getGAstProductions();\n        const topProduction = gastProductions[topRuleName];\n        const nextPossibleTokenTypes = new NextAfterTokenWalker(topProduction, grammarPath).startWalking();\n        return nextPossibleTokenTypes;\n    }\n}\n//# sourceMappingURL=context_assist.js.map","import { forEach, has, isArray, isFunction, last as peek, some, } from \"lodash-es\";\nimport { Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Rule, Terminal, } from \"@chevrotain/gast\";\nimport { Lexer } from \"../../../scan/lexer_public.js\";\nimport { augmentTokenTypes, hasShortKeyProperty, } from \"../../../scan/tokens.js\";\nimport { createToken, createTokenInstance, } from \"../../../scan/tokens_public.js\";\nimport { END_OF_FILE } from \"../parser.js\";\nimport { BITS_FOR_OCCURRENCE_IDX } from \"../../grammar/keys.js\";\nconst RECORDING_NULL_OBJECT = {\n    description: \"This Object indicates the Parser is during Recording Phase\",\n};\nObject.freeze(RECORDING_NULL_OBJECT);\nconst HANDLE_SEPARATOR = true;\nconst MAX_METHOD_IDX = Math.pow(2, BITS_FOR_OCCURRENCE_IDX) - 1;\nconst RFT = createToken({ name: \"RECORDING_PHASE_TOKEN\", pattern: Lexer.NA });\naugmentTokenTypes([RFT]);\nconst RECORDING_PHASE_TOKEN = createTokenInstance(RFT, \"This IToken indicates the Parser is in Recording Phase\\n\\t\" +\n    \"\" +\n    \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\", \n// Using \"-1\" instead of NaN (as in EOF) because an actual number is less likely to\n// cause errors if the output of LA or CONSUME would be (incorrectly) used during the recording phase.\n-1, -1, -1, -1, -1, -1);\nObject.freeze(RECORDING_PHASE_TOKEN);\nconst RECORDING_PHASE_CSTNODE = {\n    name: \"This CSTNode indicates the Parser is in Recording Phase\\n\\t\" +\n        \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n    children: {},\n};\n/**\n * This trait handles the creation of the GAST structure for Chevrotain Grammars\n */\nexport class GastRecorder {\n    initGastRecorder(config) {\n        this.recordingProdStack = [];\n        this.RECORDING_PHASE = false;\n    }\n    enableRecording() {\n        this.RECORDING_PHASE = true;\n        this.TRACE_INIT(\"Enable Recording\", () => {\n            /**\n             * Warning Dark Voodoo Magic upcoming!\n             * We are \"replacing\" the public parsing DSL methods API\n             * With **new** alternative implementations on the Parser **instance**\n             *\n             * So far this is the only way I've found to avoid performance regressions during parsing time.\n             * - Approx 30% performance regression was measured on Chrome 75 Canary when attempting to replace the \"internal\"\n             *   implementations directly instead.\n             */\n            for (let i = 0; i < 10; i++) {\n                const idx = i > 0 ? i : \"\";\n                this[`CONSUME${idx}`] = function (arg1, arg2) {\n                    return this.consumeInternalRecord(arg1, i, arg2);\n                };\n                this[`SUBRULE${idx}`] = function (arg1, arg2) {\n                    return this.subruleInternalRecord(arg1, i, arg2);\n                };\n                this[`OPTION${idx}`] = function (arg1) {\n                    return this.optionInternalRecord(arg1, i);\n                };\n                this[`OR${idx}`] = function (arg1) {\n                    return this.orInternalRecord(arg1, i);\n                };\n                this[`MANY${idx}`] = function (arg1) {\n                    this.manyInternalRecord(i, arg1);\n                };\n                this[`MANY_SEP${idx}`] = function (arg1) {\n                    this.manySepFirstInternalRecord(i, arg1);\n                };\n                this[`AT_LEAST_ONE${idx}`] = function (arg1) {\n                    this.atLeastOneInternalRecord(i, arg1);\n                };\n                this[`AT_LEAST_ONE_SEP${idx}`] = function (arg1) {\n                    this.atLeastOneSepFirstInternalRecord(i, arg1);\n                };\n            }\n            // DSL methods with the idx(suffix) as an argument\n            this[`consume`] = function (idx, arg1, arg2) {\n                return this.consumeInternalRecord(arg1, idx, arg2);\n            };\n            this[`subrule`] = function (idx, arg1, arg2) {\n                return this.subruleInternalRecord(arg1, idx, arg2);\n            };\n            this[`option`] = function (idx, arg1) {\n                return this.optionInternalRecord(arg1, idx);\n            };\n            this[`or`] = function (idx, arg1) {\n                return this.orInternalRecord(arg1, idx);\n            };\n            this[`many`] = function (idx, arg1) {\n                this.manyInternalRecord(idx, arg1);\n            };\n            this[`atLeastOne`] = function (idx, arg1) {\n                this.atLeastOneInternalRecord(idx, arg1);\n            };\n            this.ACTION = this.ACTION_RECORD;\n            this.BACKTRACK = this.BACKTRACK_RECORD;\n            this.LA = this.LA_RECORD;\n        });\n    }\n    disableRecording() {\n        this.RECORDING_PHASE = false;\n        // By deleting these **instance** properties, any future invocation\n        // will be deferred to the original methods on the **prototype** object\n        // This seems to get rid of any incorrect optimizations that V8 may\n        // do during the recording phase.\n        this.TRACE_INIT(\"Deleting Recording methods\", () => {\n            const that = this;\n            for (let i = 0; i < 10; i++) {\n                const idx = i > 0 ? i : \"\";\n                delete that[`CONSUME${idx}`];\n                delete that[`SUBRULE${idx}`];\n                delete that[`OPTION${idx}`];\n                delete that[`OR${idx}`];\n                delete that[`MANY${idx}`];\n                delete that[`MANY_SEP${idx}`];\n                delete that[`AT_LEAST_ONE${idx}`];\n                delete that[`AT_LEAST_ONE_SEP${idx}`];\n            }\n            delete that[`consume`];\n            delete that[`subrule`];\n            delete that[`option`];\n            delete that[`or`];\n            delete that[`many`];\n            delete that[`atLeastOne`];\n            delete that.ACTION;\n            delete that.BACKTRACK;\n            delete that.LA;\n        });\n    }\n    //   Parser methods are called inside an ACTION?\n    //   Maybe try/catch/finally on ACTIONS while disabling the recorders state changes?\n    // @ts-expect-error -- noop place holder\n    ACTION_RECORD(impl) {\n        // NO-OP during recording\n    }\n    // Executing backtracking logic will break our recording logic assumptions\n    BACKTRACK_RECORD(grammarRule, args) {\n        return () => true;\n    }\n    // LA is part of the official API and may be used for custom lookahead logic\n    // by end users who may forget to wrap it in ACTION or inside a GATE\n    LA_RECORD(howMuch) {\n        // We cannot use the RECORD_PHASE_TOKEN here because someone may depend\n        // On LA return EOF at the end of the input so an infinite loop may occur.\n        return END_OF_FILE;\n    }\n    topLevelRuleRecord(name, def) {\n        try {\n            const newTopLevelRule = new Rule({ definition: [], name: name });\n            newTopLevelRule.name = name;\n            this.recordingProdStack.push(newTopLevelRule);\n            def.call(this);\n            this.recordingProdStack.pop();\n            return newTopLevelRule;\n        }\n        catch (originalError) {\n            if (originalError.KNOWN_RECORDER_ERROR !== true) {\n                try {\n                    originalError.message =\n                        originalError.message +\n                            '\\n\\t This error was thrown during the \"grammar recording phase\" For more info see:\\n\\t' +\n                            \"https://chevrotain.io/docs/guide/internals.html#grammar-recording\";\n                }\n                catch (mutabilityError) {\n                    // We may not be able to modify the original error object\n                    throw originalError;\n                }\n            }\n            throw originalError;\n        }\n    }\n    // Implementation of parsing DSL\n    optionInternalRecord(actionORMethodDef, occurrence) {\n        return recordProd.call(this, Option, actionORMethodDef, occurrence);\n    }\n    atLeastOneInternalRecord(occurrence, actionORMethodDef) {\n        recordProd.call(this, RepetitionMandatory, actionORMethodDef, occurrence);\n    }\n    atLeastOneSepFirstInternalRecord(occurrence, options) {\n        recordProd.call(this, RepetitionMandatoryWithSeparator, options, occurrence, HANDLE_SEPARATOR);\n    }\n    manyInternalRecord(occurrence, actionORMethodDef) {\n        recordProd.call(this, Repetition, actionORMethodDef, occurrence);\n    }\n    manySepFirstInternalRecord(occurrence, options) {\n        recordProd.call(this, RepetitionWithSeparator, options, occurrence, HANDLE_SEPARATOR);\n    }\n    orInternalRecord(altsOrOpts, occurrence) {\n        return recordOrProd.call(this, altsOrOpts, occurrence);\n    }\n    subruleInternalRecord(ruleToCall, occurrence, options) {\n        assertMethodIdxIsValid(occurrence);\n        if (!ruleToCall || has(ruleToCall, \"ruleName\") === false) {\n            const error = new Error(`<SUBRULE${getIdxSuffix(occurrence)}> argument is invalid` +\n                ` expecting a Parser method reference but got: <${JSON.stringify(ruleToCall)}>` +\n                `\\n inside top level rule: <${this.recordingProdStack[0].name}>`);\n            error.KNOWN_RECORDER_ERROR = true;\n            throw error;\n        }\n        const prevProd = peek(this.recordingProdStack);\n        const ruleName = ruleToCall.ruleName;\n        const newNoneTerminal = new NonTerminal({\n            idx: occurrence,\n            nonTerminalName: ruleName,\n            label: options === null || options === void 0 ? void 0 : options.LABEL,\n            // The resolving of the `referencedRule` property will be done once all the Rule's GASTs have been created\n            referencedRule: undefined,\n        });\n        prevProd.definition.push(newNoneTerminal);\n        return this.outputCst\n            ? RECORDING_PHASE_CSTNODE\n            : RECORDING_NULL_OBJECT;\n    }\n    consumeInternalRecord(tokType, occurrence, options) {\n        assertMethodIdxIsValid(occurrence);\n        if (!hasShortKeyProperty(tokType)) {\n            const error = new Error(`<CONSUME${getIdxSuffix(occurrence)}> argument is invalid` +\n                ` expecting a TokenType reference but got: <${JSON.stringify(tokType)}>` +\n                `\\n inside top level rule: <${this.recordingProdStack[0].name}>`);\n            error.KNOWN_RECORDER_ERROR = true;\n            throw error;\n        }\n        const prevProd = peek(this.recordingProdStack);\n        const newNoneTerminal = new Terminal({\n            idx: occurrence,\n            terminalType: tokType,\n            label: options === null || options === void 0 ? void 0 : options.LABEL,\n        });\n        prevProd.definition.push(newNoneTerminal);\n        return RECORDING_PHASE_TOKEN;\n    }\n}\nfunction recordProd(prodConstructor, mainProdArg, occurrence, handleSep = false) {\n    assertMethodIdxIsValid(occurrence);\n    const prevProd = peek(this.recordingProdStack);\n    const grammarAction = isFunction(mainProdArg) ? mainProdArg : mainProdArg.DEF;\n    const newProd = new prodConstructor({ definition: [], idx: occurrence });\n    if (handleSep) {\n        newProd.separator = mainProdArg.SEP;\n    }\n    if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n        newProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n    }\n    this.recordingProdStack.push(newProd);\n    grammarAction.call(this);\n    prevProd.definition.push(newProd);\n    this.recordingProdStack.pop();\n    return RECORDING_NULL_OBJECT;\n}\nfunction recordOrProd(mainProdArg, occurrence) {\n    assertMethodIdxIsValid(occurrence);\n    const prevProd = peek(this.recordingProdStack);\n    // Only an array of alternatives\n    const hasOptions = isArray(mainProdArg) === false;\n    const alts = hasOptions === false ? mainProdArg : mainProdArg.DEF;\n    const newOrProd = new Alternation({\n        definition: [],\n        idx: occurrence,\n        ignoreAmbiguities: hasOptions && mainProdArg.IGNORE_AMBIGUITIES === true,\n    });\n    if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n        newOrProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n    }\n    const hasPredicates = some(alts, (currAlt) => isFunction(currAlt.GATE));\n    newOrProd.hasPredicates = hasPredicates;\n    prevProd.definition.push(newOrProd);\n    forEach(alts, (currAlt) => {\n        const currAltFlat = new Alternative({ definition: [] });\n        newOrProd.definition.push(currAltFlat);\n        if (has(currAlt, \"IGNORE_AMBIGUITIES\")) {\n            currAltFlat.ignoreAmbiguities = currAlt.IGNORE_AMBIGUITIES; // assumes end user provides the correct config value/type\n        }\n        // **implicit** ignoreAmbiguities due to usage of gate\n        else if (has(currAlt, \"GATE\")) {\n            currAltFlat.ignoreAmbiguities = true;\n        }\n        this.recordingProdStack.push(currAltFlat);\n        currAlt.ALT.call(this);\n        this.recordingProdStack.pop();\n    });\n    return RECORDING_NULL_OBJECT;\n}\nfunction getIdxSuffix(idx) {\n    return idx === 0 ? \"\" : `${idx}`;\n}\nfunction assertMethodIdxIsValid(idx) {\n    if (idx < 0 || idx > MAX_METHOD_IDX) {\n        const error = new Error(\n        // The stack trace will contain all the needed details\n        `Invalid DSL Method idx value: <${idx}>\\n\\t` +\n            `Idx value must be a none negative value smaller than ${MAX_METHOD_IDX + 1}`);\n        error.KNOWN_RECORDER_ERROR = true;\n        throw error;\n    }\n}\n//# sourceMappingURL=gast_recorder.js.map","import { has } from \"lodash-es\";\nimport { timer } from \"@chevrotain/utils\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class PerformanceTracer {\n    initPerformanceTracer(config) {\n        if (has(config, \"traceInitPerf\")) {\n            const userTraceInitPerf = config.traceInitPerf;\n            const traceIsNumber = typeof userTraceInitPerf === \"number\";\n            this.traceInitMaxIdent = traceIsNumber\n                ? userTraceInitPerf\n                : Infinity;\n            this.traceInitPerf = traceIsNumber\n                ? userTraceInitPerf > 0\n                : userTraceInitPerf; // assumes end user provides the correct config value/type\n        }\n        else {\n            this.traceInitMaxIdent = 0;\n            this.traceInitPerf = DEFAULT_PARSER_CONFIG.traceInitPerf;\n        }\n        this.traceInitIndent = -1;\n    }\n    TRACE_INIT(phaseDesc, phaseImpl) {\n        // No need to optimize this using NOOP pattern because\n        // It is not called in a hot spot...\n        if (this.traceInitPerf === true) {\n            this.traceInitIndent++;\n            const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n            if (this.traceInitIndent < this.traceInitMaxIdent) {\n                console.log(`${indent}--> <${phaseDesc}>`);\n            }\n            const { time, value } = timer(phaseImpl);\n            /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n            const traceMethod = time > 10 ? console.warn : console.log;\n            if (this.traceInitIndent < this.traceInitMaxIdent) {\n                traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n            }\n            this.traceInitIndent--;\n            return value;\n        }\n        else {\n            return phaseImpl();\n        }\n    }\n}\n//# sourceMappingURL=perf_tracer.js.map","export function applyMixins(derivedCtor, baseCtors) {\n    baseCtors.forEach((baseCtor) => {\n        const baseProto = baseCtor.prototype;\n        Object.getOwnPropertyNames(baseProto).forEach((propName) => {\n            if (propName === \"constructor\") {\n                return;\n            }\n            const basePropDescriptor = Object.getOwnPropertyDescriptor(baseProto, propName);\n            // Handle Accessors\n            if (basePropDescriptor &&\n                (basePropDescriptor.get || basePropDescriptor.set)) {\n                Object.defineProperty(derivedCtor.prototype, propName, basePropDescriptor);\n            }\n            else {\n                derivedCtor.prototype[propName] = baseCtor.prototype[propName];\n            }\n        });\n    });\n}\n//# sourceMappingURL=apply_mixins.js.map","import { clone, forEach, has, isEmpty, map, values } from \"lodash-es\";\nimport { toFastProperties } from \"@chevrotain/utils\";\nimport { computeAllProdsFollows } from \"../grammar/follow.js\";\nimport { createTokenInstance, EOF } from \"../../scan/tokens_public.js\";\nimport { defaultGrammarValidatorErrorProvider, defaultParserErrorProvider, } from \"../errors_public.js\";\nimport { resolveGrammar, validateGrammar, } from \"../grammar/gast/gast_resolver_public.js\";\nimport { Recoverable } from \"./traits/recoverable.js\";\nimport { LooksAhead } from \"./traits/looksahead.js\";\nimport { TreeBuilder } from \"./traits/tree_builder.js\";\nimport { LexerAdapter } from \"./traits/lexer_adapter.js\";\nimport { RecognizerApi } from \"./traits/recognizer_api.js\";\nimport { RecognizerEngine } from \"./traits/recognizer_engine.js\";\nimport { ErrorHandler } from \"./traits/error_handler.js\";\nimport { ContentAssist } from \"./traits/context_assist.js\";\nimport { GastRecorder } from \"./traits/gast_recorder.js\";\nimport { PerformanceTracer } from \"./traits/perf_tracer.js\";\nimport { applyMixins } from \"./utils/apply_mixins.js\";\nimport { validateLookahead } from \"../grammar/checks.js\";\nexport const END_OF_FILE = createTokenInstance(EOF, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\nObject.freeze(END_OF_FILE);\nexport const DEFAULT_PARSER_CONFIG = Object.freeze({\n    recoveryEnabled: false,\n    maxLookahead: 3,\n    dynamicTokensEnabled: false,\n    outputCst: true,\n    errorMessageProvider: defaultParserErrorProvider,\n    nodeLocationTracking: \"none\",\n    traceInitPerf: false,\n    skipValidations: false,\n});\nexport const DEFAULT_RULE_CONFIG = Object.freeze({\n    recoveryValueFunc: () => undefined,\n    resyncEnabled: true,\n});\nexport var ParserDefinitionErrorType;\n(function (ParserDefinitionErrorType) {\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"INVALID_RULE_NAME\"] = 0] = \"INVALID_RULE_NAME\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"DUPLICATE_RULE_NAME\"] = 1] = \"DUPLICATE_RULE_NAME\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"INVALID_RULE_OVERRIDE\"] = 2] = \"INVALID_RULE_OVERRIDE\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"DUPLICATE_PRODUCTIONS\"] = 3] = \"DUPLICATE_PRODUCTIONS\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"UNRESOLVED_SUBRULE_REF\"] = 4] = \"UNRESOLVED_SUBRULE_REF\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"LEFT_RECURSION\"] = 5] = \"LEFT_RECURSION\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"NONE_LAST_EMPTY_ALT\"] = 6] = \"NONE_LAST_EMPTY_ALT\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"AMBIGUOUS_ALTS\"] = 7] = \"AMBIGUOUS_ALTS\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"CONFLICT_TOKENS_RULES_NAMESPACE\"] = 8] = \"CONFLICT_TOKENS_RULES_NAMESPACE\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"INVALID_TOKEN_NAME\"] = 9] = \"INVALID_TOKEN_NAME\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"NO_NON_EMPTY_LOOKAHEAD\"] = 10] = \"NO_NON_EMPTY_LOOKAHEAD\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"AMBIGUOUS_PREFIX_ALTS\"] = 11] = \"AMBIGUOUS_PREFIX_ALTS\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"TOO_MANY_ALTS\"] = 12] = \"TOO_MANY_ALTS\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"CUSTOM_LOOKAHEAD_VALIDATION\"] = 13] = \"CUSTOM_LOOKAHEAD_VALIDATION\";\n})(ParserDefinitionErrorType || (ParserDefinitionErrorType = {}));\nexport function EMPTY_ALT(value = undefined) {\n    return function () {\n        return value;\n    };\n}\nexport class Parser {\n    /**\n     *  @deprecated use the **instance** method with the same name instead\n     */\n    static performSelfAnalysis(parserInstance) {\n        throw Error(\"The **static** `performSelfAnalysis` method has been deprecated.\" +\n            \"\\t\\nUse the **instance** method with the same name instead.\");\n    }\n    performSelfAnalysis() {\n        this.TRACE_INIT(\"performSelfAnalysis\", () => {\n            let defErrorsMsgs;\n            this.selfAnalysisDone = true;\n            const className = this.className;\n            this.TRACE_INIT(\"toFastProps\", () => {\n                // Without this voodoo magic the parser would be x3-x4 slower\n                // It seems it is better to invoke `toFastProperties` **before**\n                // Any manipulations of the `this` object done during the recording phase.\n                toFastProperties(this);\n            });\n            this.TRACE_INIT(\"Grammar Recording\", () => {\n                try {\n                    this.enableRecording();\n                    // Building the GAST\n                    forEach(this.definedRulesNames, (currRuleName) => {\n                        const wrappedRule = this[currRuleName];\n                        const originalGrammarAction = wrappedRule[\"originalGrammarAction\"];\n                        let recordedRuleGast;\n                        this.TRACE_INIT(`${currRuleName} Rule`, () => {\n                            recordedRuleGast = this.topLevelRuleRecord(currRuleName, originalGrammarAction);\n                        });\n                        this.gastProductionsCache[currRuleName] = recordedRuleGast;\n                    });\n                }\n                finally {\n                    this.disableRecording();\n                }\n            });\n            let resolverErrors = [];\n            this.TRACE_INIT(\"Grammar Resolving\", () => {\n                resolverErrors = resolveGrammar({\n                    rules: values(this.gastProductionsCache),\n                });\n                this.definitionErrors = this.definitionErrors.concat(resolverErrors);\n            });\n            this.TRACE_INIT(\"Grammar Validations\", () => {\n                // only perform additional grammar validations IFF no resolving errors have occurred.\n                // as unresolved grammar may lead to unhandled runtime exceptions in the follow up validations.\n                if (isEmpty(resolverErrors) && this.skipValidations === false) {\n                    const validationErrors = validateGrammar({\n                        rules: values(this.gastProductionsCache),\n                        tokenTypes: values(this.tokensMap),\n                        errMsgProvider: defaultGrammarValidatorErrorProvider,\n                        grammarName: className,\n                    });\n                    const lookaheadValidationErrors = validateLookahead({\n                        lookaheadStrategy: this.lookaheadStrategy,\n                        rules: values(this.gastProductionsCache),\n                        tokenTypes: values(this.tokensMap),\n                        grammarName: className,\n                    });\n                    this.definitionErrors = this.definitionErrors.concat(validationErrors, lookaheadValidationErrors);\n                }\n            });\n            // this analysis may fail if the grammar is not perfectly valid\n            if (isEmpty(this.definitionErrors)) {\n                // The results of these computations are not needed unless error recovery is enabled.\n                if (this.recoveryEnabled) {\n                    this.TRACE_INIT(\"computeAllProdsFollows\", () => {\n                        const allFollows = computeAllProdsFollows(values(this.gastProductionsCache));\n                        this.resyncFollows = allFollows;\n                    });\n                }\n                this.TRACE_INIT(\"ComputeLookaheadFunctions\", () => {\n                    var _a, _b;\n                    (_b = (_a = this.lookaheadStrategy).initialize) === null || _b === void 0 ? void 0 : _b.call(_a, {\n                        rules: values(this.gastProductionsCache),\n                    });\n                    this.preComputeLookaheadFunctions(values(this.gastProductionsCache));\n                });\n            }\n            if (!Parser.DEFER_DEFINITION_ERRORS_HANDLING &&\n                !isEmpty(this.definitionErrors)) {\n                defErrorsMsgs = map(this.definitionErrors, (defError) => defError.message);\n                throw new Error(`Parser Definition Errors detected:\\n ${defErrorsMsgs.join(\"\\n-------------------------------\\n\")}`);\n            }\n        });\n    }\n    constructor(tokenVocabulary, config) {\n        this.definitionErrors = [];\n        this.selfAnalysisDone = false;\n        const that = this;\n        that.initErrorHandler(config);\n        that.initLexerAdapter();\n        that.initLooksAhead(config);\n        that.initRecognizerEngine(tokenVocabulary, config);\n        that.initRecoverable(config);\n        that.initTreeBuilder(config);\n        that.initContentAssist();\n        that.initGastRecorder(config);\n        that.initPerformanceTracer(config);\n        if (has(config, \"ignoredIssues\")) {\n            throw new Error(\"The <ignoredIssues> IParserConfig property has been deprecated.\\n\\t\" +\n                \"Please use the <IGNORE_AMBIGUITIES> flag on the relevant DSL method instead.\\n\\t\" +\n                \"See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#IGNORING_AMBIGUITIES\\n\\t\" +\n                \"For further details.\");\n        }\n        this.skipValidations = has(config, \"skipValidations\")\n            ? config.skipValidations // casting assumes the end user passing the correct type\n            : DEFAULT_PARSER_CONFIG.skipValidations;\n    }\n}\n// Set this flag to true if you don't want the Parser to throw error when problems in it's definition are detected.\n// (normally during the parser's constructor).\n// This is a design time flag, it will not affect the runtime error handling of the parser, just design time errors,\n// for example: duplicate rule names, referencing an unresolved subrule, ect...\n// This flag should not be enabled during normal usage, it is used in special situations, for example when\n// needing to display the parser definition errors in some GUI(online playground).\nParser.DEFER_DEFINITION_ERRORS_HANDLING = false;\napplyMixins(Parser, [\n    Recoverable,\n    LooksAhead,\n    TreeBuilder,\n    LexerAdapter,\n    RecognizerEngine,\n    RecognizerApi,\n    ErrorHandler,\n    ContentAssist,\n    GastRecorder,\n    PerformanceTracer,\n]);\nexport class CstParser extends Parser {\n    constructor(tokenVocabulary, config = DEFAULT_PARSER_CONFIG) {\n        const configClone = clone(config);\n        configClone.outputCst = true;\n        super(tokenVocabulary, configClone);\n    }\n}\nexport class EmbeddedActionsParser extends Parser {\n    constructor(tokenVocabulary, config = DEFAULT_PARSER_CONFIG) {\n        const configClone = clone(config);\n        configClone.outputCst = false;\n        super(tokenVocabulary, configClone);\n    }\n}\n//# sourceMappingURL=parser.js.map","import { buildModel } from \"./model.js\";\nimport { genDts } from \"./generate.js\";\nconst defaultOptions = {\n    includeVisitorInterface: true,\n    visitorInterfaceName: \"ICstNodeVisitor\",\n};\nexport function generateCstDts(productions, options) {\n    const effectiveOptions = Object.assign(Object.assign({}, defaultOptions), options);\n    const model = buildModel(productions);\n    return genDts(model, effectiveOptions);\n}\n//# sourceMappingURL=api.js.map","/* istanbul ignore file - tricky to import some things from this module during testing */\n// semantic version\nexport { VERSION } from \"./version.js\";\nexport { CstParser, EmbeddedActionsParser, ParserDefinitionErrorType, EMPTY_ALT, } from \"./parse/parser/parser.js\";\nexport { Lexer, LexerDefinitionErrorType } from \"./scan/lexer_public.js\";\n// Tokens utilities\nexport { createToken, createTokenInstance, EOF, tokenLabel, tokenMatcher, tokenName, } from \"./scan/tokens_public.js\";\n// Lookahead\nexport { getLookaheadPaths } from \"./parse/grammar/lookahead.js\";\nexport { LLkLookaheadStrategy } from \"./parse/grammar/llk_lookahead.js\";\n// Other Utilities\nexport { defaultParserErrorProvider } from \"./parse/errors_public.js\";\nexport { EarlyExitException, isRecognitionException, MismatchedTokenException, NotAllInputParsedException, NoViableAltException, } from \"./parse/exceptions_public.js\";\nexport { defaultLexerErrorProvider } from \"./scan/lexer_errors_public.js\";\n// grammar reflection API\nexport { Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Rule, Terminal, } from \"@chevrotain/gast\";\n// GAST Utilities\nexport { serializeGrammar, serializeProduction, GAstVisitor, } from \"@chevrotain/gast\";\nexport { generateCstDts } from \"@chevrotain/cst-dts-gen\";\n/* istanbul ignore next */\nexport function clearCache() {\n    console.warn(\"The clearCache function was 'soft' removed from the Chevrotain API.\" +\n        \"\\n\\t It performs no action other than printing this message.\" +\n        \"\\n\\t Please avoid using it as it will be completely removed in the future\");\n}\nexport { createSyntaxDiagramsCode } from \"./diagrams/render_public.js\";\nexport class Parser {\n    constructor() {\n        throw new Error(\"The Parser class has been deprecated, use CstParser or EmbeddedActionsParser instead.\\t\\n\" +\n            \"See: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_7-0-0\");\n    }\n}\n//# sourceMappingURL=api.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { DefaultNameRegexp } from '../utils/cst-utils.js';\nimport { isCommentTerminal, terminalRegex } from '../utils/grammar-utils.js';\nimport { isMultilineComment } from '../utils/regexp-utils.js';\nimport { isTerminalRule } from './generated/ast.js';\n/**\n * Create the default grammar configuration (used by `createDefaultModule`). This can be overridden in a\n * language-specific module.\n */\nexport function createGrammarConfig(services) {\n    const rules = [];\n    const grammar = services.Grammar;\n    for (const rule of grammar.rules) {\n        if (isTerminalRule(rule) && isCommentTerminal(rule) && isMultilineComment(terminalRegex(rule))) {\n            rules.push(rule.name);\n        }\n    }\n    return {\n        multilineCommentRules: rules,\n        nameRegexp: DefaultNameRegexp\n    };\n}\n//# sourceMappingURL=grammar-config.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport map from \"lodash-es/map.js\";\nimport filter from \"lodash-es/filter.js\";\nimport { Alternation, NonTerminal, Option, RepetitionMandatory, Repetition, Terminal, RepetitionWithSeparator, RepetitionMandatoryWithSeparator } from \"chevrotain\";\nexport function buildATNKey(rule, type, occurrence) {\n    return `${rule.name}_${type}_${occurrence}`;\n}\nexport const ATN_INVALID_TYPE = 0;\nexport const ATN_BASIC = 1;\nexport const ATN_RULE_START = 2;\nexport const ATN_PLUS_BLOCK_START = 4;\nexport const ATN_STAR_BLOCK_START = 5;\n// Currently unused as the ATN is not used for lexing\nexport const ATN_TOKEN_START = 6;\nexport const ATN_RULE_STOP = 7;\nexport const ATN_BLOCK_END = 8;\nexport const ATN_STAR_LOOP_BACK = 9;\nexport const ATN_STAR_LOOP_ENTRY = 10;\nexport const ATN_PLUS_LOOP_BACK = 11;\nexport const ATN_LOOP_END = 12;\nexport class AbstractTransition {\n    constructor(target) {\n        this.target = target;\n    }\n    isEpsilon() {\n        return false;\n    }\n}\nexport class AtomTransition extends AbstractTransition {\n    constructor(target, tokenType) {\n        super(target);\n        this.tokenType = tokenType;\n    }\n}\nexport class EpsilonTransition extends AbstractTransition {\n    constructor(target) {\n        super(target);\n    }\n    isEpsilon() {\n        return true;\n    }\n}\nexport class RuleTransition extends AbstractTransition {\n    constructor(ruleStart, rule, followState) {\n        super(ruleStart);\n        this.rule = rule;\n        this.followState = followState;\n    }\n    isEpsilon() {\n        return true;\n    }\n}\nexport function createATN(rules) {\n    const atn = {\n        decisionMap: {},\n        decisionStates: [],\n        ruleToStartState: new Map(),\n        ruleToStopState: new Map(),\n        states: []\n    };\n    createRuleStartAndStopATNStates(atn, rules);\n    const ruleLength = rules.length;\n    for (let i = 0; i < ruleLength; i++) {\n        const rule = rules[i];\n        const ruleBlock = block(atn, rule, rule);\n        if (ruleBlock === undefined) {\n            continue;\n        }\n        buildRuleHandle(atn, rule, ruleBlock);\n    }\n    return atn;\n}\nfunction createRuleStartAndStopATNStates(atn, rules) {\n    const ruleLength = rules.length;\n    for (let i = 0; i < ruleLength; i++) {\n        const rule = rules[i];\n        const start = newState(atn, rule, undefined, {\n            type: ATN_RULE_START\n        });\n        const stop = newState(atn, rule, undefined, {\n            type: ATN_RULE_STOP\n        });\n        start.stop = stop;\n        atn.ruleToStartState.set(rule, start);\n        atn.ruleToStopState.set(rule, stop);\n    }\n}\nfunction atom(atn, rule, production) {\n    if (production instanceof Terminal) {\n        return tokenRef(atn, rule, production.terminalType, production);\n    }\n    else if (production instanceof NonTerminal) {\n        return ruleRef(atn, rule, production);\n    }\n    else if (production instanceof Alternation) {\n        return alternation(atn, rule, production);\n    }\n    else if (production instanceof Option) {\n        return option(atn, rule, production);\n    }\n    else if (production instanceof Repetition) {\n        return repetition(atn, rule, production);\n    }\n    else if (production instanceof RepetitionWithSeparator) {\n        return repetitionSep(atn, rule, production);\n    }\n    else if (production instanceof RepetitionMandatory) {\n        return repetitionMandatory(atn, rule, production);\n    }\n    else if (production instanceof RepetitionMandatoryWithSeparator) {\n        return repetitionMandatorySep(atn, rule, production);\n    }\n    else {\n        return block(atn, rule, production);\n    }\n}\nfunction repetition(atn, rule, repetition) {\n    const starState = newState(atn, rule, repetition, {\n        type: ATN_STAR_BLOCK_START\n    });\n    defineDecisionState(atn, starState);\n    const handle = makeAlts(atn, rule, starState, repetition, block(atn, rule, repetition));\n    return star(atn, rule, repetition, handle);\n}\nfunction repetitionSep(atn, rule, repetition) {\n    const starState = newState(atn, rule, repetition, {\n        type: ATN_STAR_BLOCK_START\n    });\n    defineDecisionState(atn, starState);\n    const handle = makeAlts(atn, rule, starState, repetition, block(atn, rule, repetition));\n    const sep = tokenRef(atn, rule, repetition.separator, repetition);\n    return star(atn, rule, repetition, handle, sep);\n}\nfunction repetitionMandatory(atn, rule, repetition) {\n    const plusState = newState(atn, rule, repetition, {\n        type: ATN_PLUS_BLOCK_START\n    });\n    defineDecisionState(atn, plusState);\n    const handle = makeAlts(atn, rule, plusState, repetition, block(atn, rule, repetition));\n    return plus(atn, rule, repetition, handle);\n}\nfunction repetitionMandatorySep(atn, rule, repetition) {\n    const plusState = newState(atn, rule, repetition, {\n        type: ATN_PLUS_BLOCK_START\n    });\n    defineDecisionState(atn, plusState);\n    const handle = makeAlts(atn, rule, plusState, repetition, block(atn, rule, repetition));\n    const sep = tokenRef(atn, rule, repetition.separator, repetition);\n    return plus(atn, rule, repetition, handle, sep);\n}\nfunction alternation(atn, rule, alternation) {\n    const start = newState(atn, rule, alternation, {\n        type: ATN_BASIC\n    });\n    defineDecisionState(atn, start);\n    const alts = map(alternation.definition, (e) => atom(atn, rule, e));\n    const handle = makeAlts(atn, rule, start, alternation, ...alts);\n    return handle;\n}\nfunction option(atn, rule, option) {\n    const start = newState(atn, rule, option, {\n        type: ATN_BASIC\n    });\n    defineDecisionState(atn, start);\n    const handle = makeAlts(atn, rule, start, option, block(atn, rule, option));\n    return optional(atn, rule, option, handle);\n}\nfunction block(atn, rule, block) {\n    const handles = filter(map(block.definition, (e) => atom(atn, rule, e)), (e) => e !== undefined);\n    if (handles.length === 1) {\n        return handles[0];\n    }\n    else if (handles.length === 0) {\n        return undefined;\n    }\n    else {\n        return makeBlock(atn, handles);\n    }\n}\nfunction plus(atn, rule, plus, handle, sep) {\n    const blkStart = handle.left;\n    const blkEnd = handle.right;\n    const loop = newState(atn, rule, plus, {\n        type: ATN_PLUS_LOOP_BACK\n    });\n    defineDecisionState(atn, loop);\n    const end = newState(atn, rule, plus, {\n        type: ATN_LOOP_END\n    });\n    blkStart.loopback = loop;\n    end.loopback = loop;\n    atn.decisionMap[buildATNKey(rule, sep ? 'RepetitionMandatoryWithSeparator' : 'RepetitionMandatory', plus.idx)] = loop;\n    epsilon(blkEnd, loop); // block can see loop back\n    // Depending on whether we have a separator we put the exit transition at index 1 or 0\n    // This influences the chosen option in the lookahead DFA\n    if (sep === undefined) {\n        epsilon(loop, blkStart); // loop back to start\n        epsilon(loop, end); // exit\n    }\n    else {\n        epsilon(loop, end); // exit\n        // loop back to start with separator\n        epsilon(loop, sep.left);\n        epsilon(sep.right, blkStart);\n    }\n    return {\n        left: blkStart,\n        right: end\n    };\n}\nfunction star(atn, rule, star, handle, sep) {\n    const start = handle.left;\n    const end = handle.right;\n    const entry = newState(atn, rule, star, {\n        type: ATN_STAR_LOOP_ENTRY\n    });\n    defineDecisionState(atn, entry);\n    const loopEnd = newState(atn, rule, star, {\n        type: ATN_LOOP_END\n    });\n    const loop = newState(atn, rule, star, {\n        type: ATN_STAR_LOOP_BACK\n    });\n    entry.loopback = loop;\n    loopEnd.loopback = loop;\n    epsilon(entry, start); // loop enter edge (alt 2)\n    epsilon(entry, loopEnd); // bypass loop edge (alt 1)\n    epsilon(end, loop); // block end hits loop back\n    if (sep !== undefined) {\n        epsilon(loop, loopEnd); // end loop\n        // loop back to start of handle using separator\n        epsilon(loop, sep.left);\n        epsilon(sep.right, start);\n    }\n    else {\n        epsilon(loop, entry); // loop back to entry/exit decision\n    }\n    atn.decisionMap[buildATNKey(rule, sep ? 'RepetitionWithSeparator' : 'Repetition', star.idx)] = entry;\n    return {\n        left: entry,\n        right: loopEnd\n    };\n}\nfunction optional(atn, rule, optional, handle) {\n    const start = handle.left;\n    const end = handle.right;\n    epsilon(start, end);\n    atn.decisionMap[buildATNKey(rule, 'Option', optional.idx)] = start;\n    return handle;\n}\nfunction defineDecisionState(atn, state) {\n    atn.decisionStates.push(state);\n    state.decision = atn.decisionStates.length - 1;\n    return state.decision;\n}\nfunction makeAlts(atn, rule, start, production, ...alts) {\n    const end = newState(atn, rule, production, {\n        type: ATN_BLOCK_END,\n        start\n    });\n    start.end = end;\n    for (const alt of alts) {\n        if (alt !== undefined) {\n            // hook alts up to decision block\n            epsilon(start, alt.left);\n            epsilon(alt.right, end);\n        }\n        else {\n            epsilon(start, end);\n        }\n    }\n    const handle = {\n        left: start,\n        right: end\n    };\n    atn.decisionMap[buildATNKey(rule, getProdType(production), production.idx)] = start;\n    return handle;\n}\nfunction getProdType(production) {\n    if (production instanceof Alternation) {\n        return 'Alternation';\n    }\n    else if (production instanceof Option) {\n        return 'Option';\n    }\n    else if (production instanceof Repetition) {\n        return 'Repetition';\n    }\n    else if (production instanceof RepetitionWithSeparator) {\n        return 'RepetitionWithSeparator';\n    }\n    else if (production instanceof RepetitionMandatory) {\n        return 'RepetitionMandatory';\n    }\n    else if (production instanceof RepetitionMandatoryWithSeparator) {\n        return 'RepetitionMandatoryWithSeparator';\n    }\n    else {\n        throw new Error('Invalid production type encountered');\n    }\n}\nfunction makeBlock(atn, alts) {\n    const altsLength = alts.length;\n    for (let i = 0; i < altsLength - 1; i++) {\n        const handle = alts[i];\n        let transition;\n        if (handle.left.transitions.length === 1) {\n            transition = handle.left.transitions[0];\n        }\n        const isRuleTransition = transition instanceof RuleTransition;\n        const ruleTransition = transition;\n        const next = alts[i + 1].left;\n        if (handle.left.type === ATN_BASIC &&\n            handle.right.type === ATN_BASIC &&\n            transition !== undefined &&\n            ((isRuleTransition && ruleTransition.followState === handle.right) ||\n                transition.target === handle.right)) {\n            // we can avoid epsilon edge to next element\n            if (isRuleTransition) {\n                ruleTransition.followState = next;\n            }\n            else {\n                transition.target = next;\n            }\n            removeState(atn, handle.right); // we skipped over this state\n        }\n        else {\n            // need epsilon if previous block's right end node is complex\n            epsilon(handle.right, next);\n        }\n    }\n    const first = alts[0];\n    const last = alts[altsLength - 1];\n    return {\n        left: first.left,\n        right: last.right\n    };\n}\nfunction tokenRef(atn, rule, tokenType, production) {\n    const left = newState(atn, rule, production, {\n        type: ATN_BASIC\n    });\n    const right = newState(atn, rule, production, {\n        type: ATN_BASIC\n    });\n    addTransition(left, new AtomTransition(right, tokenType));\n    return {\n        left,\n        right\n    };\n}\nfunction ruleRef(atn, currentRule, nonTerminal) {\n    const rule = nonTerminal.referencedRule;\n    const start = atn.ruleToStartState.get(rule);\n    const left = newState(atn, currentRule, nonTerminal, {\n        type: ATN_BASIC\n    });\n    const right = newState(atn, currentRule, nonTerminal, {\n        type: ATN_BASIC\n    });\n    const call = new RuleTransition(start, rule, right);\n    addTransition(left, call);\n    return {\n        left,\n        right\n    };\n}\nfunction buildRuleHandle(atn, rule, block) {\n    const start = atn.ruleToStartState.get(rule);\n    epsilon(start, block.left);\n    const stop = atn.ruleToStopState.get(rule);\n    epsilon(block.right, stop);\n    const handle = {\n        left: start,\n        right: stop\n    };\n    return handle;\n}\nfunction epsilon(a, b) {\n    const transition = new EpsilonTransition(b);\n    addTransition(a, transition);\n}\nfunction newState(atn, rule, production, partial) {\n    const t = Object.assign({ atn,\n        production, epsilonOnlyTransitions: false, rule, transitions: [], nextTokenWithinRule: [], stateNumber: atn.states.length }, partial);\n    atn.states.push(t);\n    return t;\n}\nfunction addTransition(state, transition) {\n    // A single ATN state can only contain epsilon transitions or non-epsilon transitions\n    // Because they are never mixed, only setting the property for the first transition is fine\n    if (state.transitions.length === 0) {\n        state.epsilonOnlyTransitions = transition.isEpsilon();\n    }\n    state.transitions.push(transition);\n}\nfunction removeState(atn, state) {\n    atn.states.splice(atn.states.indexOf(state), 1);\n}\n//# sourceMappingURL=atn.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport map from \"lodash-es/map.js\";\nexport const DFA_ERROR = {};\nexport class ATNConfigSet {\n    constructor() {\n        this.map = {};\n        this.configs = [];\n    }\n    get size() {\n        return this.configs.length;\n    }\n    finalize() {\n        // Empties the map to free up memory\n        this.map = {};\n    }\n    add(config) {\n        const key = getATNConfigKey(config);\n        // Only add configs which don't exist in our map already\n        // While this does not influence the actual algorithm, adding them anyway would massively increase memory consumption\n        if (!(key in this.map)) {\n            this.map[key] = this.configs.length;\n            this.configs.push(config);\n        }\n    }\n    get elements() {\n        return this.configs;\n    }\n    get alts() {\n        return map(this.configs, (e) => e.alt);\n    }\n    get key() {\n        let value = \"\";\n        for (const k in this.map) {\n            value += k + \":\";\n        }\n        return value;\n    }\n}\nexport function getATNConfigKey(config, alt = true) {\n    return `${alt ? `a${config.alt}` : \"\"}s${config.state.stateNumber}:${config.stack.map((e) => e.stateNumber.toString()).join(\"_\")}`;\n}\n//# sourceMappingURL=dfa.js.map","import baseIteratee from './_baseIteratee.js';\nimport baseUniq from './_baseUniq.js';\n\n/**\n * This method is like `_.uniq` except that it accepts `iteratee` which is\n * invoked for each element in `array` to generate the criterion by which\n * uniqueness is computed. The order of result values is determined by the\n * order they occur in the array. The iteratee is invoked with one argument:\n * (value).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {Function} [iteratee=_.identity] The iteratee invoked per element.\n * @returns {Array} Returns the new duplicate free array.\n * @example\n *\n * _.uniqBy([2.1, 1.2, 2.3], Math.floor);\n * // => [2.1, 1.2]\n *\n * // The `_.property` iteratee shorthand.\n * _.uniqBy([{ 'x': 1 }, { 'x': 2 }, { 'x': 1 }], 'x');\n * // => [{ 'x': 1 }, { 'x': 2 }]\n */\nfunction uniqBy(array, iteratee) {\n  return (array && array.length) ? baseUniq(array, baseIteratee(iteratee, 2)) : [];\n}\n\nexport default uniqBy;\n","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { tokenMatcher, tokenLabel, NonTerminal, Alternation, Option, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Repetition, Terminal, LLkLookaheadStrategy, getLookaheadPaths } from \"chevrotain\";\nimport { ATN_RULE_STOP, AtomTransition, buildATNKey, createATN, EpsilonTransition, RuleTransition } from \"./atn.js\";\nimport { ATNConfigSet, DFA_ERROR, getATNConfigKey } from \"./dfa.js\";\nimport min from \"lodash-es/min.js\";\nimport flatMap from \"lodash-es/flatMap.js\";\nimport uniqBy from \"lodash-es/uniqBy.js\";\nimport map from \"lodash-es/map.js\";\nimport flatten from \"lodash-es/flatten.js\";\nimport forEach from \"lodash-es/forEach.js\";\nimport isEmpty from \"lodash-es/isEmpty.js\";\nimport reduce from \"lodash-es/reduce.js\";\nfunction createDFACache(startState, decision) {\n    const map = {};\n    return (predicateSet) => {\n        const key = predicateSet.toString();\n        let existing = map[key];\n        if (existing !== undefined) {\n            return existing;\n        }\n        else {\n            existing = {\n                atnStartState: startState,\n                decision,\n                states: {}\n            };\n            map[key] = existing;\n            return existing;\n        }\n    };\n}\nclass PredicateSet {\n    constructor() {\n        this.predicates = [];\n    }\n    is(index) {\n        return index >= this.predicates.length || this.predicates[index];\n    }\n    set(index, value) {\n        this.predicates[index] = value;\n    }\n    toString() {\n        let value = \"\";\n        const size = this.predicates.length;\n        for (let i = 0; i < size; i++) {\n            value += this.predicates[i] === true ? \"1\" : \"0\";\n        }\n        return value;\n    }\n}\nconst EMPTY_PREDICATES = new PredicateSet();\nexport class LLStarLookaheadStrategy extends LLkLookaheadStrategy {\n    constructor(options) {\n        var _a;\n        super();\n        this.logging = (_a = options === null || options === void 0 ? void 0 : options.logging) !== null && _a !== void 0 ? _a : ((message) => console.log(message));\n    }\n    initialize(options) {\n        this.atn = createATN(options.rules);\n        this.dfas = initATNSimulator(this.atn);\n    }\n    validateAmbiguousAlternationAlternatives() {\n        return [];\n    }\n    validateEmptyOrAlternatives() {\n        return [];\n    }\n    buildLookaheadForAlternation(options) {\n        const { prodOccurrence, rule, hasPredicates, dynamicTokensEnabled } = options;\n        const dfas = this.dfas;\n        const logging = this.logging;\n        const key = buildATNKey(rule, 'Alternation', prodOccurrence);\n        const decisionState = this.atn.decisionMap[key];\n        const decisionIndex = decisionState.decision;\n        const partialAlts = map(getLookaheadPaths({\n            maxLookahead: 1,\n            occurrence: prodOccurrence,\n            prodType: \"Alternation\",\n            rule: rule\n        }), (currAlt) => map(currAlt, (path) => path[0]));\n        if (isLL1Sequence(partialAlts, false) && !dynamicTokensEnabled) {\n            const choiceToAlt = reduce(partialAlts, (result, currAlt, idx) => {\n                forEach(currAlt, (currTokType) => {\n                    if (currTokType) {\n                        result[currTokType.tokenTypeIdx] = idx;\n                        forEach(currTokType.categoryMatches, (currExtendingType) => {\n                            result[currExtendingType] = idx;\n                        });\n                    }\n                });\n                return result;\n            }, {});\n            if (hasPredicates) {\n                return function (orAlts) {\n                    var _a;\n                    const nextToken = this.LA(1);\n                    const prediction = choiceToAlt[nextToken.tokenTypeIdx];\n                    if (orAlts !== undefined && prediction !== undefined) {\n                        const gate = (_a = orAlts[prediction]) === null || _a === void 0 ? void 0 : _a.GATE;\n                        if (gate !== undefined && gate.call(this) === false) {\n                            return undefined;\n                        }\n                    }\n                    return prediction;\n                };\n            }\n            else {\n                return function () {\n                    const nextToken = this.LA(1);\n                    return choiceToAlt[nextToken.tokenTypeIdx];\n                };\n            }\n        }\n        else if (hasPredicates) {\n            return function (orAlts) {\n                const predicates = new PredicateSet();\n                const length = orAlts === undefined ? 0 : orAlts.length;\n                for (let i = 0; i < length; i++) {\n                    const gate = orAlts === null || orAlts === void 0 ? void 0 : orAlts[i].GATE;\n                    predicates.set(i, gate === undefined || gate.call(this));\n                }\n                const result = adaptivePredict.call(this, dfas, decisionIndex, predicates, logging);\n                return typeof result === 'number' ? result : undefined;\n            };\n        }\n        else {\n            return function () {\n                const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging);\n                return typeof result === 'number' ? result : undefined;\n            };\n        }\n    }\n    buildLookaheadForOptional(options) {\n        const { prodOccurrence, rule, prodType, dynamicTokensEnabled } = options;\n        const dfas = this.dfas;\n        const logging = this.logging;\n        const key = buildATNKey(rule, prodType, prodOccurrence);\n        const decisionState = this.atn.decisionMap[key];\n        const decisionIndex = decisionState.decision;\n        const alts = map(getLookaheadPaths({\n            maxLookahead: 1,\n            occurrence: prodOccurrence,\n            prodType,\n            rule\n        }), (e) => {\n            return map(e, (g) => g[0]);\n        });\n        if (isLL1Sequence(alts) && alts[0][0] && !dynamicTokensEnabled) {\n            const alt = alts[0];\n            const singleTokensTypes = flatten(alt);\n            if (singleTokensTypes.length === 1 &&\n                isEmpty(singleTokensTypes[0].categoryMatches)) {\n                const expectedTokenType = singleTokensTypes[0];\n                const expectedTokenUniqueKey = expectedTokenType.tokenTypeIdx;\n                return function () {\n                    return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey;\n                };\n            }\n            else {\n                const choiceToAlt = reduce(singleTokensTypes, (result, currTokType) => {\n                    if (currTokType !== undefined) {\n                        result[currTokType.tokenTypeIdx] = true;\n                        forEach(currTokType.categoryMatches, (currExtendingType) => {\n                            result[currExtendingType] = true;\n                        });\n                    }\n                    return result;\n                }, {});\n                return function () {\n                    const nextToken = this.LA(1);\n                    return choiceToAlt[nextToken.tokenTypeIdx] === true;\n                };\n            }\n        }\n        return function () {\n            const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging);\n            return typeof result === \"object\" ? false : result === 0;\n        };\n    }\n}\nfunction isLL1Sequence(sequences, allowEmpty = true) {\n    const fullSet = new Set();\n    for (const alt of sequences) {\n        const altSet = new Set();\n        for (const tokType of alt) {\n            if (tokType === undefined) {\n                if (allowEmpty) {\n                    // Epsilon production encountered\n                    break;\n                }\n                else {\n                    return false;\n                }\n            }\n            const indices = [tokType.tokenTypeIdx].concat(tokType.categoryMatches);\n            for (const index of indices) {\n                if (fullSet.has(index)) {\n                    if (!altSet.has(index)) {\n                        return false;\n                    }\n                }\n                else {\n                    fullSet.add(index);\n                    altSet.add(index);\n                }\n            }\n        }\n    }\n    return true;\n}\nfunction initATNSimulator(atn) {\n    const decisionLength = atn.decisionStates.length;\n    const decisionToDFA = Array(decisionLength);\n    for (let i = 0; i < decisionLength; i++) {\n        decisionToDFA[i] = createDFACache(atn.decisionStates[i], i);\n    }\n    return decisionToDFA;\n}\nfunction adaptivePredict(dfaCaches, decision, predicateSet, logging) {\n    const dfa = dfaCaches[decision](predicateSet);\n    let start = dfa.start;\n    if (start === undefined) {\n        const closure = computeStartState(dfa.atnStartState);\n        start = addDFAState(dfa, newDFAState(closure));\n        dfa.start = start;\n    }\n    const alt = performLookahead.apply(this, [dfa, start, predicateSet, logging]);\n    return alt;\n}\nfunction performLookahead(dfa, s0, predicateSet, logging) {\n    let previousD = s0;\n    let i = 1;\n    const path = [];\n    let t = this.LA(i++);\n    while (true) {\n        let d = getExistingTargetState(previousD, t);\n        if (d === undefined) {\n            d = computeLookaheadTarget.apply(this, [dfa, previousD, t, i, predicateSet, logging]);\n        }\n        if (d === DFA_ERROR) {\n            return buildAdaptivePredictError(path, previousD, t);\n        }\n        if (d.isAcceptState === true) {\n            return d.prediction;\n        }\n        previousD = d;\n        path.push(t);\n        t = this.LA(i++);\n    }\n}\nfunction computeLookaheadTarget(dfa, previousD, token, lookahead, predicateSet, logging) {\n    const reach = computeReachSet(previousD.configs, token, predicateSet);\n    if (reach.size === 0) {\n        addDFAEdge(dfa, previousD, token, DFA_ERROR);\n        return DFA_ERROR;\n    }\n    let newState = newDFAState(reach);\n    const predictedAlt = getUniqueAlt(reach, predicateSet);\n    if (predictedAlt !== undefined) {\n        newState.isAcceptState = true;\n        newState.prediction = predictedAlt;\n        newState.configs.uniqueAlt = predictedAlt;\n    }\n    else if (hasConflictTerminatingPrediction(reach)) {\n        const prediction = min(reach.alts);\n        newState.isAcceptState = true;\n        newState.prediction = prediction;\n        newState.configs.uniqueAlt = prediction;\n        reportLookaheadAmbiguity.apply(this, [dfa, lookahead, reach.alts, logging]);\n    }\n    newState = addDFAEdge(dfa, previousD, token, newState);\n    return newState;\n}\nfunction reportLookaheadAmbiguity(dfa, lookahead, ambiguityIndices, logging) {\n    const prefixPath = [];\n    for (let i = 1; i <= lookahead; i++) {\n        prefixPath.push(this.LA(i).tokenType);\n    }\n    const atnState = dfa.atnStartState;\n    const topLevelRule = atnState.rule;\n    const production = atnState.production;\n    const message = buildAmbiguityError({\n        topLevelRule,\n        ambiguityIndices,\n        production,\n        prefixPath\n    });\n    logging(message);\n}\nfunction buildAmbiguityError(options) {\n    const pathMsg = map(options.prefixPath, (currtok) => tokenLabel(currtok)).join(\", \");\n    const occurrence = options.production.idx === 0 ? \"\" : options.production.idx;\n    let currMessage = `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\", \")}> in <${getProductionDslName(options.production)}${occurrence}>` +\n        ` inside <${options.topLevelRule.name}> Rule,\\n` +\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n`;\n    currMessage =\n        currMessage +\n            `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\\n` +\n            `For Further details.`;\n    return currMessage;\n}\nfunction getProductionDslName(prod) {\n    if (prod instanceof NonTerminal) {\n        return \"SUBRULE\";\n    }\n    else if (prod instanceof Option) {\n        return \"OPTION\";\n    }\n    else if (prod instanceof Alternation) {\n        return \"OR\";\n    }\n    else if (prod instanceof RepetitionMandatory) {\n        return \"AT_LEAST_ONE\";\n    }\n    else if (prod instanceof RepetitionMandatoryWithSeparator) {\n        return \"AT_LEAST_ONE_SEP\";\n    }\n    else if (prod instanceof RepetitionWithSeparator) {\n        return \"MANY_SEP\";\n    }\n    else if (prod instanceof Repetition) {\n        return \"MANY\";\n    }\n    else if (prod instanceof Terminal) {\n        return \"CONSUME\";\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nfunction buildAdaptivePredictError(path, previous, current) {\n    const nextTransitions = flatMap(previous.configs.elements, (e) => e.state.transitions);\n    const nextTokenTypes = uniqBy(nextTransitions\n        .filter((e) => e instanceof AtomTransition)\n        .map((e) => e.tokenType), (e) => e.tokenTypeIdx);\n    return {\n        actualToken: current,\n        possibleTokenTypes: nextTokenTypes,\n        tokenPath: path\n    };\n}\nfunction getExistingTargetState(state, token) {\n    return state.edges[token.tokenTypeIdx];\n}\nfunction computeReachSet(configs, token, predicateSet) {\n    const intermediate = new ATNConfigSet();\n    const skippedStopStates = [];\n    for (const c of configs.elements) {\n        if (predicateSet.is(c.alt) === false) {\n            continue;\n        }\n        if (c.state.type === ATN_RULE_STOP) {\n            skippedStopStates.push(c);\n            continue;\n        }\n        const transitionLength = c.state.transitions.length;\n        for (let i = 0; i < transitionLength; i++) {\n            const transition = c.state.transitions[i];\n            const target = getReachableTarget(transition, token);\n            if (target !== undefined) {\n                intermediate.add({\n                    state: target,\n                    alt: c.alt,\n                    stack: c.stack\n                });\n            }\n        }\n    }\n    let reach;\n    if (skippedStopStates.length === 0 && intermediate.size === 1) {\n        reach = intermediate;\n    }\n    if (reach === undefined) {\n        reach = new ATNConfigSet();\n        for (const c of intermediate.elements) {\n            closure(c, reach);\n        }\n    }\n    if (skippedStopStates.length > 0 && !hasConfigInRuleStopState(reach)) {\n        for (const c of skippedStopStates) {\n            reach.add(c);\n        }\n    }\n    return reach;\n}\nfunction getReachableTarget(transition, token) {\n    if (transition instanceof AtomTransition &&\n        tokenMatcher(token, transition.tokenType)) {\n        return transition.target;\n    }\n    return undefined;\n}\nfunction getUniqueAlt(configs, predicateSet) {\n    let alt;\n    for (const c of configs.elements) {\n        if (predicateSet.is(c.alt) === true) {\n            if (alt === undefined) {\n                alt = c.alt;\n            }\n            else if (alt !== c.alt) {\n                return undefined;\n            }\n        }\n    }\n    return alt;\n}\nfunction newDFAState(closure) {\n    return {\n        configs: closure,\n        edges: {},\n        isAcceptState: false,\n        prediction: -1\n    };\n}\nfunction addDFAEdge(dfa, from, token, to) {\n    to = addDFAState(dfa, to);\n    from.edges[token.tokenTypeIdx] = to;\n    return to;\n}\nfunction addDFAState(dfa, state) {\n    if (state === DFA_ERROR) {\n        return state;\n    }\n    // Repetitions have the same config set\n    // Therefore, storing the key of the config in a map allows us to create a loop in our DFA\n    const mapKey = state.configs.key;\n    const existing = dfa.states[mapKey];\n    if (existing !== undefined) {\n        return existing;\n    }\n    state.configs.finalize();\n    dfa.states[mapKey] = state;\n    return state;\n}\nfunction computeStartState(atnState) {\n    const configs = new ATNConfigSet();\n    const numberOfTransitions = atnState.transitions.length;\n    for (let i = 0; i < numberOfTransitions; i++) {\n        const target = atnState.transitions[i].target;\n        const config = {\n            state: target,\n            alt: i,\n            stack: []\n        };\n        closure(config, configs);\n    }\n    return configs;\n}\nfunction closure(config, configs) {\n    const p = config.state;\n    if (p.type === ATN_RULE_STOP) {\n        if (config.stack.length > 0) {\n            const atnStack = [...config.stack];\n            const followState = atnStack.pop();\n            const followConfig = {\n                state: followState,\n                alt: config.alt,\n                stack: atnStack\n            };\n            closure(followConfig, configs);\n        }\n        else {\n            // Dipping into outer context, simply add the config\n            // This will stop computation once every config is at the rule stop state\n            configs.add(config);\n        }\n        return;\n    }\n    if (!p.epsilonOnlyTransitions) {\n        configs.add(config);\n    }\n    const transitionLength = p.transitions.length;\n    for (let i = 0; i < transitionLength; i++) {\n        const transition = p.transitions[i];\n        const c = getEpsilonTarget(config, transition);\n        if (c !== undefined) {\n            closure(c, configs);\n        }\n    }\n}\nfunction getEpsilonTarget(config, transition) {\n    if (transition instanceof EpsilonTransition) {\n        return {\n            state: transition.target,\n            alt: config.alt,\n            stack: config.stack\n        };\n    }\n    else if (transition instanceof RuleTransition) {\n        const stack = [...config.stack, transition.followState];\n        return {\n            state: transition.target,\n            alt: config.alt,\n            stack\n        };\n    }\n    return undefined;\n}\nfunction hasConfigInRuleStopState(configs) {\n    for (const c of configs.elements) {\n        if (c.state.type === ATN_RULE_STOP) {\n            return true;\n        }\n    }\n    return false;\n}\nfunction allConfigsInRuleStopStates(configs) {\n    for (const c of configs.elements) {\n        if (c.state.type !== ATN_RULE_STOP) {\n            return false;\n        }\n    }\n    return true;\n}\nfunction hasConflictTerminatingPrediction(configs) {\n    if (allConfigsInRuleStopStates(configs)) {\n        return true;\n    }\n    const altSets = getConflictingAltSets(configs.elements);\n    const heuristic = hasConflictingAltSet(altSets) && !hasStateAssociatedWithOneAlt(altSets);\n    return heuristic;\n}\nfunction getConflictingAltSets(configs) {\n    const configToAlts = new Map();\n    for (const c of configs) {\n        const key = getATNConfigKey(c, false);\n        let alts = configToAlts.get(key);\n        if (alts === undefined) {\n            alts = {};\n            configToAlts.set(key, alts);\n        }\n        alts[c.alt] = true;\n    }\n    return configToAlts;\n}\nfunction hasConflictingAltSet(altSets) {\n    for (const value of Array.from(altSets.values())) {\n        if (Object.keys(value).length > 1) {\n            return true;\n        }\n    }\n    return false;\n}\nfunction hasStateAssociatedWithOneAlt(altSets) {\n    for (const value of Array.from(altSets.values())) {\n        if (Object.keys(value).length === 1) {\n            return true;\n        }\n    }\n    return false;\n}\n//# sourceMappingURL=all-star-lookahead.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport { LLStarLookaheadStrategy } from './all-star-lookahead.js';\n//# sourceMappingURL=index.js.map","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\n'use strict';\nexport var DocumentUri;\n(function (DocumentUri) {\n    function is(value) {\n        return typeof value === 'string';\n    }\n    DocumentUri.is = is;\n})(DocumentUri || (DocumentUri = {}));\nexport var URI;\n(function (URI) {\n    function is(value) {\n        return typeof value === 'string';\n    }\n    URI.is = is;\n})(URI || (URI = {}));\nexport var integer;\n(function (integer) {\n    integer.MIN_VALUE = -2147483648;\n    integer.MAX_VALUE = 2147483647;\n    function is(value) {\n        return typeof value === 'number' && integer.MIN_VALUE <= value && value <= integer.MAX_VALUE;\n    }\n    integer.is = is;\n})(integer || (integer = {}));\nexport var uinteger;\n(function (uinteger) {\n    uinteger.MIN_VALUE = 0;\n    uinteger.MAX_VALUE = 2147483647;\n    function is(value) {\n        return typeof value === 'number' && uinteger.MIN_VALUE <= value && value <= uinteger.MAX_VALUE;\n    }\n    uinteger.is = is;\n})(uinteger || (uinteger = {}));\n/**\n * The Position namespace provides helper functions to work with\n * {@link Position} literals.\n */\nexport var Position;\n(function (Position) {\n    /**\n     * Creates a new Position literal from the given line and character.\n     * @param line The position's line.\n     * @param character The position's character.\n     */\n    function create(line, character) {\n        if (line === Number.MAX_VALUE) {\n            line = uinteger.MAX_VALUE;\n        }\n        if (character === Number.MAX_VALUE) {\n            character = uinteger.MAX_VALUE;\n        }\n        return { line, character };\n    }\n    Position.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Position} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Is.uinteger(candidate.line) && Is.uinteger(candidate.character);\n    }\n    Position.is = is;\n})(Position || (Position = {}));\n/**\n * The Range namespace provides helper functions to work with\n * {@link Range} literals.\n */\nexport var Range;\n(function (Range) {\n    function create(one, two, three, four) {\n        if (Is.uinteger(one) && Is.uinteger(two) && Is.uinteger(three) && Is.uinteger(four)) {\n            return { start: Position.create(one, two), end: Position.create(three, four) };\n        }\n        else if (Position.is(one) && Position.is(two)) {\n            return { start: one, end: two };\n        }\n        else {\n            throw new Error(`Range#create called with invalid arguments[${one}, ${two}, ${three}, ${four}]`);\n        }\n    }\n    Range.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Range} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Position.is(candidate.start) && Position.is(candidate.end);\n    }\n    Range.is = is;\n})(Range || (Range = {}));\n/**\n * The Location namespace provides helper functions to work with\n * {@link Location} literals.\n */\nexport var Location;\n(function (Location) {\n    /**\n     * Creates a Location literal.\n     * @param uri The location's uri.\n     * @param range The location's range.\n     */\n    function create(uri, range) {\n        return { uri, range };\n    }\n    Location.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Location} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && (Is.string(candidate.uri) || Is.undefined(candidate.uri));\n    }\n    Location.is = is;\n})(Location || (Location = {}));\n/**\n * The LocationLink namespace provides helper functions to work with\n * {@link LocationLink} literals.\n */\nexport var LocationLink;\n(function (LocationLink) {\n    /**\n     * Creates a LocationLink literal.\n     * @param targetUri The definition's uri.\n     * @param targetRange The full range of the definition.\n     * @param targetSelectionRange The span of the symbol definition at the target.\n     * @param originSelectionRange The span of the symbol being defined in the originating source file.\n     */\n    function create(targetUri, targetRange, targetSelectionRange, originSelectionRange) {\n        return { targetUri, targetRange, targetSelectionRange, originSelectionRange };\n    }\n    LocationLink.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link LocationLink} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.targetRange) && Is.string(candidate.targetUri)\n            && Range.is(candidate.targetSelectionRange)\n            && (Range.is(candidate.originSelectionRange) || Is.undefined(candidate.originSelectionRange));\n    }\n    LocationLink.is = is;\n})(LocationLink || (LocationLink = {}));\n/**\n * The Color namespace provides helper functions to work with\n * {@link Color} literals.\n */\nexport var Color;\n(function (Color) {\n    /**\n     * Creates a new Color literal.\n     */\n    function create(red, green, blue, alpha) {\n        return {\n            red,\n            green,\n            blue,\n            alpha,\n        };\n    }\n    Color.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Color} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.numberRange(candidate.red, 0, 1)\n            && Is.numberRange(candidate.green, 0, 1)\n            && Is.numberRange(candidate.blue, 0, 1)\n            && Is.numberRange(candidate.alpha, 0, 1);\n    }\n    Color.is = is;\n})(Color || (Color = {}));\n/**\n * The ColorInformation namespace provides helper functions to work with\n * {@link ColorInformation} literals.\n */\nexport var ColorInformation;\n(function (ColorInformation) {\n    /**\n     * Creates a new ColorInformation literal.\n     */\n    function create(range, color) {\n        return {\n            range,\n            color,\n        };\n    }\n    ColorInformation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ColorInformation} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && Color.is(candidate.color);\n    }\n    ColorInformation.is = is;\n})(ColorInformation || (ColorInformation = {}));\n/**\n * The Color namespace provides helper functions to work with\n * {@link ColorPresentation} literals.\n */\nexport var ColorPresentation;\n(function (ColorPresentation) {\n    /**\n     * Creates a new ColorInformation literal.\n     */\n    function create(label, textEdit, additionalTextEdits) {\n        return {\n            label,\n            textEdit,\n            additionalTextEdits,\n        };\n    }\n    ColorPresentation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ColorInformation} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.label)\n            && (Is.undefined(candidate.textEdit) || TextEdit.is(candidate))\n            && (Is.undefined(candidate.additionalTextEdits) || Is.typedArray(candidate.additionalTextEdits, TextEdit.is));\n    }\n    ColorPresentation.is = is;\n})(ColorPresentation || (ColorPresentation = {}));\n/**\n * A set of predefined range kinds.\n */\nexport var FoldingRangeKind;\n(function (FoldingRangeKind) {\n    /**\n     * Folding range for a comment\n     */\n    FoldingRangeKind.Comment = 'comment';\n    /**\n     * Folding range for an import or include\n     */\n    FoldingRangeKind.Imports = 'imports';\n    /**\n     * Folding range for a region (e.g. `#region`)\n     */\n    FoldingRangeKind.Region = 'region';\n})(FoldingRangeKind || (FoldingRangeKind = {}));\n/**\n * The folding range namespace provides helper functions to work with\n * {@link FoldingRange} literals.\n */\nexport var FoldingRange;\n(function (FoldingRange) {\n    /**\n     * Creates a new FoldingRange literal.\n     */\n    function create(startLine, endLine, startCharacter, endCharacter, kind, collapsedText) {\n        const result = {\n            startLine,\n            endLine\n        };\n        if (Is.defined(startCharacter)) {\n            result.startCharacter = startCharacter;\n        }\n        if (Is.defined(endCharacter)) {\n            result.endCharacter = endCharacter;\n        }\n        if (Is.defined(kind)) {\n            result.kind = kind;\n        }\n        if (Is.defined(collapsedText)) {\n            result.collapsedText = collapsedText;\n        }\n        return result;\n    }\n    FoldingRange.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link FoldingRange} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.uinteger(candidate.startLine) && Is.uinteger(candidate.startLine)\n            && (Is.undefined(candidate.startCharacter) || Is.uinteger(candidate.startCharacter))\n            && (Is.undefined(candidate.endCharacter) || Is.uinteger(candidate.endCharacter))\n            && (Is.undefined(candidate.kind) || Is.string(candidate.kind));\n    }\n    FoldingRange.is = is;\n})(FoldingRange || (FoldingRange = {}));\n/**\n * The DiagnosticRelatedInformation namespace provides helper functions to work with\n * {@link DiagnosticRelatedInformation} literals.\n */\nexport var DiagnosticRelatedInformation;\n(function (DiagnosticRelatedInformation) {\n    /**\n     * Creates a new DiagnosticRelatedInformation literal.\n     */\n    function create(location, message) {\n        return {\n            location,\n            message\n        };\n    }\n    DiagnosticRelatedInformation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DiagnosticRelatedInformation} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Location.is(candidate.location) && Is.string(candidate.message);\n    }\n    DiagnosticRelatedInformation.is = is;\n})(DiagnosticRelatedInformation || (DiagnosticRelatedInformation = {}));\n/**\n * The diagnostic's severity.\n */\nexport var DiagnosticSeverity;\n(function (DiagnosticSeverity) {\n    /**\n     * Reports an error.\n     */\n    DiagnosticSeverity.Error = 1;\n    /**\n     * Reports a warning.\n     */\n    DiagnosticSeverity.Warning = 2;\n    /**\n     * Reports an information.\n     */\n    DiagnosticSeverity.Information = 3;\n    /**\n     * Reports a hint.\n     */\n    DiagnosticSeverity.Hint = 4;\n})(DiagnosticSeverity || (DiagnosticSeverity = {}));\n/**\n * The diagnostic tags.\n *\n * @since 3.15.0\n */\nexport var DiagnosticTag;\n(function (DiagnosticTag) {\n    /**\n     * Unused or unnecessary code.\n     *\n     * Clients are allowed to render diagnostics with this tag faded out instead of having\n     * an error squiggle.\n     */\n    DiagnosticTag.Unnecessary = 1;\n    /**\n     * Deprecated or obsolete code.\n     *\n     * Clients are allowed to rendered diagnostics with this tag strike through.\n     */\n    DiagnosticTag.Deprecated = 2;\n})(DiagnosticTag || (DiagnosticTag = {}));\n/**\n * The CodeDescription namespace provides functions to deal with descriptions for diagnostic codes.\n *\n * @since 3.16.0\n */\nexport var CodeDescription;\n(function (CodeDescription) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.href);\n    }\n    CodeDescription.is = is;\n})(CodeDescription || (CodeDescription = {}));\n/**\n * The Diagnostic namespace provides helper functions to work with\n * {@link Diagnostic} literals.\n */\nexport var Diagnostic;\n(function (Diagnostic) {\n    /**\n     * Creates a new Diagnostic literal.\n     */\n    function create(range, message, severity, code, source, relatedInformation) {\n        let result = { range, message };\n        if (Is.defined(severity)) {\n            result.severity = severity;\n        }\n        if (Is.defined(code)) {\n            result.code = code;\n        }\n        if (Is.defined(source)) {\n            result.source = source;\n        }\n        if (Is.defined(relatedInformation)) {\n            result.relatedInformation = relatedInformation;\n        }\n        return result;\n    }\n    Diagnostic.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Diagnostic} interface.\n     */\n    function is(value) {\n        var _a;\n        let candidate = value;\n        return Is.defined(candidate)\n            && Range.is(candidate.range)\n            && Is.string(candidate.message)\n            && (Is.number(candidate.severity) || Is.undefined(candidate.severity))\n            && (Is.integer(candidate.code) || Is.string(candidate.code) || Is.undefined(candidate.code))\n            && (Is.undefined(candidate.codeDescription) || (Is.string((_a = candidate.codeDescription) === null || _a === void 0 ? void 0 : _a.href)))\n            && (Is.string(candidate.source) || Is.undefined(candidate.source))\n            && (Is.undefined(candidate.relatedInformation) || Is.typedArray(candidate.relatedInformation, DiagnosticRelatedInformation.is));\n    }\n    Diagnostic.is = is;\n})(Diagnostic || (Diagnostic = {}));\n/**\n * The Command namespace provides helper functions to work with\n * {@link Command} literals.\n */\nexport var Command;\n(function (Command) {\n    /**\n     * Creates a new Command literal.\n     */\n    function create(title, command, ...args) {\n        let result = { title, command };\n        if (Is.defined(args) && args.length > 0) {\n            result.arguments = args;\n        }\n        return result;\n    }\n    Command.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Command} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.title) && Is.string(candidate.command);\n    }\n    Command.is = is;\n})(Command || (Command = {}));\n/**\n * The TextEdit namespace provides helper function to create replace,\n * insert and delete edits more easily.\n */\nexport var TextEdit;\n(function (TextEdit) {\n    /**\n     * Creates a replace text edit.\n     * @param range The range of text to be replaced.\n     * @param newText The new text.\n     */\n    function replace(range, newText) {\n        return { range, newText };\n    }\n    TextEdit.replace = replace;\n    /**\n     * Creates an insert text edit.\n     * @param position The position to insert the text at.\n     * @param newText The text to be inserted.\n     */\n    function insert(position, newText) {\n        return { range: { start: position, end: position }, newText };\n    }\n    TextEdit.insert = insert;\n    /**\n     * Creates a delete text edit.\n     * @param range The range of text to be deleted.\n     */\n    function del(range) {\n        return { range, newText: '' };\n    }\n    TextEdit.del = del;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate)\n            && Is.string(candidate.newText)\n            && Range.is(candidate.range);\n    }\n    TextEdit.is = is;\n})(TextEdit || (TextEdit = {}));\nexport var ChangeAnnotation;\n(function (ChangeAnnotation) {\n    function create(label, needsConfirmation, description) {\n        const result = { label };\n        if (needsConfirmation !== undefined) {\n            result.needsConfirmation = needsConfirmation;\n        }\n        if (description !== undefined) {\n            result.description = description;\n        }\n        return result;\n    }\n    ChangeAnnotation.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.label) &&\n            (Is.boolean(candidate.needsConfirmation) || candidate.needsConfirmation === undefined) &&\n            (Is.string(candidate.description) || candidate.description === undefined);\n    }\n    ChangeAnnotation.is = is;\n})(ChangeAnnotation || (ChangeAnnotation = {}));\nexport var ChangeAnnotationIdentifier;\n(function (ChangeAnnotationIdentifier) {\n    function is(value) {\n        const candidate = value;\n        return Is.string(candidate);\n    }\n    ChangeAnnotationIdentifier.is = is;\n})(ChangeAnnotationIdentifier || (ChangeAnnotationIdentifier = {}));\nexport var AnnotatedTextEdit;\n(function (AnnotatedTextEdit) {\n    /**\n     * Creates an annotated replace text edit.\n     *\n     * @param range The range of text to be replaced.\n     * @param newText The new text.\n     * @param annotation The annotation.\n     */\n    function replace(range, newText, annotation) {\n        return { range, newText, annotationId: annotation };\n    }\n    AnnotatedTextEdit.replace = replace;\n    /**\n     * Creates an annotated insert text edit.\n     *\n     * @param position The position to insert the text at.\n     * @param newText The text to be inserted.\n     * @param annotation The annotation.\n     */\n    function insert(position, newText, annotation) {\n        return { range: { start: position, end: position }, newText, annotationId: annotation };\n    }\n    AnnotatedTextEdit.insert = insert;\n    /**\n     * Creates an annotated delete text edit.\n     *\n     * @param range The range of text to be deleted.\n     * @param annotation The annotation.\n     */\n    function del(range, annotation) {\n        return { range, newText: '', annotationId: annotation };\n    }\n    AnnotatedTextEdit.del = del;\n    function is(value) {\n        const candidate = value;\n        return TextEdit.is(candidate) && (ChangeAnnotation.is(candidate.annotationId) || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    AnnotatedTextEdit.is = is;\n})(AnnotatedTextEdit || (AnnotatedTextEdit = {}));\n/**\n * The TextDocumentEdit namespace provides helper function to create\n * an edit that manipulates a text document.\n */\nexport var TextDocumentEdit;\n(function (TextDocumentEdit) {\n    /**\n     * Creates a new `TextDocumentEdit`\n     */\n    function create(textDocument, edits) {\n        return { textDocument, edits };\n    }\n    TextDocumentEdit.create = create;\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate)\n            && OptionalVersionedTextDocumentIdentifier.is(candidate.textDocument)\n            && Array.isArray(candidate.edits);\n    }\n    TextDocumentEdit.is = is;\n})(TextDocumentEdit || (TextDocumentEdit = {}));\nexport var CreateFile;\n(function (CreateFile) {\n    function create(uri, options, annotation) {\n        let result = {\n            kind: 'create',\n            uri\n        };\n        if (options !== undefined && (options.overwrite !== undefined || options.ignoreIfExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    CreateFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'create' && Is.string(candidate.uri) && (candidate.options === undefined ||\n            ((candidate.options.overwrite === undefined || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === undefined || Is.boolean(candidate.options.ignoreIfExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    CreateFile.is = is;\n})(CreateFile || (CreateFile = {}));\nexport var RenameFile;\n(function (RenameFile) {\n    function create(oldUri, newUri, options, annotation) {\n        let result = {\n            kind: 'rename',\n            oldUri,\n            newUri\n        };\n        if (options !== undefined && (options.overwrite !== undefined || options.ignoreIfExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    RenameFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'rename' && Is.string(candidate.oldUri) && Is.string(candidate.newUri) && (candidate.options === undefined ||\n            ((candidate.options.overwrite === undefined || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === undefined || Is.boolean(candidate.options.ignoreIfExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    RenameFile.is = is;\n})(RenameFile || (RenameFile = {}));\nexport var DeleteFile;\n(function (DeleteFile) {\n    function create(uri, options, annotation) {\n        let result = {\n            kind: 'delete',\n            uri\n        };\n        if (options !== undefined && (options.recursive !== undefined || options.ignoreIfNotExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    DeleteFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'delete' && Is.string(candidate.uri) && (candidate.options === undefined ||\n            ((candidate.options.recursive === undefined || Is.boolean(candidate.options.recursive)) && (candidate.options.ignoreIfNotExists === undefined || Is.boolean(candidate.options.ignoreIfNotExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    DeleteFile.is = is;\n})(DeleteFile || (DeleteFile = {}));\nexport var WorkspaceEdit;\n(function (WorkspaceEdit) {\n    function is(value) {\n        let candidate = value;\n        return candidate &&\n            (candidate.changes !== undefined || candidate.documentChanges !== undefined) &&\n            (candidate.documentChanges === undefined || candidate.documentChanges.every((change) => {\n                if (Is.string(change.kind)) {\n                    return CreateFile.is(change) || RenameFile.is(change) || DeleteFile.is(change);\n                }\n                else {\n                    return TextDocumentEdit.is(change);\n                }\n            }));\n    }\n    WorkspaceEdit.is = is;\n})(WorkspaceEdit || (WorkspaceEdit = {}));\nclass TextEditChangeImpl {\n    constructor(edits, changeAnnotations) {\n        this.edits = edits;\n        this.changeAnnotations = changeAnnotations;\n    }\n    insert(position, newText, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.insert(position, newText);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.insert(position, newText, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.insert(position, newText, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    replace(range, newText, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.replace(range, newText);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.replace(range, newText, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.replace(range, newText, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    delete(range, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.del(range);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.del(range, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.del(range, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    add(edit) {\n        this.edits.push(edit);\n    }\n    all() {\n        return this.edits;\n    }\n    clear() {\n        this.edits.splice(0, this.edits.length);\n    }\n    assertChangeAnnotations(value) {\n        if (value === undefined) {\n            throw new Error(`Text edit change is not configured to manage change annotations.`);\n        }\n    }\n}\n/**\n * A helper class\n */\nclass ChangeAnnotations {\n    constructor(annotations) {\n        this._annotations = annotations === undefined ? Object.create(null) : annotations;\n        this._counter = 0;\n        this._size = 0;\n    }\n    all() {\n        return this._annotations;\n    }\n    get size() {\n        return this._size;\n    }\n    manage(idOrAnnotation, annotation) {\n        let id;\n        if (ChangeAnnotationIdentifier.is(idOrAnnotation)) {\n            id = idOrAnnotation;\n        }\n        else {\n            id = this.nextId();\n            annotation = idOrAnnotation;\n        }\n        if (this._annotations[id] !== undefined) {\n            throw new Error(`Id ${id} is already in use.`);\n        }\n        if (annotation === undefined) {\n            throw new Error(`No annotation provided for id ${id}`);\n        }\n        this._annotations[id] = annotation;\n        this._size++;\n        return id;\n    }\n    nextId() {\n        this._counter++;\n        return this._counter.toString();\n    }\n}\n/**\n * A workspace change helps constructing changes to a workspace.\n */\nexport class WorkspaceChange {\n    constructor(workspaceEdit) {\n        this._textEditChanges = Object.create(null);\n        if (workspaceEdit !== undefined) {\n            this._workspaceEdit = workspaceEdit;\n            if (workspaceEdit.documentChanges) {\n                this._changeAnnotations = new ChangeAnnotations(workspaceEdit.changeAnnotations);\n                workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n                workspaceEdit.documentChanges.forEach((change) => {\n                    if (TextDocumentEdit.is(change)) {\n                        const textEditChange = new TextEditChangeImpl(change.edits, this._changeAnnotations);\n                        this._textEditChanges[change.textDocument.uri] = textEditChange;\n                    }\n                });\n            }\n            else if (workspaceEdit.changes) {\n                Object.keys(workspaceEdit.changes).forEach((key) => {\n                    const textEditChange = new TextEditChangeImpl(workspaceEdit.changes[key]);\n                    this._textEditChanges[key] = textEditChange;\n                });\n            }\n        }\n        else {\n            this._workspaceEdit = {};\n        }\n    }\n    /**\n     * Returns the underlying {@link WorkspaceEdit} literal\n     * use to be returned from a workspace edit operation like rename.\n     */\n    get edit() {\n        this.initDocumentChanges();\n        if (this._changeAnnotations !== undefined) {\n            if (this._changeAnnotations.size === 0) {\n                this._workspaceEdit.changeAnnotations = undefined;\n            }\n            else {\n                this._workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n            }\n        }\n        return this._workspaceEdit;\n    }\n    getTextEditChange(key) {\n        if (OptionalVersionedTextDocumentIdentifier.is(key)) {\n            this.initDocumentChanges();\n            if (this._workspaceEdit.documentChanges === undefined) {\n                throw new Error('Workspace edit is not configured for document changes.');\n            }\n            const textDocument = { uri: key.uri, version: key.version };\n            let result = this._textEditChanges[textDocument.uri];\n            if (!result) {\n                const edits = [];\n                const textDocumentEdit = {\n                    textDocument,\n                    edits\n                };\n                this._workspaceEdit.documentChanges.push(textDocumentEdit);\n                result = new TextEditChangeImpl(edits, this._changeAnnotations);\n                this._textEditChanges[textDocument.uri] = result;\n            }\n            return result;\n        }\n        else {\n            this.initChanges();\n            if (this._workspaceEdit.changes === undefined) {\n                throw new Error('Workspace edit is not configured for normal text edit changes.');\n            }\n            let result = this._textEditChanges[key];\n            if (!result) {\n                let edits = [];\n                this._workspaceEdit.changes[key] = edits;\n                result = new TextEditChangeImpl(edits);\n                this._textEditChanges[key] = result;\n            }\n            return result;\n        }\n    }\n    initDocumentChanges() {\n        if (this._workspaceEdit.documentChanges === undefined && this._workspaceEdit.changes === undefined) {\n            this._changeAnnotations = new ChangeAnnotations();\n            this._workspaceEdit.documentChanges = [];\n            this._workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n        }\n    }\n    initChanges() {\n        if (this._workspaceEdit.documentChanges === undefined && this._workspaceEdit.changes === undefined) {\n            this._workspaceEdit.changes = Object.create(null);\n        }\n    }\n    createFile(uri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = CreateFile.create(uri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = CreateFile.create(uri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    renameFile(oldUri, newUri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = RenameFile.create(oldUri, newUri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = RenameFile.create(oldUri, newUri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    deleteFile(uri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = DeleteFile.create(uri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = DeleteFile.create(uri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n}\n/**\n * The TextDocumentIdentifier namespace provides helper functions to work with\n * {@link TextDocumentIdentifier} literals.\n */\nexport var TextDocumentIdentifier;\n(function (TextDocumentIdentifier) {\n    /**\n     * Creates a new TextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     */\n    function create(uri) {\n        return { uri };\n    }\n    TextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link TextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri);\n    }\n    TextDocumentIdentifier.is = is;\n})(TextDocumentIdentifier || (TextDocumentIdentifier = {}));\n/**\n * The VersionedTextDocumentIdentifier namespace provides helper functions to work with\n * {@link VersionedTextDocumentIdentifier} literals.\n */\nexport var VersionedTextDocumentIdentifier;\n(function (VersionedTextDocumentIdentifier) {\n    /**\n     * Creates a new VersionedTextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     * @param version The document's version.\n     */\n    function create(uri, version) {\n        return { uri, version };\n    }\n    VersionedTextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link VersionedTextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && Is.integer(candidate.version);\n    }\n    VersionedTextDocumentIdentifier.is = is;\n})(VersionedTextDocumentIdentifier || (VersionedTextDocumentIdentifier = {}));\n/**\n * The OptionalVersionedTextDocumentIdentifier namespace provides helper functions to work with\n * {@link OptionalVersionedTextDocumentIdentifier} literals.\n */\nexport var OptionalVersionedTextDocumentIdentifier;\n(function (OptionalVersionedTextDocumentIdentifier) {\n    /**\n     * Creates a new OptionalVersionedTextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     * @param version The document's version.\n     */\n    function create(uri, version) {\n        return { uri, version };\n    }\n    OptionalVersionedTextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link OptionalVersionedTextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && (candidate.version === null || Is.integer(candidate.version));\n    }\n    OptionalVersionedTextDocumentIdentifier.is = is;\n})(OptionalVersionedTextDocumentIdentifier || (OptionalVersionedTextDocumentIdentifier = {}));\n/**\n * The TextDocumentItem namespace provides helper functions to work with\n * {@link TextDocumentItem} literals.\n */\nexport var TextDocumentItem;\n(function (TextDocumentItem) {\n    /**\n     * Creates a new TextDocumentItem literal.\n     * @param uri The document's uri.\n     * @param languageId The document's language identifier.\n     * @param version The document's version number.\n     * @param text The document's text.\n     */\n    function create(uri, languageId, version, text) {\n        return { uri, languageId, version, text };\n    }\n    TextDocumentItem.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link TextDocumentItem} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && Is.string(candidate.languageId) && Is.integer(candidate.version) && Is.string(candidate.text);\n    }\n    TextDocumentItem.is = is;\n})(TextDocumentItem || (TextDocumentItem = {}));\n/**\n * Describes the content type that a client supports in various\n * result literals like `Hover`, `ParameterInfo` or `CompletionItem`.\n *\n * Please note that `MarkupKinds` must not start with a `$`. This kinds\n * are reserved for internal usage.\n */\nexport var MarkupKind;\n(function (MarkupKind) {\n    /**\n     * Plain text is supported as a content format\n     */\n    MarkupKind.PlainText = 'plaintext';\n    /**\n     * Markdown is supported as a content format\n     */\n    MarkupKind.Markdown = 'markdown';\n    /**\n     * Checks whether the given value is a value of the {@link MarkupKind} type.\n     */\n    function is(value) {\n        const candidate = value;\n        return candidate === MarkupKind.PlainText || candidate === MarkupKind.Markdown;\n    }\n    MarkupKind.is = is;\n})(MarkupKind || (MarkupKind = {}));\nexport var MarkupContent;\n(function (MarkupContent) {\n    /**\n     * Checks whether the given value conforms to the {@link MarkupContent} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(value) && MarkupKind.is(candidate.kind) && Is.string(candidate.value);\n    }\n    MarkupContent.is = is;\n})(MarkupContent || (MarkupContent = {}));\n/**\n * The kind of a completion entry.\n */\nexport var CompletionItemKind;\n(function (CompletionItemKind) {\n    CompletionItemKind.Text = 1;\n    CompletionItemKind.Method = 2;\n    CompletionItemKind.Function = 3;\n    CompletionItemKind.Constructor = 4;\n    CompletionItemKind.Field = 5;\n    CompletionItemKind.Variable = 6;\n    CompletionItemKind.Class = 7;\n    CompletionItemKind.Interface = 8;\n    CompletionItemKind.Module = 9;\n    CompletionItemKind.Property = 10;\n    CompletionItemKind.Unit = 11;\n    CompletionItemKind.Value = 12;\n    CompletionItemKind.Enum = 13;\n    CompletionItemKind.Keyword = 14;\n    CompletionItemKind.Snippet = 15;\n    CompletionItemKind.Color = 16;\n    CompletionItemKind.File = 17;\n    CompletionItemKind.Reference = 18;\n    CompletionItemKind.Folder = 19;\n    CompletionItemKind.EnumMember = 20;\n    CompletionItemKind.Constant = 21;\n    CompletionItemKind.Struct = 22;\n    CompletionItemKind.Event = 23;\n    CompletionItemKind.Operator = 24;\n    CompletionItemKind.TypeParameter = 25;\n})(CompletionItemKind || (CompletionItemKind = {}));\n/**\n * Defines whether the insert text in a completion item should be interpreted as\n * plain text or a snippet.\n */\nexport var InsertTextFormat;\n(function (InsertTextFormat) {\n    /**\n     * The primary text to be inserted is treated as a plain string.\n     */\n    InsertTextFormat.PlainText = 1;\n    /**\n     * The primary text to be inserted is treated as a snippet.\n     *\n     * A snippet can define tab stops and placeholders with `$1`, `$2`\n     * and `${3:foo}`. `$0` defines the final tab stop, it defaults to\n     * the end of the snippet. Placeholders with equal identifiers are linked,\n     * that is typing in one will update others too.\n     *\n     * See also: https://microsoft.github.io/language-server-protocol/specifications/specification-current/#snippet_syntax\n     */\n    InsertTextFormat.Snippet = 2;\n})(InsertTextFormat || (InsertTextFormat = {}));\n/**\n * Completion item tags are extra annotations that tweak the rendering of a completion\n * item.\n *\n * @since 3.15.0\n */\nexport var CompletionItemTag;\n(function (CompletionItemTag) {\n    /**\n     * Render a completion as obsolete, usually using a strike-out.\n     */\n    CompletionItemTag.Deprecated = 1;\n})(CompletionItemTag || (CompletionItemTag = {}));\n/**\n * The InsertReplaceEdit namespace provides functions to deal with insert / replace edits.\n *\n * @since 3.16.0\n */\nexport var InsertReplaceEdit;\n(function (InsertReplaceEdit) {\n    /**\n     * Creates a new insert / replace edit\n     */\n    function create(newText, insert, replace) {\n        return { newText, insert, replace };\n    }\n    InsertReplaceEdit.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link InsertReplaceEdit} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return candidate && Is.string(candidate.newText) && Range.is(candidate.insert) && Range.is(candidate.replace);\n    }\n    InsertReplaceEdit.is = is;\n})(InsertReplaceEdit || (InsertReplaceEdit = {}));\n/**\n * How whitespace and indentation is handled during completion\n * item insertion.\n *\n * @since 3.16.0\n */\nexport var InsertTextMode;\n(function (InsertTextMode) {\n    /**\n     * The insertion or replace strings is taken as it is. If the\n     * value is multi line the lines below the cursor will be\n     * inserted using the indentation defined in the string value.\n     * The client will not apply any kind of adjustments to the\n     * string.\n     */\n    InsertTextMode.asIs = 1;\n    /**\n     * The editor adjusts leading whitespace of new lines so that\n     * they match the indentation up to the cursor of the line for\n     * which the item is accepted.\n     *\n     * Consider a line like this: <2tabs><cursor><3tabs>foo. Accepting a\n     * multi line completion item is indented using 2 tabs and all\n     * following lines inserted will be indented using 2 tabs as well.\n     */\n    InsertTextMode.adjustIndentation = 2;\n})(InsertTextMode || (InsertTextMode = {}));\nexport var CompletionItemLabelDetails;\n(function (CompletionItemLabelDetails) {\n    function is(value) {\n        const candidate = value;\n        return candidate && (Is.string(candidate.detail) || candidate.detail === undefined) &&\n            (Is.string(candidate.description) || candidate.description === undefined);\n    }\n    CompletionItemLabelDetails.is = is;\n})(CompletionItemLabelDetails || (CompletionItemLabelDetails = {}));\n/**\n * The CompletionItem namespace provides functions to deal with\n * completion items.\n */\nexport var CompletionItem;\n(function (CompletionItem) {\n    /**\n     * Create a completion item and seed it with a label.\n     * @param label The completion item's label\n     */\n    function create(label) {\n        return { label };\n    }\n    CompletionItem.create = create;\n})(CompletionItem || (CompletionItem = {}));\n/**\n * The CompletionList namespace provides functions to deal with\n * completion lists.\n */\nexport var CompletionList;\n(function (CompletionList) {\n    /**\n     * Creates a new completion list.\n     *\n     * @param items The completion items.\n     * @param isIncomplete The list is not complete.\n     */\n    function create(items, isIncomplete) {\n        return { items: items ? items : [], isIncomplete: !!isIncomplete };\n    }\n    CompletionList.create = create;\n})(CompletionList || (CompletionList = {}));\nexport var MarkedString;\n(function (MarkedString) {\n    /**\n     * Creates a marked string from plain text.\n     *\n     * @param plainText The plain text.\n     */\n    function fromPlainText(plainText) {\n        return plainText.replace(/[\\\\`*_{}[\\]()#+\\-.!]/g, '\\\\$&'); // escape markdown syntax tokens: http://daringfireball.net/projects/markdown/syntax#backslash\n    }\n    MarkedString.fromPlainText = fromPlainText;\n    /**\n     * Checks whether the given value conforms to the {@link MarkedString} type.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.string(candidate) || (Is.objectLiteral(candidate) && Is.string(candidate.language) && Is.string(candidate.value));\n    }\n    MarkedString.is = is;\n})(MarkedString || (MarkedString = {}));\nexport var Hover;\n(function (Hover) {\n    /**\n     * Checks whether the given value conforms to the {@link Hover} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return !!candidate && Is.objectLiteral(candidate) && (MarkupContent.is(candidate.contents) ||\n            MarkedString.is(candidate.contents) ||\n            Is.typedArray(candidate.contents, MarkedString.is)) && (value.range === undefined || Range.is(value.range));\n    }\n    Hover.is = is;\n})(Hover || (Hover = {}));\n/**\n * The ParameterInformation namespace provides helper functions to work with\n * {@link ParameterInformation} literals.\n */\nexport var ParameterInformation;\n(function (ParameterInformation) {\n    /**\n     * Creates a new parameter information literal.\n     *\n     * @param label A label string.\n     * @param documentation A doc string.\n     */\n    function create(label, documentation) {\n        return documentation ? { label, documentation } : { label };\n    }\n    ParameterInformation.create = create;\n})(ParameterInformation || (ParameterInformation = {}));\n/**\n * The SignatureInformation namespace provides helper functions to work with\n * {@link SignatureInformation} literals.\n */\nexport var SignatureInformation;\n(function (SignatureInformation) {\n    function create(label, documentation, ...parameters) {\n        let result = { label };\n        if (Is.defined(documentation)) {\n            result.documentation = documentation;\n        }\n        if (Is.defined(parameters)) {\n            result.parameters = parameters;\n        }\n        else {\n            result.parameters = [];\n        }\n        return result;\n    }\n    SignatureInformation.create = create;\n})(SignatureInformation || (SignatureInformation = {}));\n/**\n * A document highlight kind.\n */\nexport var DocumentHighlightKind;\n(function (DocumentHighlightKind) {\n    /**\n     * A textual occurrence.\n     */\n    DocumentHighlightKind.Text = 1;\n    /**\n     * Read-access of a symbol, like reading a variable.\n     */\n    DocumentHighlightKind.Read = 2;\n    /**\n     * Write-access of a symbol, like writing to a variable.\n     */\n    DocumentHighlightKind.Write = 3;\n})(DocumentHighlightKind || (DocumentHighlightKind = {}));\n/**\n * DocumentHighlight namespace to provide helper functions to work with\n * {@link DocumentHighlight} literals.\n */\nexport var DocumentHighlight;\n(function (DocumentHighlight) {\n    /**\n     * Create a DocumentHighlight object.\n     * @param range The range the highlight applies to.\n     * @param kind The highlight kind\n     */\n    function create(range, kind) {\n        let result = { range };\n        if (Is.number(kind)) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    DocumentHighlight.create = create;\n})(DocumentHighlight || (DocumentHighlight = {}));\n/**\n * A symbol kind.\n */\nexport var SymbolKind;\n(function (SymbolKind) {\n    SymbolKind.File = 1;\n    SymbolKind.Module = 2;\n    SymbolKind.Namespace = 3;\n    SymbolKind.Package = 4;\n    SymbolKind.Class = 5;\n    SymbolKind.Method = 6;\n    SymbolKind.Property = 7;\n    SymbolKind.Field = 8;\n    SymbolKind.Constructor = 9;\n    SymbolKind.Enum = 10;\n    SymbolKind.Interface = 11;\n    SymbolKind.Function = 12;\n    SymbolKind.Variable = 13;\n    SymbolKind.Constant = 14;\n    SymbolKind.String = 15;\n    SymbolKind.Number = 16;\n    SymbolKind.Boolean = 17;\n    SymbolKind.Array = 18;\n    SymbolKind.Object = 19;\n    SymbolKind.Key = 20;\n    SymbolKind.Null = 21;\n    SymbolKind.EnumMember = 22;\n    SymbolKind.Struct = 23;\n    SymbolKind.Event = 24;\n    SymbolKind.Operator = 25;\n    SymbolKind.TypeParameter = 26;\n})(SymbolKind || (SymbolKind = {}));\n/**\n * Symbol tags are extra annotations that tweak the rendering of a symbol.\n *\n * @since 3.16\n */\nexport var SymbolTag;\n(function (SymbolTag) {\n    /**\n     * Render a symbol as obsolete, usually using a strike-out.\n     */\n    SymbolTag.Deprecated = 1;\n})(SymbolTag || (SymbolTag = {}));\nexport var SymbolInformation;\n(function (SymbolInformation) {\n    /**\n     * Creates a new symbol information literal.\n     *\n     * @param name The name of the symbol.\n     * @param kind The kind of the symbol.\n     * @param range The range of the location of the symbol.\n     * @param uri The resource of the location of symbol.\n     * @param containerName The name of the symbol containing the symbol.\n     */\n    function create(name, kind, range, uri, containerName) {\n        let result = {\n            name,\n            kind,\n            location: { uri, range }\n        };\n        if (containerName) {\n            result.containerName = containerName;\n        }\n        return result;\n    }\n    SymbolInformation.create = create;\n})(SymbolInformation || (SymbolInformation = {}));\nexport var WorkspaceSymbol;\n(function (WorkspaceSymbol) {\n    /**\n     * Create a new workspace symbol.\n     *\n     * @param name The name of the symbol.\n     * @param kind The kind of the symbol.\n     * @param uri The resource of the location of the symbol.\n     * @param range An options range of the location.\n     * @returns A WorkspaceSymbol.\n     */\n    function create(name, kind, uri, range) {\n        return range !== undefined\n            ? { name, kind, location: { uri, range } }\n            : { name, kind, location: { uri } };\n    }\n    WorkspaceSymbol.create = create;\n})(WorkspaceSymbol || (WorkspaceSymbol = {}));\nexport var DocumentSymbol;\n(function (DocumentSymbol) {\n    /**\n     * Creates a new symbol information literal.\n     *\n     * @param name The name of the symbol.\n     * @param detail The detail of the symbol.\n     * @param kind The kind of the symbol.\n     * @param range The range of the symbol.\n     * @param selectionRange The selectionRange of the symbol.\n     * @param children Children of the symbol.\n     */\n    function create(name, detail, kind, range, selectionRange, children) {\n        let result = {\n            name,\n            detail,\n            kind,\n            range,\n            selectionRange\n        };\n        if (children !== undefined) {\n            result.children = children;\n        }\n        return result;\n    }\n    DocumentSymbol.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DocumentSymbol} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return candidate &&\n            Is.string(candidate.name) && Is.number(candidate.kind) &&\n            Range.is(candidate.range) && Range.is(candidate.selectionRange) &&\n            (candidate.detail === undefined || Is.string(candidate.detail)) &&\n            (candidate.deprecated === undefined || Is.boolean(candidate.deprecated)) &&\n            (candidate.children === undefined || Array.isArray(candidate.children)) &&\n            (candidate.tags === undefined || Array.isArray(candidate.tags));\n    }\n    DocumentSymbol.is = is;\n})(DocumentSymbol || (DocumentSymbol = {}));\n/**\n * A set of predefined code action kinds\n */\nexport var CodeActionKind;\n(function (CodeActionKind) {\n    /**\n     * Empty kind.\n     */\n    CodeActionKind.Empty = '';\n    /**\n     * Base kind for quickfix actions: 'quickfix'\n     */\n    CodeActionKind.QuickFix = 'quickfix';\n    /**\n     * Base kind for refactoring actions: 'refactor'\n     */\n    CodeActionKind.Refactor = 'refactor';\n    /**\n     * Base kind for refactoring extraction actions: 'refactor.extract'\n     *\n     * Example extract actions:\n     *\n     * - Extract method\n     * - Extract function\n     * - Extract variable\n     * - Extract interface from class\n     * - ...\n     */\n    CodeActionKind.RefactorExtract = 'refactor.extract';\n    /**\n     * Base kind for refactoring inline actions: 'refactor.inline'\n     *\n     * Example inline actions:\n     *\n     * - Inline function\n     * - Inline variable\n     * - Inline constant\n     * - ...\n     */\n    CodeActionKind.RefactorInline = 'refactor.inline';\n    /**\n     * Base kind for refactoring rewrite actions: 'refactor.rewrite'\n     *\n     * Example rewrite actions:\n     *\n     * - Convert JavaScript function to class\n     * - Add or remove parameter\n     * - Encapsulate field\n     * - Make method static\n     * - Move method to base class\n     * - ...\n     */\n    CodeActionKind.RefactorRewrite = 'refactor.rewrite';\n    /**\n     * Base kind for source actions: `source`\n     *\n     * Source code actions apply to the entire file.\n     */\n    CodeActionKind.Source = 'source';\n    /**\n     * Base kind for an organize imports source action: `source.organizeImports`\n     */\n    CodeActionKind.SourceOrganizeImports = 'source.organizeImports';\n    /**\n     * Base kind for auto-fix source actions: `source.fixAll`.\n     *\n     * Fix all actions automatically fix errors that have a clear fix that do not require user input.\n     * They should not suppress errors or perform unsafe fixes such as generating new types or classes.\n     *\n     * @since 3.15.0\n     */\n    CodeActionKind.SourceFixAll = 'source.fixAll';\n})(CodeActionKind || (CodeActionKind = {}));\n/**\n * The reason why code actions were requested.\n *\n * @since 3.17.0\n */\nexport var CodeActionTriggerKind;\n(function (CodeActionTriggerKind) {\n    /**\n     * Code actions were explicitly requested by the user or by an extension.\n     */\n    CodeActionTriggerKind.Invoked = 1;\n    /**\n     * Code actions were requested automatically.\n     *\n     * This typically happens when current selection in a file changes, but can\n     * also be triggered when file content changes.\n     */\n    CodeActionTriggerKind.Automatic = 2;\n})(CodeActionTriggerKind || (CodeActionTriggerKind = {}));\n/**\n * The CodeActionContext namespace provides helper functions to work with\n * {@link CodeActionContext} literals.\n */\nexport var CodeActionContext;\n(function (CodeActionContext) {\n    /**\n     * Creates a new CodeActionContext literal.\n     */\n    function create(diagnostics, only, triggerKind) {\n        let result = { diagnostics };\n        if (only !== undefined && only !== null) {\n            result.only = only;\n        }\n        if (triggerKind !== undefined && triggerKind !== null) {\n            result.triggerKind = triggerKind;\n        }\n        return result;\n    }\n    CodeActionContext.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link CodeActionContext} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.typedArray(candidate.diagnostics, Diagnostic.is)\n            && (candidate.only === undefined || Is.typedArray(candidate.only, Is.string))\n            && (candidate.triggerKind === undefined || candidate.triggerKind === CodeActionTriggerKind.Invoked || candidate.triggerKind === CodeActionTriggerKind.Automatic);\n    }\n    CodeActionContext.is = is;\n})(CodeActionContext || (CodeActionContext = {}));\nexport var CodeAction;\n(function (CodeAction) {\n    function create(title, kindOrCommandOrEdit, kind) {\n        let result = { title };\n        let checkKind = true;\n        if (typeof kindOrCommandOrEdit === 'string') {\n            checkKind = false;\n            result.kind = kindOrCommandOrEdit;\n        }\n        else if (Command.is(kindOrCommandOrEdit)) {\n            result.command = kindOrCommandOrEdit;\n        }\n        else {\n            result.edit = kindOrCommandOrEdit;\n        }\n        if (checkKind && kind !== undefined) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    CodeAction.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && Is.string(candidate.title) &&\n            (candidate.diagnostics === undefined || Is.typedArray(candidate.diagnostics, Diagnostic.is)) &&\n            (candidate.kind === undefined || Is.string(candidate.kind)) &&\n            (candidate.edit !== undefined || candidate.command !== undefined) &&\n            (candidate.command === undefined || Command.is(candidate.command)) &&\n            (candidate.isPreferred === undefined || Is.boolean(candidate.isPreferred)) &&\n            (candidate.edit === undefined || WorkspaceEdit.is(candidate.edit));\n    }\n    CodeAction.is = is;\n})(CodeAction || (CodeAction = {}));\n/**\n * The CodeLens namespace provides helper functions to work with\n * {@link CodeLens} literals.\n */\nexport var CodeLens;\n(function (CodeLens) {\n    /**\n     * Creates a new CodeLens literal.\n     */\n    function create(range, data) {\n        let result = { range };\n        if (Is.defined(data)) {\n            result.data = data;\n        }\n        return result;\n    }\n    CodeLens.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link CodeLens} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.command) || Command.is(candidate.command));\n    }\n    CodeLens.is = is;\n})(CodeLens || (CodeLens = {}));\n/**\n * The FormattingOptions namespace provides helper functions to work with\n * {@link FormattingOptions} literals.\n */\nexport var FormattingOptions;\n(function (FormattingOptions) {\n    /**\n     * Creates a new FormattingOptions literal.\n     */\n    function create(tabSize, insertSpaces) {\n        return { tabSize, insertSpaces };\n    }\n    FormattingOptions.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link FormattingOptions} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.uinteger(candidate.tabSize) && Is.boolean(candidate.insertSpaces);\n    }\n    FormattingOptions.is = is;\n})(FormattingOptions || (FormattingOptions = {}));\n/**\n * The DocumentLink namespace provides helper functions to work with\n * {@link DocumentLink} literals.\n */\nexport var DocumentLink;\n(function (DocumentLink) {\n    /**\n     * Creates a new DocumentLink literal.\n     */\n    function create(range, target, data) {\n        return { range, target, data };\n    }\n    DocumentLink.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DocumentLink} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.target) || Is.string(candidate.target));\n    }\n    DocumentLink.is = is;\n})(DocumentLink || (DocumentLink = {}));\n/**\n * The SelectionRange namespace provides helper function to work with\n * SelectionRange literals.\n */\nexport var SelectionRange;\n(function (SelectionRange) {\n    /**\n     * Creates a new SelectionRange\n     * @param range the range.\n     * @param parent an optional parent.\n     */\n    function create(range, parent) {\n        return { range, parent };\n    }\n    SelectionRange.create = create;\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && (candidate.parent === undefined || SelectionRange.is(candidate.parent));\n    }\n    SelectionRange.is = is;\n})(SelectionRange || (SelectionRange = {}));\n/**\n * A set of predefined token types. This set is not fixed\n * an clients can specify additional token types via the\n * corresponding client capabilities.\n *\n * @since 3.16.0\n */\nexport var SemanticTokenTypes;\n(function (SemanticTokenTypes) {\n    SemanticTokenTypes[\"namespace\"] = \"namespace\";\n    /**\n     * Represents a generic type. Acts as a fallback for types which can't be mapped to\n     * a specific type like class or enum.\n     */\n    SemanticTokenTypes[\"type\"] = \"type\";\n    SemanticTokenTypes[\"class\"] = \"class\";\n    SemanticTokenTypes[\"enum\"] = \"enum\";\n    SemanticTokenTypes[\"interface\"] = \"interface\";\n    SemanticTokenTypes[\"struct\"] = \"struct\";\n    SemanticTokenTypes[\"typeParameter\"] = \"typeParameter\";\n    SemanticTokenTypes[\"parameter\"] = \"parameter\";\n    SemanticTokenTypes[\"variable\"] = \"variable\";\n    SemanticTokenTypes[\"property\"] = \"property\";\n    SemanticTokenTypes[\"enumMember\"] = \"enumMember\";\n    SemanticTokenTypes[\"event\"] = \"event\";\n    SemanticTokenTypes[\"function\"] = \"function\";\n    SemanticTokenTypes[\"method\"] = \"method\";\n    SemanticTokenTypes[\"macro\"] = \"macro\";\n    SemanticTokenTypes[\"keyword\"] = \"keyword\";\n    SemanticTokenTypes[\"modifier\"] = \"modifier\";\n    SemanticTokenTypes[\"comment\"] = \"comment\";\n    SemanticTokenTypes[\"string\"] = \"string\";\n    SemanticTokenTypes[\"number\"] = \"number\";\n    SemanticTokenTypes[\"regexp\"] = \"regexp\";\n    SemanticTokenTypes[\"operator\"] = \"operator\";\n    /**\n     * @since 3.17.0\n     */\n    SemanticTokenTypes[\"decorator\"] = \"decorator\";\n})(SemanticTokenTypes || (SemanticTokenTypes = {}));\n/**\n * A set of predefined token modifiers. This set is not fixed\n * an clients can specify additional token types via the\n * corresponding client capabilities.\n *\n * @since 3.16.0\n */\nexport var SemanticTokenModifiers;\n(function (SemanticTokenModifiers) {\n    SemanticTokenModifiers[\"declaration\"] = \"declaration\";\n    SemanticTokenModifiers[\"definition\"] = \"definition\";\n    SemanticTokenModifiers[\"readonly\"] = \"readonly\";\n    SemanticTokenModifiers[\"static\"] = \"static\";\n    SemanticTokenModifiers[\"deprecated\"] = \"deprecated\";\n    SemanticTokenModifiers[\"abstract\"] = \"abstract\";\n    SemanticTokenModifiers[\"async\"] = \"async\";\n    SemanticTokenModifiers[\"modification\"] = \"modification\";\n    SemanticTokenModifiers[\"documentation\"] = \"documentation\";\n    SemanticTokenModifiers[\"defaultLibrary\"] = \"defaultLibrary\";\n})(SemanticTokenModifiers || (SemanticTokenModifiers = {}));\n/**\n * @since 3.16.0\n */\nexport var SemanticTokens;\n(function (SemanticTokens) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && (candidate.resultId === undefined || typeof candidate.resultId === 'string') &&\n            Array.isArray(candidate.data) && (candidate.data.length === 0 || typeof candidate.data[0] === 'number');\n    }\n    SemanticTokens.is = is;\n})(SemanticTokens || (SemanticTokens = {}));\n/**\n * The InlineValueText namespace provides functions to deal with InlineValueTexts.\n *\n * @since 3.17.0\n */\nexport var InlineValueText;\n(function (InlineValueText) {\n    /**\n     * Creates a new InlineValueText literal.\n     */\n    function create(range, text) {\n        return { range, text };\n    }\n    InlineValueText.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range) && Is.string(candidate.text);\n    }\n    InlineValueText.is = is;\n})(InlineValueText || (InlineValueText = {}));\n/**\n * The InlineValueVariableLookup namespace provides functions to deal with InlineValueVariableLookups.\n *\n * @since 3.17.0\n */\nexport var InlineValueVariableLookup;\n(function (InlineValueVariableLookup) {\n    /**\n     * Creates a new InlineValueText literal.\n     */\n    function create(range, variableName, caseSensitiveLookup) {\n        return { range, variableName, caseSensitiveLookup };\n    }\n    InlineValueVariableLookup.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range) && Is.boolean(candidate.caseSensitiveLookup)\n            && (Is.string(candidate.variableName) || candidate.variableName === undefined);\n    }\n    InlineValueVariableLookup.is = is;\n})(InlineValueVariableLookup || (InlineValueVariableLookup = {}));\n/**\n * The InlineValueEvaluatableExpression namespace provides functions to deal with InlineValueEvaluatableExpression.\n *\n * @since 3.17.0\n */\nexport var InlineValueEvaluatableExpression;\n(function (InlineValueEvaluatableExpression) {\n    /**\n     * Creates a new InlineValueEvaluatableExpression literal.\n     */\n    function create(range, expression) {\n        return { range, expression };\n    }\n    InlineValueEvaluatableExpression.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range)\n            && (Is.string(candidate.expression) || candidate.expression === undefined);\n    }\n    InlineValueEvaluatableExpression.is = is;\n})(InlineValueEvaluatableExpression || (InlineValueEvaluatableExpression = {}));\n/**\n * The InlineValueContext namespace provides helper functions to work with\n * {@link InlineValueContext} literals.\n *\n * @since 3.17.0\n */\nexport var InlineValueContext;\n(function (InlineValueContext) {\n    /**\n     * Creates a new InlineValueContext literal.\n     */\n    function create(frameId, stoppedLocation) {\n        return { frameId, stoppedLocation };\n    }\n    InlineValueContext.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link InlineValueContext} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.defined(candidate) && Range.is(value.stoppedLocation);\n    }\n    InlineValueContext.is = is;\n})(InlineValueContext || (InlineValueContext = {}));\n/**\n * Inlay hint kinds.\n *\n * @since 3.17.0\n */\nexport var InlayHintKind;\n(function (InlayHintKind) {\n    /**\n     * An inlay hint that for a type annotation.\n     */\n    InlayHintKind.Type = 1;\n    /**\n     * An inlay hint that is for a parameter.\n     */\n    InlayHintKind.Parameter = 2;\n    function is(value) {\n        return value === 1 || value === 2;\n    }\n    InlayHintKind.is = is;\n})(InlayHintKind || (InlayHintKind = {}));\nexport var InlayHintLabelPart;\n(function (InlayHintLabelPart) {\n    function create(value) {\n        return { value };\n    }\n    InlayHintLabelPart.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate)\n            && (candidate.tooltip === undefined || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip))\n            && (candidate.location === undefined || Location.is(candidate.location))\n            && (candidate.command === undefined || Command.is(candidate.command));\n    }\n    InlayHintLabelPart.is = is;\n})(InlayHintLabelPart || (InlayHintLabelPart = {}));\nexport var InlayHint;\n(function (InlayHint) {\n    function create(position, label, kind) {\n        const result = { position, label };\n        if (kind !== undefined) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    InlayHint.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Position.is(candidate.position)\n            && (Is.string(candidate.label) || Is.typedArray(candidate.label, InlayHintLabelPart.is))\n            && (candidate.kind === undefined || InlayHintKind.is(candidate.kind))\n            && (candidate.textEdits === undefined) || Is.typedArray(candidate.textEdits, TextEdit.is)\n            && (candidate.tooltip === undefined || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip))\n            && (candidate.paddingLeft === undefined || Is.boolean(candidate.paddingLeft))\n            && (candidate.paddingRight === undefined || Is.boolean(candidate.paddingRight));\n    }\n    InlayHint.is = is;\n})(InlayHint || (InlayHint = {}));\nexport var StringValue;\n(function (StringValue) {\n    function createSnippet(value) {\n        return { kind: 'snippet', value };\n    }\n    StringValue.createSnippet = createSnippet;\n})(StringValue || (StringValue = {}));\nexport var InlineCompletionItem;\n(function (InlineCompletionItem) {\n    function create(insertText, filterText, range, command) {\n        return { insertText, filterText, range, command };\n    }\n    InlineCompletionItem.create = create;\n})(InlineCompletionItem || (InlineCompletionItem = {}));\nexport var InlineCompletionList;\n(function (InlineCompletionList) {\n    function create(items) {\n        return { items };\n    }\n    InlineCompletionList.create = create;\n})(InlineCompletionList || (InlineCompletionList = {}));\n/**\n * Describes how an {@link InlineCompletionItemProvider inline completion provider} was triggered.\n *\n * @since 3.18.0\n * @proposed\n */\nexport var InlineCompletionTriggerKind;\n(function (InlineCompletionTriggerKind) {\n    /**\n     * Completion was triggered explicitly by a user gesture.\n     */\n    InlineCompletionTriggerKind.Invoked = 0;\n    /**\n     * Completion was triggered automatically while editing.\n     */\n    InlineCompletionTriggerKind.Automatic = 1;\n})(InlineCompletionTriggerKind || (InlineCompletionTriggerKind = {}));\nexport var SelectedCompletionInfo;\n(function (SelectedCompletionInfo) {\n    function create(range, text) {\n        return { range, text };\n    }\n    SelectedCompletionInfo.create = create;\n})(SelectedCompletionInfo || (SelectedCompletionInfo = {}));\nexport var InlineCompletionContext;\n(function (InlineCompletionContext) {\n    function create(triggerKind, selectedCompletionInfo) {\n        return { triggerKind, selectedCompletionInfo };\n    }\n    InlineCompletionContext.create = create;\n})(InlineCompletionContext || (InlineCompletionContext = {}));\nexport var WorkspaceFolder;\n(function (WorkspaceFolder) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && URI.is(candidate.uri) && Is.string(candidate.name);\n    }\n    WorkspaceFolder.is = is;\n})(WorkspaceFolder || (WorkspaceFolder = {}));\nexport const EOL = ['\\n', '\\r\\n', '\\r'];\n/**\n * @deprecated Use the text document from the new vscode-languageserver-textdocument package.\n */\nexport var TextDocument;\n(function (TextDocument) {\n    /**\n     * Creates a new ITextDocument literal from the given uri and content.\n     * @param uri The document's uri.\n     * @param languageId The document's language Id.\n     * @param version The document's version.\n     * @param content The document's content.\n     */\n    function create(uri, languageId, version, content) {\n        return new FullTextDocument(uri, languageId, version, content);\n    }\n    TextDocument.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ITextDocument} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && (Is.undefined(candidate.languageId) || Is.string(candidate.languageId)) && Is.uinteger(candidate.lineCount)\n            && Is.func(candidate.getText) && Is.func(candidate.positionAt) && Is.func(candidate.offsetAt) ? true : false;\n    }\n    TextDocument.is = is;\n    function applyEdits(document, edits) {\n        let text = document.getText();\n        let sortedEdits = mergeSort(edits, (a, b) => {\n            let diff = a.range.start.line - b.range.start.line;\n            if (diff === 0) {\n                return a.range.start.character - b.range.start.character;\n            }\n            return diff;\n        });\n        let lastModifiedOffset = text.length;\n        for (let i = sortedEdits.length - 1; i >= 0; i--) {\n            let e = sortedEdits[i];\n            let startOffset = document.offsetAt(e.range.start);\n            let endOffset = document.offsetAt(e.range.end);\n            if (endOffset <= lastModifiedOffset) {\n                text = text.substring(0, startOffset) + e.newText + text.substring(endOffset, text.length);\n            }\n            else {\n                throw new Error('Overlapping edit');\n            }\n            lastModifiedOffset = startOffset;\n        }\n        return text;\n    }\n    TextDocument.applyEdits = applyEdits;\n    function mergeSort(data, compare) {\n        if (data.length <= 1) {\n            // sorted\n            return data;\n        }\n        const p = (data.length / 2) | 0;\n        const left = data.slice(0, p);\n        const right = data.slice(p);\n        mergeSort(left, compare);\n        mergeSort(right, compare);\n        let leftIdx = 0;\n        let rightIdx = 0;\n        let i = 0;\n        while (leftIdx < left.length && rightIdx < right.length) {\n            let ret = compare(left[leftIdx], right[rightIdx]);\n            if (ret <= 0) {\n                // smaller_equal -> take left to preserve order\n                data[i++] = left[leftIdx++];\n            }\n            else {\n                // greater -> take right\n                data[i++] = right[rightIdx++];\n            }\n        }\n        while (leftIdx < left.length) {\n            data[i++] = left[leftIdx++];\n        }\n        while (rightIdx < right.length) {\n            data[i++] = right[rightIdx++];\n        }\n        return data;\n    }\n})(TextDocument || (TextDocument = {}));\n/**\n * @deprecated Use the text document from the new vscode-languageserver-textdocument package.\n */\nclass FullTextDocument {\n    constructor(uri, languageId, version, content) {\n        this._uri = uri;\n        this._languageId = languageId;\n        this._version = version;\n        this._content = content;\n        this._lineOffsets = undefined;\n    }\n    get uri() {\n        return this._uri;\n    }\n    get languageId() {\n        return this._languageId;\n    }\n    get version() {\n        return this._version;\n    }\n    getText(range) {\n        if (range) {\n            let start = this.offsetAt(range.start);\n            let end = this.offsetAt(range.end);\n            return this._content.substring(start, end);\n        }\n        return this._content;\n    }\n    update(event, version) {\n        this._content = event.text;\n        this._version = version;\n        this._lineOffsets = undefined;\n    }\n    getLineOffsets() {\n        if (this._lineOffsets === undefined) {\n            let lineOffsets = [];\n            let text = this._content;\n            let isLineStart = true;\n            for (let i = 0; i < text.length; i++) {\n                if (isLineStart) {\n                    lineOffsets.push(i);\n                    isLineStart = false;\n                }\n                let ch = text.charAt(i);\n                isLineStart = (ch === '\\r' || ch === '\\n');\n                if (ch === '\\r' && i + 1 < text.length && text.charAt(i + 1) === '\\n') {\n                    i++;\n                }\n            }\n            if (isLineStart && text.length > 0) {\n                lineOffsets.push(text.length);\n            }\n            this._lineOffsets = lineOffsets;\n        }\n        return this._lineOffsets;\n    }\n    positionAt(offset) {\n        offset = Math.max(Math.min(offset, this._content.length), 0);\n        let lineOffsets = this.getLineOffsets();\n        let low = 0, high = lineOffsets.length;\n        if (high === 0) {\n            return Position.create(0, offset);\n        }\n        while (low < high) {\n            let mid = Math.floor((low + high) / 2);\n            if (lineOffsets[mid] > offset) {\n                high = mid;\n            }\n            else {\n                low = mid + 1;\n            }\n        }\n        // low is the least x for which the line offset is larger than the current offset\n        // or array.length if no line offset is larger than the current offset\n        let line = low - 1;\n        return Position.create(line, offset - lineOffsets[line]);\n    }\n    offsetAt(position) {\n        let lineOffsets = this.getLineOffsets();\n        if (position.line >= lineOffsets.length) {\n            return this._content.length;\n        }\n        else if (position.line < 0) {\n            return 0;\n        }\n        let lineOffset = lineOffsets[position.line];\n        let nextLineOffset = (position.line + 1 < lineOffsets.length) ? lineOffsets[position.line + 1] : this._content.length;\n        return Math.max(Math.min(lineOffset + position.character, nextLineOffset), lineOffset);\n    }\n    get lineCount() {\n        return this.getLineOffsets().length;\n    }\n}\nvar Is;\n(function (Is) {\n    const toString = Object.prototype.toString;\n    function defined(value) {\n        return typeof value !== 'undefined';\n    }\n    Is.defined = defined;\n    function undefined(value) {\n        return typeof value === 'undefined';\n    }\n    Is.undefined = undefined;\n    function boolean(value) {\n        return value === true || value === false;\n    }\n    Is.boolean = boolean;\n    function string(value) {\n        return toString.call(value) === '[object String]';\n    }\n    Is.string = string;\n    function number(value) {\n        return toString.call(value) === '[object Number]';\n    }\n    Is.number = number;\n    function numberRange(value, min, max) {\n        return toString.call(value) === '[object Number]' && min <= value && value <= max;\n    }\n    Is.numberRange = numberRange;\n    function integer(value) {\n        return toString.call(value) === '[object Number]' && -2147483648 <= value && value <= 2147483647;\n    }\n    Is.integer = integer;\n    function uinteger(value) {\n        return toString.call(value) === '[object Number]' && 0 <= value && value <= 2147483647;\n    }\n    Is.uinteger = uinteger;\n    function func(value) {\n        return toString.call(value) === '[object Function]';\n    }\n    Is.func = func;\n    function objectLiteral(value) {\n        // Strictly speaking class instances pass this check as well. Since the LSP\n        // doesn't use classes we ignore this for now. If we do we need to add something\n        // like this: `Object.getPrototypeOf(Object.getPrototypeOf(x)) === null`\n        return value !== null && typeof value === 'object';\n    }\n    Is.objectLiteral = objectLiteral;\n    function typedArray(value, check) {\n        return Array.isArray(value) && value.every(check);\n    }\n    Is.typedArray = typedArray;\n})(Is || (Is = {}));\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Position } from 'vscode-languageserver-types';\nimport { tokenToRange } from '../utils/cst-utils.js';\nexport class CstNodeBuilder {\n    constructor() {\n        this.nodeStack = [];\n    }\n    get current() {\n        var _a;\n        return (_a = this.nodeStack[this.nodeStack.length - 1]) !== null && _a !== void 0 ? _a : this.rootNode;\n    }\n    buildRootNode(input) {\n        this.rootNode = new RootCstNodeImpl(input);\n        this.rootNode.root = this.rootNode;\n        this.nodeStack = [this.rootNode];\n        return this.rootNode;\n    }\n    buildCompositeNode(feature) {\n        const compositeNode = new CompositeCstNodeImpl();\n        compositeNode.grammarSource = feature;\n        compositeNode.root = this.rootNode;\n        this.current.content.push(compositeNode);\n        this.nodeStack.push(compositeNode);\n        return compositeNode;\n    }\n    buildLeafNode(token, feature) {\n        const leafNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, !feature);\n        leafNode.grammarSource = feature;\n        leafNode.root = this.rootNode;\n        this.current.content.push(leafNode);\n        return leafNode;\n    }\n    removeNode(node) {\n        const parent = node.container;\n        if (parent) {\n            const index = parent.content.indexOf(node);\n            if (index >= 0) {\n                parent.content.splice(index, 1);\n            }\n        }\n    }\n    addHiddenNodes(tokens) {\n        const nodes = [];\n        for (const token of tokens) {\n            const leafNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, true);\n            leafNode.root = this.rootNode;\n            nodes.push(leafNode);\n        }\n        let current = this.current;\n        let added = false;\n        // If we are within a composite node, we add the hidden nodes to the content\n        if (current.content.length > 0) {\n            current.content.push(...nodes);\n            return;\n        }\n        // Otherwise we are at a newly created node\n        // Instead of adding the hidden nodes here, we search for the first parent node with content\n        while (current.container) {\n            const index = current.container.content.indexOf(current);\n            if (index > 0) {\n                // Add the hidden nodes before the current node\n                current.container.content.splice(index, 0, ...nodes);\n                added = true;\n                break;\n            }\n            current = current.container;\n        }\n        // If we arrive at the root node, we add the hidden nodes at the beginning\n        // This is the case if the hidden nodes are the first nodes in the tree\n        if (!added) {\n            this.rootNode.content.unshift(...nodes);\n        }\n    }\n    construct(item) {\n        const current = this.current;\n        // The specified item could be a datatype ($type is symbol) or a fragment ($type is undefined)\n        // Only if the $type is a string, we actually assign the element\n        if (typeof item.$type === 'string') {\n            this.current.astNode = item;\n        }\n        item.$cstNode = current;\n        const node = this.nodeStack.pop();\n        // Empty composite nodes are not valid\n        // Simply remove the node from the tree\n        if ((node === null || node === void 0 ? void 0 : node.content.length) === 0) {\n            this.removeNode(node);\n        }\n    }\n}\nexport class AbstractCstNode {\n    /** @deprecated use `container` instead. */\n    get parent() {\n        return this.container;\n    }\n    /** @deprecated use `grammarSource` instead. */\n    get feature() {\n        return this.grammarSource;\n    }\n    get hidden() {\n        return false;\n    }\n    get astNode() {\n        var _a, _b;\n        const node = typeof ((_a = this._astNode) === null || _a === void 0 ? void 0 : _a.$type) === 'string' ? this._astNode : (_b = this.container) === null || _b === void 0 ? void 0 : _b.astNode;\n        if (!node) {\n            throw new Error('This node has no associated AST element');\n        }\n        return node;\n    }\n    set astNode(value) {\n        this._astNode = value;\n    }\n    /** @deprecated use `astNode` instead. */\n    get element() {\n        return this.astNode;\n    }\n    get text() {\n        return this.root.fullText.substring(this.offset, this.end);\n    }\n}\nexport class LeafCstNodeImpl extends AbstractCstNode {\n    get offset() {\n        return this._offset;\n    }\n    get length() {\n        return this._length;\n    }\n    get end() {\n        return this._offset + this._length;\n    }\n    get hidden() {\n        return this._hidden;\n    }\n    get tokenType() {\n        return this._tokenType;\n    }\n    get range() {\n        return this._range;\n    }\n    constructor(offset, length, range, tokenType, hidden = false) {\n        super();\n        this._hidden = hidden;\n        this._offset = offset;\n        this._tokenType = tokenType;\n        this._length = length;\n        this._range = range;\n    }\n}\nexport class CompositeCstNodeImpl extends AbstractCstNode {\n    constructor() {\n        super(...arguments);\n        this.content = new CstNodeContainer(this);\n    }\n    /** @deprecated use `content` instead. */\n    get children() {\n        return this.content;\n    }\n    get offset() {\n        var _a, _b;\n        return (_b = (_a = this.firstNonHiddenNode) === null || _a === void 0 ? void 0 : _a.offset) !== null && _b !== void 0 ? _b : 0;\n    }\n    get length() {\n        return this.end - this.offset;\n    }\n    get end() {\n        var _a, _b;\n        return (_b = (_a = this.lastNonHiddenNode) === null || _a === void 0 ? void 0 : _a.end) !== null && _b !== void 0 ? _b : 0;\n    }\n    get range() {\n        const firstNode = this.firstNonHiddenNode;\n        const lastNode = this.lastNonHiddenNode;\n        if (firstNode && lastNode) {\n            if (this._rangeCache === undefined) {\n                const { range: firstRange } = firstNode;\n                const { range: lastRange } = lastNode;\n                this._rangeCache = { start: firstRange.start, end: lastRange.end.line < firstRange.start.line ? firstRange.start : lastRange.end };\n            }\n            return this._rangeCache;\n        }\n        else {\n            return { start: Position.create(0, 0), end: Position.create(0, 0) };\n        }\n    }\n    get firstNonHiddenNode() {\n        for (const child of this.content) {\n            if (!child.hidden) {\n                return child;\n            }\n        }\n        return this.content[0];\n    }\n    get lastNonHiddenNode() {\n        for (let i = this.content.length - 1; i >= 0; i--) {\n            const child = this.content[i];\n            if (!child.hidden) {\n                return child;\n            }\n        }\n        return this.content[this.content.length - 1];\n    }\n}\nclass CstNodeContainer extends Array {\n    constructor(parent) {\n        super();\n        this.parent = parent;\n        Object.setPrototypeOf(this, CstNodeContainer.prototype);\n    }\n    push(...items) {\n        this.addParents(items);\n        return super.push(...items);\n    }\n    unshift(...items) {\n        this.addParents(items);\n        return super.unshift(...items);\n    }\n    splice(start, count, ...items) {\n        this.addParents(items);\n        return super.splice(start, count, ...items);\n    }\n    addParents(items) {\n        for (const item of items) {\n            item.container = this.parent;\n        }\n    }\n}\nexport class RootCstNodeImpl extends CompositeCstNodeImpl {\n    get text() {\n        return this._text.substring(this.offset, this.end);\n    }\n    get fullText() {\n        return this._text;\n    }\n    constructor(input) {\n        super();\n        this._text = '';\n        this._text = input !== null && input !== void 0 ? input : '';\n    }\n}\n//# sourceMappingURL=cst-node-builder.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { defaultParserErrorProvider, EmbeddedActionsParser, LLkLookaheadStrategy } from 'chevrotain';\nimport { LLStarLookaheadStrategy } from 'chevrotain-allstar';\nimport { isAssignment, isCrossReference, isKeyword } from '../languages/generated/ast.js';\nimport { getExplicitRuleType, isDataTypeRule } from '../utils/grammar-utils.js';\nimport { assignMandatoryProperties, getContainerOfType, linkContentToContainer } from '../utils/ast-utils.js';\nimport { CstNodeBuilder } from './cst-node-builder.js';\nexport const DatatypeSymbol = Symbol('Datatype');\nfunction isDataTypeNode(node) {\n    return node.$type === DatatypeSymbol;\n}\nconst ruleSuffix = '\\u200B';\nconst withRuleSuffix = (name) => name.endsWith(ruleSuffix) ? name : name + ruleSuffix;\nexport class AbstractLangiumParser {\n    constructor(services) {\n        this._unorderedGroups = new Map();\n        this.allRules = new Map();\n        this.lexer = services.parser.Lexer;\n        const tokens = this.lexer.definition;\n        const production = services.LanguageMetaData.mode === 'production';\n        this.wrapper = new ChevrotainWrapper(tokens, Object.assign(Object.assign({}, services.parser.ParserConfig), { skipValidations: production, errorMessageProvider: services.parser.ParserErrorMessageProvider }));\n    }\n    alternatives(idx, choices) {\n        this.wrapper.wrapOr(idx, choices);\n    }\n    optional(idx, callback) {\n        this.wrapper.wrapOption(idx, callback);\n    }\n    many(idx, callback) {\n        this.wrapper.wrapMany(idx, callback);\n    }\n    atLeastOne(idx, callback) {\n        this.wrapper.wrapAtLeastOne(idx, callback);\n    }\n    getRule(name) {\n        return this.allRules.get(name);\n    }\n    isRecording() {\n        return this.wrapper.IS_RECORDING;\n    }\n    get unorderedGroups() {\n        return this._unorderedGroups;\n    }\n    getRuleStack() {\n        return this.wrapper.RULE_STACK;\n    }\n    finalize() {\n        this.wrapper.wrapSelfAnalysis();\n    }\n}\nexport class LangiumParser extends AbstractLangiumParser {\n    get current() {\n        return this.stack[this.stack.length - 1];\n    }\n    constructor(services) {\n        super(services);\n        this.nodeBuilder = new CstNodeBuilder();\n        this.stack = [];\n        this.assignmentMap = new Map();\n        this.linker = services.references.Linker;\n        this.converter = services.parser.ValueConverter;\n        this.astReflection = services.shared.AstReflection;\n    }\n    rule(rule, impl) {\n        const type = this.computeRuleType(rule);\n        const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(type, impl).bind(this));\n        this.allRules.set(rule.name, ruleMethod);\n        if (rule.entry) {\n            this.mainRule = ruleMethod;\n        }\n        return ruleMethod;\n    }\n    computeRuleType(rule) {\n        if (rule.fragment) {\n            return undefined;\n        }\n        else if (isDataTypeRule(rule)) {\n            return DatatypeSymbol;\n        }\n        else {\n            const explicit = getExplicitRuleType(rule);\n            return explicit !== null && explicit !== void 0 ? explicit : rule.name;\n        }\n    }\n    parse(input, options = {}) {\n        this.nodeBuilder.buildRootNode(input);\n        const lexerResult = this.lexerResult = this.lexer.tokenize(input);\n        this.wrapper.input = lexerResult.tokens;\n        const ruleMethod = options.rule ? this.allRules.get(options.rule) : this.mainRule;\n        if (!ruleMethod) {\n            throw new Error(options.rule ? `No rule found with name '${options.rule}'` : 'No main rule available.');\n        }\n        const result = ruleMethod.call(this.wrapper, {});\n        this.nodeBuilder.addHiddenNodes(lexerResult.hidden);\n        this.unorderedGroups.clear();\n        this.lexerResult = undefined;\n        return {\n            value: result,\n            lexerErrors: lexerResult.errors,\n            lexerReport: lexerResult.report,\n            parserErrors: this.wrapper.errors\n        };\n    }\n    startImplementation($type, implementation) {\n        return (args) => {\n            // Only create a new AST node in case the calling rule is not a fragment rule\n            const createNode = !this.isRecording() && $type !== undefined;\n            if (createNode) {\n                const node = { $type };\n                this.stack.push(node);\n                if ($type === DatatypeSymbol) {\n                    node.value = '';\n                }\n            }\n            let result;\n            try {\n                result = implementation(args);\n            }\n            catch (err) {\n                result = undefined;\n            }\n            if (result === undefined && createNode) {\n                result = this.construct();\n            }\n            return result;\n        };\n    }\n    extractHiddenTokens(token) {\n        const hiddenTokens = this.lexerResult.hidden;\n        if (!hiddenTokens.length) {\n            return [];\n        }\n        const offset = token.startOffset;\n        for (let i = 0; i < hiddenTokens.length; i++) {\n            const token = hiddenTokens[i];\n            if (token.startOffset > offset) {\n                return hiddenTokens.splice(0, i);\n            }\n        }\n        return hiddenTokens.splice(0, hiddenTokens.length);\n    }\n    consume(idx, tokenType, feature) {\n        const token = this.wrapper.wrapConsume(idx, tokenType);\n        if (!this.isRecording() && this.isValidToken(token)) {\n            const hiddenTokens = this.extractHiddenTokens(token);\n            this.nodeBuilder.addHiddenNodes(hiddenTokens);\n            const leafNode = this.nodeBuilder.buildLeafNode(token, feature);\n            const { assignment, isCrossRef } = this.getAssignment(feature);\n            const current = this.current;\n            if (assignment) {\n                const convertedValue = isKeyword(feature) ? token.image : this.converter.convert(token.image, leafNode);\n                this.assign(assignment.operator, assignment.feature, convertedValue, leafNode, isCrossRef);\n            }\n            else if (isDataTypeNode(current)) {\n                let text = token.image;\n                if (!isKeyword(feature)) {\n                    text = this.converter.convert(text, leafNode).toString();\n                }\n                current.value += text;\n            }\n        }\n    }\n    /**\n     * Most consumed parser tokens are valid. However there are two cases in which they are not valid:\n     *\n     * 1. They were inserted during error recovery by the parser. These tokens don't really exist and should not be further processed\n     * 2. They contain invalid token ranges. This might include the special EOF token, or other tokens produced by invalid token builders.\n     */\n    isValidToken(token) {\n        return !token.isInsertedInRecovery && !isNaN(token.startOffset) && typeof token.endOffset === 'number' && !isNaN(token.endOffset);\n    }\n    subrule(idx, rule, fragment, feature, args) {\n        let cstNode;\n        if (!this.isRecording() && !fragment) {\n            // We only want to create a new CST node if the subrule actually creates a new AST node.\n            // In other cases like calls of fragment rules the current CST/AST is populated further.\n            // Note that skipping this initialization and leaving cstNode unassigned also skips the subrule assignment later on.\n            // This is intended, as fragment rules only enrich the current AST node\n            cstNode = this.nodeBuilder.buildCompositeNode(feature);\n        }\n        const subruleResult = this.wrapper.wrapSubrule(idx, rule, args);\n        if (!this.isRecording() && cstNode && cstNode.length > 0) {\n            this.performSubruleAssignment(subruleResult, feature, cstNode);\n        }\n    }\n    performSubruleAssignment(result, feature, cstNode) {\n        const { assignment, isCrossRef } = this.getAssignment(feature);\n        if (assignment) {\n            this.assign(assignment.operator, assignment.feature, result, cstNode, isCrossRef);\n        }\n        else if (!assignment) {\n            // If we call a subrule without an assignment we either:\n            // 1. append the result of the subrule (data type rule)\n            // 2. override the current object with the newly parsed object\n            // If the current element is an AST node and the result of the subrule\n            // is a data type rule, we can safely discard the results.\n            const current = this.current;\n            if (isDataTypeNode(current)) {\n                current.value += result.toString();\n            }\n            else if (typeof result === 'object' && result) {\n                const object = this.assignWithoutOverride(result, current);\n                const newItem = object;\n                this.stack.pop();\n                this.stack.push(newItem);\n            }\n        }\n    }\n    action($type, action) {\n        if (!this.isRecording()) {\n            let last = this.current;\n            if (action.feature && action.operator) {\n                last = this.construct();\n                this.nodeBuilder.removeNode(last.$cstNode);\n                const node = this.nodeBuilder.buildCompositeNode(action);\n                node.content.push(last.$cstNode);\n                const newItem = { $type };\n                this.stack.push(newItem);\n                this.assign(action.operator, action.feature, last, last.$cstNode, false);\n            }\n            else {\n                last.$type = $type;\n            }\n        }\n    }\n    construct() {\n        if (this.isRecording()) {\n            return undefined;\n        }\n        const obj = this.current;\n        linkContentToContainer(obj);\n        this.nodeBuilder.construct(obj);\n        this.stack.pop();\n        if (isDataTypeNode(obj)) {\n            return this.converter.convert(obj.value, obj.$cstNode);\n        }\n        else {\n            assignMandatoryProperties(this.astReflection, obj);\n        }\n        return obj;\n    }\n    getAssignment(feature) {\n        if (!this.assignmentMap.has(feature)) {\n            const assignment = getContainerOfType(feature, isAssignment);\n            this.assignmentMap.set(feature, {\n                assignment: assignment,\n                isCrossRef: assignment ? isCrossReference(assignment.terminal) : false\n            });\n        }\n        return this.assignmentMap.get(feature);\n    }\n    assign(operator, feature, value, cstNode, isCrossRef) {\n        const obj = this.current;\n        let item;\n        if (isCrossRef && typeof value === 'string') {\n            item = this.linker.buildReference(obj, feature, cstNode, value);\n        }\n        else {\n            item = value;\n        }\n        switch (operator) {\n            case '=': {\n                obj[feature] = item;\n                break;\n            }\n            case '?=': {\n                obj[feature] = true;\n                break;\n            }\n            case '+=': {\n                if (!Array.isArray(obj[feature])) {\n                    obj[feature] = [];\n                }\n                obj[feature].push(item);\n            }\n        }\n    }\n    assignWithoutOverride(target, source) {\n        for (const [name, existingValue] of Object.entries(source)) {\n            const newValue = target[name];\n            if (newValue === undefined) {\n                target[name] = existingValue;\n            }\n            else if (Array.isArray(newValue) && Array.isArray(existingValue)) {\n                existingValue.push(...newValue);\n                target[name] = existingValue;\n            }\n        }\n        // The target was parsed from a unassigned subrule\n        // After the subrule construction, it received a cst node\n        // This CST node will later be overriden by the cst node builder\n        // To prevent references to stale AST nodes in the CST,\n        // we need to remove the reference here\n        const targetCstNode = target.$cstNode;\n        if (targetCstNode) {\n            targetCstNode.astNode = undefined;\n            target.$cstNode = undefined;\n        }\n        return target;\n    }\n    get definitionErrors() {\n        return this.wrapper.definitionErrors;\n    }\n}\nexport class AbstractParserErrorMessageProvider {\n    buildMismatchTokenMessage(options) {\n        return defaultParserErrorProvider.buildMismatchTokenMessage(options);\n    }\n    buildNotAllInputParsedMessage(options) {\n        return defaultParserErrorProvider.buildNotAllInputParsedMessage(options);\n    }\n    buildNoViableAltMessage(options) {\n        return defaultParserErrorProvider.buildNoViableAltMessage(options);\n    }\n    buildEarlyExitMessage(options) {\n        return defaultParserErrorProvider.buildEarlyExitMessage(options);\n    }\n}\nexport class LangiumParserErrorMessageProvider extends AbstractParserErrorMessageProvider {\n    buildMismatchTokenMessage({ expected, actual }) {\n        const expectedMsg = expected.LABEL\n            ? '`' + expected.LABEL + '`'\n            : expected.name.endsWith(':KW')\n                ? `keyword '${expected.name.substring(0, expected.name.length - 3)}'`\n                : `token of type '${expected.name}'`;\n        return `Expecting ${expectedMsg} but found \\`${actual.image}\\`.`;\n    }\n    buildNotAllInputParsedMessage({ firstRedundant }) {\n        return `Expecting end of file but found \\`${firstRedundant.image}\\`.`;\n    }\n}\nexport class LangiumCompletionParser extends AbstractLangiumParser {\n    constructor() {\n        super(...arguments);\n        this.tokens = [];\n        this.elementStack = [];\n        this.lastElementStack = [];\n        this.nextTokenIndex = 0;\n        this.stackSize = 0;\n    }\n    action() {\n        // NOOP\n    }\n    construct() {\n        // NOOP\n        return undefined;\n    }\n    parse(input) {\n        this.resetState();\n        const tokens = this.lexer.tokenize(input, { mode: 'partial' });\n        this.tokens = tokens.tokens;\n        this.wrapper.input = [...this.tokens];\n        this.mainRule.call(this.wrapper, {});\n        this.unorderedGroups.clear();\n        return {\n            tokens: this.tokens,\n            elementStack: [...this.lastElementStack],\n            tokenIndex: this.nextTokenIndex\n        };\n    }\n    rule(rule, impl) {\n        const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(impl).bind(this));\n        this.allRules.set(rule.name, ruleMethod);\n        if (rule.entry) {\n            this.mainRule = ruleMethod;\n        }\n        return ruleMethod;\n    }\n    resetState() {\n        this.elementStack = [];\n        this.lastElementStack = [];\n        this.nextTokenIndex = 0;\n        this.stackSize = 0;\n    }\n    startImplementation(implementation) {\n        return (args) => {\n            const size = this.keepStackSize();\n            try {\n                implementation(args);\n            }\n            finally {\n                this.resetStackSize(size);\n            }\n        };\n    }\n    removeUnexpectedElements() {\n        this.elementStack.splice(this.stackSize);\n    }\n    keepStackSize() {\n        const size = this.elementStack.length;\n        this.stackSize = size;\n        return size;\n    }\n    resetStackSize(size) {\n        this.removeUnexpectedElements();\n        this.stackSize = size;\n    }\n    consume(idx, tokenType, feature) {\n        this.wrapper.wrapConsume(idx, tokenType);\n        if (!this.isRecording()) {\n            this.lastElementStack = [...this.elementStack, feature];\n            this.nextTokenIndex = this.currIdx + 1;\n        }\n    }\n    subrule(idx, rule, fragment, feature, args) {\n        this.before(feature);\n        this.wrapper.wrapSubrule(idx, rule, args);\n        this.after(feature);\n    }\n    before(element) {\n        if (!this.isRecording()) {\n            this.elementStack.push(element);\n        }\n    }\n    after(element) {\n        if (!this.isRecording()) {\n            const index = this.elementStack.lastIndexOf(element);\n            if (index >= 0) {\n                this.elementStack.splice(index);\n            }\n        }\n    }\n    get currIdx() {\n        return this.wrapper.currIdx;\n    }\n}\nconst defaultConfig = {\n    recoveryEnabled: true,\n    nodeLocationTracking: 'full',\n    skipValidations: true,\n    errorMessageProvider: new LangiumParserErrorMessageProvider()\n};\n/**\n * This class wraps the embedded actions parser of chevrotain and exposes protected methods.\n * This way, we can build the `LangiumParser` as a composition.\n */\nclass ChevrotainWrapper extends EmbeddedActionsParser {\n    constructor(tokens, config) {\n        const useDefaultLookahead = config && 'maxLookahead' in config;\n        super(tokens, Object.assign(Object.assign(Object.assign({}, defaultConfig), { lookaheadStrategy: useDefaultLookahead\n                ? new LLkLookaheadStrategy({ maxLookahead: config.maxLookahead })\n                : new LLStarLookaheadStrategy({\n                    // If validations are skipped, don't log the lookahead warnings\n                    logging: config.skipValidations ? () => { } : undefined\n                }) }), config));\n    }\n    get IS_RECORDING() {\n        return this.RECORDING_PHASE;\n    }\n    DEFINE_RULE(name, impl) {\n        return this.RULE(name, impl);\n    }\n    wrapSelfAnalysis() {\n        this.performSelfAnalysis();\n    }\n    wrapConsume(idx, tokenType) {\n        return this.consume(idx, tokenType);\n    }\n    wrapSubrule(idx, rule, args) {\n        return this.subrule(idx, rule, {\n            ARGS: [args]\n        });\n    }\n    wrapOr(idx, choices) {\n        this.or(idx, choices);\n    }\n    wrapOption(idx, callback) {\n        this.option(idx, callback);\n    }\n    wrapMany(idx, callback) {\n        this.many(idx, callback);\n    }\n    wrapAtLeastOne(idx, callback) {\n        this.atLeastOne(idx, callback);\n    }\n}\n//# sourceMappingURL=langium-parser.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { EMPTY_ALT, EOF } from 'chevrotain';\nimport { isAction, isAlternatives, isEndOfFile, isAssignment, isConjunction, isCrossReference, isDisjunction, isGroup, isKeyword, isNegation, isParameterReference, isParserRule, isRuleCall, isTerminalRule, isUnorderedGroup, isBooleanLiteral } from '../languages/generated/ast.js';\nimport { assertUnreachable, ErrorWithLocation } from '../utils/errors.js';\nimport { stream } from '../utils/stream.js';\nimport { findNameAssignment, getAllReachableRules, getTypeName } from '../utils/grammar-utils.js';\nexport function createParser(grammar, parser, tokens) {\n    const parserContext = {\n        parser,\n        tokens,\n        ruleNames: new Map()\n    };\n    buildRules(parserContext, grammar);\n    return parser;\n}\nfunction buildRules(parserContext, grammar) {\n    const reachable = getAllReachableRules(grammar, false);\n    const parserRules = stream(grammar.rules).filter(isParserRule).filter(rule => reachable.has(rule));\n    for (const rule of parserRules) {\n        const ctx = Object.assign(Object.assign({}, parserContext), { consume: 1, optional: 1, subrule: 1, many: 1, or: 1 });\n        parserContext.parser.rule(rule, buildElement(ctx, rule.definition));\n    }\n}\nfunction buildElement(ctx, element, ignoreGuard = false) {\n    let method;\n    if (isKeyword(element)) {\n        method = buildKeyword(ctx, element);\n    }\n    else if (isAction(element)) {\n        method = buildAction(ctx, element);\n    }\n    else if (isAssignment(element)) {\n        method = buildElement(ctx, element.terminal);\n    }\n    else if (isCrossReference(element)) {\n        method = buildCrossReference(ctx, element);\n    }\n    else if (isRuleCall(element)) {\n        method = buildRuleCall(ctx, element);\n    }\n    else if (isAlternatives(element)) {\n        method = buildAlternatives(ctx, element);\n    }\n    else if (isUnorderedGroup(element)) {\n        method = buildUnorderedGroup(ctx, element);\n    }\n    else if (isGroup(element)) {\n        method = buildGroup(ctx, element);\n    }\n    else if (isEndOfFile(element)) {\n        const idx = ctx.consume++;\n        method = () => ctx.parser.consume(idx, EOF, element);\n    }\n    else {\n        throw new ErrorWithLocation(element.$cstNode, `Unexpected element type: ${element.$type}`);\n    }\n    return wrap(ctx, ignoreGuard ? undefined : getGuardCondition(element), method, element.cardinality);\n}\nfunction buildAction(ctx, action) {\n    const actionType = getTypeName(action);\n    return () => ctx.parser.action(actionType, action);\n}\nfunction buildRuleCall(ctx, ruleCall) {\n    const rule = ruleCall.rule.ref;\n    if (isParserRule(rule)) {\n        const idx = ctx.subrule++;\n        const fragment = rule.fragment;\n        const predicate = ruleCall.arguments.length > 0 ? buildRuleCallPredicate(rule, ruleCall.arguments) : () => ({});\n        return (args) => ctx.parser.subrule(idx, getRule(ctx, rule), fragment, ruleCall, predicate(args));\n    }\n    else if (isTerminalRule(rule)) {\n        const idx = ctx.consume++;\n        const method = getToken(ctx, rule.name);\n        return () => ctx.parser.consume(idx, method, ruleCall);\n    }\n    else if (!rule) {\n        throw new ErrorWithLocation(ruleCall.$cstNode, `Undefined rule: ${ruleCall.rule.$refText}`);\n    }\n    else {\n        assertUnreachable(rule);\n    }\n}\nfunction buildRuleCallPredicate(rule, namedArgs) {\n    const predicates = namedArgs.map(e => buildPredicate(e.value));\n    return (args) => {\n        const ruleArgs = {};\n        for (let i = 0; i < predicates.length; i++) {\n            const ruleTarget = rule.parameters[i];\n            const predicate = predicates[i];\n            ruleArgs[ruleTarget.name] = predicate(args);\n        }\n        return ruleArgs;\n    };\n}\nfunction buildPredicate(condition) {\n    if (isDisjunction(condition)) {\n        const left = buildPredicate(condition.left);\n        const right = buildPredicate(condition.right);\n        return (args) => (left(args) || right(args));\n    }\n    else if (isConjunction(condition)) {\n        const left = buildPredicate(condition.left);\n        const right = buildPredicate(condition.right);\n        return (args) => (left(args) && right(args));\n    }\n    else if (isNegation(condition)) {\n        const value = buildPredicate(condition.value);\n        return (args) => !value(args);\n    }\n    else if (isParameterReference(condition)) {\n        const name = condition.parameter.ref.name;\n        return (args) => args !== undefined && args[name] === true;\n    }\n    else if (isBooleanLiteral(condition)) {\n        const value = Boolean(condition.true);\n        return () => value;\n    }\n    assertUnreachable(condition);\n}\nfunction buildAlternatives(ctx, alternatives) {\n    if (alternatives.elements.length === 1) {\n        return buildElement(ctx, alternatives.elements[0]);\n    }\n    else {\n        const methods = [];\n        for (const element of alternatives.elements) {\n            const predicatedMethod = {\n                // Since we handle the guard condition in the alternative already\n                // We can ignore the group guard condition inside\n                ALT: buildElement(ctx, element, true)\n            };\n            const guard = getGuardCondition(element);\n            if (guard) {\n                predicatedMethod.GATE = buildPredicate(guard);\n            }\n            methods.push(predicatedMethod);\n        }\n        const idx = ctx.or++;\n        return (args) => ctx.parser.alternatives(idx, methods.map(method => {\n            const alt = {\n                ALT: () => method.ALT(args)\n            };\n            const gate = method.GATE;\n            if (gate) {\n                alt.GATE = () => gate(args);\n            }\n            return alt;\n        }));\n    }\n}\nfunction buildUnorderedGroup(ctx, group) {\n    if (group.elements.length === 1) {\n        return buildElement(ctx, group.elements[0]);\n    }\n    const methods = [];\n    for (const element of group.elements) {\n        const predicatedMethod = {\n            // Since we handle the guard condition in the alternative already\n            // We can ignore the group guard condition inside\n            ALT: buildElement(ctx, element, true)\n        };\n        const guard = getGuardCondition(element);\n        if (guard) {\n            predicatedMethod.GATE = buildPredicate(guard);\n        }\n        methods.push(predicatedMethod);\n    }\n    const orIdx = ctx.or++;\n    const idFunc = (groupIdx, lParser) => {\n        const stackId = lParser.getRuleStack().join('-');\n        return `uGroup_${groupIdx}_${stackId}`;\n    };\n    const alternatives = (args) => ctx.parser.alternatives(orIdx, methods.map((method, idx) => {\n        const alt = { ALT: () => true };\n        const parser = ctx.parser;\n        alt.ALT = () => {\n            method.ALT(args);\n            if (!parser.isRecording()) {\n                const key = idFunc(orIdx, parser);\n                if (!parser.unorderedGroups.get(key)) {\n                    // init after clear state\n                    parser.unorderedGroups.set(key, []);\n                }\n                const groupState = parser.unorderedGroups.get(key);\n                if (typeof (groupState === null || groupState === void 0 ? void 0 : groupState[idx]) === 'undefined') {\n                    // Not accessed yet\n                    groupState[idx] = true;\n                }\n            }\n        };\n        const gate = method.GATE;\n        if (gate) {\n            alt.GATE = () => gate(args);\n        }\n        else {\n            alt.GATE = () => {\n                const trackedAlternatives = parser.unorderedGroups.get(idFunc(orIdx, parser));\n                const allow = !(trackedAlternatives === null || trackedAlternatives === void 0 ? void 0 : trackedAlternatives[idx]);\n                return allow;\n            };\n        }\n        return alt;\n    }));\n    const wrapped = wrap(ctx, getGuardCondition(group), alternatives, '*');\n    return (args) => {\n        wrapped(args);\n        if (!ctx.parser.isRecording()) {\n            ctx.parser.unorderedGroups.delete(idFunc(orIdx, ctx.parser));\n        }\n    };\n}\nfunction buildGroup(ctx, group) {\n    const methods = group.elements.map(e => buildElement(ctx, e));\n    return (args) => methods.forEach(method => method(args));\n}\nfunction getGuardCondition(element) {\n    if (isGroup(element)) {\n        return element.guardCondition;\n    }\n    return undefined;\n}\nfunction buildCrossReference(ctx, crossRef, terminal = crossRef.terminal) {\n    if (!terminal) {\n        if (!crossRef.type.ref) {\n            throw new Error('Could not resolve reference to type: ' + crossRef.type.$refText);\n        }\n        const assignment = findNameAssignment(crossRef.type.ref);\n        const assignTerminal = assignment === null || assignment === void 0 ? void 0 : assignment.terminal;\n        if (!assignTerminal) {\n            throw new Error('Could not find name assignment for type: ' + getTypeName(crossRef.type.ref));\n        }\n        return buildCrossReference(ctx, crossRef, assignTerminal);\n    }\n    else if (isRuleCall(terminal) && isParserRule(terminal.rule.ref)) {\n        // The terminal is a data type rule here. Everything else will result in a validation error.\n        const rule = terminal.rule.ref;\n        const idx = ctx.subrule++;\n        return (args) => ctx.parser.subrule(idx, getRule(ctx, rule), false, crossRef, args);\n    }\n    else if (isRuleCall(terminal) && isTerminalRule(terminal.rule.ref)) {\n        const idx = ctx.consume++;\n        const terminalRule = getToken(ctx, terminal.rule.ref.name);\n        return () => ctx.parser.consume(idx, terminalRule, crossRef);\n    }\n    else if (isKeyword(terminal)) {\n        const idx = ctx.consume++;\n        const keyword = getToken(ctx, terminal.value);\n        return () => ctx.parser.consume(idx, keyword, crossRef);\n    }\n    else {\n        throw new Error('Could not build cross reference parser');\n    }\n}\nfunction buildKeyword(ctx, keyword) {\n    const idx = ctx.consume++;\n    const token = ctx.tokens[keyword.value];\n    if (!token) {\n        throw new Error('Could not find token for keyword: ' + keyword.value);\n    }\n    return () => ctx.parser.consume(idx, token, keyword);\n}\nfunction wrap(ctx, guard, method, cardinality) {\n    const gate = guard && buildPredicate(guard);\n    if (!cardinality) {\n        if (gate) {\n            const idx = ctx.or++;\n            return (args) => ctx.parser.alternatives(idx, [\n                {\n                    ALT: () => method(args),\n                    GATE: () => gate(args)\n                },\n                {\n                    ALT: EMPTY_ALT(),\n                    GATE: () => !gate(args)\n                }\n            ]);\n        }\n        else {\n            return method;\n        }\n    }\n    if (cardinality === '*') {\n        const idx = ctx.many++;\n        return (args) => ctx.parser.many(idx, {\n            DEF: () => method(args),\n            GATE: gate ? () => gate(args) : undefined\n        });\n    }\n    else if (cardinality === '+') {\n        const idx = ctx.many++;\n        if (gate) {\n            const orIdx = ctx.or++;\n            // In the case of a guard condition for the `+` group\n            // We combine it with an empty alternative\n            // If the condition returns true, it needs to parse at least a single iteration\n            // If its false, it is not allowed to parse anything\n            return (args) => ctx.parser.alternatives(orIdx, [\n                {\n                    ALT: () => ctx.parser.atLeastOne(idx, {\n                        DEF: () => method(args)\n                    }),\n                    GATE: () => gate(args)\n                },\n                {\n                    ALT: EMPTY_ALT(),\n                    GATE: () => !gate(args)\n                }\n            ]);\n        }\n        else {\n            return (args) => ctx.parser.atLeastOne(idx, {\n                DEF: () => method(args),\n            });\n        }\n    }\n    else if (cardinality === '?') {\n        const idx = ctx.optional++;\n        return (args) => ctx.parser.optional(idx, {\n            DEF: () => method(args),\n            GATE: gate ? () => gate(args) : undefined\n        });\n    }\n    else {\n        assertUnreachable(cardinality);\n    }\n}\nfunction getRule(ctx, element) {\n    const name = getRuleName(ctx, element);\n    const rule = ctx.parser.getRule(name);\n    if (!rule)\n        throw new Error(`Rule \"${name}\" not found.\"`);\n    return rule;\n}\nfunction getRuleName(ctx, element) {\n    if (isParserRule(element)) {\n        return element.name;\n    }\n    else if (ctx.ruleNames.has(element)) {\n        return ctx.ruleNames.get(element);\n    }\n    else {\n        let item = element;\n        let parent = item.$container;\n        let ruleName = element.$type;\n        while (!isParserRule(parent)) {\n            if (isGroup(parent) || isAlternatives(parent) || isUnorderedGroup(parent)) {\n                const index = parent.elements.indexOf(item);\n                ruleName = index.toString() + ':' + ruleName;\n            }\n            item = parent;\n            parent = parent.$container;\n        }\n        const rule = parent;\n        ruleName = rule.name + ':' + ruleName;\n        ctx.ruleNames.set(element, ruleName);\n        return ruleName;\n    }\n}\nfunction getToken(ctx, name) {\n    const token = ctx.tokens[name];\n    if (!token)\n        throw new Error(`Token \"${name}\" not found.\"`);\n    return token;\n}\n//# sourceMappingURL=parser-builder-base.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { LangiumCompletionParser } from './langium-parser.js';\nimport { createParser } from './parser-builder-base.js';\nexport function createCompletionParser(services) {\n    const grammar = services.Grammar;\n    const lexer = services.parser.Lexer;\n    const parser = new LangiumCompletionParser(services);\n    createParser(grammar, parser, lexer.definition);\n    parser.finalize();\n    return parser;\n}\n//# sourceMappingURL=completion-parser-builder.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { LangiumParser } from './langium-parser.js';\nimport { createParser } from './parser-builder-base.js';\n/**\n * Create and finalize a Langium parser. The parser rules are derived from the grammar, which is\n * available at `services.Grammar`.\n */\nexport function createLangiumParser(services) {\n    const parser = prepareLangiumParser(services);\n    parser.finalize();\n    return parser;\n}\n/**\n * Create a Langium parser without finalizing it. This is used to extract more detailed error\n * information when the parser is initially validated.\n */\nexport function prepareLangiumParser(services) {\n    const grammar = services.Grammar;\n    const lexer = services.parser.Lexer;\n    const parser = new LangiumParser(services);\n    return createParser(grammar, parser, lexer.definition);\n}\n//# sourceMappingURL=langium-parser-builder.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken, CancellationTokenSource } from '../utils/cancellation.js';\n/**\n * Delays the execution of the current code to the next tick of the event loop.\n * Don't call this method directly in a tight loop to prevent too many promises from being created.\n */\nexport function delayNextTick() {\n    return new Promise(resolve => {\n        // In case we are running in a non-node environment, `setImmediate` isn't available.\n        // Using `setTimeout` of the browser API accomplishes the same result.\n        if (typeof setImmediate === 'undefined') {\n            setTimeout(resolve, 0);\n        }\n        else {\n            setImmediate(resolve);\n        }\n    });\n}\nlet lastTick = 0;\nlet globalInterruptionPeriod = 10;\n/**\n * Reset the global interruption period and create a cancellation token source.\n */\nexport function startCancelableOperation() {\n    lastTick = performance.now();\n    return new CancellationTokenSource();\n}\n/**\n * Change the period duration for `interruptAndCheck` to the given number of milliseconds.\n * The default value is 10ms.\n */\nexport function setInterruptionPeriod(period) {\n    globalInterruptionPeriod = period;\n}\n/**\n * This symbol may be thrown in an asynchronous context by any Langium service that receives\n * a `CancellationToken`. This means that the promise returned by such a service is rejected with\n * this symbol as rejection reason.\n */\nexport const OperationCancelled = Symbol('OperationCancelled');\n/**\n * Use this in a `catch` block to check whether the thrown object indicates that the operation\n * has been cancelled.\n */\nexport function isOperationCancelled(err) {\n    return err === OperationCancelled;\n}\n/**\n * This function does two things:\n *  1. Check the elapsed time since the last call to this function or to `startCancelableOperation`. If the predefined\n *     period (configured with `setInterruptionPeriod`) is exceeded, execution is delayed with `delayNextTick`.\n *  2. If the predefined period is not met yet or execution is resumed after an interruption, the given cancellation\n *     token is checked, and if cancellation is requested, `OperationCanceled` is thrown.\n *\n * All services in Langium that receive a `CancellationToken` may potentially call this function, so the\n * `CancellationToken` must be caught (with an `async` try-catch block or a `catch` callback attached to\n * the promise) to avoid that event being exposed as an error.\n */\nexport async function interruptAndCheck(token) {\n    if (token === CancellationToken.None) {\n        // Early exit in case cancellation was disabled by the caller\n        return;\n    }\n    const current = performance.now();\n    if (current - lastTick >= globalInterruptionPeriod) {\n        lastTick = current;\n        await delayNextTick();\n        // prevent calling delayNextTick every iteration of loop\n        // where delayNextTick takes up the majority or all of the\n        // globalInterruptionPeriod itself\n        lastTick = performance.now();\n    }\n    if (token.isCancellationRequested) {\n        throw OperationCancelled;\n    }\n}\n/**\n * Simple implementation of the deferred pattern.\n * An object that exposes a promise and functions to resolve and reject it.\n */\nexport class Deferred {\n    constructor() {\n        this.promise = new Promise((resolve, reject) => {\n            this.resolve = (arg) => {\n                resolve(arg);\n                return this;\n            };\n            this.reject = (err) => {\n                reject(err);\n                return this;\n            };\n        });\n    }\n}\n//# sourceMappingURL=promise-utils.js.map","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\n'use strict';\nclass FullTextDocument {\n    constructor(uri, languageId, version, content) {\n        this._uri = uri;\n        this._languageId = languageId;\n        this._version = version;\n        this._content = content;\n        this._lineOffsets = undefined;\n    }\n    get uri() {\n        return this._uri;\n    }\n    get languageId() {\n        return this._languageId;\n    }\n    get version() {\n        return this._version;\n    }\n    getText(range) {\n        if (range) {\n            const start = this.offsetAt(range.start);\n            const end = this.offsetAt(range.end);\n            return this._content.substring(start, end);\n        }\n        return this._content;\n    }\n    update(changes, version) {\n        for (const change of changes) {\n            if (FullTextDocument.isIncremental(change)) {\n                // makes sure start is before end\n                const range = getWellformedRange(change.range);\n                // update content\n                const startOffset = this.offsetAt(range.start);\n                const endOffset = this.offsetAt(range.end);\n                this._content = this._content.substring(0, startOffset) + change.text + this._content.substring(endOffset, this._content.length);\n                // update the offsets\n                const startLine = Math.max(range.start.line, 0);\n                const endLine = Math.max(range.end.line, 0);\n                let lineOffsets = this._lineOffsets;\n                const addedLineOffsets = computeLineOffsets(change.text, false, startOffset);\n                if (endLine - startLine === addedLineOffsets.length) {\n                    for (let i = 0, len = addedLineOffsets.length; i < len; i++) {\n                        lineOffsets[i + startLine + 1] = addedLineOffsets[i];\n                    }\n                }\n                else {\n                    if (addedLineOffsets.length < 10000) {\n                        lineOffsets.splice(startLine + 1, endLine - startLine, ...addedLineOffsets);\n                    }\n                    else { // avoid too many arguments for splice\n                        this._lineOffsets = lineOffsets = lineOffsets.slice(0, startLine + 1).concat(addedLineOffsets, lineOffsets.slice(endLine + 1));\n                    }\n                }\n                const diff = change.text.length - (endOffset - startOffset);\n                if (diff !== 0) {\n                    for (let i = startLine + 1 + addedLineOffsets.length, len = lineOffsets.length; i < len; i++) {\n                        lineOffsets[i] = lineOffsets[i] + diff;\n                    }\n                }\n            }\n            else if (FullTextDocument.isFull(change)) {\n                this._content = change.text;\n                this._lineOffsets = undefined;\n            }\n            else {\n                throw new Error('Unknown change event received');\n            }\n        }\n        this._version = version;\n    }\n    getLineOffsets() {\n        if (this._lineOffsets === undefined) {\n            this._lineOffsets = computeLineOffsets(this._content, true);\n        }\n        return this._lineOffsets;\n    }\n    positionAt(offset) {\n        offset = Math.max(Math.min(offset, this._content.length), 0);\n        const lineOffsets = this.getLineOffsets();\n        let low = 0, high = lineOffsets.length;\n        if (high === 0) {\n            return { line: 0, character: offset };\n        }\n        while (low < high) {\n            const mid = Math.floor((low + high) / 2);\n            if (lineOffsets[mid] > offset) {\n                high = mid;\n            }\n            else {\n                low = mid + 1;\n            }\n        }\n        // low is the least x for which the line offset is larger than the current offset\n        // or array.length if no line offset is larger than the current offset\n        const line = low - 1;\n        offset = this.ensureBeforeEOL(offset, lineOffsets[line]);\n        return { line, character: offset - lineOffsets[line] };\n    }\n    offsetAt(position) {\n        const lineOffsets = this.getLineOffsets();\n        if (position.line >= lineOffsets.length) {\n            return this._content.length;\n        }\n        else if (position.line < 0) {\n            return 0;\n        }\n        const lineOffset = lineOffsets[position.line];\n        if (position.character <= 0) {\n            return lineOffset;\n        }\n        const nextLineOffset = (position.line + 1 < lineOffsets.length) ? lineOffsets[position.line + 1] : this._content.length;\n        const offset = Math.min(lineOffset + position.character, nextLineOffset);\n        return this.ensureBeforeEOL(offset, lineOffset);\n    }\n    ensureBeforeEOL(offset, lineOffset) {\n        while (offset > lineOffset && isEOL(this._content.charCodeAt(offset - 1))) {\n            offset--;\n        }\n        return offset;\n    }\n    get lineCount() {\n        return this.getLineOffsets().length;\n    }\n    static isIncremental(event) {\n        const candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range !== undefined &&\n            (candidate.rangeLength === undefined || typeof candidate.rangeLength === 'number');\n    }\n    static isFull(event) {\n        const candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range === undefined && candidate.rangeLength === undefined;\n    }\n}\nexport var TextDocument;\n(function (TextDocument) {\n    /**\n     * Creates a new text document.\n     *\n     * @param uri The document's uri.\n     * @param languageId  The document's language Id.\n     * @param version The document's initial version number.\n     * @param content The document's content.\n     */\n    function create(uri, languageId, version, content) {\n        return new FullTextDocument(uri, languageId, version, content);\n    }\n    TextDocument.create = create;\n    /**\n     * Updates a TextDocument by modifying its content.\n     *\n     * @param document the document to update. Only documents created by TextDocument.create are valid inputs.\n     * @param changes the changes to apply to the document.\n     * @param version the changes version for the document.\n     * @returns The updated TextDocument. Note: That's the same document instance passed in as first parameter.\n     *\n     */\n    function update(document, changes, version) {\n        if (document instanceof FullTextDocument) {\n            document.update(changes, version);\n            return document;\n        }\n        else {\n            throw new Error('TextDocument.update: document must be created by TextDocument.create');\n        }\n    }\n    TextDocument.update = update;\n    function applyEdits(document, edits) {\n        const text = document.getText();\n        const sortedEdits = mergeSort(edits.map(getWellformedEdit), (a, b) => {\n            const diff = a.range.start.line - b.range.start.line;\n            if (diff === 0) {\n                return a.range.start.character - b.range.start.character;\n            }\n            return diff;\n        });\n        let lastModifiedOffset = 0;\n        const spans = [];\n        for (const e of sortedEdits) {\n            const startOffset = document.offsetAt(e.range.start);\n            if (startOffset < lastModifiedOffset) {\n                throw new Error('Overlapping edit');\n            }\n            else if (startOffset > lastModifiedOffset) {\n                spans.push(text.substring(lastModifiedOffset, startOffset));\n            }\n            if (e.newText.length) {\n                spans.push(e.newText);\n            }\n            lastModifiedOffset = document.offsetAt(e.range.end);\n        }\n        spans.push(text.substr(lastModifiedOffset));\n        return spans.join('');\n    }\n    TextDocument.applyEdits = applyEdits;\n})(TextDocument || (TextDocument = {}));\nfunction mergeSort(data, compare) {\n    if (data.length <= 1) {\n        // sorted\n        return data;\n    }\n    const p = (data.length / 2) | 0;\n    const left = data.slice(0, p);\n    const right = data.slice(p);\n    mergeSort(left, compare);\n    mergeSort(right, compare);\n    let leftIdx = 0;\n    let rightIdx = 0;\n    let i = 0;\n    while (leftIdx < left.length && rightIdx < right.length) {\n        const ret = compare(left[leftIdx], right[rightIdx]);\n        if (ret <= 0) {\n            // smaller_equal -> take left to preserve order\n            data[i++] = left[leftIdx++];\n        }\n        else {\n            // greater -> take right\n            data[i++] = right[rightIdx++];\n        }\n    }\n    while (leftIdx < left.length) {\n        data[i++] = left[leftIdx++];\n    }\n    while (rightIdx < right.length) {\n        data[i++] = right[rightIdx++];\n    }\n    return data;\n}\nfunction computeLineOffsets(text, isAtLineStart, textOffset = 0) {\n    const result = isAtLineStart ? [textOffset] : [];\n    for (let i = 0; i < text.length; i++) {\n        const ch = text.charCodeAt(i);\n        if (isEOL(ch)) {\n            if (ch === 13 /* CharCode.CarriageReturn */ && i + 1 < text.length && text.charCodeAt(i + 1) === 10 /* CharCode.LineFeed */) {\n                i++;\n            }\n            result.push(textOffset + i + 1);\n        }\n    }\n    return result;\n}\nfunction isEOL(char) {\n    return char === 13 /* CharCode.CarriageReturn */ || char === 10 /* CharCode.LineFeed */;\n}\nfunction getWellformedRange(range) {\n    const start = range.start;\n    const end = range.end;\n    if (start.line > end.line || (start.line === end.line && start.character > end.character)) {\n        return { start: end, end: start };\n    }\n    return range;\n}\nfunction getWellformedEdit(textEdit) {\n    const range = getWellformedRange(textEdit.range);\n    if (range !== textEdit.range) {\n        return { newText: textEdit.newText, range };\n    }\n    return textEdit;\n}\n","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n/**\n * Re-export 'TextDocument' from 'vscode-languageserver-textdocument' for convenience,\n *  including both type _and_ symbol (namespace), as we here and there also refer to the symbol,\n *  the overhead is very small, just a few kilobytes.\n * Everything else of that package (at the time contributing) is also defined\n *  in 'vscode-languageserver-protocol' or 'vscode-languageserver-types'.\n */\nexport { TextDocument } from 'vscode-languageserver-textdocument';\nimport { TextDocument } from './documents.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { stream } from '../utils/stream.js';\nimport { URI } from '../utils/uri-utils.js';\n/**\n * A document is subject to several phases that are run in predefined order. Any state value implies that\n * smaller state values are finished as well.\n */\nexport var DocumentState;\n(function (DocumentState) {\n    /**\n     * The text content has changed and needs to be parsed again. The AST held by this outdated\n     * document instance is no longer valid.\n     */\n    DocumentState[DocumentState[\"Changed\"] = 0] = \"Changed\";\n    /**\n     * An AST has been created from the text content. The document structure can be traversed,\n     * but cross-references cannot be resolved yet. If necessary, the structure can be manipulated\n     * at this stage as a preprocessing step.\n     */\n    DocumentState[DocumentState[\"Parsed\"] = 1] = \"Parsed\";\n    /**\n     * The `IndexManager` service has processed AST nodes of this document. This means the\n     * exported symbols are available in the global scope and can be resolved from other documents.\n     */\n    DocumentState[DocumentState[\"IndexedContent\"] = 2] = \"IndexedContent\";\n    /**\n     * The `ScopeComputation` service has processed this document. This means the local symbols\n     * are stored in a MultiMap so they can be looked up by the `ScopeProvider` service.\n     * Once a document has reached this state, you may follow every reference - it will lazily\n     * resolve its `ref` property and yield either the target AST node or `undefined` in case\n     * the target is not in scope.\n     */\n    DocumentState[DocumentState[\"ComputedScopes\"] = 3] = \"ComputedScopes\";\n    /**\n     * The `Linker` service has processed this document. All outgoing references have been\n     * resolved or marked as erroneous.\n     */\n    DocumentState[DocumentState[\"Linked\"] = 4] = \"Linked\";\n    /**\n     * The `IndexManager` service has processed AST node references of this document. This is\n     * necessary to determine which documents are affected by a change in one of the workspace\n     * documents.\n     */\n    DocumentState[DocumentState[\"IndexedReferences\"] = 5] = \"IndexedReferences\";\n    /**\n     * The `DocumentValidator` service has processed this document. The language server listens\n     * to the results of this phase and sends diagnostics to the client.\n     */\n    DocumentState[DocumentState[\"Validated\"] = 6] = \"Validated\";\n})(DocumentState || (DocumentState = {}));\nexport class DefaultLangiumDocumentFactory {\n    constructor(services) {\n        this.serviceRegistry = services.ServiceRegistry;\n        this.textDocuments = services.workspace.TextDocuments;\n        this.fileSystemProvider = services.workspace.FileSystemProvider;\n    }\n    async fromUri(uri, cancellationToken = CancellationToken.None) {\n        const content = await this.fileSystemProvider.readFile(uri);\n        return this.createAsync(uri, content, cancellationToken);\n    }\n    fromTextDocument(textDocument, uri, token) {\n        uri = uri !== null && uri !== void 0 ? uri : URI.parse(textDocument.uri);\n        if (CancellationToken.is(token)) {\n            return this.createAsync(uri, textDocument, token);\n        }\n        else {\n            return this.create(uri, textDocument, token);\n        }\n    }\n    fromString(text, uri, token) {\n        if (CancellationToken.is(token)) {\n            return this.createAsync(uri, text, token);\n        }\n        else {\n            return this.create(uri, text, token);\n        }\n    }\n    fromModel(model, uri) {\n        return this.create(uri, { $model: model });\n    }\n    create(uri, content, options) {\n        if (typeof content === 'string') {\n            const parseResult = this.parse(uri, content, options);\n            return this.createLangiumDocument(parseResult, uri, undefined, content);\n        }\n        else if ('$model' in content) {\n            const parseResult = { value: content.$model, parserErrors: [], lexerErrors: [] };\n            return this.createLangiumDocument(parseResult, uri);\n        }\n        else {\n            const parseResult = this.parse(uri, content.getText(), options);\n            return this.createLangiumDocument(parseResult, uri, content);\n        }\n    }\n    async createAsync(uri, content, cancelToken) {\n        if (typeof content === 'string') {\n            const parseResult = await this.parseAsync(uri, content, cancelToken);\n            return this.createLangiumDocument(parseResult, uri, undefined, content);\n        }\n        else {\n            const parseResult = await this.parseAsync(uri, content.getText(), cancelToken);\n            return this.createLangiumDocument(parseResult, uri, content);\n        }\n    }\n    /**\n     * Create a LangiumDocument from a given parse result.\n     *\n     * A TextDocument is created on demand if it is not provided as argument here. Usually this\n     * should not be necessary because the main purpose of the TextDocument is to convert between\n     * text ranges and offsets, which is done solely in LSP request handling.\n     *\n     * With the introduction of {@link update} below this method is supposed to be mainly called\n     * during workspace initialization and on addition/recognition of new files, while changes in\n     * existing documents are processed via {@link update}.\n     */\n    createLangiumDocument(parseResult, uri, textDocument, text) {\n        let document;\n        if (textDocument) {\n            document = {\n                parseResult,\n                uri,\n                state: DocumentState.Parsed,\n                references: [],\n                textDocument\n            };\n        }\n        else {\n            const textDocumentGetter = this.createTextDocumentGetter(uri, text);\n            document = {\n                parseResult,\n                uri,\n                state: DocumentState.Parsed,\n                references: [],\n                get textDocument() {\n                    return textDocumentGetter();\n                }\n            };\n        }\n        parseResult.value.$document = document;\n        return document;\n    }\n    async update(document, cancellationToken) {\n        var _a, _b;\n        // The CST full text property contains the original text that was used to create the AST.\n        const oldText = (_a = document.parseResult.value.$cstNode) === null || _a === void 0 ? void 0 : _a.root.fullText;\n        const textDocument = (_b = this.textDocuments) === null || _b === void 0 ? void 0 : _b.get(document.uri.toString());\n        const text = textDocument ? textDocument.getText() : await this.fileSystemProvider.readFile(document.uri);\n        if (textDocument) {\n            Object.defineProperty(document, 'textDocument', {\n                value: textDocument\n            });\n        }\n        else {\n            const textDocumentGetter = this.createTextDocumentGetter(document.uri, text);\n            Object.defineProperty(document, 'textDocument', {\n                get: textDocumentGetter\n            });\n        }\n        // Some of these documents can be pretty large, so parsing them again can be quite expensive.\n        // Therefore, we only parse if the text has actually changed.\n        if (oldText !== text) {\n            document.parseResult = await this.parseAsync(document.uri, text, cancellationToken);\n            document.parseResult.value.$document = document;\n        }\n        document.state = DocumentState.Parsed;\n        return document;\n    }\n    parse(uri, text, options) {\n        const services = this.serviceRegistry.getServices(uri);\n        return services.parser.LangiumParser.parse(text, options);\n    }\n    parseAsync(uri, text, cancellationToken) {\n        const services = this.serviceRegistry.getServices(uri);\n        return services.parser.AsyncParser.parse(text, cancellationToken);\n    }\n    createTextDocumentGetter(uri, text) {\n        const serviceRegistry = this.serviceRegistry;\n        let textDoc = undefined;\n        return () => {\n            return textDoc !== null && textDoc !== void 0 ? textDoc : (textDoc = TextDocument.create(uri.toString(), serviceRegistry.getServices(uri).LanguageMetaData.languageId, 0, text !== null && text !== void 0 ? text : ''));\n        };\n    }\n}\nexport class DefaultLangiumDocuments {\n    constructor(services) {\n        this.documentMap = new Map();\n        this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\n        this.serviceRegistry = services.ServiceRegistry;\n    }\n    get all() {\n        return stream(this.documentMap.values());\n    }\n    addDocument(document) {\n        const uriString = document.uri.toString();\n        if (this.documentMap.has(uriString)) {\n            throw new Error(`A document with the URI '${uriString}' is already present.`);\n        }\n        this.documentMap.set(uriString, document);\n    }\n    getDocument(uri) {\n        const uriString = uri.toString();\n        return this.documentMap.get(uriString);\n    }\n    async getOrCreateDocument(uri, cancellationToken) {\n        let document = this.getDocument(uri);\n        if (document) {\n            return document;\n        }\n        document = await this.langiumDocumentFactory.fromUri(uri, cancellationToken);\n        this.addDocument(document);\n        return document;\n    }\n    createDocument(uri, text, cancellationToken) {\n        if (cancellationToken) {\n            return this.langiumDocumentFactory.fromString(text, uri, cancellationToken).then(document => {\n                this.addDocument(document);\n                return document;\n            });\n        }\n        else {\n            const document = this.langiumDocumentFactory.fromString(text, uri);\n            this.addDocument(document);\n            return document;\n        }\n    }\n    hasDocument(uri) {\n        return this.documentMap.has(uri.toString());\n    }\n    invalidateDocument(uri) {\n        const uriString = uri.toString();\n        const langiumDoc = this.documentMap.get(uriString);\n        if (langiumDoc) {\n            const linker = this.serviceRegistry.getServices(uri).references.Linker;\n            linker.unlink(langiumDoc);\n            langiumDoc.state = DocumentState.Changed;\n            langiumDoc.precomputedScopes = undefined;\n            langiumDoc.diagnostics = undefined;\n        }\n        return langiumDoc;\n    }\n    deleteDocument(uri) {\n        const uriString = uri.toString();\n        const langiumDoc = this.documentMap.get(uriString);\n        if (langiumDoc) {\n            langiumDoc.state = DocumentState.Changed;\n            this.documentMap.delete(uriString);\n        }\n        return langiumDoc;\n    }\n}\n//# sourceMappingURL=documents.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { isAstNode, isAstNodeDescription, isLinkingError } from '../syntax-tree.js';\nimport { findRootNode, streamAst, streamReferences } from '../utils/ast-utils.js';\nimport { interruptAndCheck } from '../utils/promise-utils.js';\nimport { DocumentState } from '../workspace/documents.js';\nconst ref_resolving = Symbol('ref_resolving');\nexport class DefaultLinker {\n    constructor(services) {\n        this.reflection = services.shared.AstReflection;\n        this.langiumDocuments = () => services.shared.workspace.LangiumDocuments;\n        this.scopeProvider = services.references.ScopeProvider;\n        this.astNodeLocator = services.workspace.AstNodeLocator;\n    }\n    async link(document, cancelToken = CancellationToken.None) {\n        for (const node of streamAst(document.parseResult.value)) {\n            await interruptAndCheck(cancelToken);\n            streamReferences(node).forEach(ref => this.doLink(ref, document));\n        }\n    }\n    doLink(refInfo, document) {\n        var _a;\n        const ref = refInfo.reference;\n        // The reference may already have been resolved lazily by accessing its `ref` property.\n        if (ref._ref === undefined) {\n            ref._ref = ref_resolving;\n            try {\n                const description = this.getCandidate(refInfo);\n                if (isLinkingError(description)) {\n                    ref._ref = description;\n                }\n                else {\n                    ref._nodeDescription = description;\n                    if (this.langiumDocuments().hasDocument(description.documentUri)) {\n                        // The target document is already loaded\n                        const linkedNode = this.loadAstNode(description);\n                        ref._ref = linkedNode !== null && linkedNode !== void 0 ? linkedNode : this.createLinkingError(refInfo, description);\n                    }\n                    else {\n                        // Try to load the target AST node later using the already provided description\n                        ref._ref = undefined;\n                    }\n                }\n            }\n            catch (err) {\n                console.error(`An error occurred while resolving reference to '${ref.$refText}':`, err);\n                const errorMessage = (_a = err.message) !== null && _a !== void 0 ? _a : String(err);\n                ref._ref = Object.assign(Object.assign({}, refInfo), { message: `An error occurred while resolving reference to '${ref.$refText}': ${errorMessage}` });\n            }\n            // Add the reference to the document's array of references\n            // Only add if the reference has been not been resolved earlier\n            // Otherwise we end up with duplicates\n            // See also implementation of `buildReference`\n            document.references.push(ref);\n        }\n    }\n    unlink(document) {\n        for (const ref of document.references) {\n            delete ref._ref;\n            delete ref._nodeDescription;\n        }\n        document.references = [];\n    }\n    getCandidate(refInfo) {\n        const scope = this.scopeProvider.getScope(refInfo);\n        const description = scope.getElement(refInfo.reference.$refText);\n        return description !== null && description !== void 0 ? description : this.createLinkingError(refInfo);\n    }\n    buildReference(node, property, refNode, refText) {\n        // See behavior description in doc of Linker, update that on changes in here.\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\n        const linker = this;\n        const reference = {\n            $refNode: refNode,\n            $refText: refText,\n            get ref() {\n                var _a;\n                if (isAstNode(this._ref)) {\n                    // Most frequent case: the target is already resolved.\n                    return this._ref;\n                }\n                else if (isAstNodeDescription(this._nodeDescription)) {\n                    // A candidate has been found before, but it is not loaded yet.\n                    const linkedNode = linker.loadAstNode(this._nodeDescription);\n                    this._ref = linkedNode !== null && linkedNode !== void 0 ? linkedNode : linker.createLinkingError({ reference, container: node, property }, this._nodeDescription);\n                }\n                else if (this._ref === undefined) {\n                    // The reference has not been linked yet, so do that now.\n                    this._ref = ref_resolving;\n                    const document = findRootNode(node).$document;\n                    const refData = linker.getLinkedNode({ reference, container: node, property });\n                    if (refData.error && document && document.state < DocumentState.ComputedScopes) {\n                        // Document scope is not ready, don't set `this._ref` so linker can retry later.\n                        return this._ref = undefined;\n                    }\n                    this._ref = (_a = refData.node) !== null && _a !== void 0 ? _a : refData.error;\n                    this._nodeDescription = refData.descr;\n                    document === null || document === void 0 ? void 0 : document.references.push(this);\n                }\n                else if (this._ref === ref_resolving) {\n                    throw new Error(`Cyclic reference resolution detected: ${linker.astNodeLocator.getAstNodePath(node)}/${property} (symbol '${refText}')`);\n                }\n                return isAstNode(this._ref) ? this._ref : undefined;\n            },\n            get $nodeDescription() {\n                return this._nodeDescription;\n            },\n            get error() {\n                return isLinkingError(this._ref) ? this._ref : undefined;\n            }\n        };\n        return reference;\n    }\n    getLinkedNode(refInfo) {\n        var _a;\n        try {\n            const description = this.getCandidate(refInfo);\n            if (isLinkingError(description)) {\n                return { error: description };\n            }\n            const linkedNode = this.loadAstNode(description);\n            if (linkedNode) {\n                return { node: linkedNode, descr: description };\n            }\n            else {\n                return {\n                    descr: description,\n                    error: this.createLinkingError(refInfo, description)\n                };\n            }\n        }\n        catch (err) {\n            console.error(`An error occurred while resolving reference to '${refInfo.reference.$refText}':`, err);\n            const errorMessage = (_a = err.message) !== null && _a !== void 0 ? _a : String(err);\n            return {\n                error: Object.assign(Object.assign({}, refInfo), { message: `An error occurred while resolving reference to '${refInfo.reference.$refText}': ${errorMessage}` })\n            };\n        }\n    }\n    loadAstNode(nodeDescription) {\n        if (nodeDescription.node) {\n            return nodeDescription.node;\n        }\n        const doc = this.langiumDocuments().getDocument(nodeDescription.documentUri);\n        if (!doc) {\n            return undefined;\n        }\n        return this.astNodeLocator.getAstNode(doc.parseResult.value, nodeDescription.path);\n    }\n    createLinkingError(refInfo, targetDescription) {\n        // Check whether the document is sufficiently processed by the DocumentBuilder. If not, this is a hint for a bug\n        // in the language implementation.\n        const document = findRootNode(refInfo.container).$document;\n        if (document && document.state < DocumentState.ComputedScopes) {\n            console.warn(`Attempted reference resolution before document reached ComputedScopes state (${document.uri}).`);\n        }\n        const referenceType = this.reflection.getReferenceType(refInfo);\n        return Object.assign(Object.assign({}, refInfo), { message: `Could not resolve reference to ${referenceType} named '${refInfo.reference.$refText}'.`, targetDescription });\n    }\n}\n//# sourceMappingURL=linker.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { findNodeForProperty } from '../utils/grammar-utils.js';\nexport function isNamed(node) {\n    return typeof node.name === 'string';\n}\nexport class DefaultNameProvider {\n    getName(node) {\n        if (isNamed(node)) {\n            return node.name;\n        }\n        return undefined;\n    }\n    getNameNode(node) {\n        return findNodeForProperty(node.$cstNode, 'name');\n    }\n}\n//# sourceMappingURL=name-provider.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { URI, Utils } from 'vscode-uri';\nexport { URI };\nexport var UriUtils;\n(function (UriUtils) {\n    UriUtils.basename = Utils.basename;\n    UriUtils.dirname = Utils.dirname;\n    UriUtils.extname = Utils.extname;\n    UriUtils.joinPath = Utils.joinPath;\n    UriUtils.resolvePath = Utils.resolvePath;\n    function equals(a, b) {\n        return (a === null || a === void 0 ? void 0 : a.toString()) === (b === null || b === void 0 ? void 0 : b.toString());\n    }\n    UriUtils.equals = equals;\n    function relative(from, to) {\n        const fromPath = typeof from === 'string' ? from : from.path;\n        const toPath = typeof to === 'string' ? to : to.path;\n        const fromParts = fromPath.split('/').filter(e => e.length > 0);\n        const toParts = toPath.split('/').filter(e => e.length > 0);\n        let i = 0;\n        for (; i < fromParts.length; i++) {\n            if (fromParts[i] !== toParts[i]) {\n                break;\n            }\n        }\n        const backPart = '../'.repeat(fromParts.length - i);\n        const toPart = toParts.slice(i).join('/');\n        return backPart + toPart;\n    }\n    UriUtils.relative = relative;\n    function normalize(uri) {\n        return URI.parse(uri.toString()).toString();\n    }\n    UriUtils.normalize = normalize;\n})(UriUtils || (UriUtils = {}));\n//# sourceMappingURL=uri-utils.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { findAssignment } from '../utils/grammar-utils.js';\nimport { isReference } from '../syntax-tree.js';\nimport { getDocument } from '../utils/ast-utils.js';\nimport { isChildNode, toDocumentSegment } from '../utils/cst-utils.js';\nimport { stream } from '../utils/stream.js';\nimport { UriUtils } from '../utils/uri-utils.js';\nexport class DefaultReferences {\n    constructor(services) {\n        this.nameProvider = services.references.NameProvider;\n        this.index = services.shared.workspace.IndexManager;\n        this.nodeLocator = services.workspace.AstNodeLocator;\n    }\n    findDeclaration(sourceCstNode) {\n        if (sourceCstNode) {\n            const assignment = findAssignment(sourceCstNode);\n            const nodeElem = sourceCstNode.astNode;\n            if (assignment && nodeElem) {\n                const reference = nodeElem[assignment.feature];\n                if (isReference(reference)) {\n                    return reference.ref;\n                }\n                else if (Array.isArray(reference)) {\n                    for (const ref of reference) {\n                        if (isReference(ref) && ref.$refNode\n                            && ref.$refNode.offset <= sourceCstNode.offset\n                            && ref.$refNode.end >= sourceCstNode.end) {\n                            return ref.ref;\n                        }\n                    }\n                }\n            }\n            if (nodeElem) {\n                const nameNode = this.nameProvider.getNameNode(nodeElem);\n                // Only return the targeted node in case the targeted cst node is the name node or part of it\n                if (nameNode && (nameNode === sourceCstNode || isChildNode(sourceCstNode, nameNode))) {\n                    return nodeElem;\n                }\n            }\n        }\n        return undefined;\n    }\n    findDeclarationNode(sourceCstNode) {\n        const astNode = this.findDeclaration(sourceCstNode);\n        if (astNode === null || astNode === void 0 ? void 0 : astNode.$cstNode) {\n            const targetNode = this.nameProvider.getNameNode(astNode);\n            return targetNode !== null && targetNode !== void 0 ? targetNode : astNode.$cstNode;\n        }\n        return undefined;\n    }\n    findReferences(targetNode, options) {\n        const refs = [];\n        if (options.includeDeclaration) {\n            const ref = this.getReferenceToSelf(targetNode);\n            if (ref) {\n                refs.push(ref);\n            }\n        }\n        let indexReferences = this.index.findAllReferences(targetNode, this.nodeLocator.getAstNodePath(targetNode));\n        if (options.documentUri) {\n            indexReferences = indexReferences.filter(ref => UriUtils.equals(ref.sourceUri, options.documentUri));\n        }\n        refs.push(...indexReferences);\n        return stream(refs);\n    }\n    getReferenceToSelf(targetNode) {\n        const nameNode = this.nameProvider.getNameNode(targetNode);\n        if (nameNode) {\n            const doc = getDocument(targetNode);\n            const path = this.nodeLocator.getAstNodePath(targetNode);\n            return {\n                sourceUri: doc.uri,\n                sourcePath: path,\n                targetUri: doc.uri,\n                targetPath: path,\n                segment: toDocumentSegment(nameNode),\n                local: true\n            };\n        }\n        return undefined;\n    }\n}\n//# sourceMappingURL=references.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Reduction, stream } from './stream.js';\n/**\n * A multimap is a variation of a Map that has potentially multiple values for every key.\n */\nexport class MultiMap {\n    constructor(elements) {\n        this.map = new Map();\n        if (elements) {\n            for (const [key, value] of elements) {\n                this.add(key, value);\n            }\n        }\n    }\n    /**\n     * The total number of values in the multimap.\n     */\n    get size() {\n        return Reduction.sum(stream(this.map.values()).map(a => a.length));\n    }\n    /**\n     * Clear all entries in the multimap.\n     */\n    clear() {\n        this.map.clear();\n    }\n    /**\n     * Operates differently depending on whether a `value` is given:\n     *  * With a value, this method deletes the specific key / value pair from the multimap.\n     *  * Without a value, all values associated with the given key are deleted.\n     *\n     * @returns `true` if a value existed and has been removed, or `false` if the specified\n     *     key / value does not exist.\n     */\n    delete(key, value) {\n        if (value === undefined) {\n            return this.map.delete(key);\n        }\n        else {\n            const values = this.map.get(key);\n            if (values) {\n                const index = values.indexOf(value);\n                if (index >= 0) {\n                    if (values.length === 1) {\n                        this.map.delete(key);\n                    }\n                    else {\n                        values.splice(index, 1);\n                    }\n                    return true;\n                }\n            }\n            return false;\n        }\n    }\n    /**\n     * Returns an array of all values associated with the given key. If no value exists,\n     * an empty array is returned.\n     *\n     * _Note:_ The returned array is assumed not to be modified. Use the `set` method to add a\n     * value and `delete` to remove a value from the multimap.\n     */\n    get(key) {\n        var _a;\n        return (_a = this.map.get(key)) !== null && _a !== void 0 ? _a : [];\n    }\n    /**\n     * Operates differently depending on whether a `value` is given:\n     *  * With a value, this method returns `true` if the specific key / value pair is present in the multimap.\n     *  * Without a value, this method returns `true` if the given key is present in the multimap.\n     */\n    has(key, value) {\n        if (value === undefined) {\n            return this.map.has(key);\n        }\n        else {\n            const values = this.map.get(key);\n            if (values) {\n                return values.indexOf(value) >= 0;\n            }\n            return false;\n        }\n    }\n    /**\n     * Add the given key / value pair to the multimap.\n     */\n    add(key, value) {\n        if (this.map.has(key)) {\n            this.map.get(key).push(value);\n        }\n        else {\n            this.map.set(key, [value]);\n        }\n        return this;\n    }\n    /**\n     * Add the given set of key / value pairs to the multimap.\n     */\n    addAll(key, values) {\n        if (this.map.has(key)) {\n            this.map.get(key).push(...values);\n        }\n        else {\n            this.map.set(key, Array.from(values));\n        }\n        return this;\n    }\n    /**\n     * Invokes the given callback function for every key / value pair in the multimap.\n     */\n    forEach(callbackfn) {\n        this.map.forEach((array, key) => array.forEach(value => callbackfn(value, key, this)));\n    }\n    /**\n     * Returns an iterator of key, value pairs for every entry in the map.\n     */\n    [Symbol.iterator]() {\n        return this.entries().iterator();\n    }\n    /**\n     * Returns a stream of key, value pairs for every entry in the map.\n     */\n    entries() {\n        return stream(this.map.entries())\n            .flatMap(([key, array]) => array.map(value => [key, value]));\n    }\n    /**\n     * Returns a stream of keys in the map.\n     */\n    keys() {\n        return stream(this.map.keys());\n    }\n    /**\n     * Returns a stream of values in the map.\n     */\n    values() {\n        return stream(this.map.values()).flat();\n    }\n    /**\n     * Returns a stream of key, value set pairs for every key in the map.\n     */\n    entriesGroupedByKey() {\n        return stream(this.map.entries());\n    }\n}\nexport class BiMap {\n    get size() {\n        return this.map.size;\n    }\n    constructor(elements) {\n        this.map = new Map();\n        this.inverse = new Map();\n        if (elements) {\n            for (const [key, value] of elements) {\n                this.set(key, value);\n            }\n        }\n    }\n    clear() {\n        this.map.clear();\n        this.inverse.clear();\n    }\n    set(key, value) {\n        this.map.set(key, value);\n        this.inverse.set(value, key);\n        return this;\n    }\n    get(key) {\n        return this.map.get(key);\n    }\n    getKey(value) {\n        return this.inverse.get(value);\n    }\n    delete(key) {\n        const value = this.map.get(key);\n        if (value !== undefined) {\n            this.map.delete(key);\n            this.inverse.delete(value);\n            return true;\n        }\n        return false;\n    }\n}\n//# sourceMappingURL=collections.js.map","/******************************************************************************\n * Copyright 2021-2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { streamAllContents, streamContents } from '../utils/ast-utils.js';\nimport { MultiMap } from '../utils/collections.js';\nimport { interruptAndCheck } from '../utils/promise-utils.js';\n/**\n * The default scope computation creates and collectes descriptions of the AST nodes to be exported into the\n * _global_ scope from the given document. By default those are the document's root AST node and its directly\n * contained child nodes.\n *\n * Besides, it gathers all AST nodes that have a name (according to the `NameProvider` service) and includes them\n * in the local scope of their particular container nodes. As a result, for every cross-reference in the AST,\n * target elements from the same level (siblings) and further up towards the root (parents and siblings of parents)\n * are visible. Elements being nested inside lower levels (children, children of siblings and parents' siblings)\n * are _invisible_ by default, but that can be changed by customizing this service.\n */\nexport class DefaultScopeComputation {\n    constructor(services) {\n        this.nameProvider = services.references.NameProvider;\n        this.descriptions = services.workspace.AstNodeDescriptionProvider;\n    }\n    async computeExports(document, cancelToken = CancellationToken.None) {\n        return this.computeExportsForNode(document.parseResult.value, document, undefined, cancelToken);\n    }\n    /**\n     * Creates {@link AstNodeDescription AstNodeDescriptions} for the given {@link AstNode parentNode} and its children.\n     * The list of children to be considered is determined by the function parameter {@link children}.\n     * By default only the direct children of {@link parentNode} are visited, nested nodes are not exported.\n     *\n     * @param parentNode AST node to be exported, i.e., of which an {@link AstNodeDescription} shall be added to the returned list.\n     * @param document The document containing the AST node to be exported.\n     * @param children A function called with {@link parentNode} as single argument and returning an {@link Iterable} supplying the children to be visited, which must be directly or transitively contained in {@link parentNode}.\n     * @param cancelToken Indicates when to cancel the current operation.\n     * @throws `OperationCancelled` if a user action occurs during execution.\n     * @returns A list of {@link AstNodeDescription AstNodeDescriptions} to be published to index.\n     */\n    async computeExportsForNode(parentNode, document, children = streamContents, cancelToken = CancellationToken.None) {\n        const exports = [];\n        this.exportNode(parentNode, exports, document);\n        for (const node of children(parentNode)) {\n            await interruptAndCheck(cancelToken);\n            this.exportNode(node, exports, document);\n        }\n        return exports;\n    }\n    /**\n     * Add a single node to the list of exports if it has a name. Override this method to change how\n     * symbols are exported, e.g. by modifying their exported name.\n     */\n    exportNode(node, exports, document) {\n        const name = this.nameProvider.getName(node);\n        if (name) {\n            exports.push(this.descriptions.createDescription(node, name, document));\n        }\n    }\n    async computeLocalScopes(document, cancelToken = CancellationToken.None) {\n        const rootNode = document.parseResult.value;\n        const scopes = new MultiMap();\n        // Here we navigate the full AST - local scopes shall be available in the whole document\n        for (const node of streamAllContents(rootNode)) {\n            await interruptAndCheck(cancelToken);\n            this.processNode(node, document, scopes);\n        }\n        return scopes;\n    }\n    /**\n     * Process a single node during scopes computation. The default implementation makes the node visible\n     * in the subtree of its container (if the node has a name). Override this method to change this,\n     * e.g. by increasing the visibility to a higher level in the AST.\n     */\n    processNode(node, document, scopes) {\n        const container = node.$container;\n        if (container) {\n            const name = this.nameProvider.getName(node);\n            if (name) {\n                scopes.add(container, this.descriptions.createDescription(node, name, document));\n            }\n        }\n    }\n}\n//# sourceMappingURL=scope-computation.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { EMPTY_STREAM, stream } from '../utils/stream.js';\n/**\n * The default scope implementation is based on a `Stream`. It has an optional _outer scope_ describing\n * the next level of elements, which are queried when a target element is not found in the stream provided\n * to this scope.\n */\nexport class StreamScope {\n    constructor(elements, outerScope, options) {\n        var _a;\n        this.elements = elements;\n        this.outerScope = outerScope;\n        this.caseInsensitive = (_a = options === null || options === void 0 ? void 0 : options.caseInsensitive) !== null && _a !== void 0 ? _a : false;\n    }\n    getAllElements() {\n        if (this.outerScope) {\n            return this.elements.concat(this.outerScope.getAllElements());\n        }\n        else {\n            return this.elements;\n        }\n    }\n    getElement(name) {\n        const local = this.caseInsensitive\n            ? this.elements.find(e => e.name.toLowerCase() === name.toLowerCase())\n            : this.elements.find(e => e.name === name);\n        if (local) {\n            return local;\n        }\n        if (this.outerScope) {\n            return this.outerScope.getElement(name);\n        }\n        return undefined;\n    }\n}\nexport class MapScope {\n    constructor(elements, outerScope, options) {\n        var _a;\n        this.elements = new Map();\n        this.caseInsensitive = (_a = options === null || options === void 0 ? void 0 : options.caseInsensitive) !== null && _a !== void 0 ? _a : false;\n        for (const element of elements) {\n            const name = this.caseInsensitive\n                ? element.name.toLowerCase()\n                : element.name;\n            this.elements.set(name, element);\n        }\n        this.outerScope = outerScope;\n    }\n    getElement(name) {\n        const localName = this.caseInsensitive ? name.toLowerCase() : name;\n        const local = this.elements.get(localName);\n        if (local) {\n            return local;\n        }\n        if (this.outerScope) {\n            return this.outerScope.getElement(name);\n        }\n        return undefined;\n    }\n    getAllElements() {\n        let elementStream = stream(this.elements.values());\n        if (this.outerScope) {\n            elementStream = elementStream.concat(this.outerScope.getAllElements());\n        }\n        return elementStream;\n    }\n}\nexport const EMPTY_SCOPE = {\n    getElement() {\n        return undefined;\n    },\n    getAllElements() {\n        return EMPTY_STREAM;\n    }\n};\n//# sourceMappingURL=scope.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport class DisposableCache {\n    constructor() {\n        this.toDispose = [];\n        this.isDisposed = false;\n    }\n    onDispose(disposable) {\n        this.toDispose.push(disposable);\n    }\n    dispose() {\n        this.throwIfDisposed();\n        this.clear();\n        this.isDisposed = true;\n        this.toDispose.forEach(disposable => disposable.dispose());\n    }\n    throwIfDisposed() {\n        if (this.isDisposed) {\n            throw new Error('This cache has already been disposed');\n        }\n    }\n}\nexport class SimpleCache extends DisposableCache {\n    constructor() {\n        super(...arguments);\n        this.cache = new Map();\n    }\n    has(key) {\n        this.throwIfDisposed();\n        return this.cache.has(key);\n    }\n    set(key, value) {\n        this.throwIfDisposed();\n        this.cache.set(key, value);\n    }\n    get(key, provider) {\n        this.throwIfDisposed();\n        if (this.cache.has(key)) {\n            return this.cache.get(key);\n        }\n        else if (provider) {\n            const value = provider();\n            this.cache.set(key, value);\n            return value;\n        }\n        else {\n            return undefined;\n        }\n    }\n    delete(key) {\n        this.throwIfDisposed();\n        return this.cache.delete(key);\n    }\n    clear() {\n        this.throwIfDisposed();\n        this.cache.clear();\n    }\n}\nexport class ContextCache extends DisposableCache {\n    constructor(converter) {\n        super();\n        this.cache = new Map();\n        this.converter = converter !== null && converter !== void 0 ? converter : (value => value);\n    }\n    has(contextKey, key) {\n        this.throwIfDisposed();\n        return this.cacheForContext(contextKey).has(key);\n    }\n    set(contextKey, key, value) {\n        this.throwIfDisposed();\n        this.cacheForContext(contextKey).set(key, value);\n    }\n    get(contextKey, key, provider) {\n        this.throwIfDisposed();\n        const contextCache = this.cacheForContext(contextKey);\n        if (contextCache.has(key)) {\n            return contextCache.get(key);\n        }\n        else if (provider) {\n            const value = provider();\n            contextCache.set(key, value);\n            return value;\n        }\n        else {\n            return undefined;\n        }\n    }\n    delete(contextKey, key) {\n        this.throwIfDisposed();\n        return this.cacheForContext(contextKey).delete(key);\n    }\n    clear(contextKey) {\n        this.throwIfDisposed();\n        if (contextKey) {\n            const mapKey = this.converter(contextKey);\n            this.cache.delete(mapKey);\n        }\n        else {\n            this.cache.clear();\n        }\n    }\n    cacheForContext(contextKey) {\n        const mapKey = this.converter(contextKey);\n        let documentCache = this.cache.get(mapKey);\n        if (!documentCache) {\n            documentCache = new Map();\n            this.cache.set(mapKey, documentCache);\n        }\n        return documentCache;\n    }\n}\n/**\n * Every key/value pair in this cache is scoped to a document.\n * If this document is changed or deleted, all associated key/value pairs are deleted.\n */\nexport class DocumentCache extends ContextCache {\n    /**\n     * Creates a new document cache.\n     *\n     * @param sharedServices Service container instance to hook into document lifecycle events.\n     * @param state Optional document state on which the cache should evict.\n     * If not provided, the cache will evict on `DocumentBuilder#onUpdate`.\n     * *Deleted* documents are considered in both cases.\n     *\n     * Providing a state here will use `DocumentBuilder#onDocumentPhase` instead,\n     * which triggers on all documents that have been affected by this change, assuming that the\n     * state is `DocumentState.Linked` or a later state.\n     */\n    constructor(sharedServices, state) {\n        super(uri => uri.toString());\n        if (state) {\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onDocumentPhase(state, document => {\n                this.clear(document.uri.toString());\n            }));\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((_changed, deleted) => {\n                for (const uri of deleted) { // react only on deleted documents\n                    this.clear(uri);\n                }\n            }));\n        }\n        else {\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((changed, deleted) => {\n                const allUris = changed.concat(deleted); // react on both changed and deleted documents\n                for (const uri of allUris) {\n                    this.clear(uri);\n                }\n            }));\n        }\n    }\n}\n/**\n * Every key/value pair in this cache is scoped to the whole workspace.\n * If any document in the workspace is added, changed or deleted, the whole cache is evicted.\n */\nexport class WorkspaceCache extends SimpleCache {\n    /**\n     * Creates a new workspace cache.\n     *\n     * @param sharedServices Service container instance to hook into document lifecycle events.\n     * @param state Optional document state on which the cache should evict.\n     * If not provided, the cache will evict on `DocumentBuilder#onUpdate`.\n     * *Deleted* documents are considered in both cases.\n     */\n    constructor(sharedServices, state) {\n        super();\n        if (state) {\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onBuildPhase(state, () => {\n                this.clear();\n            }));\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((_changed, deleted) => {\n                if (deleted.length > 0) { // react only on deleted documents\n                    this.clear();\n                }\n            }));\n        }\n        else {\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate(() => {\n                this.clear();\n            }));\n        }\n    }\n}\n//# sourceMappingURL=caching.js.map","/******************************************************************************\n * Copyright 2021-2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { MapScope, StreamScope } from './scope.js';\nimport { getDocument } from '../utils/ast-utils.js';\nimport { stream } from '../utils/stream.js';\nimport { WorkspaceCache } from '../utils/caching.js';\nexport class DefaultScopeProvider {\n    constructor(services) {\n        this.reflection = services.shared.AstReflection;\n        this.nameProvider = services.references.NameProvider;\n        this.descriptions = services.workspace.AstNodeDescriptionProvider;\n        this.indexManager = services.shared.workspace.IndexManager;\n        this.globalScopeCache = new WorkspaceCache(services.shared);\n    }\n    getScope(context) {\n        const scopes = [];\n        const referenceType = this.reflection.getReferenceType(context);\n        const precomputed = getDocument(context.container).precomputedScopes;\n        if (precomputed) {\n            let currentNode = context.container;\n            do {\n                const allDescriptions = precomputed.get(currentNode);\n                if (allDescriptions.length > 0) {\n                    scopes.push(stream(allDescriptions).filter(desc => this.reflection.isSubtype(desc.type, referenceType)));\n                }\n                currentNode = currentNode.$container;\n            } while (currentNode);\n        }\n        let result = this.getGlobalScope(referenceType, context);\n        for (let i = scopes.length - 1; i >= 0; i--) {\n            result = this.createScope(scopes[i], result);\n        }\n        return result;\n    }\n    /**\n     * Create a scope for the given collection of AST node descriptions.\n     */\n    createScope(elements, outerScope, options) {\n        return new StreamScope(stream(elements), outerScope, options);\n    }\n    /**\n     * Create a scope for the given collection of AST nodes, which need to be transformed into respective\n     * descriptions first. This is done using the `NameProvider` and `AstNodeDescriptionProvider` services.\n     */\n    createScopeForNodes(elements, outerScope, options) {\n        const s = stream(elements).map(e => {\n            const name = this.nameProvider.getName(e);\n            if (name) {\n                return this.descriptions.createDescription(e, name);\n            }\n            return undefined;\n        }).nonNullable();\n        return new StreamScope(s, outerScope, options);\n    }\n    /**\n     * Create a global scope filtered for the given reference type.\n     */\n    getGlobalScope(referenceType, _context) {\n        return this.globalScopeCache.get(referenceType, () => new MapScope(this.indexManager.allElements(referenceType)));\n    }\n}\n//# sourceMappingURL=scope-provider.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { URI } from 'vscode-uri';\nimport { isAstNode, isReference } from '../syntax-tree.js';\nimport { getDocument } from '../utils/ast-utils.js';\nimport { findNodesForProperty } from '../utils/grammar-utils.js';\nexport function isAstNodeWithComment(node) {\n    return typeof node.$comment === 'string';\n}\nfunction isIntermediateReference(obj) {\n    return typeof obj === 'object' && !!obj && ('$ref' in obj || '$error' in obj);\n}\nexport class DefaultJsonSerializer {\n    constructor(services) {\n        /** The set of AstNode properties to be ignored by the serializer. */\n        this.ignoreProperties = new Set(['$container', '$containerProperty', '$containerIndex', '$document', '$cstNode']);\n        this.langiumDocuments = services.shared.workspace.LangiumDocuments;\n        this.astNodeLocator = services.workspace.AstNodeLocator;\n        this.nameProvider = services.references.NameProvider;\n        this.commentProvider = services.documentation.CommentProvider;\n    }\n    serialize(node, options) {\n        const serializeOptions = options !== null && options !== void 0 ? options : {};\n        const specificReplacer = options === null || options === void 0 ? void 0 : options.replacer;\n        const defaultReplacer = (key, value) => this.replacer(key, value, serializeOptions);\n        const replacer = specificReplacer ? (key, value) => specificReplacer(key, value, defaultReplacer) : defaultReplacer;\n        try {\n            this.currentDocument = getDocument(node);\n            return JSON.stringify(node, replacer, options === null || options === void 0 ? void 0 : options.space);\n        }\n        finally {\n            this.currentDocument = undefined;\n        }\n    }\n    deserialize(content, options) {\n        const deserializeOptions = options !== null && options !== void 0 ? options : {};\n        const root = JSON.parse(content);\n        this.linkNode(root, root, deserializeOptions);\n        return root;\n    }\n    replacer(key, value, { refText, sourceText, textRegions, comments, uriConverter }) {\n        var _a, _b, _c, _d;\n        if (this.ignoreProperties.has(key)) {\n            return undefined;\n        }\n        else if (isReference(value)) {\n            const refValue = value.ref;\n            const $refText = refText ? value.$refText : undefined;\n            if (refValue) {\n                const targetDocument = getDocument(refValue);\n                let targetUri = '';\n                if (this.currentDocument && this.currentDocument !== targetDocument) {\n                    if (uriConverter) {\n                        targetUri = uriConverter(targetDocument.uri, value);\n                    }\n                    else {\n                        targetUri = targetDocument.uri.toString();\n                    }\n                }\n                const targetPath = this.astNodeLocator.getAstNodePath(refValue);\n                return {\n                    $ref: `${targetUri}#${targetPath}`,\n                    $refText\n                };\n            }\n            else {\n                return {\n                    $error: (_b = (_a = value.error) === null || _a === void 0 ? void 0 : _a.message) !== null && _b !== void 0 ? _b : 'Could not resolve reference',\n                    $refText\n                };\n            }\n        }\n        else if (isAstNode(value)) {\n            let astNode = undefined;\n            if (textRegions) {\n                astNode = this.addAstNodeRegionWithAssignmentsTo(Object.assign({}, value));\n                if ((!key || value.$document) && (astNode === null || astNode === void 0 ? void 0 : astNode.$textRegion)) {\n                    // The document URI is added to the root node of the resulting JSON tree\n                    astNode.$textRegion.documentURI = (_c = this.currentDocument) === null || _c === void 0 ? void 0 : _c.uri.toString();\n                }\n            }\n            if (sourceText && !key) {\n                astNode !== null && astNode !== void 0 ? astNode : (astNode = Object.assign({}, value));\n                astNode.$sourceText = (_d = value.$cstNode) === null || _d === void 0 ? void 0 : _d.text;\n            }\n            if (comments) {\n                astNode !== null && astNode !== void 0 ? astNode : (astNode = Object.assign({}, value));\n                const comment = this.commentProvider.getComment(value);\n                if (comment) {\n                    astNode.$comment = comment.replace(/\\r/g, '');\n                }\n            }\n            return astNode !== null && astNode !== void 0 ? astNode : value;\n        }\n        else {\n            return value;\n        }\n    }\n    addAstNodeRegionWithAssignmentsTo(node) {\n        const createDocumentSegment = cstNode => ({\n            offset: cstNode.offset,\n            end: cstNode.end,\n            length: cstNode.length,\n            range: cstNode.range,\n        });\n        if (node.$cstNode) {\n            const textRegion = node.$textRegion = createDocumentSegment(node.$cstNode);\n            const assignments = textRegion.assignments = {};\n            Object.keys(node).filter(key => !key.startsWith('$')).forEach(key => {\n                const propertyAssignments = findNodesForProperty(node.$cstNode, key).map(createDocumentSegment);\n                if (propertyAssignments.length !== 0) {\n                    assignments[key] = propertyAssignments;\n                }\n            });\n            return node;\n        }\n        return undefined;\n    }\n    linkNode(node, root, options, container, containerProperty, containerIndex) {\n        for (const [propertyName, item] of Object.entries(node)) {\n            if (Array.isArray(item)) {\n                for (let index = 0; index < item.length; index++) {\n                    const element = item[index];\n                    if (isIntermediateReference(element)) {\n                        item[index] = this.reviveReference(node, propertyName, root, element, options);\n                    }\n                    else if (isAstNode(element)) {\n                        this.linkNode(element, root, options, node, propertyName, index);\n                    }\n                }\n            }\n            else if (isIntermediateReference(item)) {\n                node[propertyName] = this.reviveReference(node, propertyName, root, item, options);\n            }\n            else if (isAstNode(item)) {\n                this.linkNode(item, root, options, node, propertyName);\n            }\n        }\n        const mutable = node;\n        mutable.$container = container;\n        mutable.$containerProperty = containerProperty;\n        mutable.$containerIndex = containerIndex;\n    }\n    reviveReference(container, property, root, reference, options) {\n        let refText = reference.$refText;\n        let error = reference.$error;\n        if (reference.$ref) {\n            const ref = this.getRefNode(root, reference.$ref, options.uriConverter);\n            if (isAstNode(ref)) {\n                if (!refText) {\n                    refText = this.nameProvider.getName(ref);\n                }\n                return {\n                    $refText: refText !== null && refText !== void 0 ? refText : '',\n                    ref\n                };\n            }\n            else {\n                error = ref;\n            }\n        }\n        if (error) {\n            const ref = {\n                $refText: refText !== null && refText !== void 0 ? refText : ''\n            };\n            ref.error = {\n                container,\n                property,\n                message: error,\n                reference: ref\n            };\n            return ref;\n        }\n        else {\n            return undefined;\n        }\n    }\n    getRefNode(root, uri, uriConverter) {\n        try {\n            const fragmentIndex = uri.indexOf('#');\n            if (fragmentIndex === 0) {\n                const node = this.astNodeLocator.getAstNode(root, uri.substring(1));\n                if (!node) {\n                    return 'Could not resolve path: ' + uri;\n                }\n                return node;\n            }\n            if (fragmentIndex < 0) {\n                const documentUri = uriConverter ? uriConverter(uri) : URI.parse(uri);\n                const document = this.langiumDocuments.getDocument(documentUri);\n                if (!document) {\n                    return 'Could not find document for URI: ' + uri;\n                }\n                return document.parseResult.value;\n            }\n            const documentUri = uriConverter ? uriConverter(uri.substring(0, fragmentIndex)) : URI.parse(uri.substring(0, fragmentIndex));\n            const document = this.langiumDocuments.getDocument(documentUri);\n            if (!document) {\n                return 'Could not find document for URI: ' + uri;\n            }\n            if (fragmentIndex === uri.length - 1) {\n                return document.parseResult.value;\n            }\n            const node = this.astNodeLocator.getAstNode(document.parseResult.value, uri.substring(fragmentIndex + 1));\n            if (!node) {\n                return 'Could not resolve URI: ' + uri;\n            }\n            return node;\n        }\n        catch (err) {\n            return String(err);\n        }\n    }\n}\n//# sourceMappingURL=json-serializer.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { UriUtils } from './utils/uri-utils.js';\n/**\n * Generic registry for Langium services, but capable of being used with extending service sets as well (such as the lsp-complete LangiumCoreServices set)\n */\nexport class DefaultServiceRegistry {\n    /**\n     * @deprecated Use the new `fileExtensionMap` (or `languageIdMap`) property instead.\n     */\n    get map() {\n        return this.fileExtensionMap;\n    }\n    constructor(services) {\n        this.languageIdMap = new Map();\n        this.fileExtensionMap = new Map();\n        this.textDocuments = services === null || services === void 0 ? void 0 : services.workspace.TextDocuments;\n    }\n    register(language) {\n        const data = language.LanguageMetaData;\n        for (const ext of data.fileExtensions) {\n            if (this.fileExtensionMap.has(ext)) {\n                console.warn(`The file extension ${ext} is used by multiple languages. It is now assigned to '${data.languageId}'.`);\n            }\n            this.fileExtensionMap.set(ext, language);\n        }\n        this.languageIdMap.set(data.languageId, language);\n        if (this.languageIdMap.size === 1) {\n            this.singleton = language;\n        }\n        else {\n            this.singleton = undefined;\n        }\n    }\n    getServices(uri) {\n        var _a, _b;\n        if (this.singleton !== undefined) {\n            return this.singleton;\n        }\n        if (this.languageIdMap.size === 0) {\n            throw new Error('The service registry is empty. Use `register` to register the services of a language.');\n        }\n        const languageId = (_b = (_a = this.textDocuments) === null || _a === void 0 ? void 0 : _a.get(uri)) === null || _b === void 0 ? void 0 : _b.languageId;\n        if (languageId !== undefined) {\n            const services = this.languageIdMap.get(languageId);\n            if (services) {\n                return services;\n            }\n        }\n        const ext = UriUtils.extname(uri);\n        const services = this.fileExtensionMap.get(ext);\n        if (!services) {\n            if (languageId) {\n                throw new Error(`The service registry contains no services for the extension '${ext}' for language '${languageId}'.`);\n            }\n            else {\n                throw new Error(`The service registry contains no services for the extension '${ext}'.`);\n            }\n        }\n        return services;\n    }\n    hasServices(uri) {\n        try {\n            this.getServices(uri);\n            return true;\n        }\n        catch (_a) {\n            return false;\n        }\n    }\n    get all() {\n        return Array.from(this.languageIdMap.values());\n    }\n}\n//# sourceMappingURL=service-registry.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { assertUnreachable } from '../index.js';\nimport { MultiMap } from '../utils/collections.js';\nimport { isOperationCancelled } from '../utils/promise-utils.js';\nimport { stream } from '../utils/stream.js';\n/**\n * Create DiagnosticData for a given diagnostic code. The result can be put into the `data` field of a DiagnosticInfo.\n */\nexport function diagnosticData(code) {\n    return { code };\n}\nexport var ValidationCategory;\n(function (ValidationCategory) {\n    ValidationCategory.all = ['fast', 'slow', 'built-in'];\n})(ValidationCategory || (ValidationCategory = {}));\n/**\n * Manages a set of `ValidationCheck`s to be applied when documents are validated.\n */\nexport class ValidationRegistry {\n    constructor(services) {\n        this.entries = new MultiMap();\n        this.entriesBefore = [];\n        this.entriesAfter = [];\n        this.reflection = services.shared.AstReflection;\n    }\n    /**\n     * Register a set of validation checks. Each value in the record can be either a single validation check (i.e. a function)\n     * or an array of validation checks.\n     *\n     * @param checksRecord Set of validation checks to register.\n     * @param category Optional category for the validation checks (defaults to `'fast'`).\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\n     */\n    register(checksRecord, thisObj = this, category = 'fast') {\n        if (category === 'built-in') {\n            throw new Error(\"The 'built-in' category is reserved for lexer, parser, and linker errors.\");\n        }\n        for (const [type, ch] of Object.entries(checksRecord)) {\n            const callbacks = ch;\n            if (Array.isArray(callbacks)) {\n                for (const check of callbacks) {\n                    const entry = {\n                        check: this.wrapValidationException(check, thisObj),\n                        category\n                    };\n                    this.addEntry(type, entry);\n                }\n            }\n            else if (typeof callbacks === 'function') {\n                const entry = {\n                    check: this.wrapValidationException(callbacks, thisObj),\n                    category\n                };\n                this.addEntry(type, entry);\n            }\n            else {\n                assertUnreachable(callbacks);\n            }\n        }\n    }\n    wrapValidationException(check, thisObj) {\n        return async (node, accept, cancelToken) => {\n            await this.handleException(() => check.call(thisObj, node, accept, cancelToken), 'An error occurred during validation', accept, node);\n        };\n    }\n    async handleException(functionality, messageContext, accept, node) {\n        try {\n            await functionality();\n        }\n        catch (err) {\n            if (isOperationCancelled(err)) {\n                throw err;\n            }\n            console.error(`${messageContext}:`, err);\n            if (err instanceof Error && err.stack) {\n                console.error(err.stack);\n            }\n            const messageDetails = err instanceof Error ? err.message : String(err);\n            accept('error', `${messageContext}: ${messageDetails}`, { node });\n        }\n    }\n    addEntry(type, entry) {\n        if (type === 'AstNode') {\n            this.entries.add('AstNode', entry);\n            return;\n        }\n        for (const subtype of this.reflection.getAllSubTypes(type)) {\n            this.entries.add(subtype, entry);\n        }\n    }\n    getChecks(type, categories) {\n        let checks = stream(this.entries.get(type))\n            .concat(this.entries.get('AstNode'));\n        if (categories) {\n            checks = checks.filter(entry => categories.includes(entry.category));\n        }\n        return checks.map(entry => entry.check);\n    }\n    /**\n     * Register logic which will be executed once before validating all the nodes of an AST/Langium document.\n     * This helps to prepare or initialize some information which are required or reusable for the following checks on the AstNodes.\n     *\n     * As an example, for validating unique fully-qualified names of nodes in the AST,\n     * here the map for mapping names to nodes could be established.\n     * During the usual checks on the nodes, they are put into this map with their name.\n     *\n     * Note that this approach makes validations stateful, which is relevant e.g. when cancelling the validation.\n     * Therefore it is recommended to clear stored information\n     * _before_ validating an AST to validate each AST unaffected from other ASTs\n     * AND _after_ validating the AST to free memory by information which are no longer used.\n     *\n     * @param checkBefore a set-up function which will be called once before actually validating an AST\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\n     */\n    registerBeforeDocument(checkBefore, thisObj = this) {\n        this.entriesBefore.push(this.wrapPreparationException(checkBefore, 'An error occurred during set-up of the validation', thisObj));\n    }\n    /**\n     * Register logic which will be executed once after validating all the nodes of an AST/Langium document.\n     * This helps to finally evaluate information which are collected during the checks on the AstNodes.\n     *\n     * As an example, for validating unique fully-qualified names of nodes in the AST,\n     * here the map with all the collected nodes and their names is checked\n     * and validation hints are created for all nodes with the same name.\n     *\n     * Note that this approach makes validations stateful, which is relevant e.g. when cancelling the validation.\n     * Therefore it is recommended to clear stored information\n     * _before_ validating an AST to validate each AST unaffected from other ASTs\n     * AND _after_ validating the AST to free memory by information which are no longer used.\n     *\n     * @param checkBefore a set-up function which will be called once before actually validating an AST\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\n     */\n    registerAfterDocument(checkAfter, thisObj = this) {\n        this.entriesAfter.push(this.wrapPreparationException(checkAfter, 'An error occurred during tear-down of the validation', thisObj));\n    }\n    wrapPreparationException(check, messageContext, thisObj) {\n        return async (rootNode, accept, categories, cancelToken) => {\n            await this.handleException(() => check.call(thisObj, rootNode, accept, categories, cancelToken), messageContext, accept, rootNode);\n        };\n    }\n    get checksBefore() {\n        return this.entriesBefore;\n    }\n    get checksAfter() {\n        return this.entriesAfter;\n    }\n}\n//# sourceMappingURL=validation-registry.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { findNodeForKeyword, findNodeForProperty } from '../utils/grammar-utils.js';\nimport { streamAst } from '../utils/ast-utils.js';\nimport { tokenToRange } from '../utils/cst-utils.js';\nimport { interruptAndCheck, isOperationCancelled } from '../utils/promise-utils.js';\nimport { diagnosticData } from './validation-registry.js';\nexport class DefaultDocumentValidator {\n    constructor(services) {\n        this.validationRegistry = services.validation.ValidationRegistry;\n        this.metadata = services.LanguageMetaData;\n    }\n    async validateDocument(document, options = {}, cancelToken = CancellationToken.None) {\n        const parseResult = document.parseResult;\n        const diagnostics = [];\n        await interruptAndCheck(cancelToken);\n        if (!options.categories || options.categories.includes('built-in')) {\n            this.processLexingErrors(parseResult, diagnostics, options);\n            if (options.stopAfterLexingErrors && diagnostics.some(d => { var _a; return ((_a = d.data) === null || _a === void 0 ? void 0 : _a.code) === DocumentValidator.LexingError; })) {\n                return diagnostics;\n            }\n            this.processParsingErrors(parseResult, diagnostics, options);\n            if (options.stopAfterParsingErrors && diagnostics.some(d => { var _a; return ((_a = d.data) === null || _a === void 0 ? void 0 : _a.code) === DocumentValidator.ParsingError; })) {\n                return diagnostics;\n            }\n            this.processLinkingErrors(document, diagnostics, options);\n            if (options.stopAfterLinkingErrors && diagnostics.some(d => { var _a; return ((_a = d.data) === null || _a === void 0 ? void 0 : _a.code) === DocumentValidator.LinkingError; })) {\n                return diagnostics;\n            }\n        }\n        // Process custom validations\n        try {\n            diagnostics.push(...await this.validateAst(parseResult.value, options, cancelToken));\n        }\n        catch (err) {\n            if (isOperationCancelled(err)) {\n                throw err;\n            }\n            console.error('An error occurred during validation:', err);\n        }\n        await interruptAndCheck(cancelToken);\n        return diagnostics;\n    }\n    processLexingErrors(parseResult, diagnostics, _options) {\n        var _a, _b, _c;\n        const lexerDiagnostics = [...parseResult.lexerErrors, ...(_b = (_a = parseResult.lexerReport) === null || _a === void 0 ? void 0 : _a.diagnostics) !== null && _b !== void 0 ? _b : []];\n        for (const lexerDiagnostic of lexerDiagnostics) {\n            const severity = (_c = lexerDiagnostic.severity) !== null && _c !== void 0 ? _c : 'error';\n            const diagnostic = {\n                severity: toDiagnosticSeverity(severity),\n                range: {\n                    start: {\n                        line: lexerDiagnostic.line - 1,\n                        character: lexerDiagnostic.column - 1\n                    },\n                    end: {\n                        line: lexerDiagnostic.line - 1,\n                        character: lexerDiagnostic.column + lexerDiagnostic.length - 1\n                    }\n                },\n                message: lexerDiagnostic.message,\n                data: toDiagnosticData(severity),\n                source: this.getSource()\n            };\n            diagnostics.push(diagnostic);\n        }\n    }\n    processParsingErrors(parseResult, diagnostics, _options) {\n        for (const parserError of parseResult.parserErrors) {\n            let range = undefined;\n            // We can run into the chevrotain error recovery here\n            // The token contained in the parser error might be automatically inserted\n            // In this case every position value will be `NaN`\n            if (isNaN(parserError.token.startOffset)) {\n                // Some special parser error types contain a `previousToken`\n                // We can simply append our diagnostic to that token\n                if ('previousToken' in parserError) {\n                    const token = parserError.previousToken;\n                    if (!isNaN(token.startOffset)) {\n                        const position = { line: token.endLine - 1, character: token.endColumn };\n                        range = { start: position, end: position };\n                    }\n                    else {\n                        // No valid prev token. Might be empty document or containing only hidden tokens.\n                        // Point to document start\n                        const position = { line: 0, character: 0 };\n                        range = { start: position, end: position };\n                    }\n                }\n            }\n            else {\n                range = tokenToRange(parserError.token);\n            }\n            if (range) {\n                const diagnostic = {\n                    severity: toDiagnosticSeverity('error'),\n                    range,\n                    message: parserError.message,\n                    data: diagnosticData(DocumentValidator.ParsingError),\n                    source: this.getSource()\n                };\n                diagnostics.push(diagnostic);\n            }\n        }\n    }\n    processLinkingErrors(document, diagnostics, _options) {\n        for (const reference of document.references) {\n            const linkingError = reference.error;\n            if (linkingError) {\n                const info = {\n                    node: linkingError.container,\n                    property: linkingError.property,\n                    index: linkingError.index,\n                    data: {\n                        code: DocumentValidator.LinkingError,\n                        containerType: linkingError.container.$type,\n                        property: linkingError.property,\n                        refText: linkingError.reference.$refText\n                    }\n                };\n                diagnostics.push(this.toDiagnostic('error', linkingError.message, info));\n            }\n        }\n    }\n    async validateAst(rootNode, options, cancelToken = CancellationToken.None) {\n        const validationItems = [];\n        const acceptor = (severity, message, info) => {\n            validationItems.push(this.toDiagnostic(severity, message, info));\n        };\n        await this.validateAstBefore(rootNode, options, acceptor, cancelToken);\n        await this.validateAstNodes(rootNode, options, acceptor, cancelToken);\n        await this.validateAstAfter(rootNode, options, acceptor, cancelToken);\n        return validationItems;\n    }\n    async validateAstBefore(rootNode, options, acceptor, cancelToken = CancellationToken.None) {\n        var _a;\n        const checksBefore = this.validationRegistry.checksBefore;\n        for (const checkBefore of checksBefore) {\n            await interruptAndCheck(cancelToken);\n            await checkBefore(rootNode, acceptor, (_a = options.categories) !== null && _a !== void 0 ? _a : [], cancelToken);\n        }\n    }\n    async validateAstNodes(rootNode, options, acceptor, cancelToken = CancellationToken.None) {\n        await Promise.all(streamAst(rootNode).map(async (node) => {\n            await interruptAndCheck(cancelToken);\n            const checks = this.validationRegistry.getChecks(node.$type, options.categories);\n            for (const check of checks) {\n                await check(node, acceptor, cancelToken);\n            }\n        }));\n    }\n    async validateAstAfter(rootNode, options, acceptor, cancelToken = CancellationToken.None) {\n        var _a;\n        const checksAfter = this.validationRegistry.checksAfter;\n        for (const checkAfter of checksAfter) {\n            await interruptAndCheck(cancelToken);\n            await checkAfter(rootNode, acceptor, (_a = options.categories) !== null && _a !== void 0 ? _a : [], cancelToken);\n        }\n    }\n    toDiagnostic(severity, message, info) {\n        return {\n            message,\n            range: getDiagnosticRange(info),\n            severity: toDiagnosticSeverity(severity),\n            code: info.code,\n            codeDescription: info.codeDescription,\n            tags: info.tags,\n            relatedInformation: info.relatedInformation,\n            data: info.data,\n            source: this.getSource()\n        };\n    }\n    getSource() {\n        return this.metadata.languageId;\n    }\n}\nexport function getDiagnosticRange(info) {\n    if (info.range) {\n        return info.range;\n    }\n    let cstNode;\n    if (typeof info.property === 'string') {\n        cstNode = findNodeForProperty(info.node.$cstNode, info.property, info.index);\n    }\n    else if (typeof info.keyword === 'string') {\n        cstNode = findNodeForKeyword(info.node.$cstNode, info.keyword, info.index);\n    }\n    cstNode !== null && cstNode !== void 0 ? cstNode : (cstNode = info.node.$cstNode);\n    if (!cstNode) {\n        return {\n            start: { line: 0, character: 0 },\n            end: { line: 0, character: 0 }\n        };\n    }\n    return cstNode.range;\n}\n/**\n * Transforms the diagnostic severity from the {@link LexingDiagnosticSeverity} format to LSP's `DiagnosticSeverity` format.\n *\n * @param severity The lexing diagnostic severity\n * @returns Diagnostic severity according to `vscode-languageserver-types/lib/esm/main.js#DiagnosticSeverity`\n */\nexport function toDiagnosticSeverity(severity) {\n    switch (severity) {\n        case 'error':\n            return 1;\n        case 'warning':\n            return 2;\n        case 'info':\n            return 3;\n        case 'hint':\n            return 4;\n        default:\n            throw new Error('Invalid diagnostic severity: ' + severity);\n    }\n}\nexport function toDiagnosticData(severity) {\n    switch (severity) {\n        case 'error':\n            return diagnosticData(DocumentValidator.LexingError);\n        case 'warning':\n            return diagnosticData(DocumentValidator.LexingWarning);\n        case 'info':\n            return diagnosticData(DocumentValidator.LexingInfo);\n        case 'hint':\n            return diagnosticData(DocumentValidator.LexingHint);\n        default:\n            throw new Error('Invalid diagnostic severity: ' + severity);\n    }\n}\nexport var DocumentValidator;\n(function (DocumentValidator) {\n    DocumentValidator.LexingError = 'lexing-error';\n    DocumentValidator.LexingWarning = 'lexing-warning';\n    DocumentValidator.LexingInfo = 'lexing-info';\n    DocumentValidator.LexingHint = 'lexing-hint';\n    DocumentValidator.ParsingError = 'parsing-error';\n    DocumentValidator.LinkingError = 'linking-error';\n})(DocumentValidator || (DocumentValidator = {}));\n//# sourceMappingURL=document-validator.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { isLinkingError } from '../syntax-tree.js';\nimport { getDocument, streamAst, streamReferences } from '../utils/ast-utils.js';\nimport { toDocumentSegment } from '../utils/cst-utils.js';\nimport { interruptAndCheck } from '../utils/promise-utils.js';\nimport { UriUtils } from '../utils/uri-utils.js';\nexport class DefaultAstNodeDescriptionProvider {\n    constructor(services) {\n        this.astNodeLocator = services.workspace.AstNodeLocator;\n        this.nameProvider = services.references.NameProvider;\n    }\n    createDescription(node, name, document) {\n        const doc = document !== null && document !== void 0 ? document : getDocument(node);\n        name !== null && name !== void 0 ? name : (name = this.nameProvider.getName(node));\n        const path = this.astNodeLocator.getAstNodePath(node);\n        if (!name) {\n            throw new Error(`Node at path ${path} has no name.`);\n        }\n        let nameNodeSegment;\n        const nameSegmentGetter = () => { var _a; return nameNodeSegment !== null && nameNodeSegment !== void 0 ? nameNodeSegment : (nameNodeSegment = toDocumentSegment((_a = this.nameProvider.getNameNode(node)) !== null && _a !== void 0 ? _a : node.$cstNode)); };\n        return {\n            node,\n            name,\n            get nameSegment() {\n                return nameSegmentGetter();\n            },\n            selectionSegment: toDocumentSegment(node.$cstNode),\n            type: node.$type,\n            documentUri: doc.uri,\n            path\n        };\n    }\n}\nexport class DefaultReferenceDescriptionProvider {\n    constructor(services) {\n        this.nodeLocator = services.workspace.AstNodeLocator;\n    }\n    async createDescriptions(document, cancelToken = CancellationToken.None) {\n        const descr = [];\n        const rootNode = document.parseResult.value;\n        for (const astNode of streamAst(rootNode)) {\n            await interruptAndCheck(cancelToken);\n            streamReferences(astNode).filter(refInfo => !isLinkingError(refInfo)).forEach(refInfo => {\n                // TODO: Consider logging a warning or throw an exception when DocumentState is < than Linked\n                const description = this.createDescription(refInfo);\n                if (description) {\n                    descr.push(description);\n                }\n            });\n        }\n        return descr;\n    }\n    createDescription(refInfo) {\n        const targetNodeDescr = refInfo.reference.$nodeDescription;\n        const refCstNode = refInfo.reference.$refNode;\n        if (!targetNodeDescr || !refCstNode) {\n            return undefined;\n        }\n        const docUri = getDocument(refInfo.container).uri;\n        return {\n            sourceUri: docUri,\n            sourcePath: this.nodeLocator.getAstNodePath(refInfo.container),\n            targetUri: targetNodeDescr.documentUri,\n            targetPath: targetNodeDescr.path,\n            segment: toDocumentSegment(refCstNode),\n            local: UriUtils.equals(targetNodeDescr.documentUri, docUri)\n        };\n    }\n}\n//# sourceMappingURL=ast-descriptions.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport class DefaultAstNodeLocator {\n    constructor() {\n        this.segmentSeparator = '/';\n        this.indexSeparator = '@';\n    }\n    getAstNodePath(node) {\n        if (node.$container) {\n            const containerPath = this.getAstNodePath(node.$container);\n            const newSegment = this.getPathSegment(node);\n            const nodePath = containerPath + this.segmentSeparator + newSegment;\n            return nodePath;\n        }\n        return '';\n    }\n    getPathSegment({ $containerProperty, $containerIndex }) {\n        if (!$containerProperty) {\n            throw new Error(\"Missing '$containerProperty' in AST node.\");\n        }\n        if ($containerIndex !== undefined) {\n            return $containerProperty + this.indexSeparator + $containerIndex;\n        }\n        return $containerProperty;\n    }\n    getAstNode(node, path) {\n        const segments = path.split(this.segmentSeparator);\n        return segments.reduce((previousValue, currentValue) => {\n            if (!previousValue || currentValue.length === 0) {\n                return previousValue;\n            }\n            const propertyIndex = currentValue.indexOf(this.indexSeparator);\n            if (propertyIndex > 0) {\n                const property = currentValue.substring(0, propertyIndex);\n                const arrayIndex = parseInt(currentValue.substring(propertyIndex + 1));\n                const array = previousValue[property];\n                return array === null || array === void 0 ? void 0 : array[arrayIndex];\n            }\n            return previousValue[currentValue];\n        }, node);\n    }\n}\n//# sourceMappingURL=ast-node-locator.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Emitter } from '../utils/event.js';\nimport { Deferred } from '../utils/promise-utils.js';\n/**\n * Base configuration provider for building up other configuration providers\n */\nexport class DefaultConfigurationProvider {\n    constructor(services) {\n        this._ready = new Deferred();\n        this.settings = {};\n        this.workspaceConfig = false;\n        this.onConfigurationSectionUpdateEmitter = new Emitter();\n        this.serviceRegistry = services.ServiceRegistry;\n    }\n    get ready() {\n        return this._ready.promise;\n    }\n    initialize(params) {\n        var _a, _b;\n        this.workspaceConfig = (_b = (_a = params.capabilities.workspace) === null || _a === void 0 ? void 0 : _a.configuration) !== null && _b !== void 0 ? _b : false;\n    }\n    async initialized(params) {\n        if (this.workspaceConfig) {\n            if (params.register) {\n                // params.register(...) is a function to be provided by the calling language server for the sake of\n                //  decoupling this implementation from the concrete LSP implementations, specifically the LSP Connection\n                const languages = this.serviceRegistry.all;\n                params.register({\n                    // Listen to configuration changes for all languages\n                    section: languages.map(lang => this.toSectionName(lang.LanguageMetaData.languageId))\n                });\n            }\n            if (params.fetchConfiguration) {\n                // params.fetchConfiguration(...) is a function to be provided by the calling language server for the sake of\n                //  decoupling this implementation from the concrete LSP implementations, specifically the LSP Connection\n                const configToUpdate = this.serviceRegistry.all.map(lang => ({\n                    // Fetch the configuration changes for all languages\n                    section: this.toSectionName(lang.LanguageMetaData.languageId)\n                }));\n                // get workspace configurations (default scope URI)\n                const configs = await params.fetchConfiguration(configToUpdate);\n                configToUpdate.forEach((conf, idx) => {\n                    this.updateSectionConfiguration(conf.section, configs[idx]);\n                });\n            }\n        }\n        this._ready.resolve();\n    }\n    /**\n     *  Updates the cached configurations using the `change` notification parameters.\n     *\n     * @param change The parameters of a change configuration notification.\n     * `settings` property of the change object could be expressed as `Record<string, Record<string, any>>`\n     */\n    updateConfiguration(change) {\n        if (!change.settings) {\n            return;\n        }\n        Object.keys(change.settings).forEach(section => {\n            const configuration = change.settings[section];\n            this.updateSectionConfiguration(section, configuration);\n            this.onConfigurationSectionUpdateEmitter.fire({ section, configuration });\n        });\n    }\n    updateSectionConfiguration(section, configuration) {\n        this.settings[section] = configuration;\n    }\n    /**\n    * Returns a configuration value stored for the given language.\n    *\n    * @param language The language id\n    * @param configuration Configuration name\n    */\n    async getConfiguration(language, configuration) {\n        await this.ready;\n        const sectionName = this.toSectionName(language);\n        if (this.settings[sectionName]) {\n            return this.settings[sectionName][configuration];\n        }\n    }\n    toSectionName(languageId) {\n        return `${languageId}`;\n    }\n    get onConfigurationSectionUpdate() {\n        return this.onConfigurationSectionUpdateEmitter.event;\n    }\n}\n//# sourceMappingURL=configuration.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport var Disposable;\n(function (Disposable) {\n    function create(callback) {\n        return {\n            dispose: async () => await callback()\n        };\n    }\n    Disposable.create = create;\n})(Disposable || (Disposable = {}));\n//# sourceMappingURL=disposable.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { Disposable } from '../utils/disposable.js';\nimport { MultiMap } from '../utils/collections.js';\nimport { OperationCancelled, interruptAndCheck, isOperationCancelled } from '../utils/promise-utils.js';\nimport { stream } from '../utils/stream.js';\nimport { ValidationCategory } from '../validation/validation-registry.js';\nimport { DocumentState } from './documents.js';\nexport class DefaultDocumentBuilder {\n    constructor(services) {\n        this.updateBuildOptions = {\n            // Default: run only the built-in validation checks and those in the _fast_ category (includes those without category)\n            validation: {\n                categories: ['built-in', 'fast']\n            }\n        };\n        this.updateListeners = [];\n        this.buildPhaseListeners = new MultiMap();\n        this.documentPhaseListeners = new MultiMap();\n        this.buildState = new Map();\n        this.documentBuildWaiters = new Map();\n        this.currentState = DocumentState.Changed;\n        this.langiumDocuments = services.workspace.LangiumDocuments;\n        this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\n        this.textDocuments = services.workspace.TextDocuments;\n        this.indexManager = services.workspace.IndexManager;\n        this.serviceRegistry = services.ServiceRegistry;\n    }\n    async build(documents, options = {}, cancelToken = CancellationToken.None) {\n        var _a, _b;\n        for (const document of documents) {\n            const key = document.uri.toString();\n            if (document.state === DocumentState.Validated) {\n                if (typeof options.validation === 'boolean' && options.validation) {\n                    // Force re-running all validation checks\n                    document.state = DocumentState.IndexedReferences;\n                    document.diagnostics = undefined;\n                    this.buildState.delete(key);\n                }\n                else if (typeof options.validation === 'object') {\n                    const buildState = this.buildState.get(key);\n                    const previousCategories = (_a = buildState === null || buildState === void 0 ? void 0 : buildState.result) === null || _a === void 0 ? void 0 : _a.validationChecks;\n                    if (previousCategories) {\n                        // Validation with explicit options was requested for a document that has already been partly validated.\n                        // In this case, we need to merge the previous validation categories with the new ones.\n                        const newCategories = (_b = options.validation.categories) !== null && _b !== void 0 ? _b : ValidationCategory.all;\n                        const categories = newCategories.filter(c => !previousCategories.includes(c));\n                        if (categories.length > 0) {\n                            this.buildState.set(key, {\n                                completed: false,\n                                options: {\n                                    validation: Object.assign(Object.assign({}, options.validation), { categories })\n                                },\n                                result: buildState.result\n                            });\n                            document.state = DocumentState.IndexedReferences;\n                        }\n                    }\n                }\n            }\n            else {\n                // Default: forget any previous build options\n                this.buildState.delete(key);\n            }\n        }\n        this.currentState = DocumentState.Changed;\n        await this.emitUpdate(documents.map(e => e.uri), []);\n        await this.buildDocuments(documents, options, cancelToken);\n    }\n    async update(changed, deleted, cancelToken = CancellationToken.None) {\n        this.currentState = DocumentState.Changed;\n        // Remove all metadata of documents that are reported as deleted\n        for (const deletedUri of deleted) {\n            this.langiumDocuments.deleteDocument(deletedUri);\n            this.buildState.delete(deletedUri.toString());\n            this.indexManager.remove(deletedUri);\n        }\n        // Set the state of all changed documents to `Changed` so they are completely rebuilt\n        for (const changedUri of changed) {\n            const invalidated = this.langiumDocuments.invalidateDocument(changedUri);\n            if (!invalidated) {\n                // We create an unparsed, invalid document.\n                // This will be parsed as soon as we reach the first document builder phase.\n                // This allows to cancel the parsing process later in case we need it.\n                const newDocument = this.langiumDocumentFactory.fromModel({ $type: 'INVALID' }, changedUri);\n                newDocument.state = DocumentState.Changed;\n                this.langiumDocuments.addDocument(newDocument);\n            }\n            this.buildState.delete(changedUri.toString());\n        }\n        // Set the state of all documents that should be relinked to `ComputedScopes` (if not already lower)\n        const allChangedUris = stream(changed).concat(deleted).map(uri => uri.toString()).toSet();\n        this.langiumDocuments.all\n            .filter(doc => !allChangedUris.has(doc.uri.toString()) && this.shouldRelink(doc, allChangedUris))\n            .forEach(doc => {\n            const linker = this.serviceRegistry.getServices(doc.uri).references.Linker;\n            linker.unlink(doc);\n            doc.state = Math.min(doc.state, DocumentState.ComputedScopes);\n            doc.diagnostics = undefined;\n        });\n        // Notify listeners of the update\n        await this.emitUpdate(changed, deleted);\n        // Only allow interrupting the execution after all state changes are done\n        await interruptAndCheck(cancelToken);\n        // Collect and sort all documents that we should rebuild\n        const rebuildDocuments = this.sortDocuments(this.langiumDocuments.all\n            .filter(doc => {\n            var _a;\n            // This includes those that were reported as changed and those that we selected for relinking\n            return doc.state < DocumentState.Linked\n                // This includes those for which a previous build has been cancelled\n                || !((_a = this.buildState.get(doc.uri.toString())) === null || _a === void 0 ? void 0 : _a.completed);\n        })\n            .toArray());\n        await this.buildDocuments(rebuildDocuments, this.updateBuildOptions, cancelToken);\n    }\n    async emitUpdate(changed, deleted) {\n        await Promise.all(this.updateListeners.map(listener => listener(changed, deleted)));\n    }\n    /**\n     * Sort the given documents by priority. By default, documents with an open text document are prioritized.\n     * This is useful to ensure that visible documents show their diagnostics before all other documents.\n     *\n     * This improves the responsiveness in large workspaces as users usually don't care about diagnostics\n     * in files that are currently not opened in the editor.\n     */\n    sortDocuments(documents) {\n        let left = 0;\n        let right = documents.length - 1;\n        while (left < right) {\n            while (left < documents.length && this.hasTextDocument(documents[left])) {\n                left++;\n            }\n            while (right >= 0 && !this.hasTextDocument(documents[right])) {\n                right--;\n            }\n            if (left < right) {\n                [documents[left], documents[right]] = [documents[right], documents[left]];\n            }\n        }\n        return documents;\n    }\n    hasTextDocument(doc) {\n        var _a;\n        return Boolean((_a = this.textDocuments) === null || _a === void 0 ? void 0 : _a.get(doc.uri));\n    }\n    /**\n     * Check whether the given document should be relinked after changes were found in the given URIs.\n     */\n    shouldRelink(document, changedUris) {\n        // Relink documents with linking errors -- maybe those references can be resolved now\n        if (document.references.some(ref => ref.error !== undefined)) {\n            return true;\n        }\n        // Check whether the document is affected by any of the changed URIs\n        return this.indexManager.isAffected(document, changedUris);\n    }\n    onUpdate(callback) {\n        this.updateListeners.push(callback);\n        return Disposable.create(() => {\n            const index = this.updateListeners.indexOf(callback);\n            if (index >= 0) {\n                this.updateListeners.splice(index, 1);\n            }\n        });\n    }\n    /**\n     * Build the given documents by stepping through all build phases. If a document's state indicates\n     * that a certain build phase is already done, the phase is skipped for that document.\n     *\n     * @param documents The documents to build.\n     * @param options the {@link BuildOptions} to use.\n     * @param cancelToken A cancellation token that can be used to cancel the build.\n     * @returns A promise that resolves when the build is done.\n     */\n    async buildDocuments(documents, options, cancelToken) {\n        this.prepareBuild(documents, options);\n        // 0. Parse content\n        await this.runCancelable(documents, DocumentState.Parsed, cancelToken, doc => this.langiumDocumentFactory.update(doc, cancelToken));\n        // 1. Index content\n        await this.runCancelable(documents, DocumentState.IndexedContent, cancelToken, doc => this.indexManager.updateContent(doc, cancelToken));\n        // 2. Compute scopes\n        await this.runCancelable(documents, DocumentState.ComputedScopes, cancelToken, async (doc) => {\n            const scopeComputation = this.serviceRegistry.getServices(doc.uri).references.ScopeComputation;\n            doc.precomputedScopes = await scopeComputation.computeLocalScopes(doc, cancelToken);\n        });\n        // 3. Linking\n        await this.runCancelable(documents, DocumentState.Linked, cancelToken, doc => {\n            const linker = this.serviceRegistry.getServices(doc.uri).references.Linker;\n            return linker.link(doc, cancelToken);\n        });\n        // 4. Index references\n        await this.runCancelable(documents, DocumentState.IndexedReferences, cancelToken, doc => this.indexManager.updateReferences(doc, cancelToken));\n        // 5. Validation\n        const toBeValidated = documents.filter(doc => this.shouldValidate(doc));\n        await this.runCancelable(toBeValidated, DocumentState.Validated, cancelToken, doc => this.validate(doc, cancelToken));\n        // If we've made it to this point without being cancelled, we can mark the build state as completed.\n        for (const doc of documents) {\n            const state = this.buildState.get(doc.uri.toString());\n            if (state) {\n                state.completed = true;\n            }\n        }\n    }\n    /**\n     * Runs prior to beginning the build process to update the {@link DocumentBuildState} for each document\n     *\n     * @param documents collection of documents to be built\n     * @param options the {@link BuildOptions} to use\n     */\n    prepareBuild(documents, options) {\n        for (const doc of documents) {\n            const key = doc.uri.toString();\n            const state = this.buildState.get(key);\n            // If the document has no previous build state, we set it. If it has one, but it's already marked\n            // as completed, we overwrite it. If the previous build was not completed, we keep its state\n            // and continue where it was cancelled.\n            if (!state || state.completed) {\n                this.buildState.set(key, {\n                    completed: false,\n                    options,\n                    result: state === null || state === void 0 ? void 0 : state.result\n                });\n            }\n        }\n    }\n    /**\n     * Runs a cancelable operation on a set of documents to bring them to a specified {@link DocumentState}.\n     *\n     * @param documents The array of documents to process.\n     * @param targetState The target {@link DocumentState} to bring the documents to.\n     * @param cancelToken A token that can be used to cancel the operation.\n     * @param callback A function to be called for each document.\n     * @returns A promise that resolves when all documents have been processed or the operation is canceled.\n     * @throws Will throw `OperationCancelled` if the operation is canceled via a `CancellationToken`.\n     */\n    async runCancelable(documents, targetState, cancelToken, callback) {\n        const filtered = documents.filter(doc => doc.state < targetState);\n        for (const document of filtered) {\n            await interruptAndCheck(cancelToken);\n            await callback(document);\n            document.state = targetState;\n            await this.notifyDocumentPhase(document, targetState, cancelToken);\n        }\n        // Do not use `filtered` here, as that will miss documents that have previously reached the current target state\n        // For example, this happens in case the cancellation triggers between the processing of two documents\n        // Or files that were picked up during the workspace initialization\n        const targetStateDocs = documents.filter(doc => doc.state === targetState);\n        await this.notifyBuildPhase(targetStateDocs, targetState, cancelToken);\n        this.currentState = targetState;\n    }\n    onBuildPhase(targetState, callback) {\n        this.buildPhaseListeners.add(targetState, callback);\n        return Disposable.create(() => {\n            this.buildPhaseListeners.delete(targetState, callback);\n        });\n    }\n    onDocumentPhase(targetState, callback) {\n        this.documentPhaseListeners.add(targetState, callback);\n        return Disposable.create(() => {\n            this.documentPhaseListeners.delete(targetState, callback);\n        });\n    }\n    waitUntil(state, uriOrToken, cancelToken) {\n        let uri = undefined;\n        if (uriOrToken && 'path' in uriOrToken) {\n            uri = uriOrToken;\n        }\n        else {\n            cancelToken = uriOrToken;\n        }\n        cancelToken !== null && cancelToken !== void 0 ? cancelToken : (cancelToken = CancellationToken.None);\n        if (uri) {\n            const document = this.langiumDocuments.getDocument(uri);\n            if (document && document.state > state) {\n                return Promise.resolve(uri);\n            }\n        }\n        if (this.currentState >= state) {\n            return Promise.resolve(undefined);\n        }\n        else if (cancelToken.isCancellationRequested) {\n            return Promise.reject(OperationCancelled);\n        }\n        return new Promise((resolve, reject) => {\n            const buildDisposable = this.onBuildPhase(state, () => {\n                buildDisposable.dispose();\n                cancelDisposable.dispose();\n                if (uri) {\n                    const document = this.langiumDocuments.getDocument(uri);\n                    resolve(document === null || document === void 0 ? void 0 : document.uri);\n                }\n                else {\n                    resolve(undefined);\n                }\n            });\n            const cancelDisposable = cancelToken.onCancellationRequested(() => {\n                buildDisposable.dispose();\n                cancelDisposable.dispose();\n                reject(OperationCancelled);\n            });\n        });\n    }\n    async notifyDocumentPhase(document, state, cancelToken) {\n        const listeners = this.documentPhaseListeners.get(state);\n        const listenersCopy = listeners.slice();\n        for (const listener of listenersCopy) {\n            try {\n                await listener(document, cancelToken);\n            }\n            catch (err) {\n                // Ignore cancellation errors\n                // We want to finish the listeners before throwing\n                if (!isOperationCancelled(err)) {\n                    throw err;\n                }\n            }\n        }\n    }\n    async notifyBuildPhase(documents, state, cancelToken) {\n        if (documents.length === 0) {\n            // Don't notify when no document has been processed\n            return;\n        }\n        const listeners = this.buildPhaseListeners.get(state);\n        const listenersCopy = listeners.slice();\n        for (const listener of listenersCopy) {\n            await interruptAndCheck(cancelToken);\n            await listener(documents, cancelToken);\n        }\n    }\n    /**\n     * Determine whether the given document should be validated during a build. The default\n     * implementation checks the `validation` property of the build options. If it's set to `true`\n     * or a `ValidationOptions` object, the document is included in the validation phase.\n     */\n    shouldValidate(document) {\n        return Boolean(this.getBuildOptions(document).validation);\n    }\n    /**\n     * Run validation checks on the given document and store the resulting diagnostics in the document.\n     * If the document already contains diagnostics, the new ones are added to the list.\n     */\n    async validate(document, cancelToken) {\n        var _a, _b;\n        const validator = this.serviceRegistry.getServices(document.uri).validation.DocumentValidator;\n        const validationSetting = this.getBuildOptions(document).validation;\n        const options = typeof validationSetting === 'object' ? validationSetting : undefined;\n        const diagnostics = await validator.validateDocument(document, options, cancelToken);\n        if (document.diagnostics) {\n            document.diagnostics.push(...diagnostics);\n        }\n        else {\n            document.diagnostics = diagnostics;\n        }\n        // Store information about the executed validation in the build state\n        const state = this.buildState.get(document.uri.toString());\n        if (state) {\n            (_a = state.result) !== null && _a !== void 0 ? _a : (state.result = {});\n            const newCategories = (_b = options === null || options === void 0 ? void 0 : options.categories) !== null && _b !== void 0 ? _b : ValidationCategory.all;\n            if (state.result.validationChecks) {\n                state.result.validationChecks.push(...newCategories);\n            }\n            else {\n                state.result.validationChecks = [...newCategories];\n            }\n        }\n    }\n    getBuildOptions(document) {\n        var _a, _b;\n        return (_b = (_a = this.buildState.get(document.uri.toString())) === null || _a === void 0 ? void 0 : _a.options) !== null && _b !== void 0 ? _b : {};\n    }\n}\n//# sourceMappingURL=document-builder.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { getDocument } from '../utils/ast-utils.js';\nimport { ContextCache } from '../utils/caching.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { stream } from '../utils/stream.js';\nimport { UriUtils } from '../utils/uri-utils.js';\nexport class DefaultIndexManager {\n    constructor(services) {\n        /**\n         * The symbol index stores all `AstNodeDescription` items exported by a document.\n         * The key used in this map is the string representation of the specific document URI.\n         */\n        this.symbolIndex = new Map();\n        /**\n         * This is a cache for the `allElements()` method.\n         * It caches the descriptions from `symbolIndex` grouped by types.\n         */\n        this.symbolByTypeIndex = new ContextCache();\n        /**\n         * This index keeps track of all `ReferenceDescription` items exported by a document.\n         * This is used to compute which elements are affected by a document change\n         * and for finding references to an AST node.\n         */\n        this.referenceIndex = new Map();\n        this.documents = services.workspace.LangiumDocuments;\n        this.serviceRegistry = services.ServiceRegistry;\n        this.astReflection = services.AstReflection;\n    }\n    findAllReferences(targetNode, astNodePath) {\n        const targetDocUri = getDocument(targetNode).uri;\n        const result = [];\n        this.referenceIndex.forEach(docRefs => {\n            docRefs.forEach(refDescr => {\n                if (UriUtils.equals(refDescr.targetUri, targetDocUri) && refDescr.targetPath === astNodePath) {\n                    result.push(refDescr);\n                }\n            });\n        });\n        return stream(result);\n    }\n    allElements(nodeType, uris) {\n        let documentUris = stream(this.symbolIndex.keys());\n        if (uris) {\n            documentUris = documentUris.filter(uri => !uris || uris.has(uri));\n        }\n        return documentUris\n            .map(uri => this.getFileDescriptions(uri, nodeType))\n            .flat();\n    }\n    getFileDescriptions(uri, nodeType) {\n        var _a;\n        if (!nodeType) {\n            return (_a = this.symbolIndex.get(uri)) !== null && _a !== void 0 ? _a : [];\n        }\n        const descriptions = this.symbolByTypeIndex.get(uri, nodeType, () => {\n            var _a;\n            const allFileDescriptions = (_a = this.symbolIndex.get(uri)) !== null && _a !== void 0 ? _a : [];\n            return allFileDescriptions.filter(e => this.astReflection.isSubtype(e.type, nodeType));\n        });\n        return descriptions;\n    }\n    remove(uri) {\n        const uriString = uri.toString();\n        this.symbolIndex.delete(uriString);\n        this.symbolByTypeIndex.clear(uriString);\n        this.referenceIndex.delete(uriString);\n    }\n    async updateContent(document, cancelToken = CancellationToken.None) {\n        const services = this.serviceRegistry.getServices(document.uri);\n        const exports = await services.references.ScopeComputation.computeExports(document, cancelToken);\n        const uri = document.uri.toString();\n        this.symbolIndex.set(uri, exports);\n        this.symbolByTypeIndex.clear(uri);\n    }\n    async updateReferences(document, cancelToken = CancellationToken.None) {\n        const services = this.serviceRegistry.getServices(document.uri);\n        const indexData = await services.workspace.ReferenceDescriptionProvider.createDescriptions(document, cancelToken);\n        this.referenceIndex.set(document.uri.toString(), indexData);\n    }\n    isAffected(document, changedUris) {\n        const references = this.referenceIndex.get(document.uri.toString());\n        if (!references) {\n            return false;\n        }\n        return references.some(ref => !ref.local && changedUris.has(ref.targetUri.toString()));\n    }\n}\n//# sourceMappingURL=index-manager.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { Deferred, interruptAndCheck } from '../utils/promise-utils.js';\nimport { URI, UriUtils } from '../utils/uri-utils.js';\nexport class DefaultWorkspaceManager {\n    constructor(services) {\n        this.initialBuildOptions = {};\n        this._ready = new Deferred();\n        this.serviceRegistry = services.ServiceRegistry;\n        this.langiumDocuments = services.workspace.LangiumDocuments;\n        this.documentBuilder = services.workspace.DocumentBuilder;\n        this.fileSystemProvider = services.workspace.FileSystemProvider;\n        this.mutex = services.workspace.WorkspaceLock;\n    }\n    get ready() {\n        return this._ready.promise;\n    }\n    get workspaceFolders() {\n        return this.folders;\n    }\n    initialize(params) {\n        var _a;\n        this.folders = (_a = params.workspaceFolders) !== null && _a !== void 0 ? _a : undefined;\n    }\n    initialized(_params) {\n        // Initialize the workspace even if there are no workspace folders\n        // We still want to load additional documents (language library or similar) during initialization\n        return this.mutex.write(token => { var _a; return this.initializeWorkspace((_a = this.folders) !== null && _a !== void 0 ? _a : [], token); });\n    }\n    async initializeWorkspace(folders, cancelToken = CancellationToken.None) {\n        const documents = await this.performStartup(folders);\n        // Only after creating all documents do we check whether we need to cancel the initialization\n        // The document builder will later pick up on all unprocessed documents\n        await interruptAndCheck(cancelToken);\n        await this.documentBuilder.build(documents, this.initialBuildOptions, cancelToken);\n    }\n    /**\n     * Performs the uninterruptable startup sequence of the workspace manager.\n     * This methods loads all documents in the workspace and other documents and returns them.\n     */\n    async performStartup(folders) {\n        const fileExtensions = this.serviceRegistry.all.flatMap(e => e.LanguageMetaData.fileExtensions);\n        const documents = [];\n        const collector = (document) => {\n            documents.push(document);\n            if (!this.langiumDocuments.hasDocument(document.uri)) {\n                this.langiumDocuments.addDocument(document);\n            }\n        };\n        // Even though we don't await the initialization of the workspace manager,\n        // we can still assume that all library documents and file documents are loaded by the time we start building documents.\n        // The mutex prevents anything from performing a workspace build until we check the cancellation token\n        await this.loadAdditionalDocuments(folders, collector);\n        await Promise.all(folders.map(wf => [wf, this.getRootFolder(wf)])\n            .map(async (entry) => this.traverseFolder(...entry, fileExtensions, collector)));\n        this._ready.resolve();\n        return documents;\n    }\n    /**\n     * Load all additional documents that shall be visible in the context of the given workspace\n     * folders and add them to the collector. This can be used to include built-in libraries of\n     * your language, which can be either loaded from provided files or constructed in memory.\n     */\n    loadAdditionalDocuments(_folders, _collector) {\n        return Promise.resolve();\n    }\n    /**\n     * Determine the root folder of the source documents in the given workspace folder.\n     * The default implementation returns the URI of the workspace folder, but you can override\n     * this to return a subfolder like `src` instead.\n     */\n    getRootFolder(workspaceFolder) {\n        return URI.parse(workspaceFolder.uri);\n    }\n    /**\n     * Traverse the file system folder identified by the given URI and its subfolders. All\n     * contained files that match the file extensions are added to the collector.\n     */\n    async traverseFolder(workspaceFolder, folderPath, fileExtensions, collector) {\n        const content = await this.fileSystemProvider.readDirectory(folderPath);\n        await Promise.all(content.map(async (entry) => {\n            if (this.includeEntry(workspaceFolder, entry, fileExtensions)) {\n                if (entry.isDirectory) {\n                    await this.traverseFolder(workspaceFolder, entry.uri, fileExtensions, collector);\n                }\n                else if (entry.isFile) {\n                    const document = await this.langiumDocuments.getOrCreateDocument(entry.uri);\n                    collector(document);\n                }\n            }\n        }));\n    }\n    /**\n     * Determine whether the given folder entry shall be included while indexing the workspace.\n     */\n    includeEntry(_workspaceFolder, entry, fileExtensions) {\n        const name = UriUtils.basename(entry.uri);\n        if (name.startsWith('.')) {\n            return false;\n        }\n        if (entry.isDirectory) {\n            return name !== 'node_modules' && name !== 'out';\n        }\n        else if (entry.isFile) {\n            const extname = UriUtils.extname(entry.uri);\n            return fileExtensions.includes(extname);\n        }\n        return false;\n    }\n}\n//# sourceMappingURL=workspace-manager.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Lexer as ChevrotainLexer, defaultLexerErrorProvider } from 'chevrotain';\nexport class DefaultLexerErrorMessageProvider {\n    buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column) {\n        return defaultLexerErrorProvider.buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column);\n    }\n    buildUnableToPopLexerModeMessage(token) {\n        return defaultLexerErrorProvider.buildUnableToPopLexerModeMessage(token);\n    }\n}\nexport const DEFAULT_TOKENIZE_OPTIONS = { mode: 'full' };\nexport class DefaultLexer {\n    constructor(services) {\n        this.errorMessageProvider = services.parser.LexerErrorMessageProvider;\n        this.tokenBuilder = services.parser.TokenBuilder;\n        const tokens = this.tokenBuilder.buildTokens(services.Grammar, {\n            caseInsensitive: services.LanguageMetaData.caseInsensitive\n        });\n        this.tokenTypes = this.toTokenTypeDictionary(tokens);\n        const lexerTokens = isTokenTypeDictionary(tokens) ? Object.values(tokens) : tokens;\n        const production = services.LanguageMetaData.mode === 'production';\n        this.chevrotainLexer = new ChevrotainLexer(lexerTokens, {\n            positionTracking: 'full',\n            skipValidations: production,\n            errorMessageProvider: this.errorMessageProvider\n        });\n    }\n    get definition() {\n        return this.tokenTypes;\n    }\n    tokenize(text, _options = DEFAULT_TOKENIZE_OPTIONS) {\n        var _a, _b, _c;\n        const chevrotainResult = this.chevrotainLexer.tokenize(text);\n        return {\n            tokens: chevrotainResult.tokens,\n            errors: chevrotainResult.errors,\n            hidden: (_a = chevrotainResult.groups.hidden) !== null && _a !== void 0 ? _a : [],\n            report: (_c = (_b = this.tokenBuilder).flushLexingReport) === null || _c === void 0 ? void 0 : _c.call(_b, text)\n        };\n    }\n    toTokenTypeDictionary(buildTokens) {\n        if (isTokenTypeDictionary(buildTokens))\n            return buildTokens;\n        const tokens = isIMultiModeLexerDefinition(buildTokens) ? Object.values(buildTokens.modes).flat() : buildTokens;\n        const res = {};\n        tokens.forEach(token => res[token.name] = token);\n        return res;\n    }\n}\n/**\n * Returns a check whether the given TokenVocabulary is TokenType array\n */\nexport function isTokenTypeArray(tokenVocabulary) {\n    return Array.isArray(tokenVocabulary) && (tokenVocabulary.length === 0 || 'name' in tokenVocabulary[0]);\n}\n/**\n * Returns a check whether the given TokenVocabulary is IMultiModeLexerDefinition\n */\nexport function isIMultiModeLexerDefinition(tokenVocabulary) {\n    return tokenVocabulary && 'modes' in tokenVocabulary && 'defaultMode' in tokenVocabulary;\n}\n/**\n * Returns a check whether the given TokenVocabulary is TokenTypeDictionary\n */\nexport function isTokenTypeDictionary(tokenVocabulary) {\n    return !isTokenTypeArray(tokenVocabulary) && !isIMultiModeLexerDefinition(tokenVocabulary);\n}\n//# sourceMappingURL=lexer.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Position, Range } from 'vscode-languageserver-types';\nimport { NEWLINE_REGEXP, escapeRegExp } from '../utils/regexp-utils.js';\nimport { URI } from '../utils/uri-utils.js';\nexport function parseJSDoc(node, start, options) {\n    let opts;\n    let position;\n    if (typeof node === 'string') {\n        position = start;\n        opts = options;\n    }\n    else {\n        position = node.range.start;\n        opts = start;\n    }\n    if (!position) {\n        position = Position.create(0, 0);\n    }\n    const lines = getLines(node);\n    const normalizedOptions = normalizeOptions(opts);\n    const tokens = tokenize({\n        lines,\n        position,\n        options: normalizedOptions\n    });\n    return parseJSDocComment({\n        index: 0,\n        tokens,\n        position\n    });\n}\nexport function isJSDoc(node, options) {\n    const normalizedOptions = normalizeOptions(options);\n    const lines = getLines(node);\n    if (lines.length === 0) {\n        return false;\n    }\n    const first = lines[0];\n    const last = lines[lines.length - 1];\n    const firstRegex = normalizedOptions.start;\n    const lastRegex = normalizedOptions.end;\n    return Boolean(firstRegex === null || firstRegex === void 0 ? void 0 : firstRegex.exec(first)) && Boolean(lastRegex === null || lastRegex === void 0 ? void 0 : lastRegex.exec(last));\n}\nfunction getLines(node) {\n    let content = '';\n    if (typeof node === 'string') {\n        content = node;\n    }\n    else {\n        content = node.text;\n    }\n    const lines = content.split(NEWLINE_REGEXP);\n    return lines;\n}\nconst tagRegex = /\\s*(@([\\p{L}][\\p{L}\\p{N}]*)?)/uy;\nconst inlineTagRegex = /\\{(@[\\p{L}][\\p{L}\\p{N}]*)(\\s*)([^\\r\\n}]+)?\\}/gu;\nfunction tokenize(context) {\n    var _a, _b, _c;\n    const tokens = [];\n    let currentLine = context.position.line;\n    let currentCharacter = context.position.character;\n    for (let i = 0; i < context.lines.length; i++) {\n        const first = i === 0;\n        const last = i === context.lines.length - 1;\n        let line = context.lines[i];\n        let index = 0;\n        if (first && context.options.start) {\n            const match = (_a = context.options.start) === null || _a === void 0 ? void 0 : _a.exec(line);\n            if (match) {\n                index = match.index + match[0].length;\n            }\n        }\n        else {\n            const match = (_b = context.options.line) === null || _b === void 0 ? void 0 : _b.exec(line);\n            if (match) {\n                index = match.index + match[0].length;\n            }\n        }\n        if (last) {\n            const match = (_c = context.options.end) === null || _c === void 0 ? void 0 : _c.exec(line);\n            if (match) {\n                line = line.substring(0, match.index);\n            }\n        }\n        line = line.substring(0, lastCharacter(line));\n        const whitespaceEnd = skipWhitespace(line, index);\n        if (whitespaceEnd >= line.length) {\n            // Only create a break token when we already have previous tokens\n            if (tokens.length > 0) {\n                const position = Position.create(currentLine, currentCharacter);\n                tokens.push({\n                    type: 'break',\n                    content: '',\n                    range: Range.create(position, position)\n                });\n            }\n        }\n        else {\n            tagRegex.lastIndex = index;\n            const tagMatch = tagRegex.exec(line);\n            if (tagMatch) {\n                const fullMatch = tagMatch[0];\n                const value = tagMatch[1];\n                const start = Position.create(currentLine, currentCharacter + index);\n                const end = Position.create(currentLine, currentCharacter + index + fullMatch.length);\n                tokens.push({\n                    type: 'tag',\n                    content: value,\n                    range: Range.create(start, end)\n                });\n                index += fullMatch.length;\n                index = skipWhitespace(line, index);\n            }\n            if (index < line.length) {\n                const rest = line.substring(index);\n                const inlineTagMatches = Array.from(rest.matchAll(inlineTagRegex));\n                tokens.push(...buildInlineTokens(inlineTagMatches, rest, currentLine, currentCharacter + index));\n            }\n        }\n        currentLine++;\n        currentCharacter = 0;\n    }\n    // Remove last break token if there is one\n    if (tokens.length > 0 && tokens[tokens.length - 1].type === 'break') {\n        return tokens.slice(0, -1);\n    }\n    return tokens;\n}\nfunction buildInlineTokens(tags, line, lineIndex, characterIndex) {\n    const tokens = [];\n    if (tags.length === 0) {\n        const start = Position.create(lineIndex, characterIndex);\n        const end = Position.create(lineIndex, characterIndex + line.length);\n        tokens.push({\n            type: 'text',\n            content: line,\n            range: Range.create(start, end)\n        });\n    }\n    else {\n        let lastIndex = 0;\n        for (const match of tags) {\n            const matchIndex = match.index;\n            const startContent = line.substring(lastIndex, matchIndex);\n            if (startContent.length > 0) {\n                tokens.push({\n                    type: 'text',\n                    content: line.substring(lastIndex, matchIndex),\n                    range: Range.create(Position.create(lineIndex, lastIndex + characterIndex), Position.create(lineIndex, matchIndex + characterIndex))\n                });\n            }\n            let offset = startContent.length + 1;\n            const tagName = match[1];\n            tokens.push({\n                type: 'inline-tag',\n                content: tagName,\n                range: Range.create(Position.create(lineIndex, lastIndex + offset + characterIndex), Position.create(lineIndex, lastIndex + offset + tagName.length + characterIndex))\n            });\n            offset += tagName.length;\n            if (match.length === 4) {\n                offset += match[2].length;\n                const value = match[3];\n                tokens.push({\n                    type: 'text',\n                    content: value,\n                    range: Range.create(Position.create(lineIndex, lastIndex + offset + characterIndex), Position.create(lineIndex, lastIndex + offset + value.length + characterIndex))\n                });\n            }\n            else {\n                tokens.push({\n                    type: 'text',\n                    content: '',\n                    range: Range.create(Position.create(lineIndex, lastIndex + offset + characterIndex), Position.create(lineIndex, lastIndex + offset + characterIndex))\n                });\n            }\n            lastIndex = matchIndex + match[0].length;\n        }\n        const endContent = line.substring(lastIndex);\n        if (endContent.length > 0) {\n            tokens.push({\n                type: 'text',\n                content: endContent,\n                range: Range.create(Position.create(lineIndex, lastIndex + characterIndex), Position.create(lineIndex, lastIndex + characterIndex + endContent.length))\n            });\n        }\n    }\n    return tokens;\n}\nconst nonWhitespaceRegex = /\\S/;\nconst whitespaceEndRegex = /\\s*$/;\nfunction skipWhitespace(line, index) {\n    const match = line.substring(index).match(nonWhitespaceRegex);\n    if (match) {\n        return index + match.index;\n    }\n    else {\n        return line.length;\n    }\n}\nfunction lastCharacter(line) {\n    const match = line.match(whitespaceEndRegex);\n    if (match && typeof match.index === 'number') {\n        return match.index;\n    }\n    return undefined;\n}\n// Parsing\nfunction parseJSDocComment(context) {\n    var _a, _b, _c, _d;\n    const startPosition = Position.create(context.position.line, context.position.character);\n    if (context.tokens.length === 0) {\n        return new JSDocCommentImpl([], Range.create(startPosition, startPosition));\n    }\n    const elements = [];\n    while (context.index < context.tokens.length) {\n        const element = parseJSDocElement(context, elements[elements.length - 1]);\n        if (element) {\n            elements.push(element);\n        }\n    }\n    const start = (_b = (_a = elements[0]) === null || _a === void 0 ? void 0 : _a.range.start) !== null && _b !== void 0 ? _b : startPosition;\n    const end = (_d = (_c = elements[elements.length - 1]) === null || _c === void 0 ? void 0 : _c.range.end) !== null && _d !== void 0 ? _d : startPosition;\n    return new JSDocCommentImpl(elements, Range.create(start, end));\n}\nfunction parseJSDocElement(context, last) {\n    const next = context.tokens[context.index];\n    if (next.type === 'tag') {\n        return parseJSDocTag(context, false);\n    }\n    else if (next.type === 'text' || next.type === 'inline-tag') {\n        return parseJSDocText(context);\n    }\n    else {\n        appendEmptyLine(next, last);\n        context.index++;\n        return undefined;\n    }\n}\nfunction appendEmptyLine(token, element) {\n    if (element) {\n        const line = new JSDocLineImpl('', token.range);\n        if ('inlines' in element) {\n            element.inlines.push(line);\n        }\n        else {\n            element.content.inlines.push(line);\n        }\n    }\n}\nfunction parseJSDocText(context) {\n    let token = context.tokens[context.index];\n    const firstToken = token;\n    let lastToken = token;\n    const lines = [];\n    while (token && token.type !== 'break' && token.type !== 'tag') {\n        lines.push(parseJSDocInline(context));\n        lastToken = token;\n        token = context.tokens[context.index];\n    }\n    return new JSDocTextImpl(lines, Range.create(firstToken.range.start, lastToken.range.end));\n}\nfunction parseJSDocInline(context) {\n    const token = context.tokens[context.index];\n    if (token.type === 'inline-tag') {\n        return parseJSDocTag(context, true);\n    }\n    else {\n        return parseJSDocLine(context);\n    }\n}\nfunction parseJSDocTag(context, inline) {\n    const tagToken = context.tokens[context.index++];\n    const name = tagToken.content.substring(1);\n    const nextToken = context.tokens[context.index];\n    if ((nextToken === null || nextToken === void 0 ? void 0 : nextToken.type) === 'text') {\n        if (inline) {\n            const docLine = parseJSDocLine(context);\n            return new JSDocTagImpl(name, new JSDocTextImpl([docLine], docLine.range), inline, Range.create(tagToken.range.start, docLine.range.end));\n        }\n        else {\n            const textDoc = parseJSDocText(context);\n            return new JSDocTagImpl(name, textDoc, inline, Range.create(tagToken.range.start, textDoc.range.end));\n        }\n    }\n    else {\n        const range = tagToken.range;\n        return new JSDocTagImpl(name, new JSDocTextImpl([], range), inline, range);\n    }\n}\nfunction parseJSDocLine(context) {\n    const token = context.tokens[context.index++];\n    return new JSDocLineImpl(token.content, token.range);\n}\nfunction normalizeOptions(options) {\n    if (!options) {\n        return normalizeOptions({\n            start: '/**',\n            end: '*/',\n            line: '*'\n        });\n    }\n    const { start, end, line } = options;\n    return {\n        start: normalizeOption(start, true),\n        end: normalizeOption(end, false),\n        line: normalizeOption(line, true)\n    };\n}\nfunction normalizeOption(option, start) {\n    if (typeof option === 'string' || typeof option === 'object') {\n        const escaped = typeof option === 'string' ? escapeRegExp(option) : option.source;\n        if (start) {\n            return new RegExp(`^\\\\s*${escaped}`);\n        }\n        else {\n            return new RegExp(`\\\\s*${escaped}\\\\s*$`);\n        }\n    }\n    else {\n        return option;\n    }\n}\nclass JSDocCommentImpl {\n    constructor(elements, range) {\n        this.elements = elements;\n        this.range = range;\n    }\n    getTag(name) {\n        return this.getAllTags().find(e => e.name === name);\n    }\n    getTags(name) {\n        return this.getAllTags().filter(e => e.name === name);\n    }\n    getAllTags() {\n        return this.elements.filter((e) => 'name' in e);\n    }\n    toString() {\n        let value = '';\n        for (const element of this.elements) {\n            if (value.length === 0) {\n                value = element.toString();\n            }\n            else {\n                const text = element.toString();\n                value += fillNewlines(value) + text;\n            }\n        }\n        return value.trim();\n    }\n    toMarkdown(options) {\n        let value = '';\n        for (const element of this.elements) {\n            if (value.length === 0) {\n                value = element.toMarkdown(options);\n            }\n            else {\n                const text = element.toMarkdown(options);\n                value += fillNewlines(value) + text;\n            }\n        }\n        return value.trim();\n    }\n}\nclass JSDocTagImpl {\n    constructor(name, content, inline, range) {\n        this.name = name;\n        this.content = content;\n        this.inline = inline;\n        this.range = range;\n    }\n    toString() {\n        let text = `@${this.name}`;\n        const content = this.content.toString();\n        if (this.content.inlines.length === 1) {\n            text = `${text} ${content}`;\n        }\n        else if (this.content.inlines.length > 1) {\n            text = `${text}\\n${content}`;\n        }\n        if (this.inline) {\n            // Inline tags are surrounded by curly braces\n            return `{${text}}`;\n        }\n        else {\n            return text;\n        }\n    }\n    toMarkdown(options) {\n        var _a, _b;\n        return (_b = (_a = options === null || options === void 0 ? void 0 : options.renderTag) === null || _a === void 0 ? void 0 : _a.call(options, this)) !== null && _b !== void 0 ? _b : this.toMarkdownDefault(options);\n    }\n    toMarkdownDefault(options) {\n        const content = this.content.toMarkdown(options);\n        if (this.inline) {\n            const rendered = renderInlineTag(this.name, content, options !== null && options !== void 0 ? options : {});\n            if (typeof rendered === 'string') {\n                return rendered;\n            }\n        }\n        let marker = '';\n        if ((options === null || options === void 0 ? void 0 : options.tag) === 'italic' || (options === null || options === void 0 ? void 0 : options.tag) === undefined) {\n            marker = '*';\n        }\n        else if ((options === null || options === void 0 ? void 0 : options.tag) === 'bold') {\n            marker = '**';\n        }\n        else if ((options === null || options === void 0 ? void 0 : options.tag) === 'bold-italic') {\n            marker = '***';\n        }\n        let text = `${marker}@${this.name}${marker}`;\n        if (this.content.inlines.length === 1) {\n            text = `${text}  ${content}`;\n        }\n        else if (this.content.inlines.length > 1) {\n            text = `${text}\\n${content}`;\n        }\n        if (this.inline) {\n            // Inline tags are surrounded by curly braces\n            return `{${text}}`;\n        }\n        else {\n            return text;\n        }\n    }\n}\nfunction renderInlineTag(tag, content, options) {\n    var _a, _b;\n    if (tag === 'linkplain' || tag === 'linkcode' || tag === 'link') {\n        const index = content.indexOf(' ');\n        let display = content;\n        if (index > 0) {\n            const displayStart = skipWhitespace(content, index);\n            display = content.substring(displayStart);\n            content = content.substring(0, index);\n        }\n        if (tag === 'linkcode' || (tag === 'link' && options.link === 'code')) {\n            // Surround the display value in a markdown inline code block\n            display = `\\`${display}\\``;\n        }\n        const renderedLink = (_b = (_a = options.renderLink) === null || _a === void 0 ? void 0 : _a.call(options, content, display)) !== null && _b !== void 0 ? _b : renderLinkDefault(content, display);\n        return renderedLink;\n    }\n    return undefined;\n}\nfunction renderLinkDefault(content, display) {\n    try {\n        URI.parse(content, true);\n        return `[${display}](${content})`;\n    }\n    catch (_a) {\n        return content;\n    }\n}\nclass JSDocTextImpl {\n    constructor(lines, range) {\n        this.inlines = lines;\n        this.range = range;\n    }\n    toString() {\n        let text = '';\n        for (let i = 0; i < this.inlines.length; i++) {\n            const inline = this.inlines[i];\n            const next = this.inlines[i + 1];\n            text += inline.toString();\n            if (next && next.range.start.line > inline.range.start.line) {\n                text += '\\n';\n            }\n        }\n        return text;\n    }\n    toMarkdown(options) {\n        let text = '';\n        for (let i = 0; i < this.inlines.length; i++) {\n            const inline = this.inlines[i];\n            const next = this.inlines[i + 1];\n            text += inline.toMarkdown(options);\n            if (next && next.range.start.line > inline.range.start.line) {\n                text += '\\n';\n            }\n        }\n        return text;\n    }\n}\nclass JSDocLineImpl {\n    constructor(text, range) {\n        this.text = text;\n        this.range = range;\n    }\n    toString() {\n        return this.text;\n    }\n    toMarkdown() {\n        return this.text;\n    }\n}\nfunction fillNewlines(text) {\n    if (text.endsWith('\\n')) {\n        return '\\n';\n    }\n    else {\n        return '\\n\\n';\n    }\n}\n//# sourceMappingURL=jsdoc.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { getDocument } from '../utils/ast-utils.js';\nimport { isJSDoc, parseJSDoc } from './jsdoc.js';\nexport class JSDocDocumentationProvider {\n    constructor(services) {\n        this.indexManager = services.shared.workspace.IndexManager;\n        this.commentProvider = services.documentation.CommentProvider;\n    }\n    getDocumentation(node) {\n        const comment = this.commentProvider.getComment(node);\n        if (comment && isJSDoc(comment)) {\n            const parsedJSDoc = parseJSDoc(comment);\n            return parsedJSDoc.toMarkdown({\n                renderLink: (link, display) => {\n                    return this.documentationLinkRenderer(node, link, display);\n                },\n                renderTag: (tag) => {\n                    return this.documentationTagRenderer(node, tag);\n                }\n            });\n        }\n        return undefined;\n    }\n    documentationLinkRenderer(node, name, display) {\n        var _a;\n        const description = (_a = this.findNameInPrecomputedScopes(node, name)) !== null && _a !== void 0 ? _a : this.findNameInGlobalScope(node, name);\n        if (description && description.nameSegment) {\n            const line = description.nameSegment.range.start.line + 1;\n            const character = description.nameSegment.range.start.character + 1;\n            const uri = description.documentUri.with({ fragment: `L${line},${character}` });\n            return `[${display}](${uri.toString()})`;\n        }\n        else {\n            return undefined;\n        }\n    }\n    documentationTagRenderer(_node, _tag) {\n        // Fall back to the default tag rendering\n        return undefined;\n    }\n    findNameInPrecomputedScopes(node, name) {\n        const document = getDocument(node);\n        const precomputed = document.precomputedScopes;\n        if (!precomputed) {\n            return undefined;\n        }\n        let currentNode = node;\n        do {\n            const allDescriptions = precomputed.get(currentNode);\n            const description = allDescriptions.find(e => e.name === name);\n            if (description) {\n                return description;\n            }\n            currentNode = currentNode.$container;\n        } while (currentNode);\n        return undefined;\n    }\n    findNameInGlobalScope(node, name) {\n        const description = this.indexManager.allElements().find(e => e.name === name);\n        return description;\n    }\n}\n//# sourceMappingURL=documentation-provider.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { isAstNodeWithComment } from '../serializer/json-serializer.js';\nimport { findCommentNode } from '../utils/cst-utils.js';\nexport class DefaultCommentProvider {\n    constructor(services) {\n        this.grammarConfig = () => services.parser.GrammarConfig;\n    }\n    getComment(node) {\n        var _a;\n        if (isAstNodeWithComment(node)) {\n            return node.$comment;\n        }\n        return (_a = findCommentNode(node.$cstNode, this.grammarConfig().multilineCommentRules)) === null || _a === void 0 ? void 0 : _a.text;\n    }\n}\n//# sourceMappingURL=comment-provider.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Deferred, OperationCancelled } from '../utils/promise-utils.js';\nimport { Emitter } from '../utils/event.js';\n/**\n * Default implementation of the async parser which simply wraps the sync parser in a promise.\n *\n * @remarks\n * A real implementation would create worker threads or web workers to offload the parsing work.\n */\nexport class DefaultAsyncParser {\n    constructor(services) {\n        this.syncParser = services.parser.LangiumParser;\n    }\n    parse(text, _cancelToken) {\n        return Promise.resolve(this.syncParser.parse(text));\n    }\n}\nexport class AbstractThreadedAsyncParser {\n    constructor(services) {\n        /**\n         * The thread count determines how many threads are used to parse files in parallel.\n         * The default value is 8. Decreasing this value increases startup performance, but decreases parallel parsing performance.\n         */\n        this.threadCount = 8;\n        /**\n         * The termination delay determines how long the parser waits for a thread to finish after a cancellation request.\n         * The default value is 200(ms).\n         */\n        this.terminationDelay = 200;\n        this.workerPool = [];\n        this.queue = [];\n        this.hydrator = services.serializer.Hydrator;\n    }\n    initializeWorkers() {\n        while (this.workerPool.length < this.threadCount) {\n            const worker = this.createWorker();\n            worker.onReady(() => {\n                if (this.queue.length > 0) {\n                    const deferred = this.queue.shift();\n                    if (deferred) {\n                        worker.lock();\n                        deferred.resolve(worker);\n                    }\n                }\n            });\n            this.workerPool.push(worker);\n        }\n    }\n    async parse(text, cancelToken) {\n        const worker = await this.acquireParserWorker(cancelToken);\n        const deferred = new Deferred();\n        let timeout;\n        // If the cancellation token is requested, we wait for a certain time before terminating the worker.\n        // Since the cancellation token lives longer than the parsing process, we need to dispose the event listener.\n        // Otherwise, we might accidentally terminate the worker after the parsing process has finished.\n        const cancellation = cancelToken.onCancellationRequested(() => {\n            timeout = setTimeout(() => {\n                this.terminateWorker(worker);\n            }, this.terminationDelay);\n        });\n        worker.parse(text).then(result => {\n            const hydrated = this.hydrator.hydrate(result);\n            deferred.resolve(hydrated);\n        }).catch(err => {\n            deferred.reject(err);\n        }).finally(() => {\n            cancellation.dispose();\n            clearTimeout(timeout);\n        });\n        return deferred.promise;\n    }\n    terminateWorker(worker) {\n        worker.terminate();\n        const index = this.workerPool.indexOf(worker);\n        if (index >= 0) {\n            this.workerPool.splice(index, 1);\n        }\n    }\n    async acquireParserWorker(cancelToken) {\n        this.initializeWorkers();\n        for (const worker of this.workerPool) {\n            if (worker.ready) {\n                worker.lock();\n                return worker;\n            }\n        }\n        const deferred = new Deferred();\n        cancelToken.onCancellationRequested(() => {\n            const index = this.queue.indexOf(deferred);\n            if (index >= 0) {\n                this.queue.splice(index, 1);\n            }\n            deferred.reject(OperationCancelled);\n        });\n        this.queue.push(deferred);\n        return deferred.promise;\n    }\n}\nexport class ParserWorker {\n    get ready() {\n        return this._ready;\n    }\n    get onReady() {\n        return this.onReadyEmitter.event;\n    }\n    constructor(sendMessage, onMessage, onError, terminate) {\n        this.onReadyEmitter = new Emitter();\n        this.deferred = new Deferred();\n        this._ready = true;\n        this._parsing = false;\n        this.sendMessage = sendMessage;\n        this._terminate = terminate;\n        onMessage(result => {\n            const parseResult = result;\n            this.deferred.resolve(parseResult);\n            this.unlock();\n        });\n        onError(error => {\n            this.deferred.reject(error);\n            this.unlock();\n        });\n    }\n    terminate() {\n        this.deferred.reject(OperationCancelled);\n        this._terminate();\n    }\n    lock() {\n        this._ready = false;\n    }\n    unlock() {\n        this._parsing = false;\n        this._ready = true;\n        this.onReadyEmitter.fire();\n    }\n    parse(text) {\n        if (this._parsing) {\n            throw new Error('Parser worker is busy');\n        }\n        this._parsing = true;\n        this.deferred = new Deferred();\n        this.sendMessage(text);\n        return this.deferred.promise;\n    }\n}\n//# sourceMappingURL=async-parser.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken, CancellationTokenSource } from '../utils/cancellation.js';\nimport { Deferred, isOperationCancelled, startCancelableOperation } from '../utils/promise-utils.js';\nexport class DefaultWorkspaceLock {\n    constructor() {\n        this.previousTokenSource = new CancellationTokenSource();\n        this.writeQueue = [];\n        this.readQueue = [];\n        this.done = true;\n    }\n    write(action) {\n        this.cancelWrite();\n        const tokenSource = startCancelableOperation();\n        this.previousTokenSource = tokenSource;\n        return this.enqueue(this.writeQueue, action, tokenSource.token);\n    }\n    read(action) {\n        return this.enqueue(this.readQueue, action);\n    }\n    enqueue(queue, action, cancellationToken = CancellationToken.None) {\n        const deferred = new Deferred();\n        const entry = {\n            action,\n            deferred,\n            cancellationToken\n        };\n        queue.push(entry);\n        this.performNextOperation();\n        return deferred.promise;\n    }\n    async performNextOperation() {\n        if (!this.done) {\n            return;\n        }\n        const entries = [];\n        if (this.writeQueue.length > 0) {\n            // Just perform the next write action\n            entries.push(this.writeQueue.shift());\n        }\n        else if (this.readQueue.length > 0) {\n            // Empty the read queue and perform all actions in parallel\n            entries.push(...this.readQueue.splice(0, this.readQueue.length));\n        }\n        else {\n            return;\n        }\n        this.done = false;\n        await Promise.all(entries.map(async ({ action, deferred, cancellationToken }) => {\n            try {\n                // Move the execution of the action to the next event loop tick via `Promise.resolve()`\n                const result = await Promise.resolve().then(() => action(cancellationToken));\n                deferred.resolve(result);\n            }\n            catch (err) {\n                if (isOperationCancelled(err)) {\n                    // If the operation was cancelled, we don't want to reject the promise\n                    deferred.resolve(undefined);\n                }\n                else {\n                    deferred.reject(err);\n                }\n            }\n        }));\n        this.done = true;\n        this.performNextOperation();\n    }\n    cancelWrite() {\n        this.previousTokenSource.cancel();\n    }\n}\n//# sourceMappingURL=workspace-lock.js.map","/******************************************************************************\n * Copyright 2024 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CompositeCstNodeImpl, LeafCstNodeImpl, RootCstNodeImpl } from '../parser/cst-node-builder.js';\nimport { isAbstractElement } from '../languages/generated/ast.js';\nimport { isRootCstNode, isCompositeCstNode, isLeafCstNode, isAstNode, isReference } from '../syntax-tree.js';\nimport { streamAst } from '../utils/ast-utils.js';\nimport { BiMap } from '../utils/collections.js';\nimport { streamCst } from '../utils/cst-utils.js';\nexport class DefaultHydrator {\n    constructor(services) {\n        this.grammarElementIdMap = new BiMap();\n        this.tokenTypeIdMap = new BiMap();\n        this.grammar = services.Grammar;\n        this.lexer = services.parser.Lexer;\n        this.linker = services.references.Linker;\n    }\n    dehydrate(result) {\n        return {\n            lexerErrors: result.lexerErrors,\n            lexerReport: result.lexerReport ? this.dehydrateLexerReport(result.lexerReport) : undefined,\n            // We need to create shallow copies of the errors\n            // The original errors inherit from the `Error` class, which is not transferable across worker threads\n            parserErrors: result.parserErrors.map(e => (Object.assign(Object.assign({}, e), { message: e.message }))),\n            value: this.dehydrateAstNode(result.value, this.createDehyrationContext(result.value))\n        };\n    }\n    dehydrateLexerReport(lexerReport) {\n        // By default, lexer reports are serializable\n        return lexerReport;\n    }\n    createDehyrationContext(node) {\n        const astNodes = new Map();\n        const cstNodes = new Map();\n        for (const astNode of streamAst(node)) {\n            astNodes.set(astNode, {});\n        }\n        if (node.$cstNode) {\n            for (const cstNode of streamCst(node.$cstNode)) {\n                cstNodes.set(cstNode, {});\n            }\n        }\n        return {\n            astNodes,\n            cstNodes\n        };\n    }\n    dehydrateAstNode(node, context) {\n        const obj = context.astNodes.get(node);\n        obj.$type = node.$type;\n        obj.$containerIndex = node.$containerIndex;\n        obj.$containerProperty = node.$containerProperty;\n        if (node.$cstNode !== undefined) {\n            obj.$cstNode = this.dehydrateCstNode(node.$cstNode, context);\n        }\n        for (const [name, value] of Object.entries(node)) {\n            if (name.startsWith('$')) {\n                continue;\n            }\n            if (Array.isArray(value)) {\n                const arr = [];\n                obj[name] = arr;\n                for (const item of value) {\n                    if (isAstNode(item)) {\n                        arr.push(this.dehydrateAstNode(item, context));\n                    }\n                    else if (isReference(item)) {\n                        arr.push(this.dehydrateReference(item, context));\n                    }\n                    else {\n                        arr.push(item);\n                    }\n                }\n            }\n            else if (isAstNode(value)) {\n                obj[name] = this.dehydrateAstNode(value, context);\n            }\n            else if (isReference(value)) {\n                obj[name] = this.dehydrateReference(value, context);\n            }\n            else if (value !== undefined) {\n                obj[name] = value;\n            }\n        }\n        return obj;\n    }\n    dehydrateReference(reference, context) {\n        const obj = {};\n        obj.$refText = reference.$refText;\n        if (reference.$refNode) {\n            obj.$refNode = context.cstNodes.get(reference.$refNode);\n        }\n        return obj;\n    }\n    dehydrateCstNode(node, context) {\n        const cstNode = context.cstNodes.get(node);\n        if (isRootCstNode(node)) {\n            cstNode.fullText = node.fullText;\n        }\n        else {\n            // Note: This returns undefined for hidden nodes (i.e. comments)\n            cstNode.grammarSource = this.getGrammarElementId(node.grammarSource);\n        }\n        cstNode.hidden = node.hidden;\n        cstNode.astNode = context.astNodes.get(node.astNode);\n        if (isCompositeCstNode(node)) {\n            cstNode.content = node.content.map(child => this.dehydrateCstNode(child, context));\n        }\n        else if (isLeafCstNode(node)) {\n            cstNode.tokenType = node.tokenType.name;\n            cstNode.offset = node.offset;\n            cstNode.length = node.length;\n            cstNode.startLine = node.range.start.line;\n            cstNode.startColumn = node.range.start.character;\n            cstNode.endLine = node.range.end.line;\n            cstNode.endColumn = node.range.end.character;\n        }\n        return cstNode;\n    }\n    hydrate(result) {\n        const node = result.value;\n        const context = this.createHydrationContext(node);\n        if ('$cstNode' in node) {\n            this.hydrateCstNode(node.$cstNode, context);\n        }\n        return {\n            lexerErrors: result.lexerErrors,\n            lexerReport: result.lexerReport,\n            parserErrors: result.parserErrors,\n            value: this.hydrateAstNode(node, context)\n        };\n    }\n    createHydrationContext(node) {\n        const astNodes = new Map();\n        const cstNodes = new Map();\n        for (const astNode of streamAst(node)) {\n            astNodes.set(astNode, {});\n        }\n        let root;\n        if (node.$cstNode) {\n            for (const cstNode of streamCst(node.$cstNode)) {\n                let cst;\n                if ('fullText' in cstNode) {\n                    cst = new RootCstNodeImpl(cstNode.fullText);\n                    root = cst;\n                }\n                else if ('content' in cstNode) {\n                    cst = new CompositeCstNodeImpl();\n                }\n                else if ('tokenType' in cstNode) {\n                    cst = this.hydrateCstLeafNode(cstNode);\n                }\n                if (cst) {\n                    cstNodes.set(cstNode, cst);\n                    cst.root = root;\n                }\n            }\n        }\n        return {\n            astNodes,\n            cstNodes\n        };\n    }\n    hydrateAstNode(node, context) {\n        const astNode = context.astNodes.get(node);\n        astNode.$type = node.$type;\n        astNode.$containerIndex = node.$containerIndex;\n        astNode.$containerProperty = node.$containerProperty;\n        if (node.$cstNode) {\n            astNode.$cstNode = context.cstNodes.get(node.$cstNode);\n        }\n        for (const [name, value] of Object.entries(node)) {\n            if (name.startsWith('$')) {\n                continue;\n            }\n            if (Array.isArray(value)) {\n                const arr = [];\n                astNode[name] = arr;\n                for (const item of value) {\n                    if (isAstNode(item)) {\n                        arr.push(this.setParent(this.hydrateAstNode(item, context), astNode));\n                    }\n                    else if (isReference(item)) {\n                        arr.push(this.hydrateReference(item, astNode, name, context));\n                    }\n                    else {\n                        arr.push(item);\n                    }\n                }\n            }\n            else if (isAstNode(value)) {\n                astNode[name] = this.setParent(this.hydrateAstNode(value, context), astNode);\n            }\n            else if (isReference(value)) {\n                astNode[name] = this.hydrateReference(value, astNode, name, context);\n            }\n            else if (value !== undefined) {\n                astNode[name] = value;\n            }\n        }\n        return astNode;\n    }\n    setParent(node, parent) {\n        node.$container = parent;\n        return node;\n    }\n    hydrateReference(reference, node, name, context) {\n        return this.linker.buildReference(node, name, context.cstNodes.get(reference.$refNode), reference.$refText);\n    }\n    hydrateCstNode(cstNode, context, num = 0) {\n        const cstNodeObj = context.cstNodes.get(cstNode);\n        if (typeof cstNode.grammarSource === 'number') {\n            cstNodeObj.grammarSource = this.getGrammarElement(cstNode.grammarSource);\n        }\n        cstNodeObj.astNode = context.astNodes.get(cstNode.astNode);\n        if (isCompositeCstNode(cstNodeObj)) {\n            for (const child of cstNode.content) {\n                const hydrated = this.hydrateCstNode(child, context, num++);\n                cstNodeObj.content.push(hydrated);\n            }\n        }\n        return cstNodeObj;\n    }\n    hydrateCstLeafNode(cstNode) {\n        const tokenType = this.getTokenType(cstNode.tokenType);\n        const offset = cstNode.offset;\n        const length = cstNode.length;\n        const startLine = cstNode.startLine;\n        const startColumn = cstNode.startColumn;\n        const endLine = cstNode.endLine;\n        const endColumn = cstNode.endColumn;\n        const hidden = cstNode.hidden;\n        const node = new LeafCstNodeImpl(offset, length, {\n            start: {\n                line: startLine,\n                character: startColumn\n            },\n            end: {\n                line: endLine,\n                character: endColumn\n            }\n        }, tokenType, hidden);\n        return node;\n    }\n    getTokenType(name) {\n        return this.lexer.definition[name];\n    }\n    getGrammarElementId(node) {\n        if (!node) {\n            return undefined;\n        }\n        if (this.grammarElementIdMap.size === 0) {\n            this.createGrammarElementIdMap();\n        }\n        return this.grammarElementIdMap.get(node);\n    }\n    getGrammarElement(id) {\n        if (this.grammarElementIdMap.size === 0) {\n            this.createGrammarElementIdMap();\n        }\n        const element = this.grammarElementIdMap.getKey(id);\n        return element;\n    }\n    createGrammarElementIdMap() {\n        let id = 0;\n        for (const element of streamAst(this.grammar)) {\n            if (isAbstractElement(element)) {\n                this.grammarElementIdMap.set(element, id++);\n            }\n        }\n    }\n}\n//# sourceMappingURL=hydrator.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n******************************************************************************/\nimport { createGrammarConfig } from './languages/grammar-config.js';\nimport { createCompletionParser } from './parser/completion-parser-builder.js';\nimport { createLangiumParser } from './parser/langium-parser-builder.js';\nimport { DefaultTokenBuilder } from './parser/token-builder.js';\nimport { DefaultValueConverter } from './parser/value-converter.js';\nimport { DefaultLinker } from './references/linker.js';\nimport { DefaultNameProvider } from './references/name-provider.js';\nimport { DefaultReferences } from './references/references.js';\nimport { DefaultScopeComputation } from './references/scope-computation.js';\nimport { DefaultScopeProvider } from './references/scope-provider.js';\nimport { DefaultJsonSerializer } from './serializer/json-serializer.js';\nimport { DefaultServiceRegistry } from './service-registry.js';\nimport { DefaultDocumentValidator } from './validation/document-validator.js';\nimport { ValidationRegistry } from './validation/validation-registry.js';\nimport { DefaultAstNodeDescriptionProvider, DefaultReferenceDescriptionProvider } from './workspace/ast-descriptions.js';\nimport { DefaultAstNodeLocator } from './workspace/ast-node-locator.js';\nimport { DefaultConfigurationProvider } from './workspace/configuration.js';\nimport { DefaultDocumentBuilder } from './workspace/document-builder.js';\nimport { DefaultLangiumDocumentFactory, DefaultLangiumDocuments } from './workspace/documents.js';\nimport { DefaultIndexManager } from './workspace/index-manager.js';\nimport { DefaultWorkspaceManager } from './workspace/workspace-manager.js';\nimport { DefaultLexer, DefaultLexerErrorMessageProvider } from './parser/lexer.js';\nimport { JSDocDocumentationProvider } from './documentation/documentation-provider.js';\nimport { DefaultCommentProvider } from './documentation/comment-provider.js';\nimport { LangiumParserErrorMessageProvider } from './parser/langium-parser.js';\nimport { DefaultAsyncParser } from './parser/async-parser.js';\nimport { DefaultWorkspaceLock } from './workspace/workspace-lock.js';\nimport { DefaultHydrator } from './serializer/hydrator.js';\n/**\n * Creates a dependency injection module configuring the default core services.\n * This is a set of services that are dedicated to a specific language.\n */\nexport function createDefaultCoreModule(context) {\n    return {\n        documentation: {\n            CommentProvider: (services) => new DefaultCommentProvider(services),\n            DocumentationProvider: (services) => new JSDocDocumentationProvider(services)\n        },\n        parser: {\n            AsyncParser: (services) => new DefaultAsyncParser(services),\n            GrammarConfig: (services) => createGrammarConfig(services),\n            LangiumParser: (services) => createLangiumParser(services),\n            CompletionParser: (services) => createCompletionParser(services),\n            ValueConverter: () => new DefaultValueConverter(),\n            TokenBuilder: () => new DefaultTokenBuilder(),\n            Lexer: (services) => new DefaultLexer(services),\n            ParserErrorMessageProvider: () => new LangiumParserErrorMessageProvider(),\n            LexerErrorMessageProvider: () => new DefaultLexerErrorMessageProvider()\n        },\n        workspace: {\n            AstNodeLocator: () => new DefaultAstNodeLocator(),\n            AstNodeDescriptionProvider: (services) => new DefaultAstNodeDescriptionProvider(services),\n            ReferenceDescriptionProvider: (services) => new DefaultReferenceDescriptionProvider(services)\n        },\n        references: {\n            Linker: (services) => new DefaultLinker(services),\n            NameProvider: () => new DefaultNameProvider(),\n            ScopeProvider: (services) => new DefaultScopeProvider(services),\n            ScopeComputation: (services) => new DefaultScopeComputation(services),\n            References: (services) => new DefaultReferences(services)\n        },\n        serializer: {\n            Hydrator: (services) => new DefaultHydrator(services),\n            JsonSerializer: (services) => new DefaultJsonSerializer(services)\n        },\n        validation: {\n            DocumentValidator: (services) => new DefaultDocumentValidator(services),\n            ValidationRegistry: (services) => new ValidationRegistry(services)\n        },\n        shared: () => context.shared\n    };\n}\n/**\n * Creates a dependency injection module configuring the default shared core services.\n * This is the set of services that are shared between multiple languages.\n */\nexport function createDefaultSharedCoreModule(context) {\n    return {\n        ServiceRegistry: (services) => new DefaultServiceRegistry(services),\n        workspace: {\n            LangiumDocuments: (services) => new DefaultLangiumDocuments(services),\n            LangiumDocumentFactory: (services) => new DefaultLangiumDocumentFactory(services),\n            DocumentBuilder: (services) => new DefaultDocumentBuilder(services),\n            IndexManager: (services) => new DefaultIndexManager(services),\n            WorkspaceManager: (services) => new DefaultWorkspaceManager(services),\n            FileSystemProvider: (services) => context.fileSystemProvider(services),\n            WorkspaceLock: () => new DefaultWorkspaceLock(),\n            ConfigurationProvider: (services) => new DefaultConfigurationProvider(services)\n        }\n    };\n}\n//# sourceMappingURL=default-module.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport var Module;\n(function (Module) {\n    Module.merge = (m1, m2) => _merge(_merge({}, m1), m2);\n})(Module || (Module = {}));\n/**\n * Given a set of modules, the inject function returns a lazily evaluated injector\n * that injects dependencies into the requested service when it is requested the\n * first time. Subsequent requests will return the same service.\n *\n * In the case of cyclic dependencies, an Error will be thrown. This can be fixed\n * by injecting a provider `() => T` instead of a `T`.\n *\n * Please note that the arguments may be objects or arrays. However, the result will\n * be an object. Using it with for..of will have no effect.\n *\n * @param module1 first Module\n * @param module2 (optional) second Module\n * @param module3 (optional) third Module\n * @param module4 (optional) fourth Module\n * @param module5 (optional) fifth Module\n * @param module6 (optional) sixth Module\n * @param module7 (optional) seventh Module\n * @param module8 (optional) eighth Module\n * @param module9 (optional) ninth Module\n * @returns a new object of type I\n */\nexport function inject(module1, module2, module3, module4, module5, module6, module7, module8, module9) {\n    const module = [module1, module2, module3, module4, module5, module6, module7, module8, module9].reduce(_merge, {});\n    return _inject(module);\n}\nconst isProxy = Symbol('isProxy');\n/**\n * Eagerly load all services in the given dependency injection container. This is sometimes\n * necessary because services can register event listeners in their constructors.\n */\nexport function eagerLoad(item) {\n    if (item && item[isProxy]) {\n        for (const value of Object.values(item)) {\n            eagerLoad(value);\n        }\n    }\n    return item;\n}\n/**\n * Helper function that returns an injector by creating a proxy.\n * Invariant: injector is of type I. If injector is undefined, then T = I.\n */\nfunction _inject(module, injector) {\n    const proxy = new Proxy({}, {\n        deleteProperty: () => false,\n        set: () => {\n            throw new Error('Cannot set property on injected service container');\n        },\n        get: (obj, prop) => {\n            if (prop === isProxy) {\n                return true;\n            }\n            else {\n                return _resolve(obj, prop, module, injector || proxy);\n            }\n        },\n        getOwnPropertyDescriptor: (obj, prop) => (_resolve(obj, prop, module, injector || proxy), Object.getOwnPropertyDescriptor(obj, prop)), // used by for..in\n        has: (_, prop) => prop in module, // used by ..in..\n        ownKeys: () => [...Object.getOwnPropertyNames(module)] // used by for..in\n    });\n    return proxy;\n}\n/**\n * Internally used to tag a requested dependency, directly before calling the factory.\n * This allows us to find cycles during instance creation.\n */\nconst __requested__ = Symbol();\n/**\n * Returns the value `obj[prop]`. If the value does not exist, yet, it is resolved from\n * the module description. The result of service factories is cached. Groups are\n * recursively proxied.\n *\n * @param obj an object holding all group proxies and services\n * @param prop the key of a value within obj\n * @param module an object containing groups and service factories\n * @param injector the first level proxy that provides access to all values\n * @returns the requested value `obj[prop]`\n * @throws Error if a dependency cycle is detected\n */\nfunction _resolve(obj, prop, module, injector) {\n    if (prop in obj) {\n        if (obj[prop] instanceof Error) {\n            throw new Error('Construction failure. Please make sure that your dependencies are constructable.', { cause: obj[prop] });\n        }\n        if (obj[prop] === __requested__) {\n            throw new Error('Cycle detected. Please make \"' + String(prop) + '\" lazy. Visit https://langium.org/docs/reference/configuration-services/#resolving-cyclic-dependencies');\n        }\n        return obj[prop];\n    }\n    else if (prop in module) {\n        const value = module[prop];\n        obj[prop] = __requested__;\n        try {\n            obj[prop] = (typeof value === 'function') ? value(injector) : _inject(value, injector);\n        }\n        catch (error) {\n            obj[prop] = error instanceof Error ? error : undefined;\n            throw error;\n        }\n        return obj[prop];\n    }\n    else {\n        return undefined;\n    }\n}\n/**\n * Performs a deep-merge of two modules by writing source entries into the target module.\n *\n * @param target the module which is written\n * @param source the module which is read\n * @returns the target module\n */\nfunction _merge(target, source) {\n    if (source) {\n        for (const [key, value2] of Object.entries(source)) {\n            if (value2 !== undefined) {\n                const value1 = target[key];\n                if (value1 !== null && value2 !== null && typeof value1 === 'object' && typeof value2 === 'object') {\n                    target[key] = _merge(value1, value2);\n                }\n                else {\n                    target[key] = value2;\n                }\n            }\n        }\n    }\n    return target;\n}\n//# sourceMappingURL=dependency-injection.js.map","/******************************************************************************\n * This file was generated by langium-cli 3.3.0.\n * DO NOT EDIT MANUALLY!\n ******************************************************************************/\nimport { AbstractAstReflection } from '../../syntax-tree.js';\nexport const LangiumGrammarTerminals = {\n    ID: /\\^?[_a-zA-Z][\\w_]*/,\n    STRING: /\"(\\\\.|[^\"\\\\])*\"|'(\\\\.|[^'\\\\])*'/,\n    NUMBER: /NaN|-?((\\d*\\.\\d+|\\d+)([Ee][+-]?\\d+)?|Infinity)/,\n    RegexLiteral: /\\/(?![*+?])(?:[^\\r\\n\\[/\\\\]|\\\\.|\\[(?:[^\\r\\n\\]\\\\]|\\\\.)*\\])+\\/[a-z]*/,\n    WS: /\\s+/,\n    ML_COMMENT: /\\/\\*[\\s\\S]*?\\*\\//,\n    SL_COMMENT: /\\/\\/[^\\n\\r]*/,\n};\nexport const AbstractRule = 'AbstractRule';\nexport function isAbstractRule(item) {\n    return reflection.isInstance(item, AbstractRule);\n}\nexport const AbstractType = 'AbstractType';\nexport function isAbstractType(item) {\n    return reflection.isInstance(item, AbstractType);\n}\nexport const Condition = 'Condition';\nexport function isCondition(item) {\n    return reflection.isInstance(item, Condition);\n}\nexport function isFeatureName(item) {\n    return isPrimitiveType(item) || item === 'current' || item === 'entry' || item === 'extends' || item === 'false' || item === 'fragment' || item === 'grammar' || item === 'hidden' || item === 'import' || item === 'interface' || item === 'returns' || item === 'terminal' || item === 'true' || item === 'type' || item === 'infer' || item === 'infers' || item === 'with' || (typeof item === 'string' && (/\\^?[_a-zA-Z][\\w_]*/.test(item)));\n}\nexport function isPrimitiveType(item) {\n    return item === 'string' || item === 'number' || item === 'boolean' || item === 'Date' || item === 'bigint';\n}\nexport const TypeDefinition = 'TypeDefinition';\nexport function isTypeDefinition(item) {\n    return reflection.isInstance(item, TypeDefinition);\n}\nexport const ValueLiteral = 'ValueLiteral';\nexport function isValueLiteral(item) {\n    return reflection.isInstance(item, ValueLiteral);\n}\nexport const AbstractElement = 'AbstractElement';\nexport function isAbstractElement(item) {\n    return reflection.isInstance(item, AbstractElement);\n}\nexport const ArrayLiteral = 'ArrayLiteral';\nexport function isArrayLiteral(item) {\n    return reflection.isInstance(item, ArrayLiteral);\n}\nexport const ArrayType = 'ArrayType';\nexport function isArrayType(item) {\n    return reflection.isInstance(item, ArrayType);\n}\nexport const BooleanLiteral = 'BooleanLiteral';\nexport function isBooleanLiteral(item) {\n    return reflection.isInstance(item, BooleanLiteral);\n}\nexport const Conjunction = 'Conjunction';\nexport function isConjunction(item) {\n    return reflection.isInstance(item, Conjunction);\n}\nexport const Disjunction = 'Disjunction';\nexport function isDisjunction(item) {\n    return reflection.isInstance(item, Disjunction);\n}\nexport const Grammar = 'Grammar';\nexport function isGrammar(item) {\n    return reflection.isInstance(item, Grammar);\n}\nexport const GrammarImport = 'GrammarImport';\nexport function isGrammarImport(item) {\n    return reflection.isInstance(item, GrammarImport);\n}\nexport const InferredType = 'InferredType';\nexport function isInferredType(item) {\n    return reflection.isInstance(item, InferredType);\n}\nexport const Interface = 'Interface';\nexport function isInterface(item) {\n    return reflection.isInstance(item, Interface);\n}\nexport const NamedArgument = 'NamedArgument';\nexport function isNamedArgument(item) {\n    return reflection.isInstance(item, NamedArgument);\n}\nexport const Negation = 'Negation';\nexport function isNegation(item) {\n    return reflection.isInstance(item, Negation);\n}\nexport const NumberLiteral = 'NumberLiteral';\nexport function isNumberLiteral(item) {\n    return reflection.isInstance(item, NumberLiteral);\n}\nexport const Parameter = 'Parameter';\nexport function isParameter(item) {\n    return reflection.isInstance(item, Parameter);\n}\nexport const ParameterReference = 'ParameterReference';\nexport function isParameterReference(item) {\n    return reflection.isInstance(item, ParameterReference);\n}\nexport const ParserRule = 'ParserRule';\nexport function isParserRule(item) {\n    return reflection.isInstance(item, ParserRule);\n}\nexport const ReferenceType = 'ReferenceType';\nexport function isReferenceType(item) {\n    return reflection.isInstance(item, ReferenceType);\n}\nexport const ReturnType = 'ReturnType';\nexport function isReturnType(item) {\n    return reflection.isInstance(item, ReturnType);\n}\nexport const SimpleType = 'SimpleType';\nexport function isSimpleType(item) {\n    return reflection.isInstance(item, SimpleType);\n}\nexport const StringLiteral = 'StringLiteral';\nexport function isStringLiteral(item) {\n    return reflection.isInstance(item, StringLiteral);\n}\nexport const TerminalRule = 'TerminalRule';\nexport function isTerminalRule(item) {\n    return reflection.isInstance(item, TerminalRule);\n}\nexport const Type = 'Type';\nexport function isType(item) {\n    return reflection.isInstance(item, Type);\n}\nexport const TypeAttribute = 'TypeAttribute';\nexport function isTypeAttribute(item) {\n    return reflection.isInstance(item, TypeAttribute);\n}\nexport const UnionType = 'UnionType';\nexport function isUnionType(item) {\n    return reflection.isInstance(item, UnionType);\n}\nexport const Action = 'Action';\nexport function isAction(item) {\n    return reflection.isInstance(item, Action);\n}\nexport const Alternatives = 'Alternatives';\nexport function isAlternatives(item) {\n    return reflection.isInstance(item, Alternatives);\n}\nexport const Assignment = 'Assignment';\nexport function isAssignment(item) {\n    return reflection.isInstance(item, Assignment);\n}\nexport const CharacterRange = 'CharacterRange';\nexport function isCharacterRange(item) {\n    return reflection.isInstance(item, CharacterRange);\n}\nexport const CrossReference = 'CrossReference';\nexport function isCrossReference(item) {\n    return reflection.isInstance(item, CrossReference);\n}\nexport const EndOfFile = 'EndOfFile';\nexport function isEndOfFile(item) {\n    return reflection.isInstance(item, EndOfFile);\n}\nexport const Group = 'Group';\nexport function isGroup(item) {\n    return reflection.isInstance(item, Group);\n}\nexport const Keyword = 'Keyword';\nexport function isKeyword(item) {\n    return reflection.isInstance(item, Keyword);\n}\nexport const NegatedToken = 'NegatedToken';\nexport function isNegatedToken(item) {\n    return reflection.isInstance(item, NegatedToken);\n}\nexport const RegexToken = 'RegexToken';\nexport function isRegexToken(item) {\n    return reflection.isInstance(item, RegexToken);\n}\nexport const RuleCall = 'RuleCall';\nexport function isRuleCall(item) {\n    return reflection.isInstance(item, RuleCall);\n}\nexport const TerminalAlternatives = 'TerminalAlternatives';\nexport function isTerminalAlternatives(item) {\n    return reflection.isInstance(item, TerminalAlternatives);\n}\nexport const TerminalGroup = 'TerminalGroup';\nexport function isTerminalGroup(item) {\n    return reflection.isInstance(item, TerminalGroup);\n}\nexport const TerminalRuleCall = 'TerminalRuleCall';\nexport function isTerminalRuleCall(item) {\n    return reflection.isInstance(item, TerminalRuleCall);\n}\nexport const UnorderedGroup = 'UnorderedGroup';\nexport function isUnorderedGroup(item) {\n    return reflection.isInstance(item, UnorderedGroup);\n}\nexport const UntilToken = 'UntilToken';\nexport function isUntilToken(item) {\n    return reflection.isInstance(item, UntilToken);\n}\nexport const Wildcard = 'Wildcard';\nexport function isWildcard(item) {\n    return reflection.isInstance(item, Wildcard);\n}\nexport class LangiumGrammarAstReflection extends AbstractAstReflection {\n    getAllTypes() {\n        return [AbstractElement, AbstractRule, AbstractType, Action, Alternatives, ArrayLiteral, ArrayType, Assignment, BooleanLiteral, CharacterRange, Condition, Conjunction, CrossReference, Disjunction, EndOfFile, Grammar, GrammarImport, Group, InferredType, Interface, Keyword, NamedArgument, NegatedToken, Negation, NumberLiteral, Parameter, ParameterReference, ParserRule, ReferenceType, RegexToken, ReturnType, RuleCall, SimpleType, StringLiteral, TerminalAlternatives, TerminalGroup, TerminalRule, TerminalRuleCall, Type, TypeAttribute, TypeDefinition, UnionType, UnorderedGroup, UntilToken, ValueLiteral, Wildcard];\n    }\n    computeIsSubtype(subtype, supertype) {\n        switch (subtype) {\n            case Action:\n            case Alternatives:\n            case Assignment:\n            case CharacterRange:\n            case CrossReference:\n            case EndOfFile:\n            case Group:\n            case Keyword:\n            case NegatedToken:\n            case RegexToken:\n            case RuleCall:\n            case TerminalAlternatives:\n            case TerminalGroup:\n            case TerminalRuleCall:\n            case UnorderedGroup:\n            case UntilToken:\n            case Wildcard: {\n                return this.isSubtype(AbstractElement, supertype);\n            }\n            case ArrayLiteral:\n            case NumberLiteral:\n            case StringLiteral: {\n                return this.isSubtype(ValueLiteral, supertype);\n            }\n            case ArrayType:\n            case ReferenceType:\n            case SimpleType:\n            case UnionType: {\n                return this.isSubtype(TypeDefinition, supertype);\n            }\n            case BooleanLiteral: {\n                return this.isSubtype(Condition, supertype) || this.isSubtype(ValueLiteral, supertype);\n            }\n            case Conjunction:\n            case Disjunction:\n            case Negation:\n            case ParameterReference: {\n                return this.isSubtype(Condition, supertype);\n            }\n            case InferredType:\n            case Interface:\n            case Type: {\n                return this.isSubtype(AbstractType, supertype);\n            }\n            case ParserRule: {\n                return this.isSubtype(AbstractRule, supertype) || this.isSubtype(AbstractType, supertype);\n            }\n            case TerminalRule: {\n                return this.isSubtype(AbstractRule, supertype);\n            }\n            default: {\n                return false;\n            }\n        }\n    }\n    getReferenceType(refInfo) {\n        const referenceId = `${refInfo.container.$type}:${refInfo.property}`;\n        switch (referenceId) {\n            case 'Action:type':\n            case 'CrossReference:type':\n            case 'Interface:superTypes':\n            case 'ParserRule:returnType':\n            case 'SimpleType:typeRef': {\n                return AbstractType;\n            }\n            case 'Grammar:hiddenTokens':\n            case 'ParserRule:hiddenTokens':\n            case 'RuleCall:rule': {\n                return AbstractRule;\n            }\n            case 'Grammar:usedGrammars': {\n                return Grammar;\n            }\n            case 'NamedArgument:parameter':\n            case 'ParameterReference:parameter': {\n                return Parameter;\n            }\n            case 'TerminalRuleCall:rule': {\n                return TerminalRule;\n            }\n            default: {\n                throw new Error(`${referenceId} is not a valid reference id.`);\n            }\n        }\n    }\n    getTypeMetaData(type) {\n        switch (type) {\n            case AbstractElement: {\n                return {\n                    name: AbstractElement,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case ArrayLiteral: {\n                return {\n                    name: ArrayLiteral,\n                    properties: [\n                        { name: 'elements', defaultValue: [] }\n                    ]\n                };\n            }\n            case ArrayType: {\n                return {\n                    name: ArrayType,\n                    properties: [\n                        { name: 'elementType' }\n                    ]\n                };\n            }\n            case BooleanLiteral: {\n                return {\n                    name: BooleanLiteral,\n                    properties: [\n                        { name: 'true', defaultValue: false }\n                    ]\n                };\n            }\n            case Conjunction: {\n                return {\n                    name: Conjunction,\n                    properties: [\n                        { name: 'left' },\n                        { name: 'right' }\n                    ]\n                };\n            }\n            case Disjunction: {\n                return {\n                    name: Disjunction,\n                    properties: [\n                        { name: 'left' },\n                        { name: 'right' }\n                    ]\n                };\n            }\n            case Grammar: {\n                return {\n                    name: Grammar,\n                    properties: [\n                        { name: 'definesHiddenTokens', defaultValue: false },\n                        { name: 'hiddenTokens', defaultValue: [] },\n                        { name: 'imports', defaultValue: [] },\n                        { name: 'interfaces', defaultValue: [] },\n                        { name: 'isDeclared', defaultValue: false },\n                        { name: 'name' },\n                        { name: 'rules', defaultValue: [] },\n                        { name: 'types', defaultValue: [] },\n                        { name: 'usedGrammars', defaultValue: [] }\n                    ]\n                };\n            }\n            case GrammarImport: {\n                return {\n                    name: GrammarImport,\n                    properties: [\n                        { name: 'path' }\n                    ]\n                };\n            }\n            case InferredType: {\n                return {\n                    name: InferredType,\n                    properties: [\n                        { name: 'name' }\n                    ]\n                };\n            }\n            case Interface: {\n                return {\n                    name: Interface,\n                    properties: [\n                        { name: 'attributes', defaultValue: [] },\n                        { name: 'name' },\n                        { name: 'superTypes', defaultValue: [] }\n                    ]\n                };\n            }\n            case NamedArgument: {\n                return {\n                    name: NamedArgument,\n                    properties: [\n                        { name: 'calledByName', defaultValue: false },\n                        { name: 'parameter' },\n                        { name: 'value' }\n                    ]\n                };\n            }\n            case Negation: {\n                return {\n                    name: Negation,\n                    properties: [\n                        { name: 'value' }\n                    ]\n                };\n            }\n            case NumberLiteral: {\n                return {\n                    name: NumberLiteral,\n                    properties: [\n                        { name: 'value' }\n                    ]\n                };\n            }\n            case Parameter: {\n                return {\n                    name: Parameter,\n                    properties: [\n                        { name: 'name' }\n                    ]\n                };\n            }\n            case ParameterReference: {\n                return {\n                    name: ParameterReference,\n                    properties: [\n                        { name: 'parameter' }\n                    ]\n                };\n            }\n            case ParserRule: {\n                return {\n                    name: ParserRule,\n                    properties: [\n                        { name: 'dataType' },\n                        { name: 'definesHiddenTokens', defaultValue: false },\n                        { name: 'definition' },\n                        { name: 'entry', defaultValue: false },\n                        { name: 'fragment', defaultValue: false },\n                        { name: 'hiddenTokens', defaultValue: [] },\n                        { name: 'inferredType' },\n                        { name: 'name' },\n                        { name: 'parameters', defaultValue: [] },\n                        { name: 'returnType' },\n                        { name: 'wildcard', defaultValue: false }\n                    ]\n                };\n            }\n            case ReferenceType: {\n                return {\n                    name: ReferenceType,\n                    properties: [\n                        { name: 'referenceType' }\n                    ]\n                };\n            }\n            case ReturnType: {\n                return {\n                    name: ReturnType,\n                    properties: [\n                        { name: 'name' }\n                    ]\n                };\n            }\n            case SimpleType: {\n                return {\n                    name: SimpleType,\n                    properties: [\n                        { name: 'primitiveType' },\n                        { name: 'stringType' },\n                        { name: 'typeRef' }\n                    ]\n                };\n            }\n            case StringLiteral: {\n                return {\n                    name: StringLiteral,\n                    properties: [\n                        { name: 'value' }\n                    ]\n                };\n            }\n            case TerminalRule: {\n                return {\n                    name: TerminalRule,\n                    properties: [\n                        { name: 'definition' },\n                        { name: 'fragment', defaultValue: false },\n                        { name: 'hidden', defaultValue: false },\n                        { name: 'name' },\n                        { name: 'type' }\n                    ]\n                };\n            }\n            case Type: {\n                return {\n                    name: Type,\n                    properties: [\n                        { name: 'name' },\n                        { name: 'type' }\n                    ]\n                };\n            }\n            case TypeAttribute: {\n                return {\n                    name: TypeAttribute,\n                    properties: [\n                        { name: 'defaultValue' },\n                        { name: 'isOptional', defaultValue: false },\n                        { name: 'name' },\n                        { name: 'type' }\n                    ]\n                };\n            }\n            case UnionType: {\n                return {\n                    name: UnionType,\n                    properties: [\n                        { name: 'types', defaultValue: [] }\n                    ]\n                };\n            }\n            case Action: {\n                return {\n                    name: Action,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'feature' },\n                        { name: 'inferredType' },\n                        { name: 'lookahead' },\n                        { name: 'operator' },\n                        { name: 'type' }\n                    ]\n                };\n            }\n            case Alternatives: {\n                return {\n                    name: Alternatives,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'elements', defaultValue: [] },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case Assignment: {\n                return {\n                    name: Assignment,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'feature' },\n                        { name: 'lookahead' },\n                        { name: 'operator' },\n                        { name: 'terminal' }\n                    ]\n                };\n            }\n            case CharacterRange: {\n                return {\n                    name: CharacterRange,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'left' },\n                        { name: 'lookahead' },\n                        { name: 'right' }\n                    ]\n                };\n            }\n            case CrossReference: {\n                return {\n                    name: CrossReference,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'deprecatedSyntax', defaultValue: false },\n                        { name: 'lookahead' },\n                        { name: 'terminal' },\n                        { name: 'type' }\n                    ]\n                };\n            }\n            case EndOfFile: {\n                return {\n                    name: EndOfFile,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case Group: {\n                return {\n                    name: Group,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'elements', defaultValue: [] },\n                        { name: 'guardCondition' },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case Keyword: {\n                return {\n                    name: Keyword,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'value' }\n                    ]\n                };\n            }\n            case NegatedToken: {\n                return {\n                    name: NegatedToken,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'terminal' }\n                    ]\n                };\n            }\n            case RegexToken: {\n                return {\n                    name: RegexToken,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'regex' }\n                    ]\n                };\n            }\n            case RuleCall: {\n                return {\n                    name: RuleCall,\n                    properties: [\n                        { name: 'arguments', defaultValue: [] },\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'rule' }\n                    ]\n                };\n            }\n            case TerminalAlternatives: {\n                return {\n                    name: TerminalAlternatives,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'elements', defaultValue: [] },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case TerminalGroup: {\n                return {\n                    name: TerminalGroup,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'elements', defaultValue: [] },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case TerminalRuleCall: {\n                return {\n                    name: TerminalRuleCall,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'rule' }\n                    ]\n                };\n            }\n            case UnorderedGroup: {\n                return {\n                    name: UnorderedGroup,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'elements', defaultValue: [] },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            case UntilToken: {\n                return {\n                    name: UntilToken,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' },\n                        { name: 'terminal' }\n                    ]\n                };\n            }\n            case Wildcard: {\n                return {\n                    name: Wildcard,\n                    properties: [\n                        { name: 'cardinality' },\n                        { name: 'lookahead' }\n                    ]\n                };\n            }\n            default: {\n                return {\n                    name: type,\n                    properties: []\n                };\n            }\n        }\n    }\n}\nexport const reflection = new LangiumGrammarAstReflection();\n//# sourceMappingURL=ast.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Lexer } from 'chevrotain';\nimport { isKeyword, isParserRule, isTerminalRule } from '../languages/generated/ast.js';\nimport { streamAllContents } from '../utils/ast-utils.js';\nimport { getAllReachableRules, terminalRegex } from '../utils/grammar-utils.js';\nimport { getCaseInsensitivePattern, isWhitespace, partialMatches } from '../utils/regexp-utils.js';\nimport { stream } from '../utils/stream.js';\nexport class DefaultTokenBuilder {\n    constructor() {\n        /**\n         * The list of diagnostics stored during the lexing process of a single text.\n         */\n        this.diagnostics = [];\n    }\n    buildTokens(grammar, options) {\n        const reachableRules = stream(getAllReachableRules(grammar, false));\n        const terminalTokens = this.buildTerminalTokens(reachableRules);\n        const tokens = this.buildKeywordTokens(reachableRules, terminalTokens, options);\n        terminalTokens.forEach(terminalToken => {\n            const pattern = terminalToken.PATTERN;\n            if (typeof pattern === 'object' && pattern && 'test' in pattern && isWhitespace(pattern)) {\n                tokens.unshift(terminalToken);\n            }\n            else {\n                tokens.push(terminalToken);\n            }\n        });\n        // We don't need to add the EOF token explicitly.\n        // It is automatically available at the end of the token stream.\n        return tokens;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    flushLexingReport(text) {\n        return { diagnostics: this.popDiagnostics() };\n    }\n    popDiagnostics() {\n        const diagnostics = [...this.diagnostics];\n        this.diagnostics = [];\n        return diagnostics;\n    }\n    buildTerminalTokens(rules) {\n        return rules.filter(isTerminalRule).filter(e => !e.fragment)\n            .map(terminal => this.buildTerminalToken(terminal)).toArray();\n    }\n    buildTerminalToken(terminal) {\n        const regex = terminalRegex(terminal);\n        const pattern = this.requiresCustomPattern(regex) ? this.regexPatternFunction(regex) : regex;\n        const tokenType = {\n            name: terminal.name,\n            PATTERN: pattern,\n        };\n        if (typeof pattern === 'function') {\n            tokenType.LINE_BREAKS = true;\n        }\n        if (terminal.hidden) {\n            // Only skip tokens that are able to accept whitespace\n            tokenType.GROUP = isWhitespace(regex) ? Lexer.SKIPPED : 'hidden';\n        }\n        return tokenType;\n    }\n    requiresCustomPattern(regex) {\n        if (regex.flags.includes('u') || regex.flags.includes('s')) {\n            // Unicode and dotall regexes are not supported by Chevrotain.\n            return true;\n        }\n        else if (regex.source.includes('?<=') || regex.source.includes('?<!')) {\n            // Negative and positive lookbehind are not supported by Chevrotain yet.\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    regexPatternFunction(regex) {\n        const stickyRegex = new RegExp(regex, regex.flags + 'y');\n        return (text, offset) => {\n            stickyRegex.lastIndex = offset;\n            const execResult = stickyRegex.exec(text);\n            return execResult;\n        };\n    }\n    buildKeywordTokens(rules, terminalTokens, options) {\n        return rules\n            // We filter by parser rules, since keywords in terminal rules get transformed into regex and are not actual tokens\n            .filter(isParserRule)\n            .flatMap(rule => streamAllContents(rule).filter(isKeyword))\n            .distinct(e => e.value).toArray()\n            // Sort keywords by descending length\n            .sort((a, b) => b.value.length - a.value.length)\n            .map(keyword => this.buildKeywordToken(keyword, terminalTokens, Boolean(options === null || options === void 0 ? void 0 : options.caseInsensitive)));\n    }\n    buildKeywordToken(keyword, terminalTokens, caseInsensitive) {\n        const keywordPattern = this.buildKeywordPattern(keyword, caseInsensitive);\n        const tokenType = {\n            name: keyword.value,\n            PATTERN: keywordPattern,\n            LONGER_ALT: this.findLongerAlt(keyword, terminalTokens)\n        };\n        if (typeof keywordPattern === 'function') {\n            tokenType.LINE_BREAKS = true;\n        }\n        return tokenType;\n    }\n    buildKeywordPattern(keyword, caseInsensitive) {\n        return caseInsensitive ?\n            new RegExp(getCaseInsensitivePattern(keyword.value)) :\n            keyword.value;\n    }\n    findLongerAlt(keyword, terminalTokens) {\n        return terminalTokens.reduce((longerAlts, token) => {\n            const pattern = token === null || token === void 0 ? void 0 : token.PATTERN;\n            if ((pattern === null || pattern === void 0 ? void 0 : pattern.source) && partialMatches('^' + pattern.source + '$', keyword.value)) {\n                longerAlts.push(token);\n            }\n            return longerAlts;\n        }, []);\n    }\n}\n//# sourceMappingURL=token-builder.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { isCrossReference, isRuleCall } from '../languages/generated/ast.js';\nimport { getCrossReferenceTerminal, getRuleType } from '../utils/grammar-utils.js';\nexport class DefaultValueConverter {\n    convert(input, cstNode) {\n        let feature = cstNode.grammarSource;\n        if (isCrossReference(feature)) {\n            feature = getCrossReferenceTerminal(feature);\n        }\n        if (isRuleCall(feature)) {\n            const rule = feature.rule.ref;\n            if (!rule) {\n                throw new Error('This cst node was not parsed by a rule.');\n            }\n            return this.runConverter(rule, input, cstNode);\n        }\n        return input;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    runConverter(rule, input, cstNode) {\n        var _a;\n        switch (rule.name.toUpperCase()) {\n            case 'INT': return ValueConverter.convertInt(input);\n            case 'STRING': return ValueConverter.convertString(input);\n            case 'ID': return ValueConverter.convertID(input);\n        }\n        switch ((_a = getRuleType(rule)) === null || _a === void 0 ? void 0 : _a.toLowerCase()) {\n            case 'number': return ValueConverter.convertNumber(input);\n            case 'boolean': return ValueConverter.convertBoolean(input);\n            case 'bigint': return ValueConverter.convertBigint(input);\n            case 'date': return ValueConverter.convertDate(input);\n            default: return input;\n        }\n    }\n}\nexport var ValueConverter;\n(function (ValueConverter) {\n    function convertString(input) {\n        let result = '';\n        for (let i = 1; i < input.length - 1; i++) {\n            const c = input.charAt(i);\n            if (c === '\\\\') {\n                const c1 = input.charAt(++i);\n                result += convertEscapeCharacter(c1);\n            }\n            else {\n                result += c;\n            }\n        }\n        return result;\n    }\n    ValueConverter.convertString = convertString;\n    function convertEscapeCharacter(char) {\n        switch (char) {\n            case 'b': return '\\b';\n            case 'f': return '\\f';\n            case 'n': return '\\n';\n            case 'r': return '\\r';\n            case 't': return '\\t';\n            case 'v': return '\\v';\n            case '0': return '\\0';\n            default: return char;\n        }\n    }\n    function convertID(input) {\n        if (input.charAt(0) === '^') {\n            return input.substring(1);\n        }\n        else {\n            return input;\n        }\n    }\n    ValueConverter.convertID = convertID;\n    function convertInt(input) {\n        return parseInt(input);\n    }\n    ValueConverter.convertInt = convertInt;\n    function convertBigint(input) {\n        return BigInt(input);\n    }\n    ValueConverter.convertBigint = convertBigint;\n    function convertDate(input) {\n        return new Date(input);\n    }\n    ValueConverter.convertDate = convertDate;\n    function convertNumber(input) {\n        return Number(input);\n    }\n    ValueConverter.convertNumber = convertNumber;\n    function convertBoolean(input) {\n        return input.toLowerCase() === 'true';\n    }\n    ValueConverter.convertBoolean = convertBoolean;\n})(ValueConverter || (ValueConverter = {}));\n//# sourceMappingURL=value-converter.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport function isAstNode(obj) {\n    return typeof obj === 'object' && obj !== null && typeof obj.$type === 'string';\n}\nexport function isReference(obj) {\n    return typeof obj === 'object' && obj !== null && typeof obj.$refText === 'string';\n}\nexport function isAstNodeDescription(obj) {\n    return typeof obj === 'object' && obj !== null\n        && typeof obj.name === 'string'\n        && typeof obj.type === 'string'\n        && typeof obj.path === 'string';\n}\nexport function isLinkingError(obj) {\n    return typeof obj === 'object' && obj !== null\n        && isAstNode(obj.container)\n        && isReference(obj.reference)\n        && typeof obj.message === 'string';\n}\n/**\n * An abstract implementation of the {@link AstReflection} interface.\n * Serves to cache subtype computation results to improve performance throughout different parts of Langium.\n */\nexport class AbstractAstReflection {\n    constructor() {\n        this.subtypes = {};\n        this.allSubtypes = {};\n    }\n    isInstance(node, type) {\n        return isAstNode(node) && this.isSubtype(node.$type, type);\n    }\n    isSubtype(subtype, supertype) {\n        if (subtype === supertype) {\n            return true;\n        }\n        let nested = this.subtypes[subtype];\n        if (!nested) {\n            nested = this.subtypes[subtype] = {};\n        }\n        const existing = nested[supertype];\n        if (existing !== undefined) {\n            return existing;\n        }\n        else {\n            const result = this.computeIsSubtype(subtype, supertype);\n            nested[supertype] = result;\n            return result;\n        }\n    }\n    getAllSubTypes(type) {\n        const existing = this.allSubtypes[type];\n        if (existing) {\n            return existing;\n        }\n        else {\n            const allTypes = this.getAllTypes();\n            const types = [];\n            for (const possibleSubType of allTypes) {\n                if (this.isSubtype(possibleSubType, type)) {\n                    types.push(possibleSubType);\n                }\n            }\n            this.allSubtypes[type] = types;\n            return types;\n        }\n    }\n}\nexport function isCompositeCstNode(node) {\n    return typeof node === 'object' && node !== null && Array.isArray(node.content);\n}\nexport function isLeafCstNode(node) {\n    return typeof node === 'object' && node !== null && typeof node.tokenType === 'object';\n}\nexport function isRootCstNode(node) {\n    return isCompositeCstNode(node) && typeof node.fullText === 'string';\n}\n//# sourceMappingURL=syntax-tree.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { isAstNode, isReference } from '../syntax-tree.js';\nimport { DONE_RESULT, stream, StreamImpl, TreeStreamImpl } from './stream.js';\nimport { inRange } from './cst-utils.js';\n/**\n * Link the `$container` and other related properties of every AST node that is directly contained\n * in the given `node`.\n */\nexport function linkContentToContainer(node) {\n    for (const [name, value] of Object.entries(node)) {\n        if (!name.startsWith('$')) {\n            if (Array.isArray(value)) {\n                value.forEach((item, index) => {\n                    if (isAstNode(item)) {\n                        item.$container = node;\n                        item.$containerProperty = name;\n                        item.$containerIndex = index;\n                    }\n                });\n            }\n            else if (isAstNode(value)) {\n                value.$container = node;\n                value.$containerProperty = name;\n            }\n        }\n    }\n}\n/**\n * Walk along the hierarchy of containers from the given AST node to the root and return the first\n * node that matches the type predicate. If the start node itself matches, it is returned.\n * If no container matches, `undefined` is returned.\n */\nexport function getContainerOfType(node, typePredicate) {\n    let item = node;\n    while (item) {\n        if (typePredicate(item)) {\n            return item;\n        }\n        item = item.$container;\n    }\n    return undefined;\n}\n/**\n * Walk along the hierarchy of containers from the given AST node to the root and check for existence\n * of a container that matches the given predicate. The start node is included in the checks.\n */\nexport function hasContainerOfType(node, predicate) {\n    let item = node;\n    while (item) {\n        if (predicate(item)) {\n            return true;\n        }\n        item = item.$container;\n    }\n    return false;\n}\n/**\n * Retrieve the document in which the given AST node is contained. A reference to the document is\n * usually held by the root node of the AST.\n *\n * @throws an error if the node is not contained in a document.\n */\nexport function getDocument(node) {\n    const rootNode = findRootNode(node);\n    const result = rootNode.$document;\n    if (!result) {\n        throw new Error('AST node has no document.');\n    }\n    return result;\n}\n/**\n * Returns the root node of the given AST node by following the `$container` references.\n */\nexport function findRootNode(node) {\n    while (node.$container) {\n        node = node.$container;\n    }\n    return node;\n}\n/**\n * Create a stream of all AST nodes that are directly contained in the given node. This includes\n * single-valued as well as multi-valued (array) properties.\n */\nexport function streamContents(node, options) {\n    if (!node) {\n        throw new Error('Node must be an AstNode.');\n    }\n    const range = options === null || options === void 0 ? void 0 : options.range;\n    return new StreamImpl(() => ({\n        keys: Object.keys(node),\n        keyIndex: 0,\n        arrayIndex: 0\n    }), state => {\n        while (state.keyIndex < state.keys.length) {\n            const property = state.keys[state.keyIndex];\n            if (!property.startsWith('$')) {\n                const value = node[property];\n                if (isAstNode(value)) {\n                    state.keyIndex++;\n                    if (isAstNodeInRange(value, range)) {\n                        return { done: false, value };\n                    }\n                }\n                else if (Array.isArray(value)) {\n                    while (state.arrayIndex < value.length) {\n                        const index = state.arrayIndex++;\n                        const element = value[index];\n                        if (isAstNode(element) && isAstNodeInRange(element, range)) {\n                            return { done: false, value: element };\n                        }\n                    }\n                    state.arrayIndex = 0;\n                }\n            }\n            state.keyIndex++;\n        }\n        return DONE_RESULT;\n    });\n}\n/**\n * Create a stream of all AST nodes that are directly and indirectly contained in the given root node.\n * This does not include the root node itself.\n */\nexport function streamAllContents(root, options) {\n    if (!root) {\n        throw new Error('Root node must be an AstNode.');\n    }\n    return new TreeStreamImpl(root, node => streamContents(node, options));\n}\n/**\n * Create a stream of all AST nodes that are directly and indirectly contained in the given root node,\n * including the root node itself.\n */\nexport function streamAst(root, options) {\n    if (!root) {\n        throw new Error('Root node must be an AstNode.');\n    }\n    else if ((options === null || options === void 0 ? void 0 : options.range) && !isAstNodeInRange(root, options.range)) {\n        // Return an empty stream if the root node isn't in range\n        return new TreeStreamImpl(root, () => []);\n    }\n    return new TreeStreamImpl(root, node => streamContents(node, options), { includeRoot: true });\n}\nfunction isAstNodeInRange(astNode, range) {\n    var _a;\n    if (!range) {\n        return true;\n    }\n    const nodeRange = (_a = astNode.$cstNode) === null || _a === void 0 ? void 0 : _a.range;\n    if (!nodeRange) {\n        return false;\n    }\n    return inRange(nodeRange, range);\n}\n/**\n * Create a stream of all cross-references that are held by the given AST node. This includes\n * single-valued as well as multi-valued (array) properties.\n */\nexport function streamReferences(node) {\n    return new StreamImpl(() => ({\n        keys: Object.keys(node),\n        keyIndex: 0,\n        arrayIndex: 0\n    }), state => {\n        while (state.keyIndex < state.keys.length) {\n            const property = state.keys[state.keyIndex];\n            if (!property.startsWith('$')) {\n                const value = node[property];\n                if (isReference(value)) {\n                    state.keyIndex++;\n                    return { done: false, value: { reference: value, container: node, property } };\n                }\n                else if (Array.isArray(value)) {\n                    while (state.arrayIndex < value.length) {\n                        const index = state.arrayIndex++;\n                        const element = value[index];\n                        if (isReference(element)) {\n                            return { done: false, value: { reference: element, container: node, property, index } };\n                        }\n                    }\n                    state.arrayIndex = 0;\n                }\n            }\n            state.keyIndex++;\n        }\n        return DONE_RESULT;\n    });\n}\n/**\n * Returns a Stream of references to the target node from the AstNode tree\n *\n * @param targetNode AstNode we are looking for\n * @param lookup AstNode where we search for references. If not provided, the root node of the document is used as the default value\n */\nexport function findLocalReferences(targetNode, lookup = getDocument(targetNode).parseResult.value) {\n    const refs = [];\n    streamAst(lookup).forEach(node => {\n        streamReferences(node).forEach(refInfo => {\n            if (refInfo.reference.ref === targetNode) {\n                refs.push(refInfo.reference);\n            }\n        });\n    });\n    return stream(refs);\n}\n/**\n * Assigns all mandatory AST properties to the specified node.\n *\n * @param reflection Reflection object used to gather mandatory properties for the node.\n * @param node Specified node is modified in place and properties are directly assigned.\n */\nexport function assignMandatoryProperties(reflection, node) {\n    const typeMetaData = reflection.getTypeMetaData(node.$type);\n    const genericNode = node;\n    for (const property of typeMetaData.properties) {\n        // Only set the value if the property is not already set and if it has a default value\n        if (property.defaultValue !== undefined && genericNode[property.name] === undefined) {\n            genericNode[property.name] = copyDefaultValue(property.defaultValue);\n        }\n    }\n}\nfunction copyDefaultValue(propertyType) {\n    if (Array.isArray(propertyType)) {\n        return [...propertyType.map(copyDefaultValue)];\n    }\n    else {\n        return propertyType;\n    }\n}\n/**\n * Creates a deep copy of the specified AST node.\n * The resulting copy will only contain semantically relevant information, such as the `$type` property and AST properties.\n *\n * References are copied without resolved cross reference. The specified function is used to rebuild them.\n */\nexport function copyAstNode(node, buildReference) {\n    const copy = { $type: node.$type };\n    for (const [name, value] of Object.entries(node)) {\n        if (!name.startsWith('$')) {\n            if (isAstNode(value)) {\n                copy[name] = copyAstNode(value, buildReference);\n            }\n            else if (isReference(value)) {\n                copy[name] = buildReference(copy, name, value.$refNode, value.$refText);\n            }\n            else if (Array.isArray(value)) {\n                const copiedArray = [];\n                for (const element of value) {\n                    if (isAstNode(element)) {\n                        copiedArray.push(copyAstNode(element, buildReference));\n                    }\n                    else if (isReference(element)) {\n                        copiedArray.push(buildReference(copy, name, element.$refNode, element.$refText));\n                    }\n                    else {\n                        copiedArray.push(element);\n                    }\n                }\n                copy[name] = copiedArray;\n            }\n            else {\n                copy[name] = value;\n            }\n        }\n    }\n    linkContentToContainer(copy);\n    return copy;\n}\n//# sourceMappingURL=ast-utils.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { isCompositeCstNode, isLeafCstNode, isRootCstNode } from '../syntax-tree.js';\nimport { TreeStreamImpl } from './stream.js';\n/**\n * Create a stream of all CST nodes that are directly and indirectly contained in the given root node,\n * including the root node itself.\n */\nexport function streamCst(node) {\n    return new TreeStreamImpl(node, element => {\n        if (isCompositeCstNode(element)) {\n            return element.content;\n        }\n        else {\n            return [];\n        }\n    }, { includeRoot: true });\n}\n/**\n * Create a stream of all leaf nodes that are directly and indirectly contained in the given root node.\n */\nexport function flattenCst(node) {\n    return streamCst(node).filter(isLeafCstNode);\n}\n/**\n * Determines whether the specified cst node is a child of the specified parent node.\n */\nexport function isChildNode(child, parent) {\n    while (child.container) {\n        child = child.container;\n        if (child === parent) {\n            return true;\n        }\n    }\n    return false;\n}\nexport function tokenToRange(token) {\n    // Chevrotain uses 1-based indices everywhere\n    // So we subtract 1 from every value to align with the LSP\n    return {\n        start: {\n            character: token.startColumn - 1,\n            line: token.startLine - 1\n        },\n        end: {\n            character: token.endColumn, // endColumn uses the correct index\n            line: token.endLine - 1\n        }\n    };\n}\nexport function toDocumentSegment(node) {\n    if (!node) {\n        return undefined;\n    }\n    const { offset, end, range } = node;\n    return {\n        range,\n        offset,\n        end,\n        length: end - offset\n    };\n}\nexport var RangeComparison;\n(function (RangeComparison) {\n    RangeComparison[RangeComparison[\"Before\"] = 0] = \"Before\";\n    RangeComparison[RangeComparison[\"After\"] = 1] = \"After\";\n    RangeComparison[RangeComparison[\"OverlapFront\"] = 2] = \"OverlapFront\";\n    RangeComparison[RangeComparison[\"OverlapBack\"] = 3] = \"OverlapBack\";\n    RangeComparison[RangeComparison[\"Inside\"] = 4] = \"Inside\";\n    RangeComparison[RangeComparison[\"Outside\"] = 5] = \"Outside\";\n})(RangeComparison || (RangeComparison = {}));\nexport function compareRange(range, to) {\n    if (range.end.line < to.start.line || (range.end.line === to.start.line && range.end.character <= to.start.character)) {\n        return RangeComparison.Before;\n    }\n    else if (range.start.line > to.end.line || (range.start.line === to.end.line && range.start.character >= to.end.character)) {\n        return RangeComparison.After;\n    }\n    const startInside = range.start.line > to.start.line || (range.start.line === to.start.line && range.start.character >= to.start.character);\n    const endInside = range.end.line < to.end.line || (range.end.line === to.end.line && range.end.character <= to.end.character);\n    if (startInside && endInside) {\n        return RangeComparison.Inside;\n    }\n    else if (startInside) {\n        return RangeComparison.OverlapBack;\n    }\n    else if (endInside) {\n        return RangeComparison.OverlapFront;\n    }\n    else {\n        return RangeComparison.Outside;\n    }\n}\nexport function inRange(range, to) {\n    const comparison = compareRange(range, to);\n    return comparison > RangeComparison.After;\n}\n// The \\p{L} regex matches any unicode letter character, i.e. characters from non-english alphabets\n// Together with \\w it matches any kind of character which can commonly appear in IDs\nexport const DefaultNameRegexp = /^[\\w\\p{L}]$/u;\n/**\n * Performs `findLeafNodeAtOffset` with a minor difference: When encountering a character that matches the `nameRegexp` argument,\n * it will instead return the leaf node at the `offset - 1` position.\n *\n * For LSP services, users expect that the declaration of an element is available if the cursor is directly after the element.\n */\nexport function findDeclarationNodeAtOffset(cstNode, offset, nameRegexp = DefaultNameRegexp) {\n    if (cstNode) {\n        if (offset > 0) {\n            const localOffset = offset - cstNode.offset;\n            const textAtOffset = cstNode.text.charAt(localOffset);\n            if (!nameRegexp.test(textAtOffset)) {\n                offset--;\n            }\n        }\n        return findLeafNodeAtOffset(cstNode, offset);\n    }\n    return undefined;\n}\nexport function findCommentNode(cstNode, commentNames) {\n    if (cstNode) {\n        const previous = getPreviousNode(cstNode, true);\n        if (previous && isCommentNode(previous, commentNames)) {\n            return previous;\n        }\n        if (isRootCstNode(cstNode)) {\n            // Go from the first non-hidden node through all nodes in reverse order\n            // We do this to find the comment node which directly precedes the root node\n            const endIndex = cstNode.content.findIndex(e => !e.hidden);\n            for (let i = endIndex - 1; i >= 0; i--) {\n                const child = cstNode.content[i];\n                if (isCommentNode(child, commentNames)) {\n                    return child;\n                }\n            }\n        }\n    }\n    return undefined;\n}\nexport function isCommentNode(cstNode, commentNames) {\n    return isLeafCstNode(cstNode) && commentNames.includes(cstNode.tokenType.name);\n}\n/**\n * Finds the leaf CST node at the specified 0-based string offset.\n * Note that the given offset will be within the range of the returned leaf node.\n *\n * If the offset does not point to a CST node (but just white space), this method will return `undefined`.\n *\n * @param node The CST node to search through.\n * @param offset The specified offset.\n * @returns The CST node at the specified offset.\n */\nexport function findLeafNodeAtOffset(node, offset) {\n    if (isLeafCstNode(node)) {\n        return node;\n    }\n    else if (isCompositeCstNode(node)) {\n        const searchResult = binarySearch(node, offset, false);\n        if (searchResult) {\n            return findLeafNodeAtOffset(searchResult, offset);\n        }\n    }\n    return undefined;\n}\n/**\n * Finds the leaf CST node at the specified 0-based string offset.\n * If no CST node exists at the specified position, it will return the leaf node before it.\n *\n * If there is no leaf node before the specified offset, this method will return `undefined`.\n *\n * @param node The CST node to search through.\n * @param offset The specified offset.\n * @returns The CST node closest to the specified offset.\n */\nexport function findLeafNodeBeforeOffset(node, offset) {\n    if (isLeafCstNode(node)) {\n        return node;\n    }\n    else if (isCompositeCstNode(node)) {\n        const searchResult = binarySearch(node, offset, true);\n        if (searchResult) {\n            return findLeafNodeBeforeOffset(searchResult, offset);\n        }\n    }\n    return undefined;\n}\nfunction binarySearch(node, offset, closest) {\n    let left = 0;\n    let right = node.content.length - 1;\n    let closestNode = undefined;\n    while (left <= right) {\n        const middle = Math.floor((left + right) / 2);\n        const middleNode = node.content[middle];\n        if (middleNode.offset <= offset && middleNode.end > offset) {\n            // Found an exact match\n            return middleNode;\n        }\n        if (middleNode.end <= offset) {\n            // Update the closest node (less than offset) and move to the right half\n            closestNode = closest ? middleNode : undefined;\n            left = middle + 1;\n        }\n        else {\n            // Move to the left half\n            right = middle - 1;\n        }\n    }\n    return closestNode;\n}\nexport function getPreviousNode(node, hidden = true) {\n    while (node.container) {\n        const parent = node.container;\n        let index = parent.content.indexOf(node);\n        while (index > 0) {\n            index--;\n            const previous = parent.content[index];\n            if (hidden || !previous.hidden) {\n                return previous;\n            }\n        }\n        node = parent;\n    }\n    return undefined;\n}\nexport function getNextNode(node, hidden = true) {\n    while (node.container) {\n        const parent = node.container;\n        let index = parent.content.indexOf(node);\n        const last = parent.content.length - 1;\n        while (index < last) {\n            index++;\n            const next = parent.content[index];\n            if (hidden || !next.hidden) {\n                return next;\n            }\n        }\n        node = parent;\n    }\n    return undefined;\n}\nexport function getStartlineNode(node) {\n    if (node.range.start.character === 0) {\n        return node;\n    }\n    const line = node.range.start.line;\n    let last = node;\n    let index;\n    while (node.container) {\n        const parent = node.container;\n        const selfIndex = index !== null && index !== void 0 ? index : parent.content.indexOf(node);\n        if (selfIndex === 0) {\n            node = parent;\n            index = undefined;\n        }\n        else {\n            index = selfIndex - 1;\n            node = parent.content[index];\n        }\n        if (node.range.start.line !== line) {\n            break;\n        }\n        last = node;\n    }\n    return last;\n}\nexport function getInteriorNodes(start, end) {\n    const commonParent = getCommonParent(start, end);\n    if (!commonParent) {\n        return [];\n    }\n    return commonParent.parent.content.slice(commonParent.a + 1, commonParent.b);\n}\nfunction getCommonParent(a, b) {\n    const aParents = getParentChain(a);\n    const bParents = getParentChain(b);\n    let current;\n    for (let i = 0; i < aParents.length && i < bParents.length; i++) {\n        const aParent = aParents[i];\n        const bParent = bParents[i];\n        if (aParent.parent === bParent.parent) {\n            current = {\n                parent: aParent.parent,\n                a: aParent.index,\n                b: bParent.index\n            };\n        }\n        else {\n            break;\n        }\n    }\n    return current;\n}\nfunction getParentChain(node) {\n    const chain = [];\n    while (node.container) {\n        const parent = node.container;\n        const index = parent.content.indexOf(node);\n        chain.push({\n            parent,\n            index\n        });\n        node = parent;\n    }\n    return chain.reverse();\n}\n//# sourceMappingURL=cst-utils.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport class ErrorWithLocation extends Error {\n    constructor(node, message) {\n        super(node ? `${message} at ${node.range.start.line}:${node.range.start.character}` : message);\n    }\n}\nexport function assertUnreachable(_) {\n    throw new Error('Error! The input value was not handled.');\n}\n//# sourceMappingURL=errors.js.map","/******************************************************************************\n * Copyright 2021-2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { assertUnreachable } from '../utils/errors.js';\nimport * as ast from '../languages/generated/ast.js';\nimport { isCompositeCstNode } from '../syntax-tree.js';\nimport { getContainerOfType, streamAllContents } from './ast-utils.js';\nimport { streamCst } from './cst-utils.js';\nimport { escapeRegExp, isWhitespace } from './regexp-utils.js';\n/**\n * Returns the entry rule of the given grammar, if any. If the grammar file does not contain an entry rule,\n * the result is `undefined`.\n */\nexport function getEntryRule(grammar) {\n    return grammar.rules.find(e => ast.isParserRule(e) && e.entry);\n}\n/**\n * Returns all hidden terminal rules of the given grammar, if any.\n */\nexport function getHiddenRules(grammar) {\n    return grammar.rules.filter((e) => ast.isTerminalRule(e) && e.hidden);\n}\n/**\n * Returns all rules that can be reached from the topmost rules of the specified grammar (entry and hidden terminal rules).\n *\n * @param grammar The grammar that contains all rules\n * @param allTerminals Whether or not to include terminals that are referenced only by other terminals\n * @returns A list of referenced parser and terminal rules. If the grammar contains no entry rule,\n *      this function returns all rules of the specified grammar.\n */\nexport function getAllReachableRules(grammar, allTerminals) {\n    const ruleNames = new Set();\n    const entryRule = getEntryRule(grammar);\n    if (!entryRule) {\n        return new Set(grammar.rules);\n    }\n    const topMostRules = [entryRule].concat(getHiddenRules(grammar));\n    for (const rule of topMostRules) {\n        ruleDfs(rule, ruleNames, allTerminals);\n    }\n    const rules = new Set();\n    for (const rule of grammar.rules) {\n        if (ruleNames.has(rule.name) || (ast.isTerminalRule(rule) && rule.hidden)) {\n            rules.add(rule);\n        }\n    }\n    return rules;\n}\nfunction ruleDfs(rule, visitedSet, allTerminals) {\n    visitedSet.add(rule.name);\n    streamAllContents(rule).forEach(node => {\n        if (ast.isRuleCall(node) || (allTerminals && ast.isTerminalRuleCall(node))) {\n            const refRule = node.rule.ref;\n            if (refRule && !visitedSet.has(refRule.name)) {\n                ruleDfs(refRule, visitedSet, allTerminals);\n            }\n        }\n    });\n}\n/**\n * Determines the grammar expression used to parse a cross-reference (usually a reference to a terminal rule).\n * A cross-reference can declare this expression explicitly in the form `[Type : Terminal]`, but if `Terminal`\n * is omitted, this function attempts to infer it from the name of the referenced `Type` (using `findNameAssignment`).\n *\n * Returns the grammar expression used to parse the given cross-reference, or `undefined` if it is not declared\n * and cannot be inferred.\n */\nexport function getCrossReferenceTerminal(crossRef) {\n    if (crossRef.terminal) {\n        return crossRef.terminal;\n    }\n    else if (crossRef.type.ref) {\n        const nameAssigment = findNameAssignment(crossRef.type.ref);\n        return nameAssigment === null || nameAssigment === void 0 ? void 0 : nameAssigment.terminal;\n    }\n    return undefined;\n}\n/**\n * Determines whether the given terminal rule represents a comment. This is true if the rule is marked\n * as `hidden` and it does not match white space. This means every hidden token (i.e. excluded from the AST)\n * that contains visible characters is considered a comment.\n */\nexport function isCommentTerminal(terminalRule) {\n    return terminalRule.hidden && !isWhitespace(terminalRegex(terminalRule));\n}\n/**\n * Find all CST nodes within the given node that contribute to the specified property.\n *\n * @param node A CST node in which to look for property assignments. If this is undefined, the result is an empty array.\n * @param property A property name of the constructed AST node. If this is undefined, the result is an empty array.\n */\nexport function findNodesForProperty(node, property) {\n    if (!node || !property) {\n        return [];\n    }\n    return findNodesForPropertyInternal(node, property, node.astNode, true);\n}\n/**\n * Find a single CST node within the given node that contributes to the specified property.\n *\n * @param node A CST node in which to look for property assignments. If this is undefined, the result is `undefined`.\n * @param property A property name of the constructed AST node. If this is undefined, the result is `undefined`.\n * @param index If no index is specified or the index is less than zero, the first found node is returned. If the\n *        specified index exceeds the number of assignments to the property, the last found node is returned. Otherwise,\n *        the node with the specified index is returned.\n */\nexport function findNodeForProperty(node, property, index) {\n    if (!node || !property) {\n        return undefined;\n    }\n    const nodes = findNodesForPropertyInternal(node, property, node.astNode, true);\n    if (nodes.length === 0) {\n        return undefined;\n    }\n    if (index !== undefined) {\n        index = Math.max(0, Math.min(index, nodes.length - 1));\n    }\n    else {\n        index = 0;\n    }\n    return nodes[index];\n}\nfunction findNodesForPropertyInternal(node, property, element, first) {\n    if (!first) {\n        const nodeFeature = getContainerOfType(node.grammarSource, ast.isAssignment);\n        if (nodeFeature && nodeFeature.feature === property) {\n            return [node];\n        }\n    }\n    if (isCompositeCstNode(node) && node.astNode === element) {\n        return node.content.flatMap(e => findNodesForPropertyInternal(e, property, element, false));\n    }\n    return [];\n}\n/**\n * Find all CST nodes within the given node that correspond to the specified keyword.\n *\n * @param node A CST node in which to look for keywords. If this is undefined, the result is an empty array.\n * @param keyword A keyword as specified in the grammar.\n */\nexport function findNodesForKeyword(node, keyword) {\n    if (!node) {\n        return [];\n    }\n    return findNodesForKeywordInternal(node, keyword, node === null || node === void 0 ? void 0 : node.astNode);\n}\n/**\n * Find a single CST node within the given node that corresponds to the specified keyword.\n *\n * @param node A CST node in which to look for keywords. If this is undefined, the result is `undefined`.\n * @param keyword A keyword as specified in the grammar.\n * @param index If no index is specified or the index is less than zero, the first found node is returned. If the\n *        specified index exceeds the number of keyword occurrences, the last found node is returned. Otherwise,\n *        the node with the specified index is returned.\n */\nexport function findNodeForKeyword(node, keyword, index) {\n    if (!node) {\n        return undefined;\n    }\n    const nodes = findNodesForKeywordInternal(node, keyword, node === null || node === void 0 ? void 0 : node.astNode);\n    if (nodes.length === 0) {\n        return undefined;\n    }\n    if (index !== undefined) {\n        index = Math.max(0, Math.min(index, nodes.length - 1));\n    }\n    else {\n        index = 0;\n    }\n    return nodes[index];\n}\nexport function findNodesForKeywordInternal(node, keyword, element) {\n    if (node.astNode !== element) {\n        return [];\n    }\n    if (ast.isKeyword(node.grammarSource) && node.grammarSource.value === keyword) {\n        return [node];\n    }\n    const treeIterator = streamCst(node).iterator();\n    let result;\n    const keywordNodes = [];\n    do {\n        result = treeIterator.next();\n        if (!result.done) {\n            const childNode = result.value;\n            if (childNode.astNode === element) {\n                if (ast.isKeyword(childNode.grammarSource) && childNode.grammarSource.value === keyword) {\n                    keywordNodes.push(childNode);\n                }\n            }\n            else {\n                treeIterator.prune();\n            }\n        }\n    } while (!result.done);\n    return keywordNodes;\n}\n/**\n * If the given CST node was parsed in the context of a property assignment, the respective `Assignment` grammar\n * node is returned. If no assignment is found, the result is `undefined`.\n *\n * @param cstNode A CST node for which to find a property assignment.\n */\nexport function findAssignment(cstNode) {\n    var _a;\n    const astNode = cstNode.astNode;\n    // Only search until the ast node of the parent cst node is no longer the original ast node\n    // This would make us jump to a preceding rule call, which contains only unrelated assignments\n    while (astNode === ((_a = cstNode.container) === null || _a === void 0 ? void 0 : _a.astNode)) {\n        const assignment = getContainerOfType(cstNode.grammarSource, ast.isAssignment);\n        if (assignment) {\n            return assignment;\n        }\n        cstNode = cstNode.container;\n    }\n    return undefined;\n}\n/**\n * Find an assignment to the `name` property for the given grammar type. This requires the `type` to be inferred\n * from a parser rule, and that rule must contain an assignment to the `name` property. In all other cases,\n * this function returns `undefined`.\n */\nexport function findNameAssignment(type) {\n    let startNode = type;\n    if (ast.isInferredType(startNode)) {\n        // for inferred types, the location to start searching for the name-assignment is different\n        if (ast.isAction(startNode.$container)) {\n            // a type which is explicitly inferred by an action: investigate the sibbling of the Action node, i.e. start searching at the Action's parent\n            startNode = startNode.$container.$container;\n        }\n        else if (ast.isParserRule(startNode.$container)) {\n            // investigate the parser rule with the explicitly inferred type\n            startNode = startNode.$container;\n        }\n        else {\n            assertUnreachable(startNode.$container);\n        }\n    }\n    return findNameAssignmentInternal(type, startNode, new Map());\n}\nfunction findNameAssignmentInternal(type, startNode, cache) {\n    var _a;\n    // the cache is only required to prevent infinite loops\n    function go(node, refType) {\n        let childAssignment = undefined;\n        const parentAssignment = getContainerOfType(node, ast.isAssignment);\n        // No parent assignment implies unassigned rule call\n        if (!parentAssignment) {\n            childAssignment = findNameAssignmentInternal(refType, refType, cache);\n        }\n        cache.set(type, childAssignment);\n        return childAssignment;\n    }\n    if (cache.has(type)) {\n        return cache.get(type);\n    }\n    cache.set(type, undefined);\n    for (const node of streamAllContents(startNode)) {\n        if (ast.isAssignment(node) && node.feature.toLowerCase() === 'name') {\n            cache.set(type, node);\n            return node;\n        }\n        else if (ast.isRuleCall(node) && ast.isParserRule(node.rule.ref)) {\n            return go(node, node.rule.ref);\n        }\n        else if (ast.isSimpleType(node) && ((_a = node.typeRef) === null || _a === void 0 ? void 0 : _a.ref)) {\n            return go(node, node.typeRef.ref);\n        }\n    }\n    return undefined;\n}\nexport function getActionAtElement(element) {\n    const parent = element.$container;\n    if (ast.isGroup(parent)) {\n        const elements = parent.elements;\n        const index = elements.indexOf(element);\n        for (let i = index - 1; i >= 0; i--) {\n            const item = elements[i];\n            if (ast.isAction(item)) {\n                return item;\n            }\n            else {\n                const action = streamAllContents(elements[i]).find(ast.isAction);\n                if (action) {\n                    return action;\n                }\n            }\n        }\n    }\n    if (ast.isAbstractElement(parent)) {\n        return getActionAtElement(parent);\n    }\n    else {\n        return undefined;\n    }\n}\nexport function isOptionalCardinality(cardinality, element) {\n    return cardinality === '?' || cardinality === '*' || (ast.isGroup(element) && Boolean(element.guardCondition));\n}\nexport function isArrayCardinality(cardinality) {\n    return cardinality === '*' || cardinality === '+';\n}\nexport function isArrayOperator(operator) {\n    return operator === '+=';\n}\n/**\n * Determines whether the given parser rule is a _data type rule_, meaning that it has a\n * primitive return type like `number`, `boolean`, etc.\n */\nexport function isDataTypeRule(rule) {\n    return isDataTypeRuleInternal(rule, new Set());\n}\nfunction isDataTypeRuleInternal(rule, visited) {\n    if (visited.has(rule)) {\n        return true;\n    }\n    else {\n        visited.add(rule);\n    }\n    for (const node of streamAllContents(rule)) {\n        if (ast.isRuleCall(node)) {\n            if (!node.rule.ref) {\n                // RuleCall to unresolved rule. Don't assume `rule` is a DataType rule.\n                return false;\n            }\n            if (ast.isParserRule(node.rule.ref) && !isDataTypeRuleInternal(node.rule.ref, visited)) {\n                return false;\n            }\n        }\n        else if (ast.isAssignment(node)) {\n            return false;\n        }\n        else if (ast.isAction(node)) {\n            return false;\n        }\n    }\n    return Boolean(rule.definition);\n}\nexport function isDataType(type) {\n    return isDataTypeInternal(type.type, new Set());\n}\nfunction isDataTypeInternal(type, visited) {\n    if (visited.has(type)) {\n        return true;\n    }\n    else {\n        visited.add(type);\n    }\n    if (ast.isArrayType(type)) {\n        return false;\n    }\n    else if (ast.isReferenceType(type)) {\n        return false;\n    }\n    else if (ast.isUnionType(type)) {\n        return type.types.every(e => isDataTypeInternal(e, visited));\n    }\n    else if (ast.isSimpleType(type)) {\n        if (type.primitiveType !== undefined) {\n            return true;\n        }\n        else if (type.stringType !== undefined) {\n            return true;\n        }\n        else if (type.typeRef !== undefined) {\n            const ref = type.typeRef.ref;\n            if (ast.isType(ref)) {\n                return isDataTypeInternal(ref.type, visited);\n            }\n            else {\n                return false;\n            }\n        }\n        else {\n            return false;\n        }\n    }\n    else {\n        return false;\n    }\n}\nexport function getExplicitRuleType(rule) {\n    if (rule.inferredType) {\n        return rule.inferredType.name;\n    }\n    else if (rule.dataType) {\n        return rule.dataType;\n    }\n    else if (rule.returnType) {\n        const refType = rule.returnType.ref;\n        if (refType) {\n            // check if we need to check Action as return type\n            if (ast.isParserRule(refType)) {\n                return refType.name;\n            }\n            else if (ast.isInterface(refType) || ast.isType(refType)) {\n                return refType.name;\n            }\n        }\n    }\n    return undefined;\n}\nexport function getTypeName(type) {\n    var _a;\n    if (ast.isParserRule(type)) {\n        return isDataTypeRule(type) ? type.name : (_a = getExplicitRuleType(type)) !== null && _a !== void 0 ? _a : type.name;\n    }\n    else if (ast.isInterface(type) || ast.isType(type) || ast.isReturnType(type)) {\n        return type.name;\n    }\n    else if (ast.isAction(type)) {\n        const actionType = getActionType(type);\n        if (actionType) {\n            return actionType;\n        }\n    }\n    else if (ast.isInferredType(type)) {\n        return type.name;\n    }\n    throw new Error('Cannot get name of Unknown Type');\n}\nexport function getActionType(action) {\n    var _a;\n    if (action.inferredType) {\n        return action.inferredType.name;\n    }\n    else if ((_a = action.type) === null || _a === void 0 ? void 0 : _a.ref) {\n        return getTypeName(action.type.ref);\n    }\n    return undefined; // not inferring and not referencing a valid type\n}\n/**\n * This function is used at development time (for code generation and the internal type system) to get the type of the AST node produced by the given rule.\n * For data type rules, the name of the rule is returned,\n * e.g. \"INT_value returns number: MY_INT;\" returns \"INT_value\".\n * @param rule the given rule\n * @returns the name of the AST node type of the rule\n */\nexport function getRuleTypeName(rule) {\n    var _a, _b, _c;\n    if (ast.isTerminalRule(rule)) {\n        return (_b = (_a = rule.type) === null || _a === void 0 ? void 0 : _a.name) !== null && _b !== void 0 ? _b : 'string';\n    }\n    else {\n        return isDataTypeRule(rule) ? rule.name : (_c = getExplicitRuleType(rule)) !== null && _c !== void 0 ? _c : rule.name;\n    }\n}\n/**\n * This function is used at runtime to get the actual type of the values produced by the given rule at runtime.\n * For data type rules, the name of the declared return type of the rule is returned (if any),\n * e.g. \"INT_value returns number: MY_INT;\" returns \"number\".\n * @param rule the given rule\n * @returns the name of the type of the produced values of the rule at runtime\n */\nexport function getRuleType(rule) {\n    var _a, _b, _c;\n    if (ast.isTerminalRule(rule)) {\n        return (_b = (_a = rule.type) === null || _a === void 0 ? void 0 : _a.name) !== null && _b !== void 0 ? _b : 'string';\n    }\n    else {\n        return (_c = getExplicitRuleType(rule)) !== null && _c !== void 0 ? _c : rule.name;\n    }\n}\nexport function terminalRegex(terminalRule) {\n    const flags = {\n        s: false,\n        i: false,\n        u: false\n    };\n    const source = abstractElementToRegex(terminalRule.definition, flags);\n    const flagText = Object.entries(flags).filter(([, value]) => value).map(([name]) => name).join('');\n    return new RegExp(source, flagText);\n}\n// Using [\\s\\S]* allows to match everything, compared to . which doesn't match line terminators\nconst WILDCARD = /[\\s\\S]/.source;\nfunction abstractElementToRegex(element, flags) {\n    if (ast.isTerminalAlternatives(element)) {\n        return terminalAlternativesToRegex(element);\n    }\n    else if (ast.isTerminalGroup(element)) {\n        return terminalGroupToRegex(element);\n    }\n    else if (ast.isCharacterRange(element)) {\n        return characterRangeToRegex(element);\n    }\n    else if (ast.isTerminalRuleCall(element)) {\n        const rule = element.rule.ref;\n        if (!rule) {\n            throw new Error('Missing rule reference.');\n        }\n        return withCardinality(abstractElementToRegex(rule.definition), {\n            cardinality: element.cardinality,\n            lookahead: element.lookahead\n        });\n    }\n    else if (ast.isNegatedToken(element)) {\n        return negateTokenToRegex(element);\n    }\n    else if (ast.isUntilToken(element)) {\n        return untilTokenToRegex(element);\n    }\n    else if (ast.isRegexToken(element)) {\n        const lastSlash = element.regex.lastIndexOf('/');\n        const source = element.regex.substring(1, lastSlash);\n        const regexFlags = element.regex.substring(lastSlash + 1);\n        if (flags) {\n            flags.i = regexFlags.includes('i');\n            flags.s = regexFlags.includes('s');\n            flags.u = regexFlags.includes('u');\n        }\n        return withCardinality(source, {\n            cardinality: element.cardinality,\n            lookahead: element.lookahead,\n            wrap: false\n        });\n    }\n    else if (ast.isWildcard(element)) {\n        return withCardinality(WILDCARD, {\n            cardinality: element.cardinality,\n            lookahead: element.lookahead\n        });\n    }\n    else {\n        throw new Error(`Invalid terminal element: ${element === null || element === void 0 ? void 0 : element.$type}`);\n    }\n}\nfunction terminalAlternativesToRegex(alternatives) {\n    return withCardinality(alternatives.elements.map(e => abstractElementToRegex(e)).join('|'), {\n        cardinality: alternatives.cardinality,\n        lookahead: alternatives.lookahead\n    });\n}\nfunction terminalGroupToRegex(group) {\n    return withCardinality(group.elements.map(e => abstractElementToRegex(e)).join(''), {\n        cardinality: group.cardinality,\n        lookahead: group.lookahead\n    });\n}\nfunction untilTokenToRegex(until) {\n    return withCardinality(`${WILDCARD}*?${abstractElementToRegex(until.terminal)}`, {\n        cardinality: until.cardinality,\n        lookahead: until.lookahead\n    });\n}\nfunction negateTokenToRegex(negate) {\n    return withCardinality(`(?!${abstractElementToRegex(negate.terminal)})${WILDCARD}*?`, {\n        cardinality: negate.cardinality,\n        lookahead: negate.lookahead\n    });\n}\nfunction characterRangeToRegex(range) {\n    if (range.right) {\n        return withCardinality(`[${keywordToRegex(range.left)}-${keywordToRegex(range.right)}]`, {\n            cardinality: range.cardinality,\n            lookahead: range.lookahead,\n            wrap: false\n        });\n    }\n    return withCardinality(keywordToRegex(range.left), {\n        cardinality: range.cardinality,\n        lookahead: range.lookahead,\n        wrap: false\n    });\n}\nfunction keywordToRegex(keyword) {\n    return escapeRegExp(keyword.value);\n}\nfunction withCardinality(regex, options) {\n    var _a;\n    if (options.wrap !== false || options.lookahead) {\n        regex = `(${(_a = options.lookahead) !== null && _a !== void 0 ? _a : ''}${regex})`;\n    }\n    if (options.cardinality) {\n        return `${regex}${options.cardinality}`;\n    }\n    return regex;\n}\n//# sourceMappingURL=grammar-utils.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { RegExpParser, BaseRegExpVisitor } from '@chevrotain/regexp-to-ast';\nexport const NEWLINE_REGEXP = /\\r?\\n/gm;\nconst regexpParser = new RegExpParser();\n/**\n * This class is in charge of heuristically identifying start/end tokens of terminals.\n *\n * The way this works is by doing the following:\n * 1. Traverse the regular expression in the \"start state\"\n * 2. Add any encountered sets/single characters to the \"start regexp\"\n * 3. Once we encounter any variable-length content (i.e. with quantifiers such as +/?/*), we enter the \"end state\"\n * 4. In the end state, any sets/single characters are added to an \"end stack\".\n * 5. If we re-encounter any variable-length content we reset the end stack\n * 6. We continue visiting the regex until the end, reseting the end stack and rebuilding it as necessary\n *\n * After traversing a regular expression the `startRegexp/endRegexp` properties allow access to the stored start/end of the terminal\n */\nclass TerminalRegExpVisitor extends BaseRegExpVisitor {\n    constructor() {\n        super(...arguments);\n        this.isStarting = true;\n        this.endRegexpStack = [];\n        this.multiline = false;\n    }\n    get endRegex() {\n        return this.endRegexpStack.join('');\n    }\n    reset(regex) {\n        this.multiline = false;\n        this.regex = regex;\n        this.startRegexp = '';\n        this.isStarting = true;\n        this.endRegexpStack = [];\n    }\n    visitGroup(node) {\n        if (node.quantifier) {\n            this.isStarting = false;\n            this.endRegexpStack = [];\n        }\n    }\n    visitCharacter(node) {\n        const char = String.fromCharCode(node.value);\n        if (!this.multiline && char === '\\n') {\n            this.multiline = true;\n        }\n        if (node.quantifier) {\n            this.isStarting = false;\n            this.endRegexpStack = [];\n        }\n        else {\n            const escapedChar = escapeRegExp(char);\n            this.endRegexpStack.push(escapedChar);\n            if (this.isStarting) {\n                this.startRegexp += escapedChar;\n            }\n        }\n    }\n    visitSet(node) {\n        if (!this.multiline) {\n            const set = this.regex.substring(node.loc.begin, node.loc.end);\n            const regex = new RegExp(set);\n            this.multiline = Boolean('\\n'.match(regex));\n        }\n        if (node.quantifier) {\n            this.isStarting = false;\n            this.endRegexpStack = [];\n        }\n        else {\n            const set = this.regex.substring(node.loc.begin, node.loc.end);\n            this.endRegexpStack.push(set);\n            if (this.isStarting) {\n                this.startRegexp += set;\n            }\n        }\n    }\n    visitChildren(node) {\n        if (node.type === 'Group') {\n            // Ignore children of groups with quantifier (+/*/?)\n            // These groups are unrelated to start/end tokens of terminals\n            const group = node;\n            if (group.quantifier) {\n                return;\n            }\n        }\n        super.visitChildren(node);\n    }\n}\nconst visitor = new TerminalRegExpVisitor();\nexport function getTerminalParts(regexp) {\n    try {\n        if (typeof regexp !== 'string') {\n            regexp = regexp.source;\n        }\n        regexp = `/${regexp}/`;\n        const pattern = regexpParser.pattern(regexp);\n        const parts = [];\n        for (const alternative of pattern.value.value) {\n            visitor.reset(regexp);\n            visitor.visit(alternative);\n            parts.push({\n                start: visitor.startRegexp,\n                end: visitor.endRegex\n            });\n        }\n        return parts;\n    }\n    catch (_a) {\n        return [];\n    }\n}\nexport function isMultilineComment(regexp) {\n    try {\n        if (typeof regexp === 'string') {\n            regexp = new RegExp(regexp);\n        }\n        regexp = regexp.toString();\n        visitor.reset(regexp);\n        // Parsing the pattern might fail (since it's user code)\n        visitor.visit(regexpParser.pattern(regexp));\n        return visitor.multiline;\n    }\n    catch (_a) {\n        return false;\n    }\n}\n/**\n * A set of all characters that are considered whitespace by the '\\s' RegExp character class.\n * Taken from [MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_expressions/Character_classes).\n */\nexport const whitespaceCharacters = ('\\f\\n\\r\\t\\v\\u0020\\u00a0\\u1680\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007' +\n    '\\u2008\\u2009\\u200a\\u2028\\u2029\\u202f\\u205f\\u3000\\ufeff').split('');\nexport function isWhitespace(value) {\n    const regexp = typeof value === 'string' ? new RegExp(value) : value;\n    return whitespaceCharacters.some((ws) => regexp.test(ws));\n}\nexport function escapeRegExp(value) {\n    return value.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\n}\nexport function getCaseInsensitivePattern(keyword) {\n    return Array.prototype.map.call(keyword, letter => /\\w/.test(letter) ? `[${letter.toLowerCase()}${letter.toUpperCase()}]` : escapeRegExp(letter)).join('');\n}\n/**\n * Determines whether the given input has a partial match with the specified regex.\n * @param regex The regex to partially match against\n * @param input The input string\n * @returns Whether any match exists.\n */\nexport function partialMatches(regex, input) {\n    const partial = partialRegExp(regex);\n    const match = input.match(partial);\n    return !!match && match[0].length > 0;\n}\n/**\n * Builds a partial regex from the input regex. A partial regex is able to match incomplete input strings. E.g.\n * a partial regex constructed from `/ab/` is able to match the string `a` without needing a following `b` character. However it won't match `b` alone.\n * @param regex The input regex to be converted.\n * @returns A partial regex constructed from the input regex.\n */\nexport function partialRegExp(regex) {\n    if (typeof regex === 'string') {\n        regex = new RegExp(regex);\n    }\n    const re = regex, source = regex.source;\n    let i = 0;\n    function process() {\n        let result = '', tmp;\n        function appendRaw(nbChars) {\n            result += source.substr(i, nbChars);\n            i += nbChars;\n        }\n        function appendOptional(nbChars) {\n            result += '(?:' + source.substr(i, nbChars) + '|$)';\n            i += nbChars;\n        }\n        while (i < source.length) {\n            switch (source[i]) {\n                case '\\\\':\n                    switch (source[i + 1]) {\n                        case 'c':\n                            appendOptional(3);\n                            break;\n                        case 'x':\n                            appendOptional(4);\n                            break;\n                        case 'u':\n                            if (re.unicode) {\n                                if (source[i + 2] === '{') {\n                                    appendOptional(source.indexOf('}', i) - i + 1);\n                                }\n                                else {\n                                    appendOptional(6);\n                                }\n                            }\n                            else {\n                                appendOptional(2);\n                            }\n                            break;\n                        case 'p':\n                        case 'P':\n                            if (re.unicode) {\n                                appendOptional(source.indexOf('}', i) - i + 1);\n                            }\n                            else {\n                                appendOptional(2);\n                            }\n                            break;\n                        case 'k':\n                            appendOptional(source.indexOf('>', i) - i + 1);\n                            break;\n                        default:\n                            appendOptional(2);\n                            break;\n                    }\n                    break;\n                case '[':\n                    tmp = /\\[(?:\\\\.|.)*?\\]/g;\n                    tmp.lastIndex = i;\n                    tmp = tmp.exec(source) || [];\n                    appendOptional(tmp[0].length);\n                    break;\n                case '|':\n                case '^':\n                case '$':\n                case '*':\n                case '+':\n                case '?':\n                    appendRaw(1);\n                    break;\n                case '{':\n                    tmp = /\\{\\d+,?\\d*\\}/g;\n                    tmp.lastIndex = i;\n                    tmp = tmp.exec(source);\n                    if (tmp) {\n                        appendRaw(tmp[0].length);\n                    }\n                    else {\n                        appendOptional(1);\n                    }\n                    break;\n                case '(':\n                    if (source[i + 1] === '?') {\n                        switch (source[i + 2]) {\n                            case ':':\n                                result += '(?:';\n                                i += 3;\n                                result += process() + '|$)';\n                                break;\n                            case '=':\n                                result += '(?=';\n                                i += 3;\n                                result += process() + ')';\n                                break;\n                            case '!':\n                                tmp = i;\n                                i += 3;\n                                process();\n                                result += source.substr(tmp, i - tmp);\n                                break;\n                            case '<':\n                                switch (source[i + 3]) {\n                                    case '=':\n                                    case '!':\n                                        tmp = i;\n                                        i += 4;\n                                        process();\n                                        result += source.substr(tmp, i - tmp);\n                                        break;\n                                    default:\n                                        appendRaw(source.indexOf('>', i) - i + 1);\n                                        result += process() + '|$)';\n                                        break;\n                                }\n                                break;\n                        }\n                    }\n                    else {\n                        appendRaw(1);\n                        result += process() + '|$)';\n                    }\n                    break;\n                case ')':\n                    ++i;\n                    return result;\n                default:\n                    appendOptional(1);\n                    break;\n            }\n        }\n        return result;\n    }\n    return new RegExp(process(), regex.flags);\n}\n//# sourceMappingURL=regexp-utils.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n/**\n * The default implementation of `Stream` works with two input functions:\n *  - The first function creates the initial state of an iteration.\n *  - The second function gets the current state as argument and returns an `IteratorResult`.\n */\nexport class StreamImpl {\n    constructor(startFn, nextFn) {\n        this.startFn = startFn;\n        this.nextFn = nextFn;\n    }\n    iterator() {\n        const iterator = {\n            state: this.startFn(),\n            next: () => this.nextFn(iterator.state),\n            [Symbol.iterator]: () => iterator\n        };\n        return iterator;\n    }\n    [Symbol.iterator]() {\n        return this.iterator();\n    }\n    isEmpty() {\n        const iterator = this.iterator();\n        return Boolean(iterator.next().done);\n    }\n    count() {\n        const iterator = this.iterator();\n        let count = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            count++;\n            next = iterator.next();\n        }\n        return count;\n    }\n    toArray() {\n        const result = [];\n        const iterator = this.iterator();\n        let next;\n        do {\n            next = iterator.next();\n            if (next.value !== undefined) {\n                result.push(next.value);\n            }\n        } while (!next.done);\n        return result;\n    }\n    toSet() {\n        return new Set(this);\n    }\n    toMap(keyFn, valueFn) {\n        const entryStream = this.map(element => [\n            keyFn ? keyFn(element) : element,\n            valueFn ? valueFn(element) : element\n        ]);\n        return new Map(entryStream);\n    }\n    toString() {\n        return this.join();\n    }\n    concat(other) {\n        return new StreamImpl(() => ({ first: this.startFn(), firstDone: false, iterator: other[Symbol.iterator]() }), state => {\n            let result;\n            if (!state.firstDone) {\n                do {\n                    result = this.nextFn(state.first);\n                    if (!result.done) {\n                        return result;\n                    }\n                } while (!result.done);\n                state.firstDone = true;\n            }\n            do {\n                result = state.iterator.next();\n                if (!result.done) {\n                    return result;\n                }\n            } while (!result.done);\n            return DONE_RESULT;\n        });\n    }\n    join(separator = ',') {\n        const iterator = this.iterator();\n        let value = '';\n        let result;\n        let addSeparator = false;\n        do {\n            result = iterator.next();\n            if (!result.done) {\n                if (addSeparator) {\n                    value += separator;\n                }\n                value += toString(result.value);\n            }\n            addSeparator = true;\n        } while (!result.done);\n        return value;\n    }\n    indexOf(searchElement, fromIndex = 0) {\n        const iterator = this.iterator();\n        let index = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            if (index >= fromIndex && next.value === searchElement) {\n                return index;\n            }\n            next = iterator.next();\n            index++;\n        }\n        return -1;\n    }\n    every(predicate) {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (!predicate(next.value)) {\n                return false;\n            }\n            next = iterator.next();\n        }\n        return true;\n    }\n    some(predicate) {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (predicate(next.value)) {\n                return true;\n            }\n            next = iterator.next();\n        }\n        return false;\n    }\n    forEach(callbackfn) {\n        const iterator = this.iterator();\n        let index = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            callbackfn(next.value, index);\n            next = iterator.next();\n            index++;\n        }\n    }\n    map(callbackfn) {\n        return new StreamImpl(this.startFn, (state) => {\n            const { done, value } = this.nextFn(state);\n            if (done) {\n                return DONE_RESULT;\n            }\n            else {\n                return { done: false, value: callbackfn(value) };\n            }\n        });\n    }\n    filter(predicate) {\n        return new StreamImpl(this.startFn, state => {\n            let result;\n            do {\n                result = this.nextFn(state);\n                if (!result.done && predicate(result.value)) {\n                    return result;\n                }\n            } while (!result.done);\n            return DONE_RESULT;\n        });\n    }\n    nonNullable() {\n        return this.filter(e => e !== undefined && e !== null);\n    }\n    reduce(callbackfn, initialValue) {\n        const iterator = this.iterator();\n        let previousValue = initialValue;\n        let next = iterator.next();\n        while (!next.done) {\n            if (previousValue === undefined) {\n                previousValue = next.value;\n            }\n            else {\n                previousValue = callbackfn(previousValue, next.value);\n            }\n            next = iterator.next();\n        }\n        return previousValue;\n    }\n    reduceRight(callbackfn, initialValue) {\n        return this.recursiveReduce(this.iterator(), callbackfn, initialValue);\n    }\n    recursiveReduce(iterator, callbackfn, initialValue) {\n        const next = iterator.next();\n        if (next.done) {\n            return initialValue;\n        }\n        const previousValue = this.recursiveReduce(iterator, callbackfn, initialValue);\n        if (previousValue === undefined) {\n            return next.value;\n        }\n        return callbackfn(previousValue, next.value);\n    }\n    find(predicate) {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (predicate(next.value)) {\n                return next.value;\n            }\n            next = iterator.next();\n        }\n        return undefined;\n    }\n    findIndex(predicate) {\n        const iterator = this.iterator();\n        let index = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            if (predicate(next.value)) {\n                return index;\n            }\n            next = iterator.next();\n            index++;\n        }\n        return -1;\n    }\n    includes(searchElement) {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (next.value === searchElement) {\n                return true;\n            }\n            next = iterator.next();\n        }\n        return false;\n    }\n    flatMap(callbackfn) {\n        return new StreamImpl(() => ({ this: this.startFn() }), (state) => {\n            do {\n                if (state.iterator) {\n                    const next = state.iterator.next();\n                    if (next.done) {\n                        state.iterator = undefined;\n                    }\n                    else {\n                        return next;\n                    }\n                }\n                const { done, value } = this.nextFn(state.this);\n                if (!done) {\n                    const mapped = callbackfn(value);\n                    if (isIterable(mapped)) {\n                        state.iterator = mapped[Symbol.iterator]();\n                    }\n                    else {\n                        return { done: false, value: mapped };\n                    }\n                }\n            } while (state.iterator);\n            return DONE_RESULT;\n        });\n    }\n    flat(depth) {\n        if (depth === undefined) {\n            depth = 1;\n        }\n        if (depth <= 0) {\n            return this;\n        }\n        const stream = depth > 1 ? this.flat(depth - 1) : this;\n        return new StreamImpl(() => ({ this: stream.startFn() }), (state) => {\n            do {\n                if (state.iterator) {\n                    const next = state.iterator.next();\n                    if (next.done) {\n                        state.iterator = undefined;\n                    }\n                    else {\n                        return next;\n                    }\n                }\n                const { done, value } = stream.nextFn(state.this);\n                if (!done) {\n                    if (isIterable(value)) {\n                        state.iterator = value[Symbol.iterator]();\n                    }\n                    else {\n                        return { done: false, value: value };\n                    }\n                }\n            } while (state.iterator);\n            return DONE_RESULT;\n        });\n    }\n    head() {\n        const iterator = this.iterator();\n        const result = iterator.next();\n        if (result.done) {\n            return undefined;\n        }\n        return result.value;\n    }\n    tail(skipCount = 1) {\n        return new StreamImpl(() => {\n            const state = this.startFn();\n            for (let i = 0; i < skipCount; i++) {\n                const next = this.nextFn(state);\n                if (next.done) {\n                    return state;\n                }\n            }\n            return state;\n        }, this.nextFn);\n    }\n    limit(maxSize) {\n        return new StreamImpl(() => ({ size: 0, state: this.startFn() }), state => {\n            state.size++;\n            if (state.size > maxSize) {\n                return DONE_RESULT;\n            }\n            return this.nextFn(state.state);\n        });\n    }\n    distinct(by) {\n        return new StreamImpl(() => ({ set: new Set(), internalState: this.startFn() }), state => {\n            let result;\n            do {\n                result = this.nextFn(state.internalState);\n                if (!result.done) {\n                    const value = by ? by(result.value) : result.value;\n                    if (!state.set.has(value)) {\n                        state.set.add(value);\n                        return result;\n                    }\n                }\n            } while (!result.done);\n            return DONE_RESULT;\n        });\n    }\n    exclude(other, key) {\n        const otherKeySet = new Set();\n        for (const item of other) {\n            const value = key ? key(item) : item;\n            otherKeySet.add(value);\n        }\n        return this.filter(e => {\n            const ownKey = key ? key(e) : e;\n            return !otherKeySet.has(ownKey);\n        });\n    }\n}\nfunction toString(item) {\n    if (typeof item === 'string') {\n        return item;\n    }\n    if (typeof item === 'undefined') {\n        return 'undefined';\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    if (typeof item.toString === 'function') {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        return item.toString();\n    }\n    return Object.prototype.toString.call(item);\n}\nfunction isIterable(obj) {\n    return !!obj && typeof obj[Symbol.iterator] === 'function';\n}\n/**\n * An empty stream of any type.\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nexport const EMPTY_STREAM = new StreamImpl(() => undefined, () => DONE_RESULT);\n/**\n * Use this `IteratorResult` when implementing a `StreamImpl` to indicate that there are no more elements in the stream.\n */\nexport const DONE_RESULT = Object.freeze({ done: true, value: undefined });\n/**\n * Create a stream from one or more iterables or array-likes.\n */\nexport function stream(...collections) {\n    if (collections.length === 1) {\n        const collection = collections[0];\n        if (collection instanceof StreamImpl) {\n            return collection;\n        }\n        if (isIterable(collection)) {\n            return new StreamImpl(() => collection[Symbol.iterator](), (iterator) => iterator.next());\n        }\n        if (typeof collection.length === 'number') {\n            return new StreamImpl(() => ({ index: 0 }), (state) => {\n                if (state.index < collection.length) {\n                    return { done: false, value: collection[state.index++] };\n                }\n                else {\n                    return DONE_RESULT;\n                }\n            });\n        }\n    }\n    if (collections.length > 1) {\n        return new StreamImpl(() => ({ collIndex: 0, arrIndex: 0 }), (state) => {\n            do {\n                if (state.iterator) {\n                    const next = state.iterator.next();\n                    if (!next.done) {\n                        return next;\n                    }\n                    state.iterator = undefined;\n                }\n                if (state.array) {\n                    if (state.arrIndex < state.array.length) {\n                        return { done: false, value: state.array[state.arrIndex++] };\n                    }\n                    state.array = undefined;\n                    state.arrIndex = 0;\n                }\n                if (state.collIndex < collections.length) {\n                    const collection = collections[state.collIndex++];\n                    if (isIterable(collection)) {\n                        state.iterator = collection[Symbol.iterator]();\n                    }\n                    else if (collection && typeof collection.length === 'number') {\n                        state.array = collection;\n                    }\n                }\n            } while (state.iterator || state.array || state.collIndex < collections.length);\n            return DONE_RESULT;\n        });\n    }\n    return EMPTY_STREAM;\n}\n/**\n * The default implementation of `TreeStream` takes a root element and a function that computes the\n * children of its argument. Whether the root node included in the stream is controlled with the\n * `includeRoot` option, which defaults to `false`.\n */\nexport class TreeStreamImpl extends StreamImpl {\n    constructor(root, children, options) {\n        super(() => ({\n            iterators: (options === null || options === void 0 ? void 0 : options.includeRoot) ? [[root][Symbol.iterator]()] : [children(root)[Symbol.iterator]()],\n            pruned: false\n        }), state => {\n            if (state.pruned) {\n                state.iterators.pop();\n                state.pruned = false;\n            }\n            while (state.iterators.length > 0) {\n                const iterator = state.iterators[state.iterators.length - 1];\n                const next = iterator.next();\n                if (next.done) {\n                    state.iterators.pop();\n                }\n                else {\n                    state.iterators.push(children(next.value)[Symbol.iterator]());\n                    return next;\n                }\n            }\n            return DONE_RESULT;\n        });\n    }\n    iterator() {\n        const iterator = {\n            state: this.startFn(),\n            next: () => this.nextFn(iterator.state),\n            prune: () => {\n                iterator.state.pruned = true;\n            },\n            [Symbol.iterator]: () => iterator\n        };\n        return iterator;\n    }\n}\n/**\n * A set of utility functions that reduce a stream to a single value.\n */\nexport var Reduction;\n(function (Reduction) {\n    /**\n     * Compute the sum of a number stream.\n     */\n    function sum(stream) {\n        return stream.reduce((a, b) => a + b, 0);\n    }\n    Reduction.sum = sum;\n    /**\n     * Compute the product of a number stream.\n     */\n    function product(stream) {\n        return stream.reduce((a, b) => a * b, 0);\n    }\n    Reduction.product = product;\n    /**\n     * Compute the minimum of a number stream. Returns `undefined` if the stream is empty.\n     */\n    function min(stream) {\n        return stream.reduce((a, b) => Math.min(a, b));\n    }\n    Reduction.min = min;\n    /**\n     * Compute the maximum of a number stream. Returns `undefined` if the stream is empty.\n     */\n    function max(stream) {\n        return stream.reduce((a, b) => Math.max(a, b));\n    }\n    Reduction.max = max;\n})(Reduction || (Reduction = {}));\n//# sourceMappingURL=stream.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport class EmptyFileSystemProvider {\n    readFile() {\n        throw new Error('No file system is available.');\n    }\n    async readDirectory() {\n        return [];\n    }\n}\nexport const EmptyFileSystem = {\n    fileSystemProvider: () => new EmptyFileSystemProvider()\n};\n//# sourceMappingURL=file-system-provider.js.map","import isSymbol from './isSymbol.js';\n\n/**\n * The base implementation of methods like `_.max` and `_.min` which accepts a\n * `comparator` to determine the extremum value.\n *\n * @private\n * @param {Array} array The array to iterate over.\n * @param {Function} iteratee The iteratee invoked per iteration.\n * @param {Function} comparator The comparator used to compare values.\n * @returns {*} Returns the extremum value.\n */\nfunction baseExtremum(array, iteratee, comparator) {\n  var index = -1,\n      length = array.length;\n\n  while (++index < length) {\n    var value = array[index],\n        current = iteratee(value);\n\n    if (current != null && (computed === undefined\n          ? (current === current && !isSymbol(current))\n          : comparator(current, computed)\n        )) {\n      var computed = current,\n          result = value;\n    }\n  }\n  return result;\n}\n\nexport default baseExtremum;\n","/**\n * The base implementation of `_.lt` which doesn't coerce arguments.\n *\n * @private\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if `value` is less than `other`,\n *  else `false`.\n */\nfunction baseLt(value, other) {\n  return value < other;\n}\n\nexport default baseLt;\n","import baseEach from './_baseEach.js';\nimport isArrayLike from './isArrayLike.js';\n\n/**\n * The base implementation of `_.map` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n */\nfunction baseMap(collection, iteratee) {\n  var index = -1,\n      result = isArrayLike(collection) ? Array(collection.length) : [];\n\n  baseEach(collection, function(value, key, collection) {\n    result[++index] = iteratee(value, key, collection);\n  });\n  return result;\n}\n\nexport default baseMap;\n","import assignValue from './_assignValue.js';\nimport castPath from './_castPath.js';\nimport isIndex from './_isIndex.js';\nimport isObject from './isObject.js';\nimport toKey from './_toKey.js';\n\n/**\n * The base implementation of `_.set`.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {Array|string} path The path of the property to set.\n * @param {*} value The value to set.\n * @param {Function} [customizer] The function to customize path creation.\n * @returns {Object} Returns `object`.\n */\nfunction baseSet(object, path, value, customizer) {\n  if (!isObject(object)) {\n    return object;\n  }\n  path = castPath(path, object);\n\n  var index = -1,\n      length = path.length,\n      lastIndex = length - 1,\n      nested = object;\n\n  while (nested != null && ++index < length) {\n    var key = toKey(path[index]),\n        newValue = value;\n\n    if (key === '__proto__' || key === 'constructor' || key === 'prototype') {\n      return object;\n    }\n\n    if (index != lastIndex) {\n      var objValue = nested[key];\n      newValue = customizer ? customizer(objValue, key, nested) : undefined;\n      if (newValue === undefined) {\n        newValue = isObject(objValue)\n          ? objValue\n          : (isIndex(path[index + 1]) ? [] : {});\n      }\n    }\n    assignValue(nested, key, newValue);\n    nested = nested[key];\n  }\n  return object;\n}\n\nexport default baseSet;\n","import baseGet from './_baseGet.js';\nimport baseSet from './_baseSet.js';\nimport castPath from './_castPath.js';\n\n/**\n * The base implementation of  `_.pickBy` without support for iteratee shorthands.\n *\n * @private\n * @param {Object} object The source object.\n * @param {string[]} paths The property paths to pick.\n * @param {Function} predicate The function invoked per property.\n * @returns {Object} Returns the new object.\n */\nfunction basePickBy(object, paths, predicate) {\n  var index = -1,\n      length = paths.length,\n      result = {};\n\n  while (++index < length) {\n    var path = paths[index],\n        value = baseGet(object, path);\n\n    if (predicate(value, path)) {\n      baseSet(result, castPath(path, object), value);\n    }\n  }\n  return result;\n}\n\nexport default basePickBy;\n","import baseClone from './_baseClone.js';\n\n/** Used to compose bitmasks for cloning. */\nvar CLONE_SYMBOLS_FLAG = 4;\n\n/**\n * Creates a shallow clone of `value`.\n *\n * **Note:** This method is loosely based on the\n * [structured clone algorithm](https://mdn.io/Structured_clone_algorithm)\n * and supports cloning arrays, array buffers, booleans, date objects, maps,\n * numbers, `Object` objects, regexes, sets, strings, symbols, and typed\n * arrays. The own enumerable properties of `arguments` objects are cloned\n * as plain objects. An empty object is returned for uncloneable values such\n * as error objects, functions, DOM nodes, and WeakMaps.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to clone.\n * @returns {*} Returns the cloned value.\n * @see _.cloneDeep\n * @example\n *\n * var objects = [{ 'a': 1 }, { 'b': 2 }];\n *\n * var shallow = _.clone(objects);\n * console.log(shallow[0] === objects[0]);\n * // => true\n */\nfunction clone(value) {\n  return baseClone(value, CLONE_SYMBOLS_FLAG);\n}\n\nexport default clone;\n","import baseRest from './_baseRest.js';\nimport eq from './eq.js';\nimport isIterateeCall from './_isIterateeCall.js';\nimport keysIn from './keysIn.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own and inherited enumerable string keyed properties of source\n * objects to the destination object for all destination properties that\n * resolve to `undefined`. Source objects are applied from left to right.\n * Once a property is set, additional values of the same property are ignored.\n *\n * **Note:** This method mutates `object`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.defaultsDeep\n * @example\n *\n * _.defaults({ 'a': 1 }, { 'b': 2 }, { 'a': 3 });\n * // => { 'a': 1, 'b': 2 }\n */\nvar defaults = baseRest(function(object, sources) {\n  object = Object(object);\n\n  var index = -1;\n  var length = sources.length;\n  var guard = length > 2 ? sources[2] : undefined;\n\n  if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n    length = 1;\n  }\n\n  while (++index < length) {\n    var source = sources[index];\n    var props = keysIn(source);\n    var propsIndex = -1;\n    var propsLength = props.length;\n\n    while (++propsIndex < propsLength) {\n      var key = props[propsIndex];\n      var value = object[key];\n\n      if (value === undefined ||\n          (eq(value, objectProto[key]) && !hasOwnProperty.call(object, key))) {\n        object[key] = source[key];\n      }\n    }\n  }\n\n  return object;\n});\n\nexport default defaults;\n","import baseIteratee from './_baseIteratee.js';\nimport isArrayLike from './isArrayLike.js';\nimport keys from './keys.js';\n\n/**\n * Creates a `_.find` or `_.findLast` function.\n *\n * @private\n * @param {Function} findIndexFunc The function to find the collection index.\n * @returns {Function} Returns the new find function.\n */\nfunction createFind(findIndexFunc) {\n  return function(collection, predicate, fromIndex) {\n    var iterable = Object(collection);\n    if (!isArrayLike(collection)) {\n      var iteratee = baseIteratee(predicate, 3);\n      collection = keys(collection);\n      predicate = function(key) { return iteratee(iterable[key], key, iterable); };\n    }\n    var index = findIndexFunc(collection, predicate, fromIndex);\n    return index > -1 ? iterable[iteratee ? collection[index] : index] : undefined;\n  };\n}\n\nexport default createFind;\n","import baseFindIndex from './_baseFindIndex.js';\nimport baseIteratee from './_baseIteratee.js';\nimport toInteger from './toInteger.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * This method is like `_.find` except that it returns the index of the first\n * element `predicate` returns truthy for instead of the element itself.\n *\n * @static\n * @memberOf _\n * @since 1.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {number} Returns the index of the found element, else `-1`.\n * @example\n *\n * var users = [\n *   { 'user': 'barney',  'active': false },\n *   { 'user': 'fred',    'active': false },\n *   { 'user': 'pebbles', 'active': true }\n * ];\n *\n * _.findIndex(users, function(o) { return o.user == 'barney'; });\n * // => 0\n *\n * // The `_.matches` iteratee shorthand.\n * _.findIndex(users, { 'user': 'fred', 'active': false });\n * // => 1\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.findIndex(users, ['active', false]);\n * // => 0\n *\n * // The `_.property` iteratee shorthand.\n * _.findIndex(users, 'active');\n * // => 2\n */\nfunction findIndex(array, predicate, fromIndex) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return -1;\n  }\n  var index = fromIndex == null ? 0 : toInteger(fromIndex);\n  if (index < 0) {\n    index = nativeMax(length + index, 0);\n  }\n  return baseFindIndex(array, baseIteratee(predicate, 3), index);\n}\n\nexport default findIndex;\n","import createFind from './_createFind.js';\nimport findIndex from './findIndex.js';\n\n/**\n * Iterates over elements of `collection`, returning the first element\n * `predicate` returns truthy for. The predicate is invoked with three\n * arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to inspect.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {*} Returns the matched element, else `undefined`.\n * @example\n *\n * var users = [\n *   { 'user': 'barney',  'age': 36, 'active': true },\n *   { 'user': 'fred',    'age': 40, 'active': false },\n *   { 'user': 'pebbles', 'age': 1,  'active': true }\n * ];\n *\n * _.find(users, function(o) { return o.age < 40; });\n * // => object for 'barney'\n *\n * // The `_.matches` iteratee shorthand.\n * _.find(users, { 'age': 1, 'active': true });\n * // => object for 'pebbles'\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.find(users, ['active', false]);\n * // => object for 'fred'\n *\n * // The `_.property` iteratee shorthand.\n * _.find(users, 'active');\n * // => object for 'barney'\n */\nvar find = createFind(findIndex);\n\nexport default find;\n","import baseFlatten from './_baseFlatten.js';\nimport map from './map.js';\n\n/**\n * Creates a flattened array of values by running each element in `collection`\n * thru `iteratee` and flattening the mapped results. The iteratee is invoked\n * with three arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * function duplicate(n) {\n *   return [n, n];\n * }\n *\n * _.flatMap([1, 2], duplicate);\n * // => [1, 1, 2, 2]\n */\nfunction flatMap(collection, iteratee) {\n  return baseFlatten(map(collection, iteratee), 1);\n}\n\nexport default flatMap;\n","import baseFlatten from './_baseFlatten.js';\n\n/**\n * Flattens `array` a single level deep.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to flatten.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * _.flatten([1, [2, [3, [4]], 5]]);\n * // => [1, 2, [3, [4]], 5]\n */\nfunction flatten(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? baseFlatten(array, 1) : [];\n}\n\nexport default flatten;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * The base implementation of `_.has` without support for deep paths.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {Array|string} key The key to check.\n * @returns {boolean} Returns `true` if `key` exists, else `false`.\n */\nfunction baseHas(object, key) {\n  return object != null && hasOwnProperty.call(object, key);\n}\n\nexport default baseHas;\n","import baseHas from './_baseHas.js';\nimport hasPath from './_hasPath.js';\n\n/**\n * Checks if `path` is a direct property of `object`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @param {Array|string} path The path to check.\n * @returns {boolean} Returns `true` if `path` exists, else `false`.\n * @example\n *\n * var object = { 'a': { 'b': 2 } };\n * var other = _.create({ 'a': _.create({ 'b': 2 }) });\n *\n * _.has(object, 'a');\n * // => true\n *\n * _.has(object, 'a.b');\n * // => true\n *\n * _.has(object, ['a', 'b']);\n * // => true\n *\n * _.has(other, 'a');\n * // => false\n */\nfunction has(object, path) {\n  return object != null && hasPath(object, path, baseHas);\n}\n\nexport default has;\n","import baseGetTag from './_baseGetTag.js';\nimport isArray from './isArray.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar stringTag = '[object String]';\n\n/**\n * Checks if `value` is classified as a `String` primitive or object.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a string, else `false`.\n * @example\n *\n * _.isString('abc');\n * // => true\n *\n * _.isString(1);\n * // => false\n */\nfunction isString(value) {\n  return typeof value == 'string' ||\n    (!isArray(value) && isObjectLike(value) && baseGetTag(value) == stringTag);\n}\n\nexport default isString;\n","/**\n * Gets the last element of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to query.\n * @returns {*} Returns the last element of `array`.\n * @example\n *\n * _.last([1, 2, 3]);\n * // => 3\n */\nfunction last(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? array[length - 1] : undefined;\n}\n\nexport default last;\n","import arrayMap from './_arrayMap.js';\nimport baseIteratee from './_baseIteratee.js';\nimport baseMap from './_baseMap.js';\nimport isArray from './isArray.js';\n\n/**\n * Creates an array of values by running each element in `collection` thru\n * `iteratee`. The iteratee is invoked with three arguments:\n * (value, index|key, collection).\n *\n * Many lodash methods are guarded to work as iteratees for methods like\n * `_.every`, `_.filter`, `_.map`, `_.mapValues`, `_.reject`, and `_.some`.\n *\n * The guarded methods are:\n * `ary`, `chunk`, `curry`, `curryRight`, `drop`, `dropRight`, `every`,\n * `fill`, `invert`, `parseInt`, `random`, `range`, `rangeRight`, `repeat`,\n * `sampleSize`, `slice`, `some`, `sortBy`, `split`, `take`, `takeRight`,\n * `template`, `trim`, `trimEnd`, `trimStart`, and `words`\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n * @example\n *\n * function square(n) {\n *   return n * n;\n * }\n *\n * _.map([4, 8], square);\n * // => [16, 64]\n *\n * _.map({ 'a': 4, 'b': 8 }, square);\n * // => [16, 64] (iteration order is not guaranteed)\n *\n * var users = [\n *   { 'user': 'barney' },\n *   { 'user': 'fred' }\n * ];\n *\n * // The `_.property` iteratee shorthand.\n * _.map(users, 'user');\n * // => ['barney', 'fred']\n */\nfunction map(collection, iteratee) {\n  var func = isArray(collection) ? arrayMap : baseMap;\n  return func(collection, baseIteratee(iteratee, 3));\n}\n\nexport default map;\n","import baseExtremum from './_baseExtremum.js';\nimport baseLt from './_baseLt.js';\nimport identity from './identity.js';\n\n/**\n * Computes the minimum value of `array`. If `array` is empty or falsey,\n * `undefined` is returned.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Math\n * @param {Array} array The array to iterate over.\n * @returns {*} Returns the minimum value.\n * @example\n *\n * _.min([4, 2, 8, 6]);\n * // => 2\n *\n * _.min([]);\n * // => undefined\n */\nfunction min(array) {\n  return (array && array.length)\n    ? baseExtremum(array, identity, baseLt)\n    : undefined;\n}\n\nexport default min;\n","/** Used to match a single whitespace character. */\nvar reWhitespace = /\\s/;\n\n/**\n * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\n * character of `string`.\n *\n * @private\n * @param {string} string The string to inspect.\n * @returns {number} Returns the index of the last non-whitespace character.\n */\nfunction trimmedEndIndex(string) {\n  var index = string.length;\n\n  while (index-- && reWhitespace.test(string.charAt(index))) {}\n  return index;\n}\n\nexport default trimmedEndIndex;\n","import trimmedEndIndex from './_trimmedEndIndex.js';\n\n/** Used to match leading whitespace. */\nvar reTrimStart = /^\\s+/;\n\n/**\n * The base implementation of `_.trim`.\n *\n * @private\n * @param {string} string The string to trim.\n * @returns {string} Returns the trimmed string.\n */\nfunction baseTrim(string) {\n  return string\n    ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\n    : string;\n}\n\nexport default baseTrim;\n","import baseTrim from './_baseTrim.js';\nimport isObject from './isObject.js';\nimport isSymbol from './isSymbol.js';\n\n/** Used as references for various `Number` constants. */\nvar NAN = 0 / 0;\n\n/** Used to detect bad signed hexadecimal string values. */\nvar reIsBadHex = /^[-+]0x[0-9a-f]+$/i;\n\n/** Used to detect binary string values. */\nvar reIsBinary = /^0b[01]+$/i;\n\n/** Used to detect octal string values. */\nvar reIsOctal = /^0o[0-7]+$/i;\n\n/** Built-in method references without a dependency on `root`. */\nvar freeParseInt = parseInt;\n\n/**\n * Converts `value` to a number.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to process.\n * @returns {number} Returns the number.\n * @example\n *\n * _.toNumber(3.2);\n * // => 3.2\n *\n * _.toNumber(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toNumber(Infinity);\n * // => Infinity\n *\n * _.toNumber('3.2');\n * // => 3.2\n */\nfunction toNumber(value) {\n  if (typeof value == 'number') {\n    return value;\n  }\n  if (isSymbol(value)) {\n    return NAN;\n  }\n  if (isObject(value)) {\n    var other = typeof value.valueOf == 'function' ? value.valueOf() : value;\n    value = isObject(other) ? (other + '') : other;\n  }\n  if (typeof value != 'string') {\n    return value === 0 ? value : +value;\n  }\n  value = baseTrim(value);\n  var isBinary = reIsBinary.test(value);\n  return (isBinary || reIsOctal.test(value))\n    ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\n    : (reIsBadHex.test(value) ? NAN : +value);\n}\n\nexport default toNumber;\n","import toNumber from './toNumber.js';\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0,\n    MAX_INTEGER = 1.7976931348623157e+308;\n\n/**\n * Converts `value` to a finite number.\n *\n * @static\n * @memberOf _\n * @since 4.12.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted number.\n * @example\n *\n * _.toFinite(3.2);\n * // => 3.2\n *\n * _.toFinite(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toFinite(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toFinite('3.2');\n * // => 3.2\n */\nfunction toFinite(value) {\n  if (!value) {\n    return value === 0 ? value : 0;\n  }\n  value = toNumber(value);\n  if (value === INFINITY || value === -INFINITY) {\n    var sign = (value < 0 ? -1 : 1);\n    return sign * MAX_INTEGER;\n  }\n  return value === value ? value : 0;\n}\n\nexport default toFinite;\n","import toFinite from './toFinite.js';\n\n/**\n * Converts `value` to an integer.\n *\n * **Note:** This method is loosely based on\n * [`ToInteger`](http://www.ecma-international.org/ecma-262/7.0/#sec-tointeger).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted integer.\n * @example\n *\n * _.toInteger(3.2);\n * // => 3\n *\n * _.toInteger(Number.MIN_VALUE);\n * // => 0\n *\n * _.toInteger(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toInteger('3.2');\n * // => 3\n */\nfunction toInteger(value) {\n  var result = toFinite(value),\n      remainder = result % 1;\n\n  return result === result ? (remainder ? result - remainder : result) : 0;\n}\n\nexport default toInteger;\n","// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n","\"use strict\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.CancellationTokenSource = exports.CancellationToken = void 0;\nconst ral_1 = require(\"./ral\");\nconst Is = require(\"./is\");\nconst events_1 = require(\"./events\");\nvar CancellationToken;\n(function (CancellationToken) {\n    CancellationToken.None = Object.freeze({\n        isCancellationRequested: false,\n        onCancellationRequested: events_1.Event.None\n    });\n    CancellationToken.Cancelled = Object.freeze({\n        isCancellationRequested: true,\n        onCancellationRequested: events_1.Event.None\n    });\n    function is(value) {\n        const candidate = value;\n        return candidate && (candidate === CancellationToken.None\n            || candidate === CancellationToken.Cancelled\n            || (Is.boolean(candidate.isCancellationRequested) && !!candidate.onCancellationRequested));\n    }\n    CancellationToken.is = is;\n})(CancellationToken || (exports.CancellationToken = CancellationToken = {}));\nconst shortcutEvent = Object.freeze(function (callback, context) {\n    const handle = (0, ral_1.default)().timer.setTimeout(callback.bind(context), 0);\n    return { dispose() { handle.dispose(); } };\n});\nclass MutableToken {\n    constructor() {\n        this._isCancelled = false;\n    }\n    cancel() {\n        if (!this._isCancelled) {\n            this._isCancelled = true;\n            if (this._emitter) {\n                this._emitter.fire(undefined);\n                this.dispose();\n            }\n        }\n    }\n    get isCancellationRequested() {\n        return this._isCancelled;\n    }\n    get onCancellationRequested() {\n        if (this._isCancelled) {\n            return shortcutEvent;\n        }\n        if (!this._emitter) {\n            this._emitter = new events_1.Emitter();\n        }\n        return this._emitter.event;\n    }\n    dispose() {\n        if (this._emitter) {\n            this._emitter.dispose();\n            this._emitter = undefined;\n        }\n    }\n}\nclass CancellationTokenSource {\n    get token() {\n        if (!this._token) {\n            // be lazy and create the token only when\n            // actually needed\n            this._token = new MutableToken();\n        }\n        return this._token;\n    }\n    cancel() {\n        if (!this._token) {\n            // save an object by returning the default\n            // cancelled token when cancellation happens\n            // before someone asks for the token\n            this._token = CancellationToken.Cancelled;\n        }\n        else {\n            this._token.cancel();\n        }\n    }\n    dispose() {\n        if (!this._token) {\n            // ensure to initialize with an empty token if we had none\n            this._token = CancellationToken.None;\n        }\n        else if (this._token instanceof MutableToken) {\n            // actually dispose\n            this._token.dispose();\n        }\n    }\n}\nexports.CancellationTokenSource = CancellationTokenSource;\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Emitter = exports.Event = void 0;\nconst ral_1 = require(\"./ral\");\nvar Event;\n(function (Event) {\n    const _disposable = { dispose() { } };\n    Event.None = function () { return _disposable; };\n})(Event || (exports.Event = Event = {}));\nclass CallbackList {\n    add(callback, context = null, bucket) {\n        if (!this._callbacks) {\n            this._callbacks = [];\n            this._contexts = [];\n        }\n        this._callbacks.push(callback);\n        this._contexts.push(context);\n        if (Array.isArray(bucket)) {\n            bucket.push({ dispose: () => this.remove(callback, context) });\n        }\n    }\n    remove(callback, context = null) {\n        if (!this._callbacks) {\n            return;\n        }\n        let foundCallbackWithDifferentContext = false;\n        for (let i = 0, len = this._callbacks.length; i < len; i++) {\n            if (this._callbacks[i] === callback) {\n                if (this._contexts[i] === context) {\n                    // callback & context match => remove it\n                    this._callbacks.splice(i, 1);\n                    this._contexts.splice(i, 1);\n                    return;\n                }\n                else {\n                    foundCallbackWithDifferentContext = true;\n                }\n            }\n        }\n        if (foundCallbackWithDifferentContext) {\n            throw new Error('When adding a listener with a context, you should remove it with the same context');\n        }\n    }\n    invoke(...args) {\n        if (!this._callbacks) {\n            return [];\n        }\n        const ret = [], callbacks = this._callbacks.slice(0), contexts = this._contexts.slice(0);\n        for (let i = 0, len = callbacks.length; i < len; i++) {\n            try {\n                ret.push(callbacks[i].apply(contexts[i], args));\n            }\n            catch (e) {\n                // eslint-disable-next-line no-console\n                (0, ral_1.default)().console.error(e);\n            }\n        }\n        return ret;\n    }\n    isEmpty() {\n        return !this._callbacks || this._callbacks.length === 0;\n    }\n    dispose() {\n        this._callbacks = undefined;\n        this._contexts = undefined;\n    }\n}\nclass Emitter {\n    constructor(_options) {\n        this._options = _options;\n    }\n    /**\n     * For the public to allow to subscribe\n     * to events from this Emitter\n     */\n    get event() {\n        if (!this._event) {\n            this._event = (listener, thisArgs, disposables) => {\n                if (!this._callbacks) {\n                    this._callbacks = new CallbackList();\n                }\n                if (this._options && this._options.onFirstListenerAdd && this._callbacks.isEmpty()) {\n                    this._options.onFirstListenerAdd(this);\n                }\n                this._callbacks.add(listener, thisArgs);\n                const result = {\n                    dispose: () => {\n                        if (!this._callbacks) {\n                            // disposable is disposed after emitter is disposed.\n                            return;\n                        }\n                        this._callbacks.remove(listener, thisArgs);\n                        result.dispose = Emitter._noop;\n                        if (this._options && this._options.onLastListenerRemove && this._callbacks.isEmpty()) {\n                            this._options.onLastListenerRemove(this);\n                        }\n                    }\n                };\n                if (Array.isArray(disposables)) {\n                    disposables.push(result);\n                }\n                return result;\n            };\n        }\n        return this._event;\n    }\n    /**\n     * To be kept private to fire an event to\n     * subscribers\n     */\n    fire(event) {\n        if (this._callbacks) {\n            this._callbacks.invoke.call(this._callbacks, event);\n        }\n    }\n    dispose() {\n        if (this._callbacks) {\n            this._callbacks.dispose();\n            this._callbacks = undefined;\n        }\n    }\n}\nexports.Emitter = Emitter;\nEmitter._noop = function () { };\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.stringArray = exports.array = exports.func = exports.error = exports.number = exports.string = exports.boolean = void 0;\nfunction boolean(value) {\n    return value === true || value === false;\n}\nexports.boolean = boolean;\nfunction string(value) {\n    return typeof value === 'string' || value instanceof String;\n}\nexports.string = string;\nfunction number(value) {\n    return typeof value === 'number' || value instanceof Number;\n}\nexports.number = number;\nfunction error(value) {\n    return value instanceof Error;\n}\nexports.error = error;\nfunction func(value) {\n    return typeof value === 'function';\n}\nexports.func = func;\nfunction array(value) {\n    return Array.isArray(value);\n}\nexports.array = array;\nfunction stringArray(value) {\n    return array(value) && value.every(elem => string(elem));\n}\nexports.stringArray = stringArray;\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nlet _ral;\nfunction RAL() {\n    if (_ral === undefined) {\n        throw new Error(`No runtime abstraction layer installed`);\n    }\n    return _ral;\n}\n(function (RAL) {\n    function install(ral) {\n        if (ral === undefined) {\n            throw new Error(`No runtime abstraction layer provided`);\n        }\n        _ral = ral;\n    }\n    RAL.install = install;\n})(RAL || (RAL = {}));\nexports.default = RAL;\n","var LIB;(()=>{\"use strict\";var t={470:t=>{function e(t){if(\"string\"!=typeof t)throw new TypeError(\"Path must be a string. Received \"+JSON.stringify(t))}function r(t,e){for(var r,n=\"\",i=0,o=-1,s=0,h=0;h<=t.length;++h){if(h<t.length)r=t.charCodeAt(h);else{if(47===r)break;r=47}if(47===r){if(o===h-1||1===s);else if(o!==h-1&&2===s){if(n.length<2||2!==i||46!==n.charCodeAt(n.length-1)||46!==n.charCodeAt(n.length-2))if(n.length>2){var a=n.lastIndexOf(\"/\");if(a!==n.length-1){-1===a?(n=\"\",i=0):i=(n=n.slice(0,a)).length-1-n.lastIndexOf(\"/\"),o=h,s=0;continue}}else if(2===n.length||1===n.length){n=\"\",i=0,o=h,s=0;continue}e&&(n.length>0?n+=\"/..\":n=\"..\",i=2)}else n.length>0?n+=\"/\"+t.slice(o+1,h):n=t.slice(o+1,h),i=h-o-1;o=h,s=0}else 46===r&&-1!==s?++s:s=-1}return n}var n={resolve:function(){for(var t,n=\"\",i=!1,o=arguments.length-1;o>=-1&&!i;o--){var s;o>=0?s=arguments[o]:(void 0===t&&(t=process.cwd()),s=t),e(s),0!==s.length&&(n=s+\"/\"+n,i=47===s.charCodeAt(0))}return n=r(n,!i),i?n.length>0?\"/\"+n:\"/\":n.length>0?n:\".\"},normalize:function(t){if(e(t),0===t.length)return\".\";var n=47===t.charCodeAt(0),i=47===t.charCodeAt(t.length-1);return 0!==(t=r(t,!n)).length||n||(t=\".\"),t.length>0&&i&&(t+=\"/\"),n?\"/\"+t:t},isAbsolute:function(t){return e(t),t.length>0&&47===t.charCodeAt(0)},join:function(){if(0===arguments.length)return\".\";for(var t,r=0;r<arguments.length;++r){var i=arguments[r];e(i),i.length>0&&(void 0===t?t=i:t+=\"/\"+i)}return void 0===t?\".\":n.normalize(t)},relative:function(t,r){if(e(t),e(r),t===r)return\"\";if((t=n.resolve(t))===(r=n.resolve(r)))return\"\";for(var i=1;i<t.length&&47===t.charCodeAt(i);++i);for(var o=t.length,s=o-i,h=1;h<r.length&&47===r.charCodeAt(h);++h);for(var a=r.length-h,c=s<a?s:a,f=-1,u=0;u<=c;++u){if(u===c){if(a>c){if(47===r.charCodeAt(h+u))return r.slice(h+u+1);if(0===u)return r.slice(h+u)}else s>c&&(47===t.charCodeAt(i+u)?f=u:0===u&&(f=0));break}var l=t.charCodeAt(i+u);if(l!==r.charCodeAt(h+u))break;47===l&&(f=u)}var g=\"\";for(u=i+f+1;u<=o;++u)u!==o&&47!==t.charCodeAt(u)||(0===g.length?g+=\"..\":g+=\"/..\");return g.length>0?g+r.slice(h+f):(h+=f,47===r.charCodeAt(h)&&++h,r.slice(h))},_makeLong:function(t){return t},dirname:function(t){if(e(t),0===t.length)return\".\";for(var r=t.charCodeAt(0),n=47===r,i=-1,o=!0,s=t.length-1;s>=1;--s)if(47===(r=t.charCodeAt(s))){if(!o){i=s;break}}else o=!1;return-1===i?n?\"/\":\".\":n&&1===i?\"//\":t.slice(0,i)},basename:function(t,r){if(void 0!==r&&\"string\"!=typeof r)throw new TypeError('\"ext\" argument must be a string');e(t);var n,i=0,o=-1,s=!0;if(void 0!==r&&r.length>0&&r.length<=t.length){if(r.length===t.length&&r===t)return\"\";var h=r.length-1,a=-1;for(n=t.length-1;n>=0;--n){var c=t.charCodeAt(n);if(47===c){if(!s){i=n+1;break}}else-1===a&&(s=!1,a=n+1),h>=0&&(c===r.charCodeAt(h)?-1==--h&&(o=n):(h=-1,o=a))}return i===o?o=a:-1===o&&(o=t.length),t.slice(i,o)}for(n=t.length-1;n>=0;--n)if(47===t.charCodeAt(n)){if(!s){i=n+1;break}}else-1===o&&(s=!1,o=n+1);return-1===o?\"\":t.slice(i,o)},extname:function(t){e(t);for(var r=-1,n=0,i=-1,o=!0,s=0,h=t.length-1;h>=0;--h){var a=t.charCodeAt(h);if(47!==a)-1===i&&(o=!1,i=h+1),46===a?-1===r?r=h:1!==s&&(s=1):-1!==r&&(s=-1);else if(!o){n=h+1;break}}return-1===r||-1===i||0===s||1===s&&r===i-1&&r===n+1?\"\":t.slice(r,i)},format:function(t){if(null===t||\"object\"!=typeof t)throw new TypeError('The \"pathObject\" argument must be of type Object. Received type '+typeof t);return function(t,e){var r=e.dir||e.root,n=e.base||(e.name||\"\")+(e.ext||\"\");return r?r===e.root?r+n:r+\"/\"+n:n}(0,t)},parse:function(t){e(t);var r={root:\"\",dir:\"\",base:\"\",ext:\"\",name:\"\"};if(0===t.length)return r;var n,i=t.charCodeAt(0),o=47===i;o?(r.root=\"/\",n=1):n=0;for(var s=-1,h=0,a=-1,c=!0,f=t.length-1,u=0;f>=n;--f)if(47!==(i=t.charCodeAt(f)))-1===a&&(c=!1,a=f+1),46===i?-1===s?s=f:1!==u&&(u=1):-1!==s&&(u=-1);else if(!c){h=f+1;break}return-1===s||-1===a||0===u||1===u&&s===a-1&&s===h+1?-1!==a&&(r.base=r.name=0===h&&o?t.slice(1,a):t.slice(h,a)):(0===h&&o?(r.name=t.slice(1,s),r.base=t.slice(1,a)):(r.name=t.slice(h,s),r.base=t.slice(h,a)),r.ext=t.slice(s,a)),h>0?r.dir=t.slice(0,h-1):o&&(r.dir=\"/\"),r},sep:\"/\",delimiter:\":\",win32:null,posix:null};n.posix=n,t.exports=n}},e={};function r(n){var i=e[n];if(void 0!==i)return i.exports;var o=e[n]={exports:{}};return t[n](o,o.exports,r),o.exports}r.d=(t,e)=>{for(var n in e)r.o(e,n)&&!r.o(t,n)&&Object.defineProperty(t,n,{enumerable:!0,get:e[n]})},r.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),r.r=t=>{\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(t,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(t,\"__esModule\",{value:!0})};var n={};(()=>{let t;if(r.r(n),r.d(n,{URI:()=>f,Utils:()=>P}),\"object\"==typeof process)t=\"win32\"===process.platform;else if(\"object\"==typeof navigator){let e=navigator.userAgent;t=e.indexOf(\"Windows\")>=0}const e=/^\\w[\\w\\d+.-]*$/,i=/^\\//,o=/^\\/\\//;function s(t,r){if(!t.scheme&&r)throw new Error(`[UriError]: Scheme is missing: {scheme: \"\", authority: \"${t.authority}\", path: \"${t.path}\", query: \"${t.query}\", fragment: \"${t.fragment}\"}`);if(t.scheme&&!e.test(t.scheme))throw new Error(\"[UriError]: Scheme contains illegal characters.\");if(t.path)if(t.authority){if(!i.test(t.path))throw new Error('[UriError]: If a URI contains an authority component, then the path component must either be empty or begin with a slash (\"/\") character')}else if(o.test(t.path))throw new Error('[UriError]: If a URI does not contain an authority component, then the path cannot begin with two slash characters (\"//\")')}const h=\"\",a=\"/\",c=/^(([^:/?#]+?):)?(\\/\\/([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?/;class f{static isUri(t){return t instanceof f||!!t&&\"string\"==typeof t.authority&&\"string\"==typeof t.fragment&&\"string\"==typeof t.path&&\"string\"==typeof t.query&&\"string\"==typeof t.scheme&&\"string\"==typeof t.fsPath&&\"function\"==typeof t.with&&\"function\"==typeof t.toString}scheme;authority;path;query;fragment;constructor(t,e,r,n,i,o=!1){\"object\"==typeof t?(this.scheme=t.scheme||h,this.authority=t.authority||h,this.path=t.path||h,this.query=t.query||h,this.fragment=t.fragment||h):(this.scheme=function(t,e){return t||e?t:\"file\"}(t,o),this.authority=e||h,this.path=function(t,e){switch(t){case\"https\":case\"http\":case\"file\":e?e[0]!==a&&(e=a+e):e=a}return e}(this.scheme,r||h),this.query=n||h,this.fragment=i||h,s(this,o))}get fsPath(){return m(this,!1)}with(t){if(!t)return this;let{scheme:e,authority:r,path:n,query:i,fragment:o}=t;return void 0===e?e=this.scheme:null===e&&(e=h),void 0===r?r=this.authority:null===r&&(r=h),void 0===n?n=this.path:null===n&&(n=h),void 0===i?i=this.query:null===i&&(i=h),void 0===o?o=this.fragment:null===o&&(o=h),e===this.scheme&&r===this.authority&&n===this.path&&i===this.query&&o===this.fragment?this:new l(e,r,n,i,o)}static parse(t,e=!1){const r=c.exec(t);return r?new l(r[2]||h,C(r[4]||h),C(r[5]||h),C(r[7]||h),C(r[9]||h),e):new l(h,h,h,h,h)}static file(e){let r=h;if(t&&(e=e.replace(/\\\\/g,a)),e[0]===a&&e[1]===a){const t=e.indexOf(a,2);-1===t?(r=e.substring(2),e=a):(r=e.substring(2,t),e=e.substring(t)||a)}return new l(\"file\",r,e,h,h)}static from(t){const e=new l(t.scheme,t.authority,t.path,t.query,t.fragment);return s(e,!0),e}toString(t=!1){return y(this,t)}toJSON(){return this}static revive(t){if(t){if(t instanceof f)return t;{const e=new l(t);return e._formatted=t.external,e._fsPath=t._sep===u?t.fsPath:null,e}}return t}}const u=t?1:void 0;class l extends f{_formatted=null;_fsPath=null;get fsPath(){return this._fsPath||(this._fsPath=m(this,!1)),this._fsPath}toString(t=!1){return t?y(this,!0):(this._formatted||(this._formatted=y(this,!1)),this._formatted)}toJSON(){const t={$mid:1};return this._fsPath&&(t.fsPath=this._fsPath,t._sep=u),this._formatted&&(t.external=this._formatted),this.path&&(t.path=this.path),this.scheme&&(t.scheme=this.scheme),this.authority&&(t.authority=this.authority),this.query&&(t.query=this.query),this.fragment&&(t.fragment=this.fragment),t}}const g={58:\"%3A\",47:\"%2F\",63:\"%3F\",35:\"%23\",91:\"%5B\",93:\"%5D\",64:\"%40\",33:\"%21\",36:\"%24\",38:\"%26\",39:\"%27\",40:\"%28\",41:\"%29\",42:\"%2A\",43:\"%2B\",44:\"%2C\",59:\"%3B\",61:\"%3D\",32:\"%20\"};function d(t,e,r){let n,i=-1;for(let o=0;o<t.length;o++){const s=t.charCodeAt(o);if(s>=97&&s<=122||s>=65&&s<=90||s>=48&&s<=57||45===s||46===s||95===s||126===s||e&&47===s||r&&91===s||r&&93===s||r&&58===s)-1!==i&&(n+=encodeURIComponent(t.substring(i,o)),i=-1),void 0!==n&&(n+=t.charAt(o));else{void 0===n&&(n=t.substr(0,o));const e=g[s];void 0!==e?(-1!==i&&(n+=encodeURIComponent(t.substring(i,o)),i=-1),n+=e):-1===i&&(i=o)}}return-1!==i&&(n+=encodeURIComponent(t.substring(i))),void 0!==n?n:t}function p(t){let e;for(let r=0;r<t.length;r++){const n=t.charCodeAt(r);35===n||63===n?(void 0===e&&(e=t.substr(0,r)),e+=g[n]):void 0!==e&&(e+=t[r])}return void 0!==e?e:t}function m(e,r){let n;return n=e.authority&&e.path.length>1&&\"file\"===e.scheme?`//${e.authority}${e.path}`:47===e.path.charCodeAt(0)&&(e.path.charCodeAt(1)>=65&&e.path.charCodeAt(1)<=90||e.path.charCodeAt(1)>=97&&e.path.charCodeAt(1)<=122)&&58===e.path.charCodeAt(2)?r?e.path.substr(1):e.path[1].toLowerCase()+e.path.substr(2):e.path,t&&(n=n.replace(/\\//g,\"\\\\\")),n}function y(t,e){const r=e?p:d;let n=\"\",{scheme:i,authority:o,path:s,query:h,fragment:c}=t;if(i&&(n+=i,n+=\":\"),(o||\"file\"===i)&&(n+=a,n+=a),o){let t=o.indexOf(\"@\");if(-1!==t){const e=o.substr(0,t);o=o.substr(t+1),t=e.lastIndexOf(\":\"),-1===t?n+=r(e,!1,!1):(n+=r(e.substr(0,t),!1,!1),n+=\":\",n+=r(e.substr(t+1),!1,!0)),n+=\"@\"}o=o.toLowerCase(),t=o.lastIndexOf(\":\"),-1===t?n+=r(o,!1,!0):(n+=r(o.substr(0,t),!1,!0),n+=o.substr(t))}if(s){if(s.length>=3&&47===s.charCodeAt(0)&&58===s.charCodeAt(2)){const t=s.charCodeAt(1);t>=65&&t<=90&&(s=`/${String.fromCharCode(t+32)}:${s.substr(3)}`)}else if(s.length>=2&&58===s.charCodeAt(1)){const t=s.charCodeAt(0);t>=65&&t<=90&&(s=`${String.fromCharCode(t+32)}:${s.substr(2)}`)}n+=r(s,!0,!1)}return h&&(n+=\"?\",n+=r(h,!1,!1)),c&&(n+=\"#\",n+=e?c:d(c,!1,!1)),n}function v(t){try{return decodeURIComponent(t)}catch{return t.length>3?t.substr(0,3)+v(t.substr(3)):t}}const b=/(%[0-9A-Za-z][0-9A-Za-z])+/g;function C(t){return t.match(b)?t.replace(b,(t=>v(t))):t}var A=r(470);const w=A.posix||A,x=\"/\";var P;!function(t){t.joinPath=function(t,...e){return t.with({path:w.join(t.path,...e)})},t.resolvePath=function(t,...e){let r=t.path,n=!1;r[0]!==x&&(r=x+r,n=!0);let i=w.resolve(r,...e);return n&&i[0]===x&&!t.authority&&(i=i.substring(1)),t.with({path:i})},t.dirname=function(t){if(0===t.path.length||t.path===x)return t;let e=w.dirname(t.path);return 1===e.length&&46===e.charCodeAt(0)&&(e=\"\"),t.with({path:e})},t.basename=function(t){return w.basename(t.path)},t.extname=function(t){return w.extname(t.path)}}(P||(P={}))})(),LIB=n})();export const{URI,Utils}=LIB;\n//# sourceMappingURL=index.mjs.map"],"names":[],"sourceRoot":""}